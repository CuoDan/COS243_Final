{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_parse import LlamaParse\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup LLM with Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LLAMACLOUD_API_KEY = os.getenv(\"LLAMACLOUD_API_KEY\")\n",
    "\n",
    "llm = Ollama(model=\"phi3.5:3.8b-mini-instruct-q8_0\", api_key=\"OLLAMA_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Settings Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload and Import ebooks function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 15:36:57.737 python[86799:21872050] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-11-27 15:36:58.002 python[86799:21872050] The class 'NSOpenPanel' overrides the method identifier.  This method is implemented by class 'NSWindow'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ebook content imported successfully to data/Linear-Algebra.pdf.txt.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from ebooklib import epub\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def upload_and_import_ebook(file_path=None, save_directory=\"data\"):\n",
    "    # Create a Tkinter root window\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the root window\n",
    "\n",
    "    # Open a file dialog to select an ebook or PDF file if no file path is provided\n",
    "    if not file_path:\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Select an Ebook or PDF\",\n",
    "            filetypes=[(\"Ebook and PDF Files\", \"*.epub *.pdf\")]\n",
    "        )\n",
    "\n",
    "    if file_path:\n",
    "        content = \"\"\n",
    "        file_extension = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "        if file_extension == \".epub\":\n",
    "            # Load the ebook\n",
    "            book = epub.read_epub(file_path)\n",
    "            \n",
    "            # Extract the content\n",
    "            for item in book.get_items():\n",
    "                if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "                    content += item.get_body_content().decode('utf-8')\n",
    "        \n",
    "        elif file_extension == \".pdf\":\n",
    "            # Load the PDF\n",
    "            pdf_document = fitz.open(file_path)\n",
    "            \n",
    "            # Extract the content\n",
    "            for page_num in range(pdf_document.page_count):\n",
    "                page = pdf_document.load_page(page_num)\n",
    "                content += page.get_text()\n",
    "\n",
    "        # Ensure the save directory exists\n",
    "        os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "        # Save the content to a file in the save directory\n",
    "        save_path = os.path.join(save_directory, os.path.basename(file_path) + \".txt\")\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "        return save_path\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example usage with file dialog\n",
    "ebook_path = upload_and_import_ebook()\n",
    "if ebook_path:\n",
    "    print(f\"Ebook content imported successfully to {ebook_path}.\")\n",
    "else:\n",
    "    print(\"No ebook or PDF selected.\")\n",
    "\n",
    "# Example usage with file path\n",
    "# ebook_path = upload_and_import_ebook(\"path/to/your/ebook_or_pdf.epub\")\n",
    "# if ebook_path:\n",
    "#     print(f\"Ebook content imported successfully to {ebook_path}.\")\n",
    "# else:\n",
    "#     print(\"Invalid file path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = SimpleDirectoryReader(input_files=[ebook_path]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced RAG (Routing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(docs)\n",
    "query_engine = index.as_query_engine(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "vector_tool = QueryEngineTool(\n",
    "    index.as_query_engine(),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"vector_search\",\n",
    "        description=\"Useful for searching for specific facts.\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "summary_tool = QueryEngineTool(\n",
    "    index.as_query_engine(response_mode=\"tree_summarize\"),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"summary\",\n",
    "        description=\"Useful for summarizing an entire document.\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "\n",
    "query_engine = RouterQueryEngine.from_defaults(\n",
    "    [vector_tool, summary_tool], select_multi=False, verbose=True, llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: When looking to understand specific details about Elementary Matrixes, using a resource that is useful for searching for specific facts would be most relevant. This allows one to find precise information and data points regarding elementary matrix properties, operations, or examples..\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Tell me about the specific details about Elementary Matrixes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementary matrices play a crucial role in linear algebra when it comes to manipulating other types of matrices through row operations. These particular kinds of square matrices are derived from standard identity matrices by performing one elementary operation, such as swapping two rows or multiplying a row by a non-zero scalar and adding it to another row.\n",
      "\n",
      "Elementary matrix transformations form the foundation for more complex processes like Gaussian elimination—an essential method used in solving systems of linear equations represented within rectangular arrays known as matrices. These transformation procedures not only aid problem solvers but are also pivotal when programming computers, which excel at handling numerical data stored or processed through such array structures.\n",
      "\n",
      "In the context provided earlier, there is a reference to elementary matrix operations being part of finding an inverse for given linear equations and their associated systems. This ties into broader concepts like inverses; algebraic properties of matrices—all essential components within the field known as \"linear algebra.\" However, specific details about how these transformations are performed or used beyond this general overview have not been provided directly from your excerpt but can be inferred based on their importance and relationship with other matrix operations.\n",
      "\n",
      "To gain more insight into elementary matrices' intricacies—such as the exact nature of row swaps, scalar multiplication/addition procedures, implications for invertibility, or proofs concerning certain conditions that must hold true (like non-invertible cases in a given context) —one would typically consult specialized mathematical texts on linear algebra. The discussion also hints at practical applications like network analysis and electrical circuits where these matrix transformations can be utilized to find solutions representing various systems' behaviors or states, illustrating the broad utility of elementary matrices beyond theoretical exercises alone.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat History to RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "\n",
    "chat_engine = CondensePlusContextChatEngine.from_defaults(\n",
    "    index.as_retriever(),\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \"You are a chatbot, able to have normal interactions, as well as talk\"\n",
    "        \" about the Kendrick and Drake beef.\"\n",
    "        \"Here are the relevant documents for the context:\\n\"\n",
    "        \"{context_str}\"\n",
    "        \"\\nInstruction: Use the previous chat history, or the context above, to interact and help the user.\"\n",
    "    ),\n",
    "    verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COS243_Final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
