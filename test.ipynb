{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_parse import LlamaParse\n",
    "import json\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup LLM with Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "LLAMACLOUD_API_KEY = os.getenv(\"LLAMACLOUD_API_KEY\")\n",
    "\n",
    "llm = Ollama(model=\"phi3.5:3.8b-mini-instruct-q8_0\", api_key=\"OLLAMA_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload and Import ebooks function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ebook or PDF selected.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from ebooklib import epub\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def upload_and_import_ebook(file_path=None, save_directory=\"data\"):\n",
    "    # Create a Tkinter root window\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the root window\n",
    "\n",
    "    # Open a file dialog to select an ebook or PDF file if no file path is provided\n",
    "    if not file_path:\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Select an Ebook or PDF\",\n",
    "            filetypes=[(\"Ebook and PDF Files\", \"*.epub *.pdf\")]\n",
    "        )\n",
    "\n",
    "    if file_path:\n",
    "        content = \"\"\n",
    "        file_extension = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "        if file_extension == \".epub\":\n",
    "            # Load the ebook\n",
    "            book = epub.read_epub(file_path)\n",
    "            \n",
    "            # Extract the content\n",
    "            for item in book.get_items():\n",
    "                if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "                    content += item.get_body_content().decode('utf-8')\n",
    "        \n",
    "        elif file_extension == \".pdf\":\n",
    "            # Load the PDF\n",
    "            pdf_document = fitz.open(file_path)\n",
    "            \n",
    "            # Extract the content\n",
    "            for page_num in range(pdf_document.page_count):\n",
    "                page = pdf_document.load_page(page_num)\n",
    "                content += page.get_text()\n",
    "\n",
    "        # Ensure the save directory exists\n",
    "        os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "        # Save the content to a file in the save directory\n",
    "        save_path = os.path.join(save_directory, os.path.basename(file_path) + \".txt\")\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "        return save_path\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example usage with file dialog\n",
    "ebook_path = upload_and_import_ebook()\n",
    "if ebook_path:\n",
    "    print(f\"Ebook content imported successfully to {ebook_path}.\")\n",
    "else:\n",
    "    print(\"No ebook or PDF selected.\")\n",
    "\n",
    "# Example usage with file path\n",
    "# ebook_path = upload_and_import_ebook(\"path/to/your/ebook_or_pdf.epub\")\n",
    "# if ebook_path:\n",
    "#     print(f\"Ebook content imported successfully to {ebook_path}.\")\n",
    "# else:\n",
    "#     print(\"Invalid file path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ebook_path:\n",
    "    docs = SimpleDirectoryReader(input_files=[ebook_path]).load_data()\n",
    "else:\n",
    "    ebook_path = \"sample_books/The Theory That Would Not Die How Bayes Rule Cracked the Enigma Code, Hunted Down Russian Submarines, and Emerged Triumphant from Two Centuries of Controversy by Sharon Bertsch McGrayne.pdf.txt\"\n",
    "    docs = SimpleDirectoryReader(input_files=[ebook_path]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id_='305cb8cb-c674-40ed-ba90-6ca501903a52', embedding=None, metadata={'file_path': 'sample_books/The Theory That Would Not Die How Bayes Rule Cracked the Enigma Code, Hunted Down Russian Submarines, and Emerged Triumphant from Two Centuries of Controversy by Sharon Bertsch McGrayne.pdf.txt', 'file_name': 'The Theory That Would Not Die How Bayes Rule Cracked the Enigma Code, Hunted Down Russian Submarines, and Emerged Triumphant from Two Centuries of Controversy by Sharon Bertsch McGrayne.pdf.txt', 'file_type': 'text/plain', 'file_size': 781759, 'creation_date': '2024-12-09', 'last_modified_date': '2024-12-04'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='the theory that would not die\\n \\nother books by\\nsharon bertsch mcgrayne\\n \\nPrometheans in the Lab: Chemistry and the Making\\nof the Modern World\\n \\nIron, Nature’s Universal Element: Why People Need\\nIron and Animals Make Magnets (with Eugenie V.\\nMielczarek)\\n \\nNobel Prize Women in Science: Their Lives, Struggles,\\nand Momentous Discoveries\\n \\nthe theory that would not die\\n \\nhow bayes’ rule cracked\\nthe enigma code,\\nhunted down russian\\nsubmarines, & emerged\\ntriumphant from two\\ncenturies of controversy\\nsharon bertsch mcgrayne\\n \\n“The Doctor sees the light” by Michael Campbell is reproduced by\\npermission of John Wiley & Sons; the lyrics by George E. P. Box in chapter\\n10 are reproduced by permission of John Wiley & Sons; the conversation\\nbetween Sir Harold Jeffreys and D. V. Lindley in chapter 3 is reproduced by\\npermission of the Master and Fellows of St. John’s College, Cambridge.\\nCopyright © 2011 by Sharon Bertsch McGrayne. All rights reserved. This\\nbook may not be reproduced, in whole or in part, including illustrations, in\\nany form (beyond that copying permitted by Sections 107 and 108 of the U.S.\\nCopyright Law and except by reviewers for the public press), without\\nwritten permission from the publishers.\\nYale University Press books may be purchased in quantity for educational,\\nbusiness, \\nor \\npromotional \\nuse. \\nFor \\ninformation, \\nplease \\ne-mail\\nsales.press@yale.edu (U.S. office) or sales@yaleup.co.uk (U.K. office).\\nDesigned by Lindsey Voskowsky. Set in Monotype Joanna type by Duke &\\nCompany, Devon, Pennsylvania. Printed in the United States of America.\\nLibrary of Congress Cataloging-in-Publication Data\\nMcGrayne, Sharon Bertsch.\\nThe theory that would not die : how Bayes’ rule cracked the enigma code,\\nhunted down Russian submarines, and emerged triumphant from two\\ncenturies of controversy / Sharon Bertsch McGrayne.\\np. cm.\\nSummary: “Bayes’ rule appears to be a straightforward, one-line theorem:\\nby updating our initial beliefs with objective new information, we get a new\\nand improved belief. To its adherents, it is an elegant statement about\\nlearning from experience. To its opponents, it is subjectivity run amok. In the\\nfirst-ever account of Bayes’ rule for general readers, Sharon Bertsch\\nMcGrayne explores this controversial theorem and the human obsessions\\nsurrounding it. She traces its discovery by an amateur mathematician in the\\n1740s through its development into roughly its modern form by French\\nscientist Pierre Simon Laplace. She reveals why respected statisticians\\nrendered it professionally taboo for 150 years—at the same time that\\npractitioners relied on it to solve crises involving great uncertainty and\\nscanty information, even breaking Germany’s Enigma code during World War\\nII, and explains how the advent of off-the-shelf computer technology in the\\n1980s proved to be a game-changer. Today, Bayes’ rule is used everywhere\\nfrom DNA de-coding to Homeland Security. Drawing on primary source\\nmaterial and interviews with statisticians and other scientists, The Theory\\nThat Would Not Die is the riveting account of how a seemingly simple\\ntheorem ignited one of the greatest controversies of all time”—Provided by\\npublisher.\\nIncludes bibliographical references and index.\\nISBN 978-0-300-16969-0 (hardback)\\n1. Bayesian statistical decision theory—History. I. Title.\\nQA279.5.M415 2011\\n519.5’42—dc22\\n2010045037\\nA catalogue record for this book is available from the British Library.\\nThis paper meets the requirements of ANSI/NISO Z39.48–1992 (Permanence\\nof Paper).\\n10 9 8 7 6 5 4 3 2 1\\nWhen the facts change, I change my opinion. What do you do, sir?\\n—John Maynard Keynes\\n \\ncontents\\n \\nPreface and Note to Readers\\nAcknowledgments\\n \\nPart I. Enlightenment and the Anti-Bayesian Reaction\\n \\n1. Causes in the Air\\n \\n2. The Man Who Did Everything\\n \\n3. Many Doubts, Few Defenders\\n \\nPart II. Second World War Era\\n \\n4. Bayes Goes to War\\n \\n5. Dead and Buried Again\\n \\nPart III. The Glorious Revival\\n \\n6. Arthur Bailey\\n \\n7. From Tool to Theology\\n \\n8. Jerome Cornfield, Lung Cancer, and Heart Attacks\\n \\n9. There’s Always a First Time\\n \\n10. 46,656 Varieties\\n \\nPart IV. To Prove Its Worth\\n \\n11. Business Decisions\\n \\n12. Who Wrote The Federalist?\\n \\n13. The Cold Warrior\\n \\n14. Three Mile Island\\n \\n15. The Navy Searches\\n \\nPart V. Victory\\n \\n16. Eureka!\\n \\n17. Rosetta Stones\\n \\nAppendixes\\n \\nDr. Fisher’s Casebook\\n \\nApplying Bayes’ Rule to Mammograms and Breast Cancer\\n \\nNotes\\nGlossary\\nBibliography\\nIndex\\npreface and note to readers\\n \\nIn a celebrated example of science gone awry, geologists accumulated the\\nevidence for Continental Drift in 1912 and then spent 50 years arguing that\\ncontinents cannot move.\\nThe scientific battle over Bayes’ rule is less well known but lasted far\\nlonger, for 150 years. It concerned a broader and more fundamental issue:\\nhow we analyze evidence, change our minds as we get new information, and\\nmake rational decisions in the face of uncertainty. And it was not resolved\\nuntil the dawn of the twenty-first century.\\nOn its face Bayes’ rule is a simple, one-line theorem: by updating our\\ninitial belief about something with objective new information, we get a new\\nand improved belief. To its adherents, this is an elegant statement about\\nlearning from experience. Generations of converts remember experiencing an\\nalmost religious epiphany as they fell under the spell of its inner logic.\\nOpponents, meanwhile, regarded Bayes’ rule as subjectivity run amok.\\nBayes’ rule began life amid an inflammatory religious controversy in\\nEngland in the 1740s: can we make rational conclusions about God based on\\nevidence about the world around us? An amateur mathematician, the\\nReverend Thomas Bayes, discovered the rule, and we celebrate him today as\\nthe iconic father of mathematical decision making. Yet Bayes consigned his\\ndiscovery to oblivion. In his time, he was a minor figure. And we know\\nabout his work today only because of his friend and editor Richard Price, an\\nalmost forgotten hero of the American Revolution.\\nBy rights, Bayes’ rule should be named for someone else: a Frenchman,\\nPierre Simon Laplace, one of the most powerful mathematicians and\\nscientists in history. To deal with an unprecedented torrent of data, Laplace\\ndiscovered the rule on his own in 1774. Over the next forty years he\\ndeveloped it into the form we use today. Applying his method, he concluded\\nthat a well-established fact—more boys are born than girls—was almost\\ncertainly the result of natural law. Only historical convention forces us to call\\nLaplace’s discovery Bayes’ rule.\\nAfter Laplace’s death, researchers and academics seeking precise and\\nobjective answers pronounced his method subjective, dead, and buried. Yet\\nat the very same time practical problem solvers relied on it to deal with real-\\nworld emergencies. One spectacular success occurred during the Second\\nWorld War, when Alan Turing developed Bayes to break Enigma, the German\\nnavy’s secret code, and in the process helped to both save Britain and invent\\nmodern electronic computers and software. Other leading mathematical\\nthinkers—Andrei Kolmogorov in Russia and Claude Shannon in New York\\n—also rethought Bayes for wartime decision making.\\nDuring the years when ivory tower theorists thought they had rendered\\nBayes taboo, it helped start workers’ compensation insurance in the United\\nStates; save the Bell Telephone system from the financial panic of 1907;\\ndeliver Alfred Dreyfus from a French prison; direct Allied artillery fire and\\nlocate German U-boats; and locate earthquake epicenters and deduce\\n(erroneously) that Earth’s core consists of molten iron.\\nTheoretically, Bayes’ rule was verboten. But it could deal with all kinds\\nof data, whether copious or sparse. During the Cold War, Bayes helped find a\\nmissing H-bomb and U.S. and Russian submarines; investigate nuclear power\\nplant safety; predict the shuttle Challenger tragedy; demonstrate that smoking\\ncauses lung cancer and that high cholesterol causes heart attacks; predict\\npresidential winners on television’s most popular news program, and much\\nmore.\\nHow could otherwise rational scientists, mathematicians, and statisticians\\nbecome so obsessed about a theorem that their argument became, as one\\nobserver called it, a massive food fight? The answer is simple. At its heart,\\nBayes runs counter to the deeply held conviction that modern science\\nrequires objectivity and precision. Bayes is a measure of belief. And it says\\nthat we can learn even from missing and inadequate data, from\\napproximations, and from ignorance.\\nAs a result of this profound philosophical disagreement, Bayes’ rule is a\\nflesh-and-blood story about a small group of beleaguered believers who\\nstruggled for legitimacy and acceptance for most of the twentieth century. It’s\\nabout how the rule’s fate got entwined with the secrecy of the Second World\\nWar and the Cold War. It’s about a theorem in want of a computer and a\\nsoftware package. And it’s about a method that—refreshed by outsiders from\\nphysics, computer science, and artificial intelligence—was adopted almost\\novernight because suddenly it worked. In a new kind of paradigm shift for a\\npragmatic world, the man who had called Bayes “the crack cocaine of\\nstatistics. . . . seductive, addictive and ultimately destructive” began\\nrecruiting Bayesians for Google.\\nToday, Bayesian spam filters whisk pornographic and fraudulent e-mail to\\nour computers’ junk bins. When a ship sinks, the Coast Guard calls on Bayes\\nand locates shipwrecked survivors who may have floated at sea for weeks.\\nScientists discover how genes are controlled and regulated. Bayes even wins\\nNobel Prizes. Online, Bayes’ rule trawls the web and sells songs and films.\\nIt has penetrated computer science, artificial intelligence, machine learning,\\nWall Street, astronomy and physics, Homeland Security, Microsoft, and\\nGoogle. It helps computers translate one language into another, tearing down\\nthe world’s millennia-old Tower of Babel. It has become a metaphor for how\\nour brains learn and function. Prominent Bayesians even advise government\\nagencies on energy, education, and research.\\nBut Bayes’ rule is not just an obscure scientific controversy laid to rest. It\\naffects us all. It’s a logic for reasoning about the broad spectrum of life that\\nlies in the gray areas between absolute truth and total uncertainty. We often\\nhave information about only a small part of what we wonder about. Yet we\\nall want to predict something based on our past experiences; we change our\\nbeliefs as we acquire new information. After suffering years of passionate\\nscorn, Bayes has provided a way of thinking rationally about the world\\naround us.\\nThis is the story of how that remarkable transformation took place.\\nNote: Observant readers may notice that I use the word “probability” a lot in\\nthis book. In common speech, most of us treat the words “probability,”\\n“likelihood,” and “odds” interchangeably. In statistics, however, these terms\\nare not synonymous; they have distinct and technical meanings. Because I’ve\\ntried to use correct terminology in The Theory That Would Not Die,\\n“probability” appears quite a bit.\\nacknowledgments\\n \\nFor their scientific advice and perspective and for their patience with\\nsomeone who asked a multitude of questions, I am deeply indebted to Dennis\\nV. Lindley, Robert E. Kass, and George F. Bertsch. These three also read and\\nmade perceptive comments about the entire book in one or more of its many\\ndrafts. I could not have written the book at all without my husband, George\\nBertsch.\\nFor insightful guidance on various crucial threads of my narrative, I thank\\nJames O. Berger, David M. Blei, Bernard Bru, Andrew I. Dale, Arthur P.\\nDempster, Persi Diaconis, Bradley Efron, Stephen E. Fienberg, Stuart\\nGeman, Roger Hahn, Peter Hoff, Tom J. Loredo, Albert Madansky, John W.\\nPratt, Henry R. (“Tony”) Richardson, Christian P. Robert, Stephen M. Stigler,\\nand David L. Wallace.\\nMany other experts and specialists spoke with me, often at length, about\\nparticular eras, problems, details, or people. They include Capt. Frank A.\\nAndrews, Frank Anscombe, George Apostolakis, Robert A. and Shirley\\nBailey, Friedrich L. Bauer, Robert T. Bell, David R. Bellhouse, Julian\\nBesag, Alan S. Blinder, George E. P. Box, David R. Brillinger, Bruce\\nBudowle, Hans Bühlmann, Frank Carter, Herman Chernoff, Juscelino F.\\nColares, Jack Copeland, Ann Cornfield, Ellen Cornfield, John Piña Craven,\\nLorraine Daston, Philip Dawid, Joseph H. Discenza, Ralph Erskine, Michael\\nFortunato, Karl Friston, Chris Frith, John (“Jack”) Frost, Dennis G. Fryback,\\nMitchell H. Gail, Alan E. Gelfand, Andrew Gelman, Edward I. George,\\nEdgar N. Gilbert, Paul M. Goggans, I. J. “Jack” Good, Steven N. Goodman,\\nJoel Greenhouse, Ulf Grenander, Gerald N. Grob, Thomas L. Hankins,\\nJeffrey E. Harris, W. Keith Hastings, David Heckerman, Charles C. Hewitt\\nJr., Ray Hilborn, David C. Hoaglin, Antje Hoering, Marvin Hoffenberg,\\nSusan P. Holmes, David Hounshell, Ronald H. Howard, David Howie,\\nBobby R. Hunt, Fred C. Iklé, David R. Jardini, William H. Jefferys, Douglas\\nM. Jesseph.\\nAlso, Michael I. Jordan, David Kahn, David H. Kaye, John G. King,\\nKenneth R. Koedinger, Daphne Koller, Tom Kratzke, James M. Landwehr,\\nBernard Lightman, Richard F. Link, Edward P. Loane, Michael C. Lovell,\\nThomas L. Marzetta, Scott H. Mathews, John McCullough, Richard F. Meyer,\\nGlenn G. Meyers, Paul J. Miranti Jr., Deputy Commander Dewitt Moody,\\nRear Admiral Brad Mooney, R. Bradford Murphy, John W. Negele, Vice\\nAdmiral John “Nick” Nicholson, Peter Norvig, Stephen M. Pollock,\\nTheodore M. Porter, Alexandre Pouget, S. James Press, Alan Rabinowitz,\\nAdrian E. Raftery, Howard Raiffa, John J. Rehr, John T. Riedl, Douglas\\nRivers, Oleg Sapozhnikov, Peter Schlaifer, Arthur Schleifer Jr., Michael N.\\nShadlen, Edward H. (“Ted”) Shortliffe, Edward H. Simpson, Harold C. Sox,\\nDavid J. Spiegelhalter, Robert F. Stambaugh, Lawrence D. Stone, William J.\\nTalbott, Judith Tanur, The Center for Defense Information, Sebastian Thrun,\\nOakley E. (Lee) Van Slyke, Gary G. Venter, Christopher Volinsky, Paul R.\\nWade, Jon Wakefield, Homer Warner, Frode Weierud, Robert B. Wilson,\\nWing H. Wong, Judith E. Zeh, and Arnold Zellner.\\nI would like to thank two outside reviewers, Jim Berger and Andrew\\nDale; both read the manuscript carefully and made useful comments to\\nimprove it.\\nSeveral friends and family members—Ruth Ann Bertsch, Cindy Vahey\\nBertsch, Fred Bertsch, Jean Colley, Genevra Gerhart, James Goodman,\\nCarolyn Keating, Timothy W. Keller, Sharon C. Rutberg, Beverly Schaefer,\\nand Audrey Jensen Weitkamp—made crucial comments. I owe thanks to the\\nmathematics library staff of the University of Washington. And my agent,\\nSusan Rabiner, and editor, William Frucht, were steadfast in their support.\\nDespite all this help, I am, of course, responsible for the errors in this\\nbook.\\npart I\\n \\nenlightenment \\nand \\nthe \\nanti-bayesian\\nreaction\\n \\n1.\\n \\ncauses in the air\\n \\nSometime during the 1740s, the Reverend Thomas Bayes made the ingenious\\ndiscovery that bears his name but then mysteriously abandoned it. It was\\nrediscovered independently by a different and far more renowned man,\\nPierre Simon Laplace, who gave it its modern mathematical form and\\nscientific application—and then moved on to other methods. Although Bayes’\\nrule drew the attention of the greatest statisticians of the twentieth century,\\nsome of them vilified both the method and its adherents, crushed it, and\\ndeclared it dead. Yet at the same time, it solved practical questions that were\\nunanswerable by any other means: the defenders of Captain Dreyfus used it\\nto demonstrate his innocence; insurance actuaries used it to set rates; Alan\\nTuring used it to decode the German Enigma cipher and arguably save the\\nAllies from losing the Second World War; the U.S. Navy used it to search for\\na missing H-bomb and to locate Soviet subs; RAND Corporation used it to\\nassess the likelihood of a nuclear accident; and Harvard and Chicago\\nresearchers used it to verify the authorship of the Federalist Papers. In\\ndiscovering its value for science, many supporters underwent a near-\\nreligious conversion yet had to conceal their use of Bayes’ rule and pretend\\nthey employed something else. It was not until the twenty-first century that the\\nmethod lost its stigma and was widely and enthusiastically embraced. The\\nstory began with a simple thought experiment.\\nBecause Bayes’ gravestone says he died in 1761 at the age of 59, we know\\nhe lived during England’s struggle to recover from nearly two centuries of\\nreligious strife, civil war, and regicide. As a member of the Presbyterian\\nChurch, a religious denomination persecuted for refusing to support the\\nChurch of England, he was considered a Dissenter or Non-Conformist.\\nDuring his grandfather’s generation, 2,000 Dissenters died in English\\nprisons. By Bayes’ time, mathematics was split along religious and political\\nlines, and many productive mathematicians were amateurs because, as\\nDissenters, they were barred from English universities.1\\nUnable to earn a degree in England, Bayes studied theology and\\npresumably mathematics at the University of Edinburgh in Presbyterian\\nScotland, where, happily for him, academic standards were much more\\nrigorous. In 1711 he left for London, where his clergyman father ordained\\nhim and apparently employed him as an assistant minister.\\nPersecution turned many English Dissenters into feisty critics, and in his\\nlate 20s Bayes took a stand on a hot theological issue: can the presence of\\nevil be reconciled with God’s presumed beneficence? In 1731 he wrote a\\npamphlet—a kind of blog—declaring that God gives people “the greatest\\nhappiness of which they are capable.”\\nDuring his 40s, Bayes’ interests in mathematics and theology began to\\ntightly intertwine. An Irish-Anglican bishop—George Berkeley, for whom\\nthe University of California’s flagship campus is named—published an\\ninflammatory pamphlet attacking Dissenting mathematicians, calculus,\\nabstract mathematics, the revered Isaac Newton, and all other “free-thinkers”\\nand “infidel mathematicians” who believed that reason could illuminate any\\nsubject. Berkeley’s pamphlet was the most spectacular event in British\\nmathematics during the 1700s.\\nLeaping into the pamphlet wars again, Bayes published a piece defending\\nand explaining Newton’s calculus. This was his only mathematical\\npublication during his lifetime. Shortly thereafter, in 1742, five men,\\nincluding a close friend of Newton’s, nominated Bayes for membership in the\\nRoyal Society. His nomination avoided any hint of controversy and described\\nhim as “a Gentleman of known merit, well skilled in Geometry and all parts\\nof Mathematical and Philosophical Learning.” The Royal Society was not the\\nprofessional organization it is today; it was a private organization of dues-\\npaying amateurs from the landed gentry. But it played a vital role because\\namateurs would produce some of the era’s breakthroughs.\\nAbout this time Bayes joined a second group of up-to-date amateur\\nmathematicians. He had moved to a small congregation in a fashionable\\nresort, the cold-water spa Tunbridge Wells. As an independently wealthy\\nbachelor—his family had made a fortune manufacturing Sheffield steel\\ncutlery—he rented rooms, apparently from a Dissenting family. His religious\\nduties—one Sunday sermon a week—were light. And spa etiquette permitted\\nDissenters, Jews, Roman Catholics, and even foreigners to mix with English\\nsociety, even with wealthy earls, as they could not elsewhere.\\nA frequent visitor to Tunbridge Wells, Philip, the Second Earl of\\nStanhope, had been passionately interested in mathematics since childhood,\\nbut his guardian had banned its study as insufficiently genteel. When\\nStanhope was 20 and free to do as he liked, he seldom raised his eyes from\\nEuclid. According to the bluestocking Elizabeth Montagu, Stanhope was\\n“always making mathematical scratches in his pocket-book, so that one half\\nthe people took him for a conjuror, and the other half for a fool.” Because of\\neither his aristocratic position or his late start Stanhope never published\\nanything of his own. Instead, he became England’s foremost patron of\\nmathematicians.\\nThe earl and the Royal Society’s energetic secretary, John Canton,\\noperated an informal network of peer reviewers who critiqued one another’s\\nwork. At some point Bayes joined the network. One day, for example,\\nStanhope sent Bayes a copy of a draft paper by a mathematician named\\nPatrick Murdoch. Bayes disagreed with some of it and sent his comments\\nback to Stanhope, who forwarded them to Murdoch, who in turn replied\\nthrough Stanhope, and so on around and around. The relationship between the\\nyoung earl and the older Reverend Bayes seems to have ripened into\\nfriendship, however, because Stanhope paid Bayes at least one personal visit\\nat Tunbridge Wells, saved two bundles of his mathematical papers in the\\nStanhope estate’s library, and even subscribed to his series of sermons.\\nAnother incendiary mix of religion and mathematics exploded over\\nEngland in 1748, when the Scottish philosopher David Hume published an\\nessay attacking some of Christianity’s fundamental narratives. Hume believed\\nthat we can’t be absolutely certain about anything that is based only on\\ntraditional beliefs, testimony, habitual relationships, or cause and effect. In\\nshort, we can rely only on what we learn from experience.\\nBecause God was regarded as the First Cause of everything, Hume’s\\nskepticism about cause-and-effect relationships was especially unsettling.\\nHume argued that certain objects are constantly associated with each other.\\nBut the fact that umbrellas and rain appear together does not mean that\\numbrellas cause rain. The fact that the sun has risen thousands of times does\\nnot guarantee that it will do so the next day. And, most important, the “design\\nof the world” does not prove the existence of a creator, an ultimate cause.\\nBecause we can seldom be certain that a particular cause will have a\\nparticular effect, we must be content with finding only probable causes and\\nprobable effects. In criticizing concepts about cause and effect Hume was\\nundermining Christianity’s core beliefs.\\nHume’s essay was nonmathematical, but it had profound scientific\\nimplications. Many mathematicians and scientists believed fervently that\\nnatural laws did indeed prove the existence of God, their First Cause. As an\\neminent mathematician Abraham de Moivre wrote in his influential book\\nDoctrine of Chances, calculations about natural events would eventually\\nreveal the underlying order of the universe and its exquisite “Wisdom and\\nDesign.”\\nWith Hume’s doubts about cause and effect swirling about, Bayes began to\\nconsider ways to treat the issue mathematically. Today, probability, the\\nmathematics of uncertainty, would be the obvious tool, but during the early\\n1700s probability barely existed. Its only extensive application was to\\ngambling, where it dealt with such basic issues as the odds of getting four\\naces in one poker hand. De Moivre, who had spent several years in French\\nprisons because he was a Protestant, had already solved that problem by\\nworking from cause to effect. But no one had figured out how to turn his work\\naround backward to ask the so-called inverse question from effect to cause:\\nwhat if a poker player deals himself four aces in each of three consecutive\\nhands? What is the underlying chance (or cause) that his deck is loaded?\\nWe don’t know precisely what piqued Bayes’ interest in the inverse\\nprobability problem. He had read de Moivre’s book, and the Earl of\\nStanhope was interested in probability as it applied to gambling.\\nAlternatively, it could have been the broad issues raised by Newton’s theory\\nof gravitation. Newton, who had died 20 years before, had stressed the\\nimportance of relying on observations, developed his theory of gravitation to\\nexplain them, and then used his theory to predict new observations. But\\nNewton had not explained the cause of gravity or wrestled with the problem\\nof how true his theory might be. Finally, Bayes’ interest may have been\\nstimulated by Hume’s philosophical essay. In any event, problems involving\\ncause and effect and uncertainty filled the air, and Bayes set out to deal with\\nthem quantitatively.\\nCrystallizing the essence of the inverse probability problem in his mind,\\nBayes decided that his goal was to learn the approximate probability of a\\nfuture event he knew nothing about except its past, that is, the number of times\\nit had occurred or failed to occur. To quantify the problem, he needed a\\nnumber, and sometime between 1746 and 1749 he hit on an ingenious\\nsolution. As a starting point he would simply invent a number—he called it a\\nguess—and refine it later as he gathered more information.\\nNext, he devised a thought experiment, a 1700s version of a computer\\nsimulation. Stripping the problem to its basics, Bayes imagined a square\\ntable so level that a ball thrown on it would have the same chance of landing\\non one spot as on any other. Subsequent generations would call his\\nconstruction a billiard table, but as a Dissenting minister Bayes would have\\ndisapproved of such games, and his experiment did not involve balls\\nbouncing off table edges or colliding with one another. As he envisioned it, a\\nball rolled randomly on the table could stop with equal probability\\nanywhere.\\nWe can imagine him sitting with his back to the table so he cannot see\\nanything on it. On a piece of paper he draws a square to represent the surface\\nof the table. He begins by having an associate toss an imaginary cue ball onto\\nthe pretend tabletop. Because his back is turned, Bayes does not know where\\nthe cue ball has landed.\\nNext, we picture him asking his colleague to throw a second ball onto the\\ntable and report whether it landed to the right or left of the cue ball. If to the\\nleft, Bayes realizes that the cue ball is more likely to sit toward the right side\\nof the table. Again Bayes’ friend throws the ball and reports only whether it\\nlands to the right or left of the cue ball. If to the right, Bayes realizes that the\\ncue can’t be on the far right-hand edge of the table.\\nHe asks his colleague to make throw after throw after throw; gamblers and\\nmathematicians already knew that the more times they tossed a coin, the more\\ntrustworthy their conclusions would be. What Bayes discovered is that, as\\nmore and more balls were thrown, each new piece of information made his\\nimaginary cue ball wobble back and forth within a more limited area.\\nAs an extreme case, if all the subsequent tosses fell to the right of the first\\nball, Bayes would have to conclude that it probably sat on the far left-hand\\nmargin of his table. By contrast, if all the tosses landed to the left of the first\\nball, it probably sat on the far right. Eventually, given enough tosses of the\\nball, Bayes could narrow the range of places where the cue ball was apt to\\nbe.\\nBayes’ genius was to take the idea of narrowing down the range of\\npositions for the cue ball and—based on this meager information—infer that\\nit had landed somewhere between two bounds. This approach could not\\nproduce a right answer. Bayes could never know precisely where the cue\\nball landed, but he could tell with increasing confidence that it was most\\nprobably within a particular range. Bayes’ simple, limited system thus\\nmoved from observations about the world back to their probable origin or\\ncause. Using his knowledge of the present (the left and right positions of the\\ntossed balls), Bayes had figured out how to say something about the past (the\\nposition of the first ball). He could even judge how confident he could be\\nabout his conclusion.\\nConceptually, Bayes’ system was simple. We modify our opinions with\\nobjective information: Initial Beliefs (our guess where the cue ball landed) +\\nRecent Objective Data (whether the most recent ball landed to the left or\\nright of our original guess) = A New and Improved Belief. Eventually, names\\nwere assigned to each part of his method: Prior for the probability of the\\ninitial belief; Likelihood for the probability of other hypotheses with\\nobjective new data; and Posterior for the probability of the newly revised\\nbelief. Each time the system is recalculated, the posterior becomes the prior\\nof the new iteration. It was an evolving system, which each new bit of\\ninformation pushed closer and closer to certitude. In short:\\nPrior times likelihood is proportional to the posterior.\\n(In the more technical language of the statistician, the likelihood is the\\nprobability of competing hypotheses for the fixed data that have been\\nobserved. However, Andrew Dale, a South African historian of statistics,\\nsimplified the matter considerably when he observed, “Put somewhat rudely,\\nthe likelihood is what remains of Bayes’s Theorem once the prior is removed\\nfrom the discussion.”)2\\nAs a special case about balls thrown randomly onto a flat table, Bayes’\\nrule is uncontroversial. But Bayes wanted to cover every case involving\\nuncertainty, even cases where nothing whatsoever was known about their\\nhistory—in his words, where we “absolutely know nothing antecedently to\\nany trials.”3 This expansion of his table experiment to cover any uncertain\\nsituation would trigger 150 years of misunderstanding and bitter attacks.\\nTwo especially popular targets for attack were Bayes’ guesswork and his\\nsuggested shortcut.\\nFirst, Bayes guessed the likely value of his initial belief (the cue ball’s\\nposition, later known as the prior). In his own words, he decided to make “a\\nguess whereabouts it’s [sic] probability is, and . . . [then] see the chance that\\nthe guess is right.” Future critics would be horrified at the idea of using a\\nmere hunch—a subjective belief—in objective and rigorous mathematics.\\nEven worse, Bayes added that if he did not know enough to distinguish the\\nposition of the balls on his table, he would assume they were equally likely\\nto fall anywhere on it. Assuming equal probabilities was a pragmatic\\napproach for dealing with uncertain circumstances. The practice was rooted\\nin traditional Christianity and the Roman Catholic Church’s ban on usury. In\\nuncertain situations such as annuities or marine insurance policies, all parties\\nwere assigned equal shares and divided profits equally. Even prominent\\nmathematicians assigned equal probabilities to gambling odds by assuming,\\nwith a remarkable lack of realism, that all tennis players or fighting cocks\\nwere equally skillful.\\nIn time, the practice of assigning equal probabilities acquired a number of\\nnames, including equal priors, equal a priori’s, equiprobability, uniform\\ndistribution probability, and the law of insufficient reason (meaning that\\nwithout enough data to assign specific probabilities, equal ones would\\nsuffice). Despite their venerable history, equal probabilities would become a\\nlightning rod for complaints that Bayes was quantifying ignorance.\\nToday, some historians try to absolve him by saying he may have applied\\nequal probabilities to his data (the subsequent throws) rather than to the\\ninitial, so-called prior toss. But this is also guesswork. And for many\\nworking statisticians, the question is irrelevant because in the tightly\\ncircumscribed case of balls that can roll anywhere on a carefully leveled\\nsurface both produce the same mathematical results.\\nWhatever Bayes meant, the damage was done. For years to come, the\\nmessage seemed clear: priors be damned. At this point, Bayes ended his\\ndiscussion.\\nHe may have mentioned his discovery to others. In 1749 someone told a\\nphysician named David Hartley something that sounds suspiciously like\\nBayes’ rule. Hartley was a Royal Society member who believed in cause-\\nand-effect relationships. In 1749 he wrote that “an ingenious friend has\\ncommunicated to me a Solution of the inverse problem . . . which shews that\\nwe may hope to determine the Proportions, and by degrees, the whole\\nNature, of unknown Causes, by a sufficient Observation of their Effects.”\\nWho was this ingenious friend? Modern-day sleuths have suggested Bayes or\\nStanhope, and in 1999 Stephen M. Stigler of the University of Chicago\\nsuggested that Nicholas Saunderson, a blind Cambridge mathematician, made\\nthe discovery instead of Bayes. No matter who talked about it, it seems\\nhighly unlikely that anyone other than Bayes made the breakthrough. Hartley\\nused terminology that is almost identical to Bayes’ published essay, and no\\none who read the article between its publication in 1764 and 1999 doubted\\nBayes’ authorship. If there had been any question about the author’s identity,\\nit is hard to imagine Bayes’ editor or his publisher not saying something\\npublicly. Thirty years later Price was still referring to the work as that of\\nThomas Bayes.\\nAlthough Bayes’ idea was discussed in Royal Society circles, he himself\\nseems not to have believed in it. Instead of sending it off to the Royal Society\\nfor publication, he buried it among his papers, where it sat for roughly a\\ndecade. Only because he filed it between memoranda dated 1746 and 1749\\ncan we conclude that he achieved his breakthrough sometime during the late\\n1740s, perhaps shortly after the publication of Hume’s essay in 1748.\\nBayes’ reason for suppressing his essay can hardly have been fear of\\ncontroversy; he had plunged twice into Britain’s pamphlet wars. Perhaps he\\nthought his discovery was useless; but if a pious clergyman like Bayes\\nthought his work could prove the existence of God, surely he would have\\npublished it. Some thought Bayes was too modest. Others wondered whether\\nhe was unsure about his mathematics. Whatever the reason, Bayes made an\\nimportant contribution to a significant problem—and suppressed it. It was the\\nfirst of several times that “Bayes’ rule” would spring to life only to\\ndisappear again from view.\\nBayes’ discovery was still gathering dust when he died in 1761. At that\\npoint relatives asked Bayes’ young friend Richard Price to examine Bayes’\\nmathematical papers.\\nPrice, another Presbyterian minister and amateur mathematician, achieved\\nfame later as an advocate of civil liberties and of the American and French\\nrevolutions. His admirers included the Continental Congress, which asked\\nhim to emigrate and manage its finances; Benjamin Franklin, who nominated\\nhim for the Royal Society; Thomas Jefferson, who asked him to write to\\nVirginia’s youths about the evils of slavery; John Adams and the feminist\\nMary Wollstonecraft, who attended his church; the prison reformer John\\nHoward, who was his best friend; and Joseph Priestley, the discoverer of\\noxygen, who said, “I question whether Dr. Price ever had a superior.” When\\nYale University conferred two honorary degrees in 1781, it gave one to\\nGeorge Washington and the other to Price. An English magazine thought Price\\nwould go down in American history beside Franklin, Washington, Lafayette,\\nand Paine. Yet today Price is known primarily for the help he gave his friend\\nBayes.\\nSorting through Bayes’ papers, Price found “an imperfect solution of one\\nof the most difficult problems in the doctrine of chances.” It was Bayes’\\nessay on the probability of causes, on moving from observations about the\\nreal world back to their most probable cause.\\nAt first Price saw no reason to devote much time to the essay.\\nMathematical infelicities and imperfections marred the manuscript, and it\\nlooked impractical. Its continual iterations—throwing the ball over and over\\nagain and recalculating the formula each time—produced large numbers that\\nwould be difficult to calculate.\\nBut once Price decided Bayes’ essay was the answer to Hume’s attack on\\ncausation, he began preparing it for publication. Devoting “a good deal of\\nlabour” to it on and off for almost two years, he added missing references\\nand citations and deleted extraneous background details in Bayes’\\nderivations. Lamentably, he also threw out his friend’s introduction, so we’ll\\nnever know precisely how much the edited essay reflects Bayes’ own\\nthinking.\\nIn a cover letter to the Royal Society, Price supplied a religious reason for\\npublishing the essay. In moving mathematically from observations of the\\nnatural world inversely back to its ultimate cause, the theorem aimed to show\\nthat “the world must be the effect of the wisdom and power of an intelligent\\ncause; and thus to confirm . . . from final causes . . . the existence of the\\nDeity.” Bayes himself was more reticent; his part of the essay does not\\nmention God.\\nA year later the Royal Society’s Philosophical Transactions published\\n“An Essay toward solving a Problem in the Doctrine of Chances.” The title\\navoided religious controversy by highlighting the method’s gambling\\napplications. Critiquing Hume a few years later, Price used Bayes for the\\nfirst and only time. As far as we know, no one else mentioned the essay for\\nthe next 17 years, when Price would again bring Bayes’ rule to light.\\nBy modern standards, we should refer to the Bayes-Price rule. Price\\ndiscovered Bayes’ work, recognized its importance, corrected it, contributed\\nto the article, and found a use for it. The modern convention of employing\\nBayes’ name alone is unfair but so entrenched that anything else makes little\\nsense.\\nAlthough it was ignored for years, Bayes’ solution to the inverse\\nprobability of causes was a masterpiece. He transformed probability from a\\ngambler’s measure of frequency into a measure of informed belief. A card\\nplayer could start by believing his opponent played with a straight deck and\\nthen modify his opinion each time a new hand was dealt. Eventually, the\\ngambler could wind up with a better assessment of his opponent’s honesty.\\nBayes combined judgments based on prior hunches with probabilities\\nbased on repeatable experiments. He introduced the signature features of\\nBayesian methods: an initial belief modified by objective new information.\\nHe could move from observations of the world to abstractions about their\\nprobable cause. And he discovered the long-sought grail of probability, what\\nfuture mathematicians would call the probability of causes, the principle of\\ninverse probability, Bayesian statistics, or simply Bayes’ rule.\\nGiven the revered status of his work today, it is also important to\\nrecognize what Bayes did not do. He did not produce the modern version of\\nBayes’ rule. He did not even employ an algebraic equation; he used\\nNewton’s old-fashioned geometric notation to calculate and add areas. Nor\\ndid he develop his theorem into a powerful mathematical method. Above all,\\nunlike Price, he did not mention Hume, religion, or God.\\nInstead, he cautiously confined himself to the probability of events and did\\nnot mention hypothesizing, predicting, deciding, or taking action. He did not\\nsuggest possible uses for his work, whether in theology, science, or social\\nscience. Future generations would extend Bayes’ discovery to do all these\\nthings and to solve a myriad of practical problems. Bayes did not even name\\nhis breakthrough. It would be called the probability of causes or inverse\\nprobability for the next 200 years. It would not be named Bayesian until the\\n1950s.\\nIn short, Bayes took the first steps. He composed the prelude for what was\\nto come.\\nFor the next two centuries few read the Bayes-Price article. In the end, this\\nis the story of two friends, Dissenting clergymen and amateur\\nmathematicians, whose labor had almost no impact. Almost, that is, except on\\nthe one person capable of doing something about it, the great French\\nmathematician Pierre Simon Laplace.\\n2.\\n \\nthe man who did everything\\n \\nJust across the English Channel from Tunbridge Wells, about the time that\\nThomas Bayes was imagining his perfectly smooth table, the mayor of a tiny\\nvillage in Normandy was celebrating the birth of a son, Pierre Simon\\nLaplace, the future Einstein of his age.\\nPierre Simon, born on March 23, 1749, and baptized two days later, came\\nfrom several generations of literate and respected dignitaries. His mother’s\\nrelatives were well-to-do farmers, but she died when he was young, and he\\nnever referred to her. His father kept the stagecoach inn in picturesque\\nBeaumonten-Auge, was a leader of the community’s 472 inhabitants, and\\nserved 30 years as mayor. By the time Pierre Simon was a teenager his father\\nseems to have been his only close relative. In years to come Pierre Simon’s\\ndecision to become a mathematician would shatter their relationship almost\\nirretrievably.1\\nFortunately for the boy there was never any question about his getting an\\neducation. Attending school was becoming the norm in France in the 1700s,\\nan enormous revolution fueled by the Catholic Church’s fight against\\nProtestant heresy and by parents convinced that education would enrich their\\nchildren spiritually, intellectually, and financially. The question was, what\\nkind of schooling?\\nDecades of religious warfare between Protestants and Catholics and\\nseveral horrendous famines caused by cold weather had made France a\\ndeterminedly secular country intent on developing its resources. Pierre\\nSimon could have studied modern science and geometry in one of the\\ncountry’s many new secular schools. Instead, the elder Laplace enrolled his\\nson in a local primary and secondary school where Benedictine monks\\nproduced clergy for the church and soldiers, lawyers, and bureaucrats for the\\ncrown. Thanks to the patronage of the Duke of Orleans, local day students\\nlike Pierre Simon attended free. The curriculum was conservative and Latin-\\nbased, heavy on copying, memorization, and philosophy. But it left Laplace\\nwith a fabulous memory and almost unbelievable perseverance.\\nAlthough the monks probably did not know it, they were competing with\\nthe French Enlightenment for the child’s attention. Contemporaries called it\\nthe Century of Lights and the Age of Science and Reason, and the\\npopularization of science was its most important intellectual phenomenon.\\nGiven the almost dizzying curiosity of the times, it is not surprising that,\\nshortly after his tenth birthday, Pierre Simon was profoundly affected by a\\nspectacular scientific prediction.2\\nDecades before, the English astronomer Edmond Halley had predicted the\\nreappearance of the long-tailed comet that now bears his name. A trio of\\nFrench astronomers, Alexis Claude Clairaut, Joseph Lalande, and Nicole-\\nReine Lepaute, the wife of a celebrated clockmaker, solved a difficult three-\\nbody problem and discovered that the gravitational pull of Jupiter and Saturn\\nwould delay the arrival of Halley’s comet. The French astronomers\\naccurately pinpointed the date—mid-April 1759 plus or minus a month—\\nwhen Europeans would be able to see the comet returning from its orbit\\naround the sun. The comet’s appearance on schedule and on course\\nelectrified Europeans. Years later Laplace said it was the event that made his\\ngeneration realize that extraordinary events like comets, eclipses, and severe\\ndroughts were caused not by divine anger but by natural laws that\\nmathematics could reveal.\\nLaplace’s extraordinary mathematical ability may not yet have been\\napparent when he turned 17 in 1766, because he did not go to the University\\nof Paris, which had a strong science faculty. Instead he went to the University\\nof Caen, which was closer to home and had a solid theological program\\nsuitable for a future cleric.\\nYet even Caen had mathematical firebrands offering advanced lectures on\\ndifferential and integral calculus. While English mathematicians were getting\\nmired in Newton’s awkward geometric version of calculus, their rivals on\\nthe Continent were using Gottfried Leibniz’s more supple algebraic calculus.\\nWith it, they were forming equations and discovering a fabulous wealth of\\nenticing new information about planets, their masses and details of their\\norbits. Laplace emerged from Caen a swashbuckling mathematical virtuoso\\neager to take on the scientific world. He had also become, no doubt to his\\nfather’s horror, a religious skeptic.\\nAt graduation Laplace faced an anguishing dilemma. His master’s degree\\npermitted him to take either the priestly vows of celibacy or the title of abbé,\\nsignifying a low-ranking clergyman who could marry and inherit property.\\nAbbés did not have good reputations; Voltaire called them “that indefinable\\nbeing which is neither ecclesiastic nor secular . . . young men, who are\\nknown for their debauchery.”3 An engraving of the period, “What Does the\\nAbbé Think of It?” shows the clergyman peering appreciatively down a\\nlady’s bosom as she dresses.4 Still, the elder Laplace wanted his son to\\nbecome a clergyman.\\nIf Laplace had been willing to become an abbé, his father might have\\nhelped him financially, and Laplace could have combined church and\\nscience. A number of abbés supported themselves in science, the most\\nfamous being Jean Antoine Nollet, who demonstrated spectacular physics\\nexperiments to the paying public. For the edification of the king and queen of\\nFrance, Nollet sent a charge of static electricity through a line of 180\\nsoldiers to make them leap comically into the air. Two abbés were even\\nelected to the prestigious Royal Academy of Sciences. Still, the lot of most\\nabbé-scientists was neither lucrative nor intellectually challenging. The\\nmajority found low-level jobs tutoring the sons of rich nobles or teaching\\nelementary mathematics and science in secondary schools. University-level\\nopportunities were limited because during the 1700s professors transmitted\\nknowledge from the past instead of doing original research.\\nBut Caen had convinced Laplace that he wanted to do something quite\\nnew. He wanted to be a full-time, professional, secular, mathematical\\nresearcher. And he wanted to explore the new algebra-generated, data-rich\\nworld of science. To his father, an ambitious man in bucolic France, a career\\nin mathematics must have seemed preposterous.\\nYoung Laplace made his move in the summer of 1769, shortly after\\ncompleting his studies at Caen. He left Normandy and traveled to Paris,\\nclutching a letter of recommendation to Jean Le Rond d’Alembert, the most\\npowerful mathematician of the age, one of Europe’s most notorious\\nanticlerics, and the object of almost incessant Jesuit attacks. D’Alembert was\\na star of the Enlightenment and the chief spokesman for the Encyclopédie,\\nwhich was making an enormous body of empirical knowledge universally\\navailable, scientific, and free of religious dogma. By throwing in his lot with\\nd’Alembert, Laplace effectively cut his ties to the Catholic Church. We can\\nonly imagine his father’s reaction, but we know that Laplace did not return\\nhome for 20 years and did not attend the old man’s funeral.\\nOnce in Paris, Laplace immediately approached the great d’Alembert and\\nshowed him a four-page student essay on inertia. Years later Laplace could\\nstill recite passages from it. Although besieged by applicants, d’Alembert\\nwas so impressed that within days he had arranged a paying job for Laplace\\nas an instructor of mathematics at the new secular, mathematics-based Royal\\nMilitary School for the younger sons of minor nobles. The school, located\\nbehind Les Invalides in Paris, provided Laplace with a salary, housing,\\nmeals, and money for wood to heat his room in winter. It was precisely the\\nkind of job he had hoped to avoid.\\nLaplace could have tried to find work applying mathematics to practical\\nproblems in one of the monarchy’s numerous research establishments or\\nmanufacturing plants. Many mathematically talented young men from modest\\nfamilies were employed in such institutions. But Laplace and his mentor\\nwere aiming far higher. Laplace wanted the challenge of doing basic research\\nfull time. And to do that, as d’Alembert must have told him, he had to get\\nelected to the Royal Academy of Sciences.\\nIn striking contrast to the amateurism of the Royal Society of London, the\\nFrench Royal Academy of Sciences was the most professional scientific\\ninstitution in Europe. Although aristocratic amateurs could become honorary\\nmembers, the organization’s highest ranks were composed of working\\nscientists chosen by merit and paid to observe, collect, and investigate facts\\nfree of dogma; to publish their findings after peer review; and to advise the\\ngovernment on technical issues like patents. To augment their low salaries,\\nacademicians could use their prestige to cobble together various part-time\\njobs.\\nWithout financial support from the church or his father, however, Laplace\\nhad to work fast. Since most academy members were chosen on the basis of a\\nlong record of solid accomplishment, he would have to be elected over the\\nheads of more senior men. And for that to happen, he needed to make a\\nspectacular impact.\\nD’Alembert, who had made Newton’s revolution the focus of French\\nmathematics, urged Laplace to concentrate on astronomy. D’Alembert had a\\nclear problem in mind.\\nOver the previous two centuries mathematical astronomy had made great\\nstrides. Nicolaus Copernicus had moved Earth from the center of the solar\\nsystem to a modest but accurate position among the planets; Johannes Kepler\\nhad connected the celestial bodies by simple laws; and Newton had\\nintroduced the concept of gravity. But Newton had described the motions of\\nheavenly bodies roughly and without explanation. His death in 1727 left\\nLaplace’s generation an enormous challenge: showing that gravitation was\\nnot a hypothesis but a fundamental law of nature.\\nAstronomy was the era’s most quantified and respected science, and only\\nit could test Newton’s theories by explaining precisely how gravitation\\naffects the movements of tides, interacting planets and comets, our moon, and\\nthe shape of Earth and other planets. Forty years of empirical data had been\\ncollected, but, as d’Alembert warned, a single exception could bring the\\nentire edifice tumbling down.\\nThe burning scientific question of the day was whether the universe was\\nstable. If Newton’s gravitational force operates throughout the universe, why\\ndon’t the planets collide with each other and cause the cosmic Armageddon\\ndescribed in the biblical book of Revelation? Was the end of the world at\\nhand?\\nAstronomers had long been aware of alarming evidence suggesting that the\\nsolar system was inherently unstable. Comparing the actual positions of the\\nmost remote known planets with centuries-old astronomical observations,\\nthey could see that Jupiter was slowly accelerating in its orbit around the sun\\nwhile Saturn was slowing down. Eventually, they thought, Jupiter would\\nsmash into the sun, and Saturn would spin off into space. The problem of\\npredicting the motions of many interacting bodies over long periods of time\\nis complex even today, and Newton concluded that God’s miraculous\\nintervention kept the heavens in equilibrium. Responding to the challenge,\\nLaplace decided to make the stability of the universe his lifework. He said\\nhis tool would be mathematics and it would be like a telescope in the hands\\nof an astronomer.\\nFor a short time Laplace actually considered modifying Newton’s theory\\nby making gravity vary with a body’s velocity as well as with its mass and\\ndistance. He also wondered fleetingly whether comets might be disturbing\\nthe orbits of Jupiter and Saturn. But he changed his mind almost immediately.\\nThe problem was not Newton’s theory. The problem was the data\\nastronomers used.\\nNewton’s system of gravitation could be accepted as true only if it agreed\\nwith precise measurements, but observational astronomy was awash with\\ninformation, some of it uncertain and inadequate. Working on the problem of\\nJupiter and Saturn, for example, Laplace would use observations made by\\nChinese astronomers in 1100 BC, Chaldeans in 600 BC, Greeks in 200 BC,\\nRomans in AD 100, and Arabs in AD 1000. Obviously, not all data were\\nequally valuable. How to resolve errors, known delicately as discrepancies,\\nwas anybody’s guess.\\nThe French academy was tackling the problem by encouraging the\\ndevelopment of more precise telescopes and graduated arcs. And as algebra\\nimproved \\ninstrumentation, \\nexperimentalists \\nwere \\nproducing \\nmore\\nquantitative results. In a veritable information explosion, the sheer collection\\nand systemization of data accelerated through the Western world. Just as the\\nnumber of known plant and animal species expanded enormously during the\\n1700s, so did knowledge about the physical universe. Even as Laplace\\narrived in Paris, the French and British academies were sending trained\\nobservers with state-of-the-art instrumentation to 120 carefully selected\\nlocations around the globe to time Venus crossing the face of the sun; this was\\na critical part of Capt. James Cook’s original mission to the South Seas. By\\ncomparing all the measurements, French mathematicians would determine the\\napproximate distance between the sun and Earth, a fundamental natural\\nconstant that would tell them the size of the solar system. But sometimes even\\nup-to-date expeditions provided contradictory data about whether, for\\ninstance, Earth was shaped like an American football or a pumpkin.\\nDealing with large amounts of complex data was emerging as a major\\nscientific problem. Given a wealth of observations, how could scientists\\nevaluate the facts at their disposal and choose the most valid? Observational\\nastronomers typically averaged their three best observations of a particular\\nphenomenon, but the practice was as straightforward as it was ad hoc; no one\\nhad ever tried to prove its validity empirically or theoretically. The\\nmathematical theory of errors was in its infancy.\\nProblems were ripe for the picking and, with his eye on membership in the\\nRoyal Academy, Laplace bombarded the society with 13 papers in five\\nyears. He submitted hundreds of pages of powerful and original mathematics\\nneeded in astronomy, celestial mechanics, and important related issues.\\nAstutely, he timed his reports to appear when openings occurred in the\\nacademy’s membership. The secretary of the academy, the Marquis de\\nCondorcet, wrote that never before had the society seen “anyone so young,\\npresent to it in so little time, so many important Mémoires, and on such\\ndiverse and such difficult matters.”5\\nAcademy members considered Laplace for membership six times but\\nrejected him repeatedly in favor of more senior scientists. D’Alembert\\ncomplained furiously that the organization refused to recognize talent.\\nLaplace considered emigrating to Prussia or Russia to work in their\\nacademies.\\nDuring this frustrating period Laplace spent his free afternoons digging in\\nthe mathematical literature in the Royal Military School’s 4,000-volume\\nlibrary. Analyzing large amounts of data was a formidable problem, and\\nLaplace was already beginning to think it would require a fundamentally new\\nway of thinking. He was beginning to see probability as a way to deal with\\nthe uncertainties pervading many events and their causes. Browsing in the\\nlibrary’s stacks, he discovered an old book on gambling probability, The\\nDoctrine of Chances, by Abraham de Moivre. The book had appeared in\\nthree editions between 1718 and 1756, and Laplace may have read the 1756\\nversion. Thomas Bayes had studied an earlier edition.\\nReading de Moivre, Laplace became more and more convinced that\\nprobability might help him deal with uncertainties in the solar system.\\nProbability barely existed as a mathematical term, much less as a theory.\\nOutside of gambling, it was applied in rudimentary form to philosophical\\nquestions like the existence of God and to commercial risk, including\\ncontracts, marine and life insurance, annuities, and money lending.\\nLaplace’s growing interest in probability created a diplomatic problem of\\nsome delicacy because d’Alembert believed probability was too subjective\\nfor science. Young as he was, Laplace was confident enough in his\\nmathematical judgment to disagree with his powerful patron. To Laplace, the\\nmovements of celestial bodies seemed so complex that he could not hope for\\nprecise solutions. Probability would not give him absolute answers, but it\\nmight show him which data were more likely to be correct. He began\\nthinking about a method for deducing the probable causes of divergent, error-\\nfilled observations in astronomy. He was feeling his way toward a broad\\ngeneral theory for moving mathematically from known events back to their\\nmost probable causes. Continental mathematicians did not know yet about\\nBayes’ discovery, so Laplace called his idea “the probability of causes” and\\n“the probability of causes and future events, derived from past events.”6\\nWrestling with the mathematics of probability in 1773, he reflected on its\\nphilosophical counterpoint. In a paper submitted and read to the academy in\\nMarch, the former abbé compared ignorant mankind, not with God but with\\nan imaginary intelligence capable of knowing All. Because humans can never\\nknow everything with certainty, probability is the mathematical expression of\\nour ignorance: “We owe to the frailty of the human mind one of the most\\ndelicate and ingenious of mathematical theories, namely the science of\\nchance or probabilities.”7\\nThe essay was a grand combination of mathematics, metaphysics, and the\\nheavens that Laplace held to his entire life. His search for a probability of\\ncauses and his view of the deity were deeply congenial. Laplace was all of\\none piece and for that reason all the more formidable. He often said he did\\nnot believe in God, and not even his biographer could decide whether he was\\nan atheist or a deist. But his probability of causes was a mathematical\\nexpression of the universe, and for the rest of his days he updated his theories\\nabout God and the probability of causes as new evidence became available.\\nLaplace was struggling with probability when one day, ten years after the\\npublication of Bayes’ essay, he picked up an astronomy journal and was\\nshocked to read that others might be hot on the same trail. They were not, but\\nthe threat of competition galvanized him. Dusting off one of his discarded\\nmanuscripts, Laplace transformed it into a broad method for determining the\\nmost likely causes of events and phenomena. He called it “Mémoire on the\\nProbability of the Causes Given Events.”\\nIt provided the first version of what today we call Bayes’ rule, Bayesian\\nprobability, or Bayesian statistical inference. Not yet recognizable as the\\nmodern Bayes’ rule, it was a one-step process for moving backward, or\\ninversely, from an effect to its most likely cause. As a mathematician in a\\ngambling-addicted culture, Laplace knew how to work out the gambler’s\\nfuture odds of an event knowing its cause (the dice). But he wanted to solve\\nscientific problems, and in real life he did not always know the gambler’s\\nodds and often had doubts about what numbers to put into his calculations. In\\na giant and intellectually nimble leap, he realized he could inject these\\nuncertainties into his thinking by considering all possible causes and then\\nchoosing among them.\\nLaplace did not state his idea as an equation. He intuited it as a principle\\nand described it only in words: the probability of a cause (given an event) is\\nproportional to the probability of the event (given its cause). Laplace did not\\ntranslate his theory into algebra at this point, but modern readers might find it\\nhelpful to see what his statement would look like today:\\n \\nwhere P(C|E) is the probability of a particular cause (given the data), and\\nP(E|C) represents the probability of an event or datum (given that cause). The\\nsign in the denominator represented with Newton’s sigma sign makes the\\ntotal probability of all possible causes add up to one.\\nArmed with his principle, Laplace could do everything Thomas Bayes\\ncould have done—as long as he accepted the restrictive assumption that all\\nhis possible causes or hypotheses were equally likely. Laplace’s goal,\\nhowever, was far more ambitious. As a scientist, he needed to study the\\nvarious possible causes of a phenomenon and then determine the best one. He\\ndid not yet know how to do that mathematically. He would need to make two\\nmore major breakthroughs and spend decades in thought.\\nLaplace’s principle, the proportionality between probable events and their\\nprobable causes, seems simple today. But he was the first mathematician to\\nwork with large data sets, and the proportionality of cause and effect would\\nmake it feasible to make complex numerical calculations using only goose\\nquills and ink pots.\\nIn a mémoire read aloud to the academy, Laplace first applied his new\\nprobability of causes to two gambling problems. In each case he understood\\nintuitively what should happen but got bogged down trying to prove it\\nmathematically. First, he imagined an urn filled with an unknown ratio of\\nblack and white tickets (his cause). He drew a number of tickets from the urn\\nand, based on that experience, asked for the probability that his next ticket\\nwould be white. Then in a frustrating battle to prove the answer he wrote no\\nfewer than 45 equations covering four quarto-sized pages.\\nHis second gambling problem involved piquet, a game requiring both luck\\nand skill. Two people start playing but stop midway through the game and\\nhave to figure out how to divide the kitty by estimating their relative skill\\nlevels (the cause). Again, Laplace understood instinctively how to solve the\\nproblem but could not yet do so mathematically.\\nAfter dealing with gambling, which he loathed, Laplace moved happily on\\nto the critical scientific problem faced by working astronomers. How should\\nthey deal with different observations of the same phenomenon? Three of the\\nera’s biggest scientific problems involved gravitational attraction on the\\nmotions of our moon, the motions of the planets Jupiter and Saturn, and the\\nshape of the Earth. Even if observers repeated their measurements at the\\nsame time and place with the same instrument, their results could be slightly\\ndifferent each time. Trying to calculate a midvalue for such discrepant\\nobservations, Laplace limited himself to three observations but still needed\\nseven pages of equations to formulate the problem. Scientifically, he\\nunderstood the right answer—average the three data points—but he would\\nhave no mathematical justification for doing so until 1810, when, without\\nusing the probability of causes, he invented the central limit theorem.\\nAlthough Bayes originated the probability of causes, Laplace clearly\\ndiscovered his version on his own. Laplace was 15 when the Bayes-Price\\nessay was published; it appeared in an English-language journal for the\\nEnglish gentry and was apparently never mentioned again. Even French\\nscientists who kept up with foreign journals thought Laplace was first and\\ncongratulated him wholeheartedly on his originality.\\nMathematics \\nconfirms \\nthat \\nLaplace \\ndiscovered \\nthe \\nprinciple\\nindependently. Bayes solved a special problem about a flat table using a\\ntwo-step process that involved a prior guess and new data. Laplace did not\\nyet know about the initial guess but dealt with the problem generally, making\\nit useful for a variety of problems. Bayes laboriously explained and\\nillustrated why uniform probabilities were permissible; Laplace assumed\\nthem instinctively. The Englishman wanted to know the range of probabilities\\nthat something will happen in light of previous experience. Laplace wanted\\nmore: as a working scientist, he wanted to know the probability that certain\\nmeasurements and numerical values associated with a phenomenon were\\nrealistic. If Bayes and Price searched for the probability that, on the basis of\\ntoday’s puddles, it had rained yesterday and would rain tomorrow, Laplace\\nasked for the probability that a particular amount of rain would fall and then\\nrefined his opinion over and over with new information to get a better value.\\nLaplace’s method was immensely influential; scientists did not pay Bayes\\nserious heed until the twentieth century.\\nMost strikingly of all, Laplace at 25 was already steadfastly determined to\\ndevelop his new method and make it useful. For the next 40 years he would\\nwork to clarify, simplify, expand, generalize, prove, and apply his new rule.\\nYet while Laplace became the indisputable intellectual giant of Bayes’ rule,\\nit represented only a small portion of his career. He also made important\\nadvances in celestial mechanics, mathematics, physics, biology, Earth\\nscience, and statistics. He juggled projects, moving from one to another and\\nthen back to the first. Happily blazing trails through every field of science\\nknown to his age, he transformed and mathematized everything he touched.\\nHe never stopped being thrilled by examples of Newton’s theory.\\nAlthough he was fast becoming the leading scientist of his era, the\\nacademy waited five years before electing him a member on March 31, 1773.\\nA few weeks later he was formally inducted into the world’s leading\\nscientific organization. His mémoire on the probability of causes was\\npublished a year later, in 1774. At the age of 24, Laplace was a professional\\nresearcher. The academy’s annual stipend, together with his teaching salary,\\nwould help support him while he refined his research on celestial mechanics\\nand the probability of causes.\\nLaplace was still grappling with probability in 1781, when Richard Price\\nvisited Paris and told Condorcet about Bayes’ discovery. Laplace\\nimmediately latched onto the Englishman’s ingenious invention, the starting\\nguess, and incorporated it into his own, earlier version of the probability of\\ncauses. Strictly speaking, he did not produce a new formula but rather a\\nstatement about the first formula assuming equal probabilities for the causes.\\nThe statement gave him confidence that he was on the right track and told him\\nthat as long as all his prior hypotheses were equally probable, his earlier\\nprinciple of 1774 was correct.8\\nLaplace could now confidently marry his intuitive grasp of a scientific\\nsituation with the eighteenth century’s passion for new and precise scientific\\ndiscoveries. Every time he got new information he could use the answer from\\nhis last solution as the starting point for another calculation. And by assuming\\nthat all his initial hypotheses were equally probable he could even derive his\\ntheorem.\\nAs Academy secretary, Condorcet wrote an introduction to Laplace’s\\nessay and explained Bayes’ contribution. Laplace later publicly credited\\nBayes with being first when he wrote, “The theory whose principles I\\nexplained some years after, . . . he accomplished in an acute and very\\ningenious, though slightly awkward, manner.”9\\nOver the next decade, however, Laplace would realize with increasing\\nclarity and frustration that his mathematics had shortcomings. It limited him\\nto assigning equal probabilities to each of his initial hypotheses. As a\\nscientist, he disapproved. If his method was ever going to reflect the actual\\nstate of affairs, he needed to be able to differentiate dubious data from more\\nvalid observations. Calling all events or observations equally probable\\ncould be true only theoretically. Many dice, for example, that appeared\\nperfectly cubed were actually skewed. In one case he started by assigning\\nplayers equal probabilities of winning, but with each round of play their\\nrespective skills emerged and their probabilities changed. “The science of\\nchances must be used with care and must be modified when we pass from the\\nmathematical case to the physical,” he counseled.10\\nMoreover, as a pragmatist, he realized he had to confront a serious\\ntechnical difficulty. Probability problems require multiplying numbers over\\nand over, whether tossing coin after coin or measuring and remeasuring an\\nobservation. The process generated huge numbers—nothing as large as those\\ncommon today but definitely cumbersome for a man working alone without\\nmechanical or electronic aids. (He did not even get an assistant to help with\\ncalculations until about 1785.)\\nLaplace was never one to shrink from difficult computations, but, as he\\ncomplained, probability problems were often impossible because they\\npresented great difficulties and numbers raised to “very high powers.”11 He\\ncould use logarithms and an early generating function that he considered\\ninadequate. But to illustrate how tedious calculations with big numbers could\\nbe, he described multiplying 20,000 × 19,999 × 19,998 × 19,997, etc. and\\nthen dividing by 1 × 2 × 3 × 4 up to 10,000. In another case he bet in a lottery\\nonly to realize he could not calculate its formula numerically; the French\\nmonarchy’s winning number had 90 digits, drawn five at a time.\\nSuch big-number problems were new. Newton had calculated with\\ngeometry, not numbers. Many mathematicians, like Bayes, used thought\\nexperiments to separate real problems from abstract and methodological\\nissues. But Laplace wanted to use mathematics to illuminate natural\\nphenomena, and he insisted that theories had to be based on actual fact.\\nProbability was propelling him into an unmanageable world.\\nArmed with the Bayes–Price starting point, Laplace broke partway through\\nthe logjam that had stymied him for seven years. So far he had concentrated\\nprimarily on probability as a way to resolve error-prone astronomical\\nobservations. Now he switched gears to concentrate on finding the most\\nprobable causes of known events. To do so, he needed to practice with a big\\ndatabase of real and reliable values. But astronomy seldom provided\\nextensive or controlled data, and the social sciences often involved so many\\npossible causes that algebraic equations were useless.\\nOnly one large amalgamation of truly trustworthy numbers existed in the\\n1700s: parish records of births, christenings, marriages, and deaths. In 1771\\nthe French government ordered all provincial officials to report birth and\\ndeath figures regularly to Paris; and three years later, the Royal Academy\\npublished 60 years of data for the Paris region. The figures confirmed what\\nthe Englishman John Graunt had discovered in 1662: slightly more boys than\\ngirls were born, in a ratio that remained constant over many years. Scientists\\nhad long assumed that the ratio, like other newly discovered regularities in\\nnature, must be the result of “Divine Providence.” Laplace disagreed.\\nSoon he was assessing not gambling or astronomical statistics but infants.\\nFor anyone interested in large numbers, babies were ideal. First, they came\\nin binomials, either boys or girls, and eighteenth-century mathematicians\\nalready knew how to treat binomials. Second, infants arrived in abundance\\nand, as Laplace emphasized, “It is necessary in this delicate research to\\nemploy sufficiently large numbers in view of the small difference that exists\\nbetween . . . the births of boys and girls.”12 When the great naturalist Comte\\nde Buffon discovered a small village in Burgundy where, for five years\\nrunning, more girls had been born than boys, he asked whether this village\\ninvalidated Laplace’s hypotheses. Absolutely not, Laplace replied firmly. A\\nstudy based on a few facts cannot overrule a much larger one.\\nThe calculations would be formidable. For example, if he had started with\\na 52:48 ratio of newborn boys to girls and a sample of 58,000 boys, Laplace\\nwould have had to multiply .52 by itself 57,999 times—and then do a similar\\ncalculation for girls. This was definitely not something anyone, not even the\\nindomitable Laplace, wanted to do by hand.\\nHe started out, however, as Bayes had suggested, by pragmatically\\nassigning equal probabilities to all his initial hunches, whether 50–50, 33–\\n33–33, or 25–25–25–25. Because their sums equal one, multiplication would\\nbe easier. He employed equal probabilities only provisionally, as a starting\\npoint, and his final hypotheses would depend on all the observational data he\\ncould add.\\nNext, he tried to confirm that Graunt was correct about the probability of a\\nboy’s birth being larger than 50%. He was building the foundation of the\\nmodern theory of testing statistical hypotheses. Poring over records of\\nchristenings in Paris and births in London, he was soon willing to bet that\\nboys would outnumber girls for the next 179 years in Paris and for the next\\n8,605 years in London. “It would be extraordinary if it was the effect of\\nchance,” he wrote, tut-tutting that people really should make sure of their\\nfacts before theorizing about them.13\\nTo transform probability’s large numbers into smaller, more manageable\\nterms Laplace invented a multitude of mathematical shortcuts and clever\\napproximations. Among them were new generating functions, transforms, and\\nasymptotic expansions. Computers have made many of his shortcuts\\nunnecessary, but generating functions remain deeply embedded in\\nmathematical analyses used for practical applications. Laplace used\\ngenerating functions as a form of mathematical wizardry to trick a function he\\ncould deal with into providing him with the function he really wanted.\\nTo Laplace, these mathematical pyrotechnics seemed as obvious as\\ncommon sense. To students’ frustration, he sprinkled his reports with phrases\\nlike, “It is easy to see, it is easy to extend, it is easy to apply, it is obvious\\nthat. . . .”14 When a confused student once asked how he had jumped\\nintuitively from one equation to another, Laplace had to work hard to\\nreconstruct his thought process.\\nHe was soon asking whether boys were more apt to be born in certain\\ngeographic regions. Perhaps “climate, food or customs . . . facilitates the\\nbirth of boys” in London.15 Over the next 30-odd years Laplace collected\\nbirth ratios from Naples in the south, St. Petersburg in the north, and French\\nprovinces in between. He concluded that climate could not explain the\\ndisparity in births. But would more boys than girls always be born? As each\\nadditional piece of evidence appeared, Laplace found his probabilities\\napproaching certainty “at a dramatically increasing rate.”\\nHe was refining hunches with objective data. In building a mathematical\\nmodel of scientific thinking, where a reasonable person could develop a\\nhypothesis and then evaluate it relentlessly in light of new knowledge, he\\nbecame the first modern Bayesian. His system was enormously sensitive to\\nnew information. Just as each throw of a coin increases the probability of its\\nbeing fair or rigged, so each additional birth record narrowed the range of\\nuncertainties. Eventually, Laplace decided that the probability of boys\\nexceeding girls was as “certain as any other moral truth” with an extremely\\ntiny margin of being wrong.16\\nGeneralizing from babies, he found a way to determine not just the\\nprobability of simple events, like the birth of one boy, but also the\\nprobability of future composite events like an entire year of births—even\\nwhen the probability of simple events (whether the next newborn will be\\nmale) was uncertain. By 1786 he was determining the influence of past\\nevents on the probability of future events and wondering how big his sample\\nof newborns had to be. By then Laplace saw probability as the primary way\\nto overcome uncertainty. Pounding the point home in one short paragraph, he\\nwrote, “Probability is relative in part to this ignorance, in part to our\\nknowledge . . . a state of indecision, . . . it’s impossible to announce with\\ncertainty.”17\\nPersevering for years, he used insights gained in one science to shed light\\non others, researching a puzzle and inventing a mathematical technique to\\nresolve it, integrating, approximating, and generalizing broadly when there\\nwas no other way to proceed. Like a modern researcher, he competed and\\ncollaborated with others and published reports on his interim progress as he\\nwent. Above all, he was tenacious. Twenty-five years later he was still\\neagerly testing his probability of causes with new information. He combed\\n65 years’ worth of orphanage registries, asked friends in Egypt and\\nAlexander von Humboldt in Central America about birth ratios there, and\\ncalled on naturalists to check the animal kingdom. Finally, in 1812, after\\ndecades of work, he cautiously concluded that the birth of more boys than\\ngirls seemed to be “a general law for the human race.”18\\nTo test his rule on a larger sample Laplace decided in 1781 to determine the\\nsize of the French population, the thermometer of its health and prosperity. A\\nconscientious administrator in eastern France had carefully counted heads in\\nseveral parishes; to estimate the population of the entire nation, he\\nrecommended multiplying the annual number of births in France by 26. His\\nproposal produced what was thought to be France’s population,\\napproximately 25.3 million. But no one knew how accurate his estimate was.\\nToday’s demographers believe that France’s population had actually grown\\nrapidly, to almost 28 million, because of fewer famines and because a\\ngovernmenttrained midwife was touring the countryside promoting the use of\\nsoap and boiling water during childbirth.\\nUsing his probability of causes, Laplace combined his prior information\\nfrom parish records about births and deaths throughout France with his new\\ninformation about headcounts in eastern France. He was adjusting estimates\\nof the nation’s population with more precise information from particular\\nregions. In 1786 he reached a figure closer to modern estimates and\\ncalculated odds of 1,000 to 1 that his estimate was off by less than half a\\nmillion. In 1802 he was able to advise Napoleon Bonaparte that a new\\ncensus should be augmented with detailed samples of about a million\\nresidents in 30 representative departments scattered equally around France.\\nAs he worked on his birth and census studies during the monarchy’s last\\nyears, Laplace became involved in an inflammatory debate about France’s\\njudicial system. Condorcet believed the social sciences should be as\\nquantifiable as the physical sciences. To help transform absolutist France\\ninto an English-style constitutional monarchy, he wanted Laplace to use\\nmathematics to explore a variety of issues. How confident can we be in a\\nsentence handed down by judge or jury? How probable is it that voting by an\\nassembly or judicial tribunal will establish the truth? Laplace agreed to\\napply his new theory of probability to questions about electoral procedures,\\nthe credibility of witnesses, decision making by judicial panels and juries,\\nand procedures of representative bodies and judicial panels.\\nLaplace took a dim view of most court judgments in France. Forensic\\nscience did not exist, so judicial systems everywhere relied on witness\\ntestimony. Taking a witness’s statement for an event, Laplace asked the\\nprobability that the witness or the judge might be truthful, misled, or simply\\nmistaken. He estimated the prior odds of an accused person’s guilt at 50–50\\nand the probability that a juror was being truthful somewhat higher. Even at\\nthat, if a jury of eight voted by simple majority, the chance that they judged\\nthe accused’s guilt wrong would be 65/256, or more than one in four. Thus\\nfor both mathematical and religious reasons Laplace sided with the\\nEnlightenment’s most radical demand, the abolition of capital punishment:\\n“The possibility of atoning for these errors is the strongest argument of\\nphilosophers who have wanted to abolish the death penalty.”19 Laplace also\\nused his rule for more complicated cases where a court must decide among\\ncontradictory witnesses or where the reliability of testimony decreases with\\neach telling. For Laplace, these questions demonstrated that ancient biblical\\naccounts by the Apostles lacked credibility.\\nWhile still counting babies, Laplace returned to study the seeming instability\\nof Saturn and Jupiter’s orbits, the problem that had helped sensitize him early\\nin his career to uncertain data. He did not, however, use his new knowledge\\nof probability to solve this important problem. He used other methods\\nbetween 1785 and 1788 to determine that Jupiter and Saturn oscillate gently\\nin an 877-year cycle around the sun and that the moon orbits Earth in a cycle\\nmillions of years long. The orbits of Jupiter, Saturn, and the moon were not\\nexceptions to Newton’s gravitation but thrilling examples of it. The solar\\nsystem was in equilibrium, and the world would not end. This discovery was\\nthe biggest advance in physical astronomy since Newton’s law of gravity.\\nDespite Laplace’s astounding productivity, his life as a professional scientist\\nwas financially precarious. Fortunately, Paris in the 1700s had more\\neducational institutions and scientific opportunities than anywhere else on\\nEarth, and academy members could patch jobs together to make a respectable\\nliving. Laplace tripled his income by examining artillery and naval\\nengineering students three or four months a year and serving as a scientist in\\nthe Duke of Orleans’ entourage. His increasingly secure position also gave\\nhim access to the government statistics he needed to develop and test his\\nprobability of causes.\\nAt the age of 39, with a bright future ahead of him, Laplace married 18-\\nyear-old Marie Anne Charlotte Courty de Romange. The average age of\\nmarriage for French women was 27, but Marie Anne came from a prosperous\\nand recently ennobled family with multiple ties to his financial and social\\ncircle. A small street off the Boulevard Saint-Germain is named Courty for\\nher family. The Laplaces would have two children; contraception, whether\\ncoitus interruptus or pessaries, was common, and the church itself\\ncampaigned against multiple childbirths because they endangered the lives of\\nmothers. Some 16 months after the wedding a Parisian mob stormed the\\nBastille, and the French Revolution began.\\nAfter the revolutionary government was attacked by foreign monarchies,\\nFrance spent a decade at war. Few scientists or engineers emigrated, even\\nduring the Reign of Terror. Mobilized for the national defense, they organized\\nthe conscription of soldiers, collected raw materials for gunpowder,\\nsupervised munitions factories, drew military maps, and invented a secret\\nweapon, reconnaissance balloons. Laplace worked throughout the upheaval\\nand served as the central figure in one of the Revolution’s most important\\nscientific projects, the metric reform to standardize weights and measures. It\\nwas Laplace who named the meter, centimeter, and millimeter.\\nNevertheless, during the 18 months of the Terror, as almost 17,000 French\\nwere executed and half a million imprisoned, his position became\\nincreasingly precarious. Radicals attacked the elite Royal Academy of\\nSciences, and publications denounced him as a modern charlatan and a\\n“Newtonian idolator.” A month after the Royal Academy was abolished\\nLaplace was arrested on suspicion of disloyalty to the Revolution but\\nneighbors interceded and he was released the next day at 4 a.m. A few\\nmonths later he was purged from the metric system commission as not\\n“worthy of confidence as to [his] republican virtues and [his] hatred of\\nkings.”20 His assistant, Jean-Baptiste Delambre, was arrested while\\nmeasuring the meridian for the meter and then released. At one point Laplace\\nwas relieved of his part-time job examining artillery students, only to be\\ngiven the same job at the École Polytechnique. Seven scientists, including\\nseveral of Laplace’s closest friends and supporters, died during the Terror.\\nUnlike Laplace, who took no part in radical politics, they had identified\\nthemselves with particular political factions. The most famous was Antoine\\nLavoisier, guillotined because he had been a royal tax collector. Condorcet,\\ntrying to escape from Paris, died in jail.\\nThe Revolution, however, transformed science from a popular hobby into\\na full-fledged profession. Laplace emerged from the chaos as a dean of\\nFrench science, charged with building new secular educational institutions\\nand training the next generation of scientists. For almost 50 years—from the\\n1780s until his death in 1827—France led world science as no other country\\nhas before or since. And for 30 of those years Laplace was among the most\\ninfluential scientists of all time.\\nAs the best-selling author of books about the celestial system and the law\\nof gravity, Laplace dedicated two volumes to a rising young general,\\nNapoleon Bonaparte. Laplace had launched Napoleon on his military career\\nby giving him a passing exam grade in military school. The two never\\nbecame personal friends, but Napoleon appointed Laplace minister of the\\ninterior for a short time and then appointed him to the largely honorary\\nSenate with a handsome salary and generous expense account that made him\\nquite a rich man. Mme Laplace became a lady-in-waiting to Napoleon’s\\nsister and received her own salary. With additional financing from Napoleon,\\nLaplace and his friend the chemist Claude Berthollet turned their country\\nhomes in Arceuil, outside Paris, into the world’s only center for young\\npostdoctoral scientists.\\nAt a reception in Josephine Bonaparte’s rose garden at Malmaison in\\n1802, the emperor, who was trying to engineer a rapprochement with the\\npapacy, started a celebrated argument with Laplace about God, astronomy,\\nand the heavens.\\n“And who is the author of all this?” Napoleon demanded.\\nLaplace replied calmly that a chain of natural causes would account for the\\nconstruction and preservation of the celestial system.\\nNapoleon complained that “Newton spoke of God in his book. I have\\nperused yours but failed to find His name even once. Why?”\\n“Sire,” Laplace replied magisterially, “I have no need of that\\nhypothesis.”21\\nLaplace’s answer, so different from Price’s idea that Bayes’ rule could\\nprove the existence of God, became a symbol of a centuries-long process that\\nwould eventually exclude religion from the scientific study of physical\\nphenomena. Laplace had long since separated his probability of causes from\\nreligious considerations: “The true object of the physical sciences is not the\\nsearch for primary causes [that is, God] but the search for laws according to\\nwhich phenomena are produced.”22 Scientific explanations of natural\\nphenomena were triumphs of civilization whereas theological debates were\\nfruitless because they could never be resolved.\\nLaplace continued his research throughout France’s political upheavals. In\\n1810 he announced the central limit theorem, one of the great scientific and\\nstatistical discoveries of all time. It asserts that, with some exceptions, any\\naverage of a large number of similar terms will have a normal, bell-shaped\\ndistribution. Suddenly, the easy-to-use bell curve was a real mathematical\\nconstruct. Laplace’s probability of causes had limited him to binomial\\nproblems, but his final proof of the central limit theorem let him deal with\\nalmost any kind of data.\\nIn providing the mathematical justification for taking the mean of many\\ndata points, the central limit theorem had a profound effect on the future of\\nBayes’ rule. At the age of 62, Laplace, its chief creator and proponent, made\\na remarkable about-face. He switched allegiances to an alternate, frequency-\\nbased approach he had also developed. From 1811 until his death 16 years\\nlater Laplace relied primarily on this approach, which twentieth-century\\ntheoreticians would use to almost obliterate Bayes’ rule.\\nLaplace made the change because he realized that where large amounts of\\ndata were concerned, both approaches generally produce much the same\\nresults. The probability of causes was still useful in particularly uncertain\\ncases because it was more powerful than frequentism. But science matured\\nduring Laplace’s lifetime. By the 1800s mathematicians had much more\\nreliable data than they had had in his youth and dealing with trustworthy data\\nwas easier with frequentism. Mathematicians did not learn until the\\nmidtwentieth century that, even with great amounts of data, the two methods\\ncan sometimes seriously disagree.\\nLooking back in 1813 on his 40-year quest to develop the probability of\\ncauses, Laplace described it as the primary method for researching unknown\\nor complicated causes of natural phenomena. He referred to it fondly as his\\nsource of large numbers and the inspiration behind his development and use\\nof generating functions.\\nAnd finally, in the climax of one small part of his career, he proved the\\nelegant, general version of his theorem that we now call Bayes’ rule. He had\\nintuited its principle as a young man in 1774. In 1781 he found a way to use\\nBayes’ two-step process to derive the formula by making certain restrictive\\nassumptions. Between 1810 and 1814 he finally realized what the general\\ntheorem had to be. It was the formula he had been dreaming about, one broad\\nenough to allow him to distinguish highly probable hypotheses from less\\nvalid ones. With it, the entire process of learning from evidence was\\ndisplayed:\\n \\nIn modern terms, the equation says that P(C|E), the probability of a\\nhypothesis (given information), equals Pprior(C), our initial estimate of its\\nprobability, times P(E|C), the probability of each new piece of information\\n(under the hypothesis), divided by the sum of the probabilities of the data in\\nall possible hypotheses.\\nUndergraduates today study Laplace’s first version of the equation, which\\ndeals with discrete events such as coin tosses and births. Advanced and\\ngraduate students and researchers use calculus with his later equation to\\nwork with observations on a continuous range between two values, for\\nexample, all the temperatures between 32 and 33 degrees. With it, Laplace\\ncould estimate a value as being within such and such a range with a\\nparticular degree of probability.\\nLaplace had owned Bayes’ rule in all but name since 1781. The formula,\\nthe method, and its masterful utilization all belong to Pierre Simon Laplace.\\nHe made probability-based statistics commonplace. By transforming a theory\\nof gambling into practical mathematics, Laplace’s work dominated\\nprobability and statistics for a century. “In my mind,” Glenn Shafer of\\nRutgers University observed, “Laplace did everything, and we just read stuff\\nback into Thomas Bayes. Laplace put it into modern terms. In a sense,\\neverything is Laplacean.”23\\nIf advancing the world’s knowledge is important, Bayes’ rule should be\\ncalled Laplace’s rule or, in modern parlance, BPL for Bayes-Price-Laplace.\\nSadly, a half century of usage forces us to give Bayes’ name to what was\\nreally Laplace’s achievement.\\nSince discovering his first version of Bayes’ rule in 1774, Laplace had\\nused it primarily to develop new mathematical techniques and had applied it\\nmost extensively to the social sciences, that is, demography and judicial\\nreform. Not until 1815, at the age of 66, did he apply it to his first love,\\nastronomy. He had received some astonishingly accurate tables compiled by\\nhis assistant Alexis Bouvard, the director of the Paris Observatory. Using\\nLaplace’s probability of causes, Bouvard had calculated a large number of\\nobservations about the masses of Jupiter and Saturn, estimated the possible\\nerror for each entry, and then predicted the probable masses of the planets.\\nLaplace was so delighted with the tables that, despite his aversion to\\ngambling, he used Bayes’ rule to place a famous bet with his readers: odds\\nwere 11,000 to 1 that Bouvard’s results for Saturn were off by less than 1%.\\nFor Jupiter, the odds were a million to one. Space-age technology confirms\\nthat Laplace and Bouvard should have won both bets.\\nLate in his career, Laplace also applied his probability of causes to a\\nvariety of calculations in Earth science, notably to the tides and to changes in\\nbarometric pressure. He used a nonnumerical common-sense version of his\\nprobability of causes to advance his famous nebular hypothesis: that the\\nplanets and their satellites in our solar system originated in a swirl of dust.\\nAnd he compared three hypotheses about the orbits of 100 comets to confirm\\nwhat he already knew: that the comets most probably originate within the\\nsun’s sphere of influence.\\nAfter the fall of Napoleon, France’s new king, Louis XVIII, bestowed the\\nhereditary title of marquis on Laplace, the son of a village innkeeper. And on\\nMarch 5, 1827, at the age of 78, Laplace died, almost exactly 100 years after\\nhis idol, Isaac Newton.\\nEulogies hailed Laplace as the Newton of France. He had brought modern\\nscience to students, governments, and the reading public and had developed\\nprobability into a formidable method for handling unknown and complex\\ncauses of natural phenomena. And in one small, relatively insignificant\\nportion of his lifework he became the first to express and use what is now\\ncalled Bayes’ rule. With it, he updated old knowledge with new, explained\\nphenomena that previous centuries had ascribed to chance or to God’s will,\\nand opened the way for future scientific exploration.\\nYet Laplace had built his probability theory on intuition. As far as he was\\nconcerned, “essentially, the theory of probability is nothing but good common\\nsense reduced to mathematics. It provides an exact appreciation of what\\nsound minds feel with a kind of instinct, frequently without being able to\\naccount for it.”24 Soon, however, scientists would begin confronting\\nsituations that intuition could not easily explain. Nature would prove to be\\nfar more complicated than even Laplace had envisioned. No sooner was the\\nold man buried than critics began complaining about Laplace’s rule.\\n3.\\n \\nmany doubts, few defenders\\n \\nWith Laplace gone, Bayes’ rule entered a tumultuous period when it was\\ndisdained, reformed, grudgingly tolerated, and finally nearly obliterated by\\nbattling theorists. Yet through it all the rule chugged sturdily along, helping to\\nresolve practical problems involving the military, communications, social\\nwelfare, and medicine in the United States and Europe.\\nThe backdrop to the drama was a set of unsubstantiated but widely\\ncirculated charges against Laplace’s reputation. The English mathematician\\nAugustus de Morgan wrote in The Penny Cyclopaedia of 1839 that Laplace\\nfailed to credit the work of others; the accusation was repeated without\\nsubstantiation for 150 years until a detailed study by Stigler concluded it was\\ngroundless. During the 1880s an anti-Napoleonic and antimonarchical\\nFrenchman named Maximilien Marie painted Laplace as a reactionary\\nultraroyalist; several English and American authors adopted Marie’s version\\nunquestioningly. The Encyclopaedia Britannica of 1912 asserted that\\nLaplace “aspired to the role of a politician, and . . . degraded to servility for\\nthe sake of a riband and a title.”1 In his long-lived but rather fanciful\\nbestseller Men of Mathematics the American E. T. Bell titled the chapter on\\nLaplace “From Peasant to Snob . . . Humble as Lincoln, proud as Lucifer.”\\nBell described Laplace as “grandiose,” “snobbish,” “pompous,” “coarse,”\\n“smug,” “intimate with Napoleon,” and “perhaps the most conspicuous\\nrefutation of the pedagogical superstition that noble pursuits necessarily\\nennoble a man’s character.”2 Bell’s book, published in 1937, influenced an\\nentire generation of mathematicians and scientists. In the 1960s an Anglo-\\nAmerican statistician Florence Nightingale David wrote without verification\\nthat Laplace met with “almost universal condemnation.”3 A scholarly\\nAmerican biography by historian Charles Coulston Gillispie and two\\ncollaborators, Robert Fox and Ivor Grattan-Guinness, hemmed and hawed. It\\nbegan by stating categorically that “not a single testimonial bespeaking\\ncongeniality survives” but ended by listing Laplace’s “close personal\\nattachments with other French scientists,” “warm and tranquil family life,”\\nand the help he gave even to critics of his research.4\\nThe realization that Laplace was one of the world’s first modern\\nprofessional scientists emerged slowly. The statistician Karl Pearson, no\\nshrinking violet, called the author of the Britannica article “one of the most\\nsuperficial writers that ever obscured the history of science. . . . Such\\nstatements published by a writer of one nation about one of the most\\ndistinguished men of a second nation, and wholly unsubstantiated by\\nreferences, are in every way deplorable.”5 Modern historians have shown\\nthat many of the disparaging comments about Laplace’s life and work were\\nfalse.\\nPersonal insults aside, Laplace launched a craze for statistics that would\\nultimately inundate both Bayes’ original rule and Laplace’s own version of\\nit. He did so by publicizing in 1827 the then-extraordinary fact that the\\nnumber of dead letters in the Parisian postal system remained roughly\\nconstant from year to year. After the French government published a\\nlandmark series of statistics about the Paris region, it appeared that many\\nirrational and godless criminal activities, including thefts, murders, and\\nsuicides, were also constants. By 1830 stable statistical ratios were firmly\\ndissociated from divine providence, and Europe was swept by a veritable\\nmania for the objective numbers needed by good government.\\nUnsettled by rapid urbanization, industrialization, and the rise of a market\\neconomy, early Victorians formed private statistical societies to study filth,\\ncriminality, and numbers. The chest sizes of Scottish soldiers, the number of\\nPrussian officers killed by kicking horses, the incidence of cholera victims—\\nstatistics were easy to collect. Even women could do it. No mathematical\\nanalysis was necessary or expected. That most of the government bureaucrats\\ncollecting statistics were ignorant of and even hostile to mathematics did not\\nmatter. Facts, pure facts, were the order of the day.\\nGone was the idea that we can use probability to quantify our lack of\\nknowledge. Gone was the search for causes conducted by Bayes, Price, and\\nLaplace. A correspondent admonished the hospital reformer Florence\\nNightingale in 1861, “Again I must repeat my objections to intermingling\\nCausation with Statistics. . . . The statistician has nothing to do with\\ncausation.”6\\n“Subjective” also became a naughty word. The French Revolution and its\\naftermath shattered the idea that all rational people share the same beliefs.\\nThe Western world split between Romantics, who rejected science outright,\\nand those who sought certainty in natural science and were enthralled by the\\nobjectivity of numbers, whether the number of knifings or of marriages at a\\nparticular age.\\nDuring the decade after Laplace’s death, four European revisionists led the\\ncharge against Laplace and probability, the mathematics of uncertainty. John\\nStuart Mill denounced probability as “an aberration of the intellect” and\\n“ignorance . . . coined into science.”7 Objectivity became a virtue,\\nsubjectivity an insult, and the probability of causes a target of skepticism, if\\nnot hostility. Awash in newly collected data, the revisionists preferred to\\njudge the probability of an event according to how frequently it occurred\\namong many observations. Eventually, adherents of this frequency-based\\nprobability became known as frequentists or sampling theorists.\\nTo frequentists Laplace was such a towering target that Thomas Bayes’\\nexistence barely registered. When critics thought of Bayes’ rule, they thought\\nof it as Laplace’s rule and focused their criticism on him and his followers.\\nArguing that probabilities should be measured by objective frequencies of\\nevents rather than by subjective degrees of belief, they treated the two\\napproaches as opposites, although Laplace had considered them basically\\nequivalent.\\nThe reformers denounced Laplace’s pragmatic simplifications as gross\\nabuses. Two of his most popular applications of probability were\\ncondemned wholesale. Laplace had asked: given that the sun has risen\\nthousands of times in the past, will it rise tomorrow? and given that the\\nplanets revolve in similar ways around the sun, is there a single cause of the\\nsolar system? He did not actually use Bayes’ rule for either project, only\\nsimple gambling odds. Sometimes, though, he and his followers began\\nanswering these questions by assuming 50–50 odds. The simplification\\nwould have been defensible had Laplace known nothing about the heavens.\\nBut he was the world’s leading mathematical astronomer, and he understood\\nbetter than anyone that sunrises and nebulae were the result of celestial\\nmechanics, not gambling odds. He had also started his study of male and\\nfemale birthrates with 50–50 odds, although scientists already knew that the\\nlikelihood of a male birth is approximately 0.52.\\nLaplace agreed that reducing scientific questions to chance boosted the\\nodds in favor of his deep conviction that physical phenomena have natural\\ncauses rather than religious ones. He warned his readers about it. His\\nfollowers also sometimes weighted their initial odds heavily in favor of\\nnatural laws and weakened counterexamples. Critics pounded away at the\\nfact that chance was irrelevant to the questions at hand. They identified\\nBayes’ rule with equal priors and damned the entire rule because of them.\\nFew of the critics tried to even imagine other kinds of priors.\\nYears later John Maynard Keynes studied the complaints made about\\nLaplace’s assessment, based on 5,000 years of history, that “it is a bet of\\n1,825,214 to 1 that [the sun] will rise tomorrow.” Summarizing the\\narguments, Keynes wrote that Laplace’s reasoning “has been rejected by\\n[George] Boole on the ground that the hypotheses on which it is based are\\narbitrary, by [John] Venn on the ground that it does not accord with\\nexperience, by [Joseph] Bertrand because it is ridiculous, and doubtless by\\nothers also. But it has been very widely accepted—by [Augustus] de\\nMorgan, by [William] Jevons, by [Rudolf] Lotze, by [Emanuel] Czuber, and\\nby Professor [Karl] Pearson—to name some representative writers of\\nsuccessive schools and periods.”8\\nAmid the dissension, Laplace’s delicate balance between subjective\\nbeliefs and objective frequencies collapsed. He had developed two theories\\nof probability and shown that when large numbers are involved they lead to\\nmore or less the same results. But if natural science was the route to certain\\nknowledge, how could it be subjective? Soon scientists were treating the two\\napproaches as diametric opposites. Lacking a definitive experiment to decide\\nthe controversy and with Laplace demonstrating that both methods often lead\\nto roughly the same result, the tiny world of probability experts would be\\nhard put to settle the argument.\\nResearch into probability mathematics petered out. Within two generations\\nof his death Laplace was remembered largely for astronomy. By 1850 not a\\nsingle copy of his massive treatise on probability was available in Parisian\\nbookstores. The physicist James Clerk Maxwell learned about probability\\nfrom Adolphe Quetelet, a Belgian factoid hunter, not from Laplace, and\\nadopted frequency-based methods for statistical mechanics and the kinetic\\ntheory of gases. Laplace and Condorcet had expected social scientists to be\\nthe biggest users of Bayes’ rule, but they were reluctant to adopt any form of\\nprobability. An American scientist and philosopher Charles Sanders Peirce\\npromoted frequency-based probability during the late 1870s and early 1880s.\\nIn 1891 a Scottish mathematician, George Chrystal, composed an obituary for\\nLaplace’s method: “The laws of . . . Inverse Probability being dead, they\\nshould be decently buried out of sight, and not embalmed in text-books and\\nexamination papers. . . . The indiscretions of great men should be quietly\\nallowed to be forgotten.”9\\nFor the third time Bayes’ rule was left for dead. The first time, Bayes\\nhimself had shelved it. The second time, Price revived it briefly before it\\nagain died of neglect. This time theoreticians buried it.\\nThe funeral was a trifle premature. Despite Chrystal’s condemnation,\\nBayes’ rule was still taught in textbooks and classrooms and used by\\nastronomers because the anti-Bayesian frequentists had not yet produced a\\nsystematic, practical substitute. In scattered niches far from the eyes of\\ndisapproving theoreticians, Bayes bubbled along, helping real-life\\npractitioners assess evidence, combine every possible form of information,\\nand cope with the gaps and uncertainties in their knowledge.\\nInto this breach between theoretical disapproval and practical utility\\nmarched the French army, under the baton of a politically powerful\\nmathematician named Joseph Louis François Bertrand. Bertrand reformed\\nBayes for artillery field officers who dealt with a host of uncertainties: the\\nenemy’s precise location; air density; wind direction; variations among their\\nhand-forged cannons; and the range, direction, and initial speed of\\nprojectiles. In his widely used textbooks Bertrand preached that Laplace’s\\nprobability of causes was the only valid method for verifying a hypothesis\\nwith new observations. He believed, however, that Laplace’s followers had\\nlost their way and must stop their practice of indiscriminately using 50–50\\nodds for prior causes. To illustrate, he told about the foolish peasants of\\nBritanny who, looking for the possible causes of shipwrecks along their\\nrocky coast, assigned equal odds to the tides and to the far more dangerous\\nnorthwest winds. Bertrand argued that equal prior odds should be confined to\\nthose rare cases when hypotheses really and truly were equally likely or\\nwhen absolutely nothing was known about their likelihoods.\\nFollowing Bertrand’s strict standards, artillery officers began assigning\\nequal probabilities only for cannons made in the same factory by roughly the\\nsame staff using identical ingredients and processes under identical\\nconditions. For the next 60 years, between the 1880s and the Second World\\nWar, French and Russian artillery officers fired their weapons according to\\nBertrand’s textbook.\\nBertrand’s strict Bayesian reforms figured in the Dreyfus affair, the\\nscandal that rocked France between 1894 and 1906. Alfred Dreyfus, a\\nFrench Jew and army officer, was falsely convicted of spying for Germany\\nand condemned to life imprisonment. Almost the only evidence against\\nDreyfus was a letter he was accused of having sold to a German military\\nattaché. Alphonse Bertillon, a police criminologist who had invented an\\nidentification system based on body measurements, testified repeatedly that,\\naccording to probability mathematics, Dreyfus had most assuredly written the\\nincriminating letter. Bertillon’s notions of probability were mathematical\\ngibberish, and he developed ever more fantastical arguments. As\\nconservative antirepublicans, Roman Catholics, and anti-Semites supported\\nDreyfus’s conviction, a campaign to exonerate him was organized by his\\nfamily, anticlericals, Jews, and left-wing politicians and intellectuals led by\\nthe novelist Émile Zola.\\nAt Dreyfus’s military trial in 1899, his lawyer called on France’s most\\nillustrious mathematician and physicist, Henri Poincaré, who had taught\\nprobability at the Sorbonne for more than ten years. Poincaré believed in\\nfrequency-based statistics. But when asked whether Bertillon’s document\\nwas written by Dreyfus or someone else, he invoked Bayes’ rule. Poincaré\\nconsidered it the only sensible way for a court of law to update a prior\\nhypothesis with new evidence, and he regarded the forgery as a typical\\nproblem in Bayesian hypothesis testing.\\nPoincaré provided Dreyfus’s lawyer with a short, sarcastic letter, which\\nthe lawyer read aloud to the courtroom: Bertillon’s “most comprehensible\\npoint [is] false. . . . This colossal error renders suspect all that follows. . . . I\\ndo not understand why you are worried. I do not know if the accused will be\\ncondemned, but if he is, it will be on the basis of other proofs. Such\\narguments cannot impress unbiased men who have received a solid scientific\\neducation.”10 At that point, according to the court stenographer, the\\ncourtroom erupted in a “prolonged uproar.” Poincaré’s testimony devastated\\nthe prosecution; all the judges had attended military schools and studied\\nBayes in Bertrand’s textbook.\\nThe judges issued a compromise verdict, again finding Dreyfus guilty but\\nreducing his sentence to five years. The public was outraged, however, and\\nthe president of the Republic issued a pardon two weeks later. Dreyfus was\\npromoted and awarded the Legion of Honor, and government reforms were\\ninstituted to strictly separate church and state. Many American lawyers,\\nunaware that probability helped to free Dreyfus, have considered his trial an\\nexample of mathematics run amok and a reason to limit the use of probability\\nin criminal cases.\\nAs the First World War approached, a French general and proponent of\\nmilitary aviation and tanks, Jean Baptiste Eugène Estienne, developed\\nelaborate Bayesian tables telling field officers how to aim and fire. Estienne\\nalso developed a Bayesian method for testing ammunition. After Germany\\ncaptured France’s industrial base in 1914, ammunition was so scarce that the\\nFrench could not use wasteful frequency-based methods to test its quality.\\nMobilized for the national defense, professors of abstract mathematics\\ndeveloped Bayesian testing tables that required destroying only 20 cartridges\\nin each lot of 20,000. Instead of conducting a predetermined number of tests,\\nthe army could stop when they were sure about the lot as a whole. During the\\nSecond World War, American and British mathematicians discovered similar\\nmethods and called them operations research.\\nBayes’ rule was supposedly still dying on the vine as the First World War\\napproached and the United States faced two emergencies caused by the\\ncountry’s rapid industrialization. In each case self-taught statisticians\\nresorted to Bayes as a tool for making informed decisions, first about\\ntelephone communications and second about injured workers.\\nThe first crisis occurred when the financial panic of 1907 threatened the\\nsurvival of the Bell telephone system owned by American Telephone and\\nTelegraph Company. Alexander Graham Bell’s patents had expired a few\\nyears earlier, and the company had overexpanded. Only the intervention of a\\nbanking consortium led by the House of Morgan prevented Bell’s collapse.\\nAt the same time, state regulators were demanding proof of Bell’s ability\\nto provide better and cheaper service than local competitors. Unfortunately,\\nBell telephone circuits were often overloaded in the late morning and early\\nafternoon, when too many customers tried to place calls at the same time.\\nDuring the rest of the day—80% of the time—Bell’s facilities were under-\\nutilized. No company could afford to build a system to handle every call that\\ncould conceivably be made at peak times.\\nEdward C. Molina, an engineer in New York City, considered the\\nuncertainties involved. Molina, whose family had emigrated from Portugal\\nvia France, was born in New York in 1877. He graduated from a city high\\nschool but, with no money for college, got a job first at Western Electric\\nCompany and then at AT&T’s engineering and research department (later\\ncalled Bell Laboratories). The Bell System of phone companies was\\nadopting a new mathematical approach to problem solving. Molina’s boss,\\nGeorge Ashley Campbell, had studied probability with Poincaré in France\\nbut other employees were learning it from the Encyclopaedia Britannica.\\nMolina taught himself mathematics and physics and became the nation’s\\nleading expert on Bayesian and Laplacean probability.\\nUnlike many others at the time, he realized that “great confusion exists\\nbecause many authorities have failed to distinguish clearly between the\\noriginal Bayes inverse theorem and its subsequent generalization by Laplace.\\nThe general theorem embraces, or brings together, both the data obtained\\nfrom a series of observations and whatever ‘collateral’ information exists in\\nrelation to the observed results.”11 As Molina explained, applied statisticians\\nwere often forced to make quick decisions based on meager observational\\ndata; in such cases, they had to rely on indirect prior knowledge, called\\ncollateral information. This could range from assessments of national or\\nhistoric trends to an executive’s mental health. Methods for utilizing both\\nstatistical and nonstatistical types of evidence were needed.\\nUsing Laplace’s formula, Molina combined his prior information about the\\neconomics of automating Bell telephone systems with data about telephone\\ncall traffic, call length, and waiting time. The result was a cost-effective way\\nfor Bell to deal with uncertainties in telephone usage.\\nMolina then worked on automating Bell’s labor-intensive system. In many\\ncities the company employed 8 to 20% of the female population as telephone\\noperators, switching wires to route calls through trunking facilities to\\ncustomers in distant exchanges. Operators were in short supply, annual\\nturnover in some cities was 100% or more annually, and wages doubled\\nbetween 1915 and 1920. Depending on one’s point of view, the work\\nepitomized either opportunities for women or the inhumane pressure of\\nmodern technology.\\nTo automate the system Molina conceived of the relay translator, which\\nconverted decimally dialed phone numbers into routing instructions. Then he\\nused Bayes to analyze technical information and the economics of various\\ncombinations of switches, selectors, and trunking lines at particular\\nexchanges. After women won the right to vote in 1920, Bell feared a\\nbacklash if it fired all its operators, so it chose an automating method that\\nmerely halved their numbers. Between the world wars, employment of\\noperators dropped from 15 to 7 per 1,000 telephones even as toll call\\nservice increased. Probability assumed an important role in the Bell System,\\nand Bayesian methods were used to develop basic sampling theory.\\nMolina won prestigious awards, but his use of Bayes remained\\ncontroversial among some Bell mathematicians, and he complained he had\\ntrouble publishing his research. Some of his problems may have stemmed\\nfrom his colorful character. He loved model boats, published articles about\\nEdgar Allan Poe’s use of probability, played the piano expertly, and donated\\nto the Metropolitan Opera in New York. He followed the Russo-Japanese\\nwar so avidly that his colleagues nicknamed him, not fondly, General Molina.\\nWhen he independently discovered the Poisson distribution, he called it the\\nMolina distribution until he learned to his embarrassment that Laplace’s\\nprotégé Siméon Denis Poisson had written about it in the 1830s.\\nMolina’s enthusiasm for Bayes-Laplacean probability did not spread to\\nother American corporations. AT&T often regarded his articles about Bayes\\nas proprietary secrets and published them only in in-house publications years\\nafter the fact.\\nWhile Bayes’ rule was helping to save the Bell System, financiers were\\nrushing to build American railroads and industries. Government safety\\nregulations were nonexistent, however, and 1 out of every 318 industrial\\nworkers was killed on the job between 1890 and 1910, and many more were\\ninjured. The country’s labor force suffered more accidents, sickness,\\ninvalidity, premature old age, and unemployment than European workers.\\nYet, unlike most of Europe, the United States had no system for insuring sick\\nand injured workers, and most blue-collar families lived one paycheck away\\nfrom needing charity. Federal judges ruled that injured employees could sue\\nonly if their bosses were personally at fault. In 1898 a U.S. Department of\\nLabor statistician could think of no other social or legal reform in which the\\nUnited States lagged so far behind other nations.\\nThe tide turned as growing numbers of workers joined the American\\nFederation of Labor and as local juries started awarding generous\\nsettlements to their disabled peers. At that point employers decided it was\\ncheaper to treat occupational health as a predictable business expense than to\\ntrust juries and encourage unionization. In an avalanche of no-fault laws\\npassed between 1911 and 1920 all but eight states began requiring employers\\nto insure their workers immediately against occupational injuries and illness.\\nThis was the first, and for decades the only, social insurance in the United\\nStates.\\nThe legislation triggered an emergency. Normally, the price of an\\ninsurance premium reflects years of accumulated data about such factors as\\naccident rates, medical costs, wages, industrywide trends, and particulars\\nabout individual companies. No such data existed in the United States. Not\\neven the most industrialized states had enough occupational health statistics\\nto price policies for all their industries. The industrial powerhouse of New\\nYork State had only enough experience to price policies for machine printers\\nand garment workers; South Carolina had only enough for cotton spinners and\\nweavers; and St. Louis and Milwaukee for beer brewers. In 1909 Nebraska\\nhad only 25 small manufacturers of any kind. As an insurance expert\\nwondered, “When will Nebraska be able to determine its pure premium on\\n‘suspenders without buckles,’ or Rhode Island on ‘butchers’ supplies?’ And\\nyet rates must be quoted for either, and moreover they must be adequate and\\nequitable.”12\\nData from other areas were seldom relevant. Germany had collected\\naccident statistics for 30 years, but its industrial conditions were safer, and\\nbecause its data were collected nationwide, premiums could be based on\\nindustrywide information. But in the United States, data were collected by\\nstate, and Massachusetts’s statistics about shoe-and bootmakers were\\nirrelevant to Nevada’s metal mines and their high fatality rates because, as\\none expert reported, “metal mines are so rare in Massachusetts as snakes in\\nIreland.”13\\nNevertheless, premiums had to be invented—overnight and out of thin air\\n—for almost every sizeable company in the country. It was a nightmare to\\nkeep any mathematically trained statistician awake at night—not that the\\nUnited States had many. Actuaries were often antagonistic to high-level\\nmathematics, and an official complained that accident and fire premiums\\nwere typically priced by untrained clerks who used opinion, what they\\n“euphoniously called underwriting judgment,”14 rather like “woman’s\\nintuition . . . (‘I don’t know why I think so, but I am sure I am right’).”15\\nCompounding the crisis, each state legislature mandated its own unique\\ninsurance system.\\nStill, premiums had to be priced accurately: high enough to keep the\\ninsurance company solvent for the life of its insurees and individualized\\nenough to reward businesses with good safety records. In an extraordinary\\nfeat, Isaac M. Rubinow, a physician and statistician for the American\\nMedical Association, organized by hand the analysis, classification, and\\ntabulation of literally millions of insurance claims, primarily from Europe, as\\na two-or three-year stopgap until each state could accumulate statistics on its\\noccupational casualties. “Every scrap of information,” he said, must be\\nused.16\\nRubinow called together 11 scientifically minded actuaries and formed the\\nCasualty Actuarial Society in 1914. Only seven were college graduates, but\\ntheir goal was lofty: to set casualty fire and workers’ compensation\\ninsurance on a sound mathematical basis. Rubinow became the organization’s\\nfirst president but left almost immediately when the insurance industry and\\nthe American Medical Association opposed extending social insurance to the\\nsick and aged. Rumors swirled that Rubinow, a Jewish immigrant from\\nRussia, had “socialist tendencies.”17\\nAlbert Wurts Whitney, a specialist in insurance mathematics from\\nBerkeley, replaced Rubinow on a workers’ compensation committee.\\nWhitney was an alumnus of Beloit College and had no graduate degrees but\\nhad taught mathematics and physics at the universities of Chicago, Nebraska,\\nand Michigan. At the University of California in Berkeley he had taught\\nprobability for future insurance professionals. Though not as steeped in the\\noriginal mathematical literature as Molina at Bell Labs, Whitney was\\nfamiliar with the theorems of both Laplace and Bayes and knew he should\\nuse one of them. He understood something else too. The equations were too\\ncomplicated for the fledgling workers’ compensation movement.\\nOne afternoon in the spring of 1918, during the First World War, Whitney\\nand his committee worked for hours stripping away every possible\\nmathematical complication and substituting dubious simplifications. They\\nagreed to assume that each business in a particular industrial class (for\\nexample, all residential roofers) faced equal risks. They would also consider\\nevery actuary equally skilled at supplementing injury data with subjective\\njudgments about “nonstatistical” or “exogenous material,” such as a business\\nowner’s drinking habits. This was Bayes’ rule where industrywide\\nexperience was used as the basis for the prior and the local business’s\\nhistory for the new data. Whitney cautioned, “We know that the [subjective]\\nrates for some classifications are more reliable than for others. [But] it is\\ndoubtful whether it is expedient in practice to recognize this fact.”18\\nBy the end of the afternoon the committee had decided to base the price of\\na customer’s premium almost exclusively on the experience of the client’s\\nbroad classification. Thus a machine shop’s premium could be based on data\\nfrom other, similar businesses or, if it was large enough, its own experience.\\nCombining data from related businesses concentrated the numbers, pulling\\nthem closer to the mean and making them more accurate, a subtle “shrinking”\\neffect that Charles Stein would explain in the 1950s. What remained was a\\nstunningly simple formula that a clerk could compute, an underwriter could\\nunderstand, and a salesman could explain to his customers. The committee\\nproudly named its creation Credibility.\\nFor the next 30 years the first social insurance system in the United States\\nrelied on this simplified Bayesian system. In a classic understatement an\\nactuary admitted, “Of course [Credibility’s] Z = P/(P+K) is not so great a\\ndiscovery as E = mc2 nor as unalterably true, but it has made life much easier\\nfor insurance men for generations.”19 Some 50 years later statisticians and\\nactuaries would be surprised to discover the Bayesian roots of Credibility.\\nNext, Whitney worked out methods for weighting each datum as to its\\nsubjective believability. Soon actuaries were adventuring “beyond anything\\nthat has been proven mathematically. The only demonstration they can make,”\\nan actuary reported later, “is that, in actual practice, it works.”20\\nSkeptical state officials and insurance underwriters sometimes wondered\\nwhere these strange Credibility figures came from. One insurance\\ncommissioner demanded, “You have supported everything else in the filing\\nwith actual experience, where is the experience supporting your Credibility\\nfactor?”21 Actuaries hastily changed the subject. When Whitney was asked\\nwhere he got the mathematical principles underlying Credibility, he pointed\\nflippantly to a colleague’s home. “In Michelbacher’s dining room,” he said.\\nCredibility theory was a practical American response to a uniquely\\nAmerican problem, and it became a cornerstone of casualty and property\\ninsurance. As claims accumulated, actuaries could check the accuracy of\\ntheir premiums by comparing them with actual claims. In 1922 actuaries\\ngained access to an enormous pool of occupational data compiled by the\\nNational Council for Compensation Insurance. As the years passed,\\npracticing actuaries had less and less need to understand the relationship\\nbetween Credibility and Bayes.\\nWhile the United States was using Bayes’ theorem for business decisions and\\nFrance was adapting it for the military, eugenics was shifting Bayes’ story\\nback to its birthplace in Great Britain. There Karl Pearson and Ronald Fisher\\nwere developing statistics—the mathematics of uncertainties—into the first\\ninformation science. Early in the twentieth century, as they created new ways\\nto study biology and heredity, theoreticians would change their attitudes\\ntoward Bayes’ rule from tepid toleration to outright hostility.\\nKarl Pearson (I repeat his first name because his son Egon figures in\\nBayes’ story too) was a zealous atheist, socialist, feminist, Darwinist,\\nGermanophile, and eugenicist. To save the British Empire, he believed the\\ngovernment should encourage the upper middle class to procreate and the\\npoor to abstain. Karl Pearson ruled Britain’s 30-odd statistical theorists for\\nyears. In the process he introduced two generations of applied\\nmathematicians to the kind of feuding and professional bullying generally\\nseen only on middleschool playgrounds.\\nContentious, unquenchably ambitious, and craggily determined, Karl\\nPearson was ambivalent about few things, but Bayes’ rule was one of them.\\nUniform priors and subjectivity made him nervous. With few other tools\\navailable to statisticians, however, he concluded sadly that “the practical\\nman will . . . accept the results of inverse probability of the Bayes-Laplace\\nbrand till better are forthcoming.”22 As Keynes said in A Treatise on\\nProbability in 1921, “There is still about it for scientists a smack of\\nastrology, of alchemy.” Four years later the American mathematician Julian\\nL. Coolidge agreed: “We use Bayes’ formula with a sigh, as the only thing\\navailable under the circumstances.”23\\nAnother geneticist, Ronald Aylmer Fisher, eventually contested Karl\\nPearson’s statistical crown and dealt Bayes’ rule a near-lethal blow. If\\nBayes’ story were a TV melodrama, it would need a clear-cut villain, and\\nFisher would probably be the audience’s choice by acclamation.\\nHe didn’t look the part. Even with thick glasses he could barely see three\\nfeet and had to be rescued from oncoming buses. His clothes were so\\nrumpled that his family thought he looked like a tramp; he smoked a pipe\\neven while swimming; and if a conversation bored him, he sometimes\\nremoved his false teeth and cleaned them in public.\\nFisher interpreted any question as a personal attack, and even he\\nrecognized that his fiery temper was the bane of his existence. A colleague,\\nWilliam Kruskal, described Fisher’s life as “a sequence of scientific fights,\\noften several at a time, at scientific meetings and in scientific papers.”24 In a\\nbasically sympathetic rendering of Fisher’s career, the Bayesian theorist\\nJimmie Savage said he “sometimes published insults that only a saint could\\nentirely forgive. . . . Fisher burned even more than the rest of us . . . to be\\noriginal, right, important, famous, and respected. And in enormous measure,\\nhe achieved all of that, though never enough to bring him peace.”25 Part of\\nFisher’s frustration may have arisen from the fact that, on many statistical\\nmatters, he was correct.\\nFisher was 16 when the family business collapsed. At Cambridge on a\\nscholarship, he became the top mathematics student in his class and, in 1911,\\nthe founder and chair of the Cambridge University Eugenics Society. A few\\nyears later he solved in one page a problem Karl Pearson had struggled over\\nfor years; Pearson thought Fisher’s solution was rubbish and refused to\\npublish it in his prestigious journal Biometrika. The two continued to feud as\\nlong as they lived. But in straightening out inconsistencies in Karl Pearson’s\\nwork, Fisher pioneered the first comprehensive and rigorous theory of\\nstatistics and set it on its mathematical and anti-Bayesian course.\\nThe enmity between these two volatile men is striking because both were\\nfervent eugenicists who believed that the careful breeding of British\\nsupermen and superwomen would improve the human population and the\\nBritish Empire. To help support his wife and eight children on a subsistence\\nfarm, Fisher accepted funds from a controversial source, Charles Darwin’s\\nson Leonard, who, as honorary president of the Eugenics Education Society,\\nadvocated the detention of “inferior types, . . . the sexes being kept apart” to\\nprevent them from bearing children.26 In return for his financial help, Fisher\\npublished more than 200 reviews in Darwin’s magazine between 1914 and\\n1934.\\nIn 1919, few jobs were available in statistics or eugenics but Fisher\\nlanded a position analyzing fertilizers at Rothamsted Agricultural Experiment\\nStation. Other statistical pioneers worked in breweries, cotton thread and\\nlight bulb factories, and the wool industry. Fisher’s job was analyzing\\nvolumes of data compiled over decades about horse manure, chemical\\nfertilizers, crop rotation, rainfall, temperature, and yields. “Raking over the\\nmuck-heap,” he called it.27 At first, like Karl Pearson, Fisher used Bayes.\\nBut during afternoon teas at Rothamsted soil scientists confronted Fisher with\\nnew kinds of literally down-to-earth problems. Fascinated, Fisher worked\\nout better ways to design experiments.\\nOver the years he pioneered randomization methods, sampling theory, tests\\nof significance, maximum likelihood estimation, analysis of variance, and\\nexperimental design methods. Thanks to Fisher, experimental scientists, who\\nhad traditionally ignored statistical methods, learned to incorporate them\\nwhen designing their projects. As the twentieth century’s statistical\\nmagistrate, Fisher often ended lengthy discussions with a one-word verdict:\\n“Randomize.” In 1925 he published a revolutionary manual of new\\ntechniques, Statistical Methods for Research Workers. A cookbook of\\ningenious statistical procedures for nonstatisticians, it turned frequency into\\nthe de facto statistical method. His first manual sold 20,000 copies, and a\\nsecond went through seven editions before Fisher’s death in 1962. His\\nanalysis of variance, which tells how to separate the effects of various\\ntreatments, has become one of the natural sciences’ most important tools. His\\nsignificance test and its p-values would be used millions of times even as,\\nover the years, it became increasingly controversial. No one today can\\ndiscuss statistics—what he called “mathematics applied to observational\\ndata”—without using some of Fisher’s vocabulary.28 Many of his ideas were\\nsolutions to computational problems caused by the limitations of the era’s\\ndesk calculators. Soon statistical departments rang with the music of bells\\nactivated by mechanical calculating machines at every step of their Fisherian\\ncalculations.\\nFisher himself became a superb geneticist who did mathematical statistics\\non the side. He filled his house with cats, dogs, and thousands of mice for\\ncross-breeding experiments; he could document each animal’s pedigree for\\ngenerations. Unlike Bayes, Price, and Laplace, he did not need to supplement\\ninadequate or conflicting observations with hunches or subjective judgments.\\nHis experiments produced small data sets and subsets tightly focused to\\nanswer a single question with rigorous mathematics. He dealt with few\\nuncertainties or gaps in data and could compare, manipulate, or repeat his\\nexperiments as needed. Thanks to the problems he analyzed, Fisher redefined\\nmost uncertainties not by their relative probabilities but by their relative\\nfrequencies. He brought to fruition Laplace’s frequency-based theories, the\\nmethods Laplace himself preferred toward the end of his life.\\nAfter 15 years at Rothamsted, Fisher moved, first, to University College\\nLondon and then to Cambridge as professor of genetics. Today, statisticians\\nregard him as one of the great minds of the twentieth century and a “mythical\\naura” surrounds both him and Karl Pearson.29 The aura around Fisher is a\\ntrifle tarnished, though. He left his family on the farm with a precarious,\\nbarebones allowance. As a colleague wrote, “If only . . . if only . . . RAF had\\nbeen a nicer man, if only he had taken pains to be clearer and less enigmatic,\\nif only he had not been obsessed with ambition and personal bitternesses. If\\nonly. But then we might not have had Fisher’s magnificent achievements.”30\\nLashing out at Bayes’ rule, Fisher called it an “impenetrable jungle” and\\n“a mistake, perhaps the only mistake to which the mathematical world has so\\ndeeply committed itself.”31 Equal priors constituted “staggering falsity.”32\\n“My personal conviction,” he declared, is “that the theory of inverse\\nprobability is founded upon an error, and must be wholly rejected.”33 A\\nscholarly statistician, Anders Hald, politely lamented “Fisher’s arrogant\\nstyle of writing.”34 Although Fisher’s work had many Bayesian elements, he\\nbattled Bayes for decades and rendered it virtually taboo among respectable\\nstatisticians. His constant readiness to quarrel made it hard for opponents to\\nengage him. Bayesians were not alone in concluding that Fisher adopted\\nsome of his positions “simply to avoid agreeing with his opponents.”35\\nDriven by the need to deal with uncertainties and save time and money,\\nfrequency-based sampling theorists enjoyed a golden age during the 1920s\\nand 1930s. Fisher liberated scientists to summarize and draw conclusions\\nwithout having to deal with Bayes’ messy prior prejudices and hunches. And\\nthanks to his insistence on mathematical rigor, statistics was becoming, if not\\nquite “real mathematics,” at least a distinct mathematical discipline,\\nmathematics as applied to data.\\nThe feud between Karl Pearson and Fisher entered its second generation\\nwhen Karl’s son Egon became another victim of Fisher’s wrath. Unlike his\\nfather, Egon Pearson was a modest, even self-effacing gentleman. At first,\\nlike his father and Fisher earlier in their careers, Egon Pearson frequently\\nused Bayes’ rule. In 1925 he published the most extensive exploration of\\nBayesian methods conducted between Laplace in the 1780s and the 1960s.\\nUsing priors for a series of seemingly whimsical experiments, he calculated\\nsuch probabilities as the fraction of London taxicabs with LX license plates;\\nmen smoking pipes on Euston Road; horse-drawn vehicles on Gower Street;\\nchestnut colts born to bay mares; and hounds with fawn-spotted coats. His\\nexperiments had a serious purpose, though. He was looking at all sorts of\\nbinomial problems, “working backwards” to find “nature’s prior,” one that\\nanyone with a binomial problem could use. He concluded that more data had\\nto be collected, but no one took up the challenge. Instead, Egon Pearson\\nbusied himself trying to make Fisher’s work more mathematically rigorous,\\nthereby enraging both Fisher and his father.\\nEgon Pearson and a Polish mathematician, Jerzy Neyman, teamed up in\\n1933 to develop the Neyman-Pearson theory of hypothesis testing. Until then,\\nstatisticians had tested one hypothesis at a time and either accepted or\\nrejected it without considering alternatives. Egon Pearson’s idea was that the\\nonly correct reason for rejecting a statistical hypothesis was to accept a more\\nprobable one. As he, Neyman, and Fisher developed it, the theory became\\none of the twentieth century’s most influential pieces of applied mathematics.\\nEgon Pearson was afraid of contradicting his father, however. His “fears of\\nK.P. and R.A.F.” precipitated a psychological crisis in 1925 and 1926: “I\\nhad to go through the painful stage of realizing that K.P. could be wrong . . .\\nand I was torn between conflicting emotions: a. finding it difficult to\\nunderstand R. A. F., b. hating him for his attacks on my paternal ‘god,’ c.\\nrealizing that in some things at least he was right.”36 To placate his father,\\nEgon gave up the woman he loved; they married many years later. And he\\nwas so afraid to submit articles to his father’s Biometrika that he and\\nNeyman published their own journal, Statistical Research Memoirs, for two\\nyears between 1936 and 1938 and ceased publication only after Karl\\nPearson died.\\nOver the years Fisher, Egon Pearson, and Neyman would develop a host of\\npowerful statistical techniques. Fisher and Neyman became fervent anti-\\nBayesians who limited themselves to events that could theoretically be\\nrepeated many times; regarded samples as their only source of information;\\nand viewed each new set of data as a separate problem, to be used if the data\\nwere powerful enough to provide statistically significant conclusions and\\ndiscarded if not. As anti-Bayesians, they banned subjective priors, although\\nthey did not argue with Bayes’ theorem when the priors were known; the\\ndifficulties and controversies arose when the prior probabilities were\\nunknown. Neyman, for example, denounced Bayes’ equal-prior shortcut as\\n“illegitimate.”37\\nIn addition, in a deep philosophical divide between the two methods,\\nfrequentists asked for the probability of a data set given full knowledge of its\\nprobable causes, while Bayesians could ask for better knowledge of the\\ncauses in light of the data. Bayesians could also consider the probability of a\\nsingle event, like rain tomorrow; encapsulate subjective information in\\npriors; update their hunches with new information; and include every datum\\npossible because each one might change the answer by a small amount.\\nIn time, however, Fisher and Neyman also split asunder, starting yet\\nanother juicy 30-year feud. Their views on testing, which could be an order\\nof magnitude apart, formed the crux of their bitter fight. According to\\nNeyman, though, the argument began because Fisher demanded that Neyman\\nlecture only from Fisher’s book. When Neyman refused, Fisher promised to\\noppose him “in all my capacities.”\\nIn an argument during a meeting of the Royal Society on March 28, 1934, a\\nsecretary took the customary word-for-word notes for verbatim publication.\\nNeyman presented a paper arguing that the Latin square (a technique invented\\nby Fisher for experimental design) was biased. Fisher immediately marched\\nto a blackboard, drew a Latin square and, using a simple argument, showed\\nthat Neyman was wrong. But Fisher was far from polite. He complained\\nsarcastically that “he had hoped that Dr. Neyman’s paper would be on a\\nsubject with which the author was fully acquainted, and on which he could\\nspeak with authority. . . . Dr. Neyman had been somewhat unwise in his\\nchoice of topics.” Fisher couldn’t seem to stop. He kept on: “Dr. Neyman had\\narrived or thought he had arrived at . . . Apart from its theoretical defects . . .\\nthe apparent inability to grasp the very simple argument . . . How had Dr.\\nNeyman been led by his symbolism to deceive himself on such a simple\\nquestion?” and on and on.38\\nBy 1936 the feud between the Neyman camp and the Fisherites was an\\nacademic cause célèbre. The two groups occupied different floors of the\\nsame building at University College London but they never mixed. Neyman’s\\ngroup met in the common room for India tea between 3:30 and 4:15 p.m.\\nFisher’s group sipped China tea from then on. They were fighting over\\nscraps. The statistics building had no potable water, so little electricity that\\nblackboards were unreadable after dark, and so little heat in winter that\\novercoats were worn inside.\\nGeorge Box, who straddled both groups (he studied under Egon Pearson,\\nbecame a Bayesian, and married one of Fisher’s daughters), said that Fisher\\nand Neyman “could both be very nasty and very generous at times.” Because\\nNeyman was decision-oriented and Fisher was more interested in scientific\\ninference, their methodologies and types of applications were different. Each\\nwas doing what was best for the problems he was working on, but neither\\nside made any attempt to understand what the other was doing. A popular in-\\nhouse riddle described the situation: “What’s the collective noun for a group\\nof statisticians?” “A quarrel.”39\\nShortly before the Second World War, Neyman moved to the University of\\nCalifornia at Berkeley and transformed it into an anti-Bayesian powerhouse.\\nThe Neyman-Pearson theory of tests became the Berkeley school’s glory and\\nemblem. The joke, of course, was that the University of Berkeley’s\\nnamesake, the Bishop Berkeley, had disapproved of calculus and\\nmathematicians.\\nThe golden age of probability theory had turned into a double-fronted\\nattack by two camps of warring frequentists united in their abhorrence of\\nBayes. In the maelstrom, the lack of reasoned discourse among the leaders of\\nstatistical mathematics delayed the development of Bayes’ rule for decades.\\nCaught in the infighting, the rule was left to find its way alone, stymied and\\ndisparaged.\\nYet even as the frequentists’ assault laid it low, the first glimmerings of a\\nrevival flickered here and there, quietly and almost unnoticed. In a\\nremarkable confluence of thinking, three men in three different countries\\nindependently came up with the same idea about Bayes: knowledge is indeed\\nhighly subjective, but we can quantify it with a bet. The amount we wager\\nshows how much we believe in something.\\nIn 1924 a French mathematician, Émile Borel, concluded that a person’s\\nsubjective degree of belief could be measured by the amount he was willing\\nto bet. Borel argued that applying probability to real problems, such as\\ninsurance, biology, agriculture, and physics, was far more important than\\nmathematical theorizing. He believed in rational behavior and lived as he\\ntaught. At the height of a scandal over Marie Curie’s possible affair with\\nanother scientist, Borel sheltered her and her daughters; in reaction, the\\nminister of public instruction threatened to fire him from his teaching post at\\nthe École Normale Supérieur, a leading school of mathematics and science.40\\nBetween the two world wars, Borel was a member of the French Chamber of\\nDeputies and a minister of the navy and helped direct national policy toward\\nresearch and education. Imprisoned briefly during the Second World War by\\nthe pro-Nazi Vichy government, he later received the Resistance Medal.\\nTwo years after Borel’s suggestion a young English mathematician and\\nphilosopher named Frank P. Ramsey made the same suggestion. Before he\\ndied at the age of 26 following surgeries for jaundice, he wondered how we\\nshould make decisions in the face of uncertainty. In an informal talk to\\nstudents at the Moral Sciences Club at Cambridge University in 1926\\nRamsey suggested that probability was based on personal beliefs that could\\nbe quantified by a wager. Such extreme subjectivity broke radically with\\nprevious thinkers like Mill, who had denounced subjective probabilities as\\nthe abhorrent quantification of ignorance.\\nRamsey, who in his brief career also contributed to economics, logic, and\\nphilosophy, believed uncertainty had to be described in terms of probability\\nrather than by tests and procedures. By talking about a measure of belief as a\\nbasis for action and by introducing a utility function and the maximization of\\nexpected utility, he showed how to act in the face of uncertainty. Neither\\nBayes nor Laplace had ventured into the world of decisions and behavior.\\nBecause Ramsey worked in Cambridge, England, the history of Bayes’ rule\\nmight have been quite different had he lived longer.\\nAt almost the same time as Borel and Ramsey, an Italian actuary and\\nmathematics professor, Bruno de Finetti, also suggested that subjective\\nbeliefs could be quantified at the racetrack. He called it “the art of\\nguessing.”41 De Finetti had to deliver his first important paper in Paris\\nbecause the most powerful Italian statistician, Corrado Gini, regarded his\\nideas as unsound. (In Gini’s defense, de Finetti told colleagues he was\\nconvinced Gini had “the evil eye.”)42 De Finetti, considered the finest Italian\\nmathematician of the twentieth century, wrote about financial economics and\\nis credited with putting Bayes’ subjectivity on a firm mathematical\\nfoundation.\\nNot even probability experts, however, noticed these outbursts of\\nsubjective betting. During the 1920s and 1930s the anti-Bayesian trio of\\nFisher, Egon Pearson, and Neyman attracted all the attention. Ramsey, Borel,\\nand de Finetti worked outside English-speaking statistical circles.\\nAnother outsider carved out a safe haven for Bayes in paternity law, a\\nsmall and inconspicuous corner of the American judicial system. Paternity\\nlaw asks, Did this man father this child? And if so, how much should he pay\\nin child support? In 1938 a Swedish professor of genetics and psychiatry\\nnamed Erik Essen-Möller developed an index of probability that was\\nmathematically equivalent to Bayes’ theorem. For 50 years, until DNA\\nprofiling became available, American lawyers used the Essen-Möller index\\nwithout knowing its Bayesian paternity. In the U.S. Uniform Parentage Act,\\nBayes even became a model for state legislation. Because paternity lawyers\\nbegan by assigning 50–50 odds to the man’s innocence, the index favored\\nfathers even though Essen-Möller believed that “mothers more frequently\\naccuse true than false fathers.”43 Bayesian paternity law was also used in\\nimmigration and inheritance cases and in cases where a child was born as a\\nresult of rape. Today, DNA evidence typically gives paternity probabilities\\nof 0.999 or more.\\nYet another outsider, Lowell J. Reed, a medical researcher at Johns\\nHopkins University in Baltimore, dramatized the shortcomings of frequentism\\nand the value of Bayes in 1936. Reed, a member of the department of\\nbiostatistics, wanted to determine the X-ray dosages that would kill\\ncancerous tumors but leave patients unharmed. He had no precise exposure\\nrecords, however, and the effects of low doses were not understood. Reed\\nnormally used frequency methods and repeated tests on fruit flies, protozoa,\\nand bacteria; but to ascertain doses for humans he would have to use\\nexpensive mammals. With Bayes, he determined the most therapeutic doses\\nfor human cancer patients by sacrificing a relatively small number of cats,\\n27. But Reed worked outside the statistical mainstream, used Bayes only\\noccasionally, and had little influence on statistics. Even Ramsey, Borel, de\\nFinetti, and Essen-Möller had to wait decades before the importance of their\\nwork was recognized.\\nIt was a geophysicist, Harold Jeffreys, who almost singlehandedly kept\\nBayes alive during the anti-Bayesian onslaught of the 1930s and 1940s.\\nCambridge University students liked to joke that they had the world’s two\\ngreatest statisticians, although one was a professor of astronomy and the\\nother a professor of genetics. Fisher was the geneticist. Jeffreys was an Earth\\nscientist who studied earthquakes, tsunamis, and tides. He said he qualified\\nfor the astronomy department “because Earth is a planet.”44\\nThanks in large part to Jeffreys’s quiet, gentlemanly personality he and\\nFisher became friends even though they disagreed, irrevocably and\\nvociferously, over Bayes. Jeffreys said he told Fisher that “on most things we\\nshould agree and when we disagreed, we would both be doubtful. After that,\\nFisher and I were great friends.”45 For example, Jeffreys believed that\\nFisher’s maximum likelihood method was basically Bayesian, and he often\\nused it because with large samples the prior did not matter and the two\\ntechniques produced approximately the same results. They differed, however,\\nwhen small amounts of data were involved. Years later others would\\ndramatize situations where Jeffreys’s and Fisher’s significance test results\\ncan differ by an order of magnitude.\\nAside from their views on Bayes, Jeffreys and Fisher had much in\\ncommon. Both were practicing scientists who manipulated statistical data;\\nneither was a mathematician or statistician. Both were educated at\\nCambridge; Jeffreys, in fact, never left and was a fellow there for 75 years,\\nlonger than any other professor. Neither man was outgoing; both were\\nappalling lecturers, their feeble voices inaudible beyond a few rows, and a\\nstudent once counted Jeffreys mumbling “er” 71 times in five minutes. Both\\nwere knighted for their work.\\nOf the two, Jeffreys led the richer personal life. At the age of 49 he\\nmarried his longtime collaborator, the mathematician Bertha Swirles; they\\nproofread their monumental Methods of Mathematical Physics during all-\\nnight stints as air raid wardens during the Second World War. He enjoyed\\nannotating discrepancies in detective novels, singing tenor in choral\\nsocieties, botanizing, walking, traveling, and, until he was 91, bicycling to\\nwork.\\nLike Laplace, Jeffreys studied the formation of the Earth and planets in\\norder to understand the origin of the solar system. He became involved in\\nstatistics because he was interested in how earthquake waves travel through\\nthe Earth. A major earthquake generates seismic waves that can be recorded\\nthousands of miles away. By measuring their arrival times at different\\nstations, Jeffreys could work back to determine the earthquake’s likely\\nepicenter and the likely composition of the Earth. It was a classic problem in\\nthe inverse probability of causes. In 1926 Jeffreys inferred that Earth’s\\ncentral core is liquid—probably molten iron, probably mixed with traces of\\nnickel.\\nAs one historian said, “Perhaps in no other field were as many remarkable\\ninferences drawn from so ambiguous and indirect data.”46 Signals were often\\ndifficult to interpret, and seismograph machines differed greatly.\\nEarthquakes, which often occurred far apart under very different conditions,\\nwere hardly repeatable. Jeffreys’s conclusions involved far more uncertainty\\nthan Fisher’s breeding experiments, which were designed to answer precise,\\nrepeatable questions. Like Laplace, Jeffreys spent a lifetime updating his\\nobservations with new results. He wrote, “The propositions that are in doubt\\n. . . constitute the most interesting part of science; every scientific advance\\ninvolves a transition from complete ignorance, through a stage of partial\\nknowledge based on evidence becoming gradually more conclusive, to the\\nstage of practical certainty.”47\\nWorking on his office floor ankle-deep with papers, Jeffreys composed\\nThe Earth: Its Origin, History, and Physical Constitution, the standard\\nwork on the planet’s structure until plate tectonics was discovered in the\\n1960s. (Sadly, while Jeffreys played the hero defending Bayes, he opposed\\nthe idea of continental drift as late as 1970, when he was 78, because he\\nthought it meant the continents would have to push their way through viscous\\nliquid.)\\nWhile analyzing earthquakes and tsunamis, Jeffreys worked out a new,\\nobjective form of Bayes for scientific applications and devised formal rules\\nfor selecting priors. As he put it, “Instead of trying to see whether there was\\nany more satisfactory form of the prior probability, a succession of authors\\nhave said that the prior probability is nonsense and therefore that the\\nprinciple of inverse probability, which cannot work without [priors], is\\nnonsense too.”48\\nJeffreys considered probability appropriate for all uncertainty, even\\nsomething as apparently certain as a scientific law, whereas frequentists\\nusually restricted probability to the uncertainties associated with\\ntheoretically repeatable data. As the statistician Dennis Lindley wrote,\\nJeffreys “would admit a probability for the existence of the greenhouse\\neffect, whereas most [frequentist] statisticians would not and would confine\\ntheir probabilities to the data on CO2, ozone, heights of the oceans, etc.”49\\nJeffreys was particularly annoyed by Fisher’s measures of uncertainty, his\\n“p-values” and significance levels. The p-value was a probability statement\\nabout data, given the hypothesis under consideration. Fisher had developed\\nthem for dealing with masses of agricultural data; he needed some way to\\ndetermine which should be trashed, which filed away, and which followed\\nup on immediately. Comparing two hypotheses, he could reject the chaff and\\nsave the wheat.\\nTechnically, p-values let laboratory workers state that their experimental\\noutcome offered statistically significant evidence against a hypothesis if the\\noutcome (or a more extreme outcome) had only a small probability (under the\\nhypothesis) of having occurred by chance alone.\\nJeffreys thought it very strange that a frequentist considered possible\\noutcomes that had not occurred. He wanted to know the probability of his\\nhypothesis about the epicenter of a particular earthquake, given his\\ninformation about the arrival times of tsunamis caused by the earthquake.\\nWhy should possible outcomes that had not occurred make anyone reject a\\nhypothesis? Few researchers repeated—or could repeat—an experiment at\\nrandom many, many more times. “Imaginary repetitions,” a critic called them.\\nBayesians considered data as fixed evidence, not as something that can vary.\\nJeffreys certainly could not repeat a particular earthquake. Moreover, the p-\\nvalue is a statement about data, whereas Jeffreys wanted to know about his\\nhypothesis given his data. As a result, Jeffreys proposed using only observed\\ndata with Bayes’ rule to compute the probability that the hypothesis was true.\\nNewton, as Jeffreys pointed out, derived his law of gravity 100 years\\nbefore Laplace proved it by discovering Jupiter’s and Saturn’s 877-year\\ncycle: “There has not been a single date in the history of the law of\\ngravitation when a modern significance test would not have rejected all laws\\n[about gravitation] and left us with no law.”50\\nBayes, on the other hand, “makes it possible to modify a law that has stood\\ncriticism for centuries without the need to suppose that its originator and his\\nfollowers were useless blunderers.”51\\nJeffreys concluded that p-values fundamentally distorted science.\\nFrequentists, he complained, “appear to regard observations as a basis for\\npossibly rejecting hypotheses, but in no case for supporting them.”52 But\\nodds are that at least some of the hypotheses Fisher rejected were worth\\ninvestigating or were actually true.\\nA frequentist who tests a precise hypothesis and obtains a p-value of .04,\\nfor example, can consider that significant evidence against the hypothesis.\\nBut Bayesians say that even with a .01 p-value (which many frequentists\\nwould see as extremely strong evidence against a hypothesis) the odds in its\\nfavor are still 1 to 9 or 10—“not earth-shaking,” says Jim Berger, a Bayesian\\ntheorist at Duke University. P-values still irritate Bayesians. Steven N.\\nGoodman, a distinguished Bayesian biostatistician at Johns Hopkins Medical\\nSchool, complained in 1999, “The p-value is almost nothing sensible you can\\nthink of. I tell students to give up trying.”53\\nJeffreys was making Laplace’s probability of causes useful for practicing\\nscientists, even as Fisher was doing the same for Laplace’s frequency-based\\nmethods. The difference was that Fisher used the word “Bayes” as an insult,\\nwhile Jeffreys called it the Pythagorean theorem of probability theory. As the\\nfirst since Laplace to apply formal Bayesian theory to a variety of important\\nscientific problems, Jeffreys became the founder of modern Bayesian\\nstatistics.\\nStatistically, the lines were drawn. Jeffreys and Fisher, two otherwise\\ncordial Cambridge professors, embarked on a two-year debate in the Royal\\nSociety’s Proceedings. Jeffreys may have been shy and uncommunicative,\\nbut when he was sure of himself he dug in, placidly but implacably. Fisher\\nremained his usual “volcanic and paranoid” self.54 Both men were\\nmagnificent scientists, the world’s leading statisticians, and each used the\\nmethods best suited to his respective field. Yet neither could see the other’s\\npoint of view. Like gladiators of old, they hurled impassioned articles back\\nand forth, criticizing one another and issuing formal rejoinders, probing\\nrebuttals, and brilliant clarifications—until Royal Society editors threw up\\ntheir hands in exasperation and ordered the warriors to cease and desist.\\nAfter the grand debate, Jeffreys wrote a monumental book, Theory of\\nProbability, which remained for years the only systematic explanation of\\nhow to apply Bayes to scientific problems. Fisher complained publicly that\\nJeffreys makes “a logical mistake on the first page which invalidates all the\\n395 formulae in his book.”55 The mistake, of course, was to use Bayes’\\ntheorem. Summarizing Jeffreys’s books, Lindley said, “De Finetti is a master\\nof theory, Fisher a master of practice, but Jeffreys is brilliant at both.”56\\nThe Fisher–Jeffreys debate ended inconclusively. Practically speaking,\\nhowever, Jeffreys lost. For the next decade and for a variety of reasons\\nfrequentism almost totally eclipsed Bayes and the inverse probability of\\ncauses.\\nFirst, Fisher was persuasive in public, while the mild-mannered Jeffreys\\nwas not: people joked that Fisher could win an argument even when Jeffreys\\nwas right. Another factor was that social scientists and statisticians needed\\nobjective methods in order to establish themselves as academically credible\\nin the 1930s. More particularly, physicists developing quantum mechanics\\nwere using frequencies in their experimental data to determine the most\\nprobable locations of electron clouds in nuclei. Quantum mechanics was new\\nand chic, and Bayes was not.\\nIn addition, Fisher’s techniques, written in a popular style with minimal\\nmathematics, were easier to apply than those of Jeffreys. A biologist or\\npsychologist could easily use Fisher’s manual to determine whether results\\nwere statistically significant. To use Jeffreys’s rather opaque and\\nmathematical approach, a scientist had to choose among five nuanced\\ncategories: the evidence against the hypothesis is “not worth more than a\\nbare mention” or it is substantial, strong, very strong, or decisive.57\\nCharacteristically, Jeffreys tucked the five categories into appendix B of his\\nbook.\\nFinally and most important, Jeffreys was interested in making inferences\\nfrom scientific evidence, not in using statistics to guide future action. To him,\\ndecision making—so important for the rise of mathematical statistics during\\nthe Second World War and the Cold War—was irrelevant. Others parted at\\nthe same divide: a big reason for the feud between Fisher and Neyman, for\\nexample, was decision theory.\\nAll these factors left Jeffreys almost totally isolated from statistical\\ntheorists. His link with Fisher was their interest in applying statistics to\\nscience. Jeffreys knew Ramsey and visited him as he was dying in the\\nhospital, but neither realized the other was working on probability theory; in\\nany case, Jeffreys was interested in scientific inference and Ramsey in\\ndecision making. Jeffreys and de Finetti worked on similar probability issues\\nduring the 1930s, but Jeffreys did not even know the Italian’s name for half a\\ncentury and would have rejected outright de Finetti’s subjectivity. Most\\nstatisticians ignored Jeffreys’s book on probability theory for years; he said\\nthat “they were completely satisfied with frequency theories.”58 Jeffreys\\naccepted a medal from the Royal Statistical Society, but attended none of its\\nmeetings. Geophysicists did not know about his probability work; a\\nsurprised geologist once asked Lindley, “You mean that your Jeffreys is the\\nsame Jeffreys as mine?”59\\nBy 1930 Jeffreys was truly a voice in the wilderness. Most statisticians\\nwere using the powerful body of ideas developed by the anti-Bayesian trio.\\nJeffreys’s great book Theory of Probability was published as part of a series\\nof physics books, not statistics books. It also appeared in the last year of\\npeace, just before the start of the Second World War and a new opportunity\\nfor Bayes’ rule.\\npart II\\n \\nsecond world war era\\n \\n4.\\n \\nbayes goes to war\\n \\nBy 1939 Bayes’ rule was virtually taboo, dead and buried as far as\\nstatisticians in the know were concerned. A disturbing question remained,\\nthough. How could wartime leaders make the best possible life-and-death\\ndecisions swiftly, without waiting for complete information? In deepest\\nsecrecy some of the greatest mathematical minds of the century would\\ncontribute to rethinking Bayes’ role during the uncertain years ahead.\\nThe U-boat peril was the only thing that ever really frightened Winston\\nChurchill during the Second World War, he recalled in his history of the\\nconflict. Britain was self-sufficient in little other than coal; it grew enough\\nfood to feed only one in three residents. But after the fall of France in 1940,\\nGermany controlled Europe’s factories and farms, and unarmed merchant\\nships had to deliver to Britain 30 million tons of food and strategic supplies\\na year from the United States, Canada, Africa, and eventually Russia. During\\nthe Battle of the Atlantic, as the fight to supply Britain was called, German\\nU-boats would sink an estimated 2,780 Allied ships, and more than 50,000\\nAllied merchant seamen would die. For Prime Minister Churchill, feeding\\nand supplying his country was the dominating factor throughout the war.\\nHitler said simply, “U-boats will win the war.”1\\nU-boat operations were tightly controlled by German headquarters in\\noccupied France. Each submarine went to sea without orders and received\\nthem by radio after it was well out in the Atlantic. As a result, an almost\\nendless cascade of coded radio messages—more than 49,000 are still\\narchived—raced back and forth between the U-boats and France. Although\\nthe British desperately needed to know where the U-boats were, the\\nmessages were unreadable. They had been encrypted by word-scrambling\\nmachines, and no one in Germany or Britain thought their codes could be\\nbroken.\\nStrangely enough, the Poles were the first to think otherwise. A few\\nintelligence officers in Poland, sandwiched as they were between Germany\\nand Russia, realized a full decade before the start of the Second World War\\nthat mathematics could make eavesdropping on their rapacious neighbors\\nquite informative. The First World War had made the need for machines to\\nencode radio messages painfully obvious. When an alphabet-scrambling\\nmachine was exhibited at an international trade show in 1923, Germany\\nbought some and began introducing complexities to make their codes more\\nsecure. The machines were named Enigma.\\nAnd enigmas they were. The Poles spent three years trying unsuccessfully\\nto crack German messages before realizing that automated cipher machines\\nhad transformed cryptography. The science of coding and decoding secret\\nmessages had become a game for mathematicians. When the Polish secret\\nservice organized a top-secret cryptography class for German-speaking\\nmathematics students, its star pupil was an actuarial mathematician named\\nMarián Rejewski. He used inspired guesswork and group theory—the new\\nmathematics of transformation—to make a crucial discovery: how the wheels\\non an Enigma were wired. By early 1938 the Poles were reading 75% of\\nGermany’s army and air force messages. Shortly before their country was\\ninvaded in 1939 they invited French and British agents to a safehouse in the\\nPyry Forest outside Warsaw, revealed their system, and sent an updated\\nEnigma machine to London.\\nTo an observer, an Enigma looked rather like a complicated typewriter,\\nwith a traditional keyboard of 26 letter keys and a second array of 26 lettered\\nlights. Each time a typist pressed a letter key, an electric current passed\\nthrough a set of three wheels and advanced one of them a notch. The\\nenciphered letter lit up on the lampboard, and the typist’s assistant read the\\nletter off to a third aide, who radioed the scramble in Morse code. At its\\ndestination, the process was reversed. The recipient typed the coded letters\\ninto his Enigma keyboard, and the original message lit up on his lampboard.\\nBy changing the wiring, wheels, starting places, and other features, an\\nEnigma operator could churn out millions upon millions of permutations.\\nGermany standardized its military communications with increasingly\\ncomplex versions of the machines. Approximately 40,000 military Enigmas\\nwere distributed to the German army, air force, navy, paramilitary, and high\\ncommand as well as to the Spanish and Italian nationalist forces and the\\nItalian navy. When German troops invaded Poland on September 1, 1939,\\nbattery-powered Enigmas were the key to their high-speed blitzkrieg as field\\nofficers in Enigma-equipped command vehicles coordinated, as never\\nbefore, a barrage of artillery fire, dive-bombing airplanes, and panzer tanks.\\nMost German naval vessels, particularly battleships, minesweepers, supply\\nships, weather report boats, and U-boats, had an Enigma.\\nUnlike the Poles, the British agency charged with cracking German\\nmilitary codes and ciphers clung to the tradition that decryption was a job for\\ngentlemen with linguistic skills. Instead of hiring mathematicians, the\\nGovernment Code and Cypher School (GC&CS) employed art historians,\\nscholars of ancient Greek and medieval German, crossword puzzlers, and\\nchess players. Mathematicians were regarded as “strange fellows.”2\\nThe British government and educational systems treated applied\\nmathematics and statistics as largely irrelevant to practical problems. Well-\\nto-do boys in English boarding schools learned Greek and Latin but not\\nscience and engineering, which were associated with low-class trade.\\nBritain had no elite engineering schools like MIT or the École Polytechnique.\\nTwo years into the war, when government officials went to Oxford to recruit\\nmen proficient in both mathematics and modern languages, they found only an\\nundergraduate mathematics major teaching himself beginning German. The\\ngovernment did not even plan to exempt mathematicians from combat.\\nKnowing that their skills would be needed eventually, mathematicians quietly\\nspread word to their colleagues to register with the government as physicists\\nbecause they at least were considered vital to the nation’s defense.\\nExacerbating the emergency was the fact that the government regarded\\nstatistical data as bothersome details. A few months before war was\\ndeclared in 1939, the giant retailer Lord Woolton was asked to organize the\\nclothing for Britain’s soldiers. He discovered to his horror that “the War\\nOffice had no statistical evidence to assist me. . . . I had the greatest\\ndifficulty in arriving at any figures that would show how many suits of\\nuniform and how many boots were involved.”3 The Department of\\nAgriculture ignored a study of the fertilizers needed to increase Britain’s\\nfood and timber supplies because it thought the Second World War was going\\nto be a nonscientific war and no more data would be needed. Government\\nfunctionaries also seemed to think that applying mathematics to real life\\nwould be easy. When the Ministry of Supply needed to assess new rockets, it\\ngave an employee one week to “learn statistics.”4\\nProbability experts were scarce. For a small elite the 1930s had been the\\ngolden age of probability theory, the language of statistics. But the majority\\nof mathematicians thought of probability as arithmetic for social scientists.\\nCambridge, the center of British mathematics, was a backwater in\\nprobability. Germany, a leader in modern mathematics and quantum physics,\\nproduced few statisticians. And one of the greatest probability thinkers of the\\ntwentieth century, Wolfgang Doeblin, was a 25-year-old French soldier\\nfighting for his life as France fell to the Germans in June 1940. The Gestapo\\nwas hunting his father, and Doeblin, surrounded and without hope of escape,\\nkilled himself to avoid any chance of betraying his parent. Doeblin’s work\\nwould one day be crucially relevant to chaos theory and random mapping\\ntransformations.\\nOddly, the Allies’ top three statisticians were sidelined during the war.\\nHarold Jeffreys was ignored, perhaps because he was an earthquake\\nspecialist and astronomy professor. British security apparently considered\\nRonald Fisher, the anti-Bayesian geneticist, to be politically untrustworthy\\nbecause he had corresponded with a German colleague. Fisher’s offers to\\nhelp the war effort were ignored, and his application for a visa to the United\\nStates was rejected without explanation. A chemist calculating the dangers of\\npoison gas succeeded in arranging a visit to Fisher only by claiming he was\\ncollecting a horse nearby. As for Jerzy Neyman, he persisted in carrying out\\nfull theoretical studies that could lead to a new theorem even though the\\nmilitary desperately needed quick and dirty advice; one of Neyman’s grants\\nwas formally terminated.\\nWith applied mathematicians and statisticians in short supply, wartime\\ndata were often analyzed not by statisticians but by actuaries, biologists,\\nphysicists, and pure mathematicians—few of whom knew that, as far as\\nsophisticated statistics was concerned, Bayes’ rule was unscientific. Their\\nignorance proved fortunate.\\nDespite the strange reputation of British mathematicians, the operational\\nhead of GC&CS prepared for war by quietly recruiting a few nonlinguists\\n—“men of the Professor type”5—from Oxford and Cambridge universities.\\nAmong that handful of men was Alan Mathison Turing, who would father the\\nmodern computer, computer science, software, artificial intelligence, the\\nTuring machine, the Turing test—and the modern Bayesian revival.\\nTuring had studied pure mathematics at Cambridge and Princeton, but his\\npassion was bridging the gap between abstract logic and the concrete world.\\nMore than a genius, Turing had imagination and vision. He had also\\ndeveloped an almost unique set of interests: the abstract mathematics of\\ntopology and logic; the applied mathematics of probability; the experimental\\nderivation of fundamental principles; the construction of machines that could\\nthink; and codes and ciphers. Turing had already spent hours in the United\\nStates discussing cryptography in his high-pitched stammer with a Canadian\\nphysicist named Malcolm MacPhail.\\nAfter Turing returned to England in the spring of 1939, his name was\\nquietly added to a short “emergency list” of people with orders to report\\nimmediately to the GC&CS in the event war was declared. He worked alone\\nthat summer, studying both probability theory and Enigma codes.\\nOccasionally he visited GC&CS to talk with a cryptanalyst, Dillwyn Knox,\\nwho had already solved a relatively simple Enigma code used by the Italian\\nnavy. By the time Germany invaded Poland, Knox and Turing probably\\nunderstood more about military Enigmas than anyone else in Britain.\\nOn September 4, the day after England declared war on Germany, Turing\\ntook a train to the GC&CS research center in Bletchley Park, a small town\\nnorth of London. He was 27 but looked 16. He was handsome, athletic, shy,\\nand nervous and had been openly homosexual at Cambridge. He cared little\\nabout appearances; he wore shabby sports coats and had dirty fingernails and\\na permanent five-o’clock shadow. He would devote the next six years to\\nEnigma and to other coding and decoding projects.\\nOn his arrival in Bletchley Park, GC&CS analysts divided up the Enigma\\nsystems, and Turing worked awhile on army codes. By January the English\\nwere reading German air force messages. During the first weeks of the war\\nTuring also designed the “bombe.” This was not a weapon in the traditional\\nsense but a high-speed electromechanical machine for testing every possible\\nwheel arrangement in an Enigma. Turing’s bombe, a radical redesign and\\nupgrade of the device invented by the Poles, would turn Bletchley Park into a\\ncode-breaking factory. Turing’s machine tested hunches, 15-letter tidbits\\nsuspected of being in the original message. Because it was faster to toss out\\npossibilities than to find one that fit, Turing’s bombe simultaneously tested\\nfor wheel combinations that could not produce the hunch.\\nTuring refined the bombe’s design with the help of mathematician Gordon\\nWelchman and engineer Harold “Doc” Keen. Their prototype, a metal\\ncabinet roughly 7 by 6 by 2.5 feet, appeared at Bletchley Park in March\\n1940. Some believe the bombe’s design was Turing’s biggest contribution to\\nbreaking Enigma.\\nDespite the progress made on breaking German air force and army codes,\\nno one at Bletchley Park wanted to tackle the German naval codes, the key to\\nwinning the U-boat war in the Atlantic. Of all the branches of the Axis\\nmilitary, Hitler’s navy operated the most complex Enigma machines and\\nsecurity systems. By war’s end, a naval Enigma machine could be set up an\\nastronomical number of ways. According to a Bletchley Park decoder, “All\\nthe coolies in China could experiment for months without reading a single\\nmessage.”6 At any one time the machine could use 1 of 4 reflector\\ncombinations (each of which could be set in 26 different ways); 3 of 8 rotors\\n(giving up to 336 permutations); more than 150 billion plugboard\\ncombinations; 17,000 possible clip positions around the rotors; and 17,000\\npossible starting positions (half a million in four-rotor machines). Many of\\nthese settings were changed every two days, sometimes every 8 or 24 hours.\\nAccording to Frank Birch, head of the GC&CS naval intelligence branch,\\nsuperior officers informed him that the “German codes were unbreakable. I\\nwas told it wasn’t worthwhile putting pundits onto them. . . . Defeatism at the\\nbeginning of the war, to my mind, played a large part in delaying the breaking\\nof the codes.”7 The naval codes were assigned to one officer and one clerk;\\nnot a single cryptanalyst was involved. Birch, however, thought the naval\\nEnigma could be broken because it had to be. The U-boats put Britain’s very\\nexistence at stake.\\nTuring had still another attitude. The fact that no one else wanted to work\\non the naval codes made them doubly attractive. A close friend called Turing\\n“a confirmed solitary.”8 Isolation appealed to him. Announcing that “no one\\nelse was doing anything about it and I could have it to myself,” Turing\\ndecided to attack the German naval code.9 He began working on naval\\nEnigma with a staff of two “girls” and an Oxford mathematician-physicist,\\nPeter Twinn.10 Turing thought the code “could be broken because it would be\\nso interesting to break it.”11\\nOne of Turing’s first jobs was to reduce the number of tests a bombe had\\nto conduct. Although it was fast, a bombe took 18 minutes to test a possible\\nwheel setting. Assuming the worst, a bombe would need four days to test all\\n336 possible wheel permutations on an Enigma. Until more bombes could be\\nbuilt, their workload had to be drastically reduced.\\nLate one night soon after joining Bletchley Park, Turing invented a manual\\nmethod for reducing the burden on the bombes. It was a highly labor-\\nintensive, Bayesian system he nicknamed Banburismus for the nearby town of\\nBanbury, where a printing shop would produce needed materials.\\n“I was not sure that it would work in practice,” Turing said.12 But if it did,\\nit would let him guess a stretch of letters in an Enigma message, hedge his\\nbets, measure his belief in their validity by using Bayesian methods to assess\\ntheir probabilities, and add more clues as they arrived. If it worked, it would\\nidentify the settings for 2 of Enigma’s 3 wheels and reduce the number of\\nwheel settings to be tested on the bombes from 336 to as few as 18. At a time\\nwhen every hour counted, the difference could save lives.\\nTuring and his slowly growing staff began to comb intelligence reports to\\ncollect “cribs,” Bletchley-ese for German words predicted to occur in the\\nplain-text, that is, the original, uncoded message. The first cribs came\\nprimarily from German weather reports because they were standardized and\\nrepeated often: “Weather for the night,” “Situation Eastern Channel,” and, as\\none blessed fool radioed nightly, “Beacons lit as ordered.” Reports from\\nBritish meteorologists about weather in the Channel provided more hunches.\\nKnowing the most frequent letter combinations in German words helped too.\\nWhen a prisoner of war told them the German navy spelled out numbers,\\nTuring realized that the word “ein” (“one,” “a,” or “an”) appeared in 90% of\\nEnigma messages; Bletchley Park clerks catalogued by hand 17,000 ways\\n“ein” could be encrypted, and a special machine was constructed to screen\\nfor them.\\nIn a fundamental breakthrough, Turing realized he could not systematize his\\nhunches or compare their probabilities without a unit of measurement. He\\nnamed his unit a ban for Banburismus and defined it as “about the smallest\\nchange in weight of evidence that is directly perceptible to human\\nintuition.”13 One ban represented odds of 10 to 1 in favor of a guess, but\\nTuring normally dealt with much smaller quantities, decibans and even\\ncentibans. The ban was basically the same as the bit, the measure of\\ninformation Claude Shannon discovered by using Bayes’ rule at roughly the\\nsame time at Bell Telephone Laboratories. Turing’s measure of belief, the\\nban, and its supporting mathematical framework have been called his greatest\\nintellectual contribution to Britain’s defense.\\nTo estimate the probability of a guess when information was arriving\\npiecemeal, Turing used bans to discriminate between sequential hypotheses.\\nHe was thus one of the first to develop what came to be called sequential\\nanalysis. He used bans to quantify how much information was needed to\\nsolve a particular problem so that, instead of deciding how many\\nobservations to make, he could target the amount of evidence needed and\\nstop when he had it.\\nBans involved a manual, paper-and-pencil system far removed from a\\nmodern computerized Bayesian calculation. Bans automated the kind of\\nsubjective guessing that Émile Borel, Frank Ramsey, and Bruno de Finetti\\nhad tried to validate during the anti-Bayesian onslaught of the 1920s and\\n1930s. Using Bayes’ rule and bans, Turing began calculating credibility\\nvalues for various kinds of hunches and compiling reference tables of bans\\nfor technicians to use. It was a statistics-based technique and produced no\\nabsolute certainties, but when the odds of a hypothesis added up to 50 to 1,\\ncryptanalysts could be close to certain they were right. Each ban made a\\nhypothesis 10 times more likely.\\nA top modern-day cryptographer explained Turing’s thinking: “When you\\nwork day after day, year after year, you need to make a best guess of what’s\\nmost likely to be breakable with the resources at hand. You may have too\\nmany choices, so you pick the more checkable guesses. At every step you\\nhedge bets. . . . Sometimes you make approximations, and other times you\\nhave precisely correct numbers with the right formulas, the right numbers, for\\nthe decibans.”14\\nIn operation, Banburismus used 5- or 6-foot-long strips of thin card-board\\nprinted in Banbury. Decoders look for repetitions and coincidences, so\\nWrens, technicians from the Women’s Royal Naval Service, punched each\\nintercepted message by hand, letter by letter, into a Banbury sheet. Then they\\nslipped one strip on top of others so that any two messages could be\\ncompared. When enough letter holes showed through both Banburies, the\\nnumber of repeats was recorded.\\nAs Patrick Mahon, who worked on Banburismus during the war, wrote in\\nhis secret history of Bletchley Park, “If by any chance, the two messages\\nhave identical content for 4 or 6 or 8 more letters . . . such a coincidence\\nbetween cipher texts is known as a ‘fit.’”\\n“The game of Banburismus involved putting together large numbers of\\npieces of probabilistic information somewhat like the reconstruction of DNA\\nsequences,” Turing’s statistical assistant, I. J. “Jack” Good, explained later.15\\nGood, the son of a Jewish watchmaker from tsarist Russia, had studied pure\\nmathematics at Cambridge and waited a year for a defense job before being\\nhired on the strength of his chess playing. Good thought “the game of\\nBanburismus was enjoyable, not easy enough to be trivial, but not difficult\\nenough to cause a nervous breakdown.”16 Bayes’ rule was proving to be a\\nnatural for cryptography, good for hedging bets when there were prior\\nguesses and decisions to be made with a minimum of time or cost.\\nTuring was developing a homegrown Bayesian system. Finding the Enigma\\nsettings that had encoded a particular message was a classic problem in the\\ninverse probability of causes. No one is sure where Turing picked Bayes up,\\nwhether he rediscovered it independently or adapted it from something\\noverheard about Jeffreys, Cambridge’s lone defender of Bayes’ rule before\\nthe war. All we know for sure is that, because Turing and Good had studied\\npure mathematics and not statistics, neither had been sufficiently poisoned by\\nanti-Bayesian attitudes.\\nIn any event, Turing talked at Bletchley Park about bans, not Bayes.\\nOnce Good asked, “Aren’t you essentially using Bayes’ theorem?”17\\nTuring answered, “I suppose.” Good concluded that Turing knew of the\\ntheorem’s existence. But Turing and Good may have been the only ones at\\nBletchley Park who realized that Banburismus was Bayesian, and heavily so.\\nGood met a friend, George A. Barnard, one day in London and—strictly\\nagainst the rules—“told him that we were using Bayes factors, and their\\nlogarithms, sequentially, to discriminate between two hypotheses but of\\ncourse I did not mention the application. Barnard said that curiously enough a\\nsimilar method was being used for quality control in the Ministry of Supply\\nfor discriminating between lots rather than hypotheses. It was really the same\\nmethod because the selection of a lot can be regarded as the acceptance of a\\nhypothesis.”18 Sequential analysis differed from frequency-based testing,\\nwhere the number of items to be tested was fixed from the beginning. In\\nsequential analysis, once several tests or observations strongly cleared or\\ncondemned a case of, say, field rations or machine-gun ammunition, the tester\\ncould move on to the next box. This almost halved the number of tests\\nrequired, and the use of logarithms massively simplified calculations by\\nsubstituting addition for multiplication. Abraham Wald of Columbia\\nUniversity is generally credited with discovering sequential analysis for\\ntesting ammunition in the United States later during the war. But Good\\nconcluded that Turing had used it first and that Turing, Wald, and Barnard all\\ndeserved credit for discovering and applying it. Oddly enough, after the war\\nBarnard would become a prominent anti-Bayesian.\\nTuring was making progress when, in May 1940, the doldrums hit. He had\\nboth the theory and the method for breaking Enigma codes but still could not\\nread U-boat messages. The Germans were building more U-boats, and Adm.\\nKarl Doenitz had formed wolf packs of subs strung across the North Atlantic;\\nwhen one U-boat spotted a convoy, it radioed the rest. During the first 40\\nmonths of the war, U-boats sank 2,177 merchant ships totaling more than 1\\nmillion tons, far more than were lost to German aircraft, mines, warships,\\nand other causes.\\nIf the British were going to be able to route supply convoys around the U-\\nboats, Turing needed more information. He needed to see one of the code-\\nbooks that U-boat Enigma operators used before broadcasting a ciphered\\nmessage. One of the factors that made breaking the Enigma code so difficult\\nwas that the operator doubly-enciphered a trio of letters that began each\\nmessage and that indicated the starting positions of the Enigma’s three\\nwheels. The operator enciphered the three letters twice over: once\\nmechanically, with his Enigma machine, and once manually, by selecting one\\nof nine sets of tables in a codebook issued to each sub. The operator learned\\nwhich table to use each day by consulting a calendar issued with the tables. If\\na U-boat came under attack, crews had strict orders to destroy the tables\\neither before abandoning ship or as the enemy was about to board.\\nIn a brilliant piece of deduction shortly after war was declared, Turing\\nfigured out this double-encipherment system, but he needed a copy of the\\ncodebook to make Banburismus work. Enigmas had so many variations that\\ntrial-and-error methods were ineffective. A codebook had to be “pinched,”\\nas Turing put it. The wait for a pinch would stretch through ten nerve-racking\\nmonths.\\nAs Turing waited desperately for the navy to get him a codebook, morale\\nat GC&CS sank. Alastair G. Denniston, the head of GC&CS, told Birch,\\n“You know, the Germans don’t mean you to read their stuff, and I don’t\\nexpect you ever will.”19\\nLong and bitter arguments broke out about whether more bombes should be\\nbuilt, and if so, how many. In August 1940 Birch wrote, “Turing and Twinn\\nare like people waiting for a miracle, without believing in miracles. . . .\\nTuring has stated categorically that with 10 machines [bombes] he could be\\nsure of breaking Enigma and keeping it broken. Well can’t we have 10\\nmachines?”20\\nA second bombe incorporating Welchman’s improvements arrived later\\nthat month, but the fight for more bombes continued throughout 1940. Birch\\ncomplained that the British navy was not getting its fair share of the bombes:\\n“Nor is it likely to. It has been argued that a large number of bombes would\\ncost a lot of money, a lot of skilled labour to make and a lot of labour to run,\\nas well as more electric power than is at present available here. Well, the\\nissue is a simple one. Tot up the difficulties and balance them against the\\nvalue to the Nation of being able to read current Enigma.”21\\nTo capture a codebook, Lt. Cmdr. Ian Fleming, the future creator of James\\nBond but at the time an aide to the head of Britain’s Directorate of Naval\\nIntelligence, concocted Operation Ruthless. It was a scheme worthy of his\\npostwar spy. The British would outfit a captured German plane with a crew\\nthat was to include a “word-perfect German speaker” (Fleming himself, who\\nhad studied German in Austria as a youth).22 After the plane faked a crash\\ninto the Channel and its crew was rescued by a German boat, the British\\nwould capture the vessel and bring it and its Enigma equipment home to\\nTuring. The escapade was elaborately planned but canceled, and Turing and\\nTwinn went to Birch looking “like undertakers cheated of a nice corpse . . . ,\\nall in a stew.”23 Instead, documents and papers—bits and pieces of clues to\\nthe contents of the all-important codebooks—were taken from two weather\\nships captured off Iceland and, in a commando raid organized specifically to\\nhelp Turing, from an armed German trawler off the Norwegian coast. With\\nthese clues, Turing began trying to deduce the contents of the all-important\\ncodebooks.\\nTuring’s group was beginning to break the German naval cipher on the\\nglorious day of May 27, 1941, when the British sank the Bismarck, then the\\nworld’s largest battleship. By June Turing had succeeded in reconstructing\\nthe codebooks from various clues, and for the first time Bletchley Park could\\nread the messages to and from the U-boat wolf packs within an hour of their\\narrival. Finally, the British could reroute convoys safely around the subs. For\\n23 blessed days in June 1941, a time when Britain still fought alone, no\\nconvoy in the North Atlantic was attacked.\\nBy then, Bletchley Park regarded Turing fondly as its eccentric genius,\\nalthough some of his unconventional behavior made practical sense. He wore\\na gas mask while bicycling to work during the June hay fever season. And he\\nmanaged his bicycle’s broken chain by counting pedal strokes and executing\\na certain maneuver every 17 revolutions. Bicycle parts were scarce, and he\\nliked identifying repeated patterns in his work.\\nBy autumn of 1941, Banburismus was again in trouble, critically short of\\ntypists and junior clerks, otherwise known as “girl power.” Turing and three\\nother decoders took a direct but unorthodox approach to the problem.\\nAppealing directly to Churchill on October 21, they wrote, “We despair of\\nany early improvement without your intervention.” Welchman probably\\ndrafted the letter, but Turing signed it first, followed by Welchman, their\\ncolleague Hugh Alexander, and P. Stuart Milner-Barry, a Cambridge\\nmathematics graduate who was the chess correspondent for The Times\\nnewspaper. Milner-Barry took a train to London, hailed a taxi, and “with a\\nsense of total incredulity (can this really be happening?) invited the taxi\\ndriver to take him to 10 Downing Street.” There he persuaded a brigadier\\ngeneral to deliver the letter personally to the prime minister and to stress its\\nurgency.\\nChurchill, who had visited Bletchley Park, had recently been informed that\\nBritain was running out of food and war supplies. He immediately sent a\\nmemorandum to his chief of staff: “Action this day: Make sure they have all\\nthey want on extreme priority and report to me that this had been done.”24\\nTuring and company heard nothing directly in response but noticed that work\\nwent more smoothly, bombes were built faster, and staff arrived sooner.\\nAs Bletchley Park was beginning to break naval Enigma, Hitler invaded\\nRussia with two-thirds of his forces in June 1941 and launched a merciless\\nbombardment of Moscow. Early in the campaign, Russia’s greatest\\nmathematician, Andrei Kolmogorov, was evacuated east to safety in Kazan\\nalong with the rest of the Russian Academy of Sciences. Shortly after,\\nRussia’s Artillery Command, reeling from Germany’s massive bombing\\nraids, asked Kolmogorov to return to the capital for consultations. Amidst the\\nchaos, he was lodged for awhile on a sofa.\\nIn a country that idolized its intelligentsia, Kolmogorov was a famous man.\\nWhen a professor’s wife heard he was going to visit her home, she began\\nfrantically cleaning and cooking. When a maid asked why, the hostess\\nreplied, “How can I explain it to you? Just imagine that you will be getting a\\nvisit from the tsar himself.”25 Kolmogorov’s legend began with his mother,\\nan independent woman of “lofty social ideals” who never married and died\\nin childbirth. Her two sisters raised Andrei, ran a small school for him and\\nhis friends, and published a newsletter with little problems he had\\ncomposed, such as “How many different ways can a button with four holes\\nbe sewn?”26 At the age of 19 at Moscow State University he escaped final\\nexaminations in his 14 courses by writing 14 original papers. He was more\\nproud of having taught school to pay his way through the university than of\\nwinning any of his awards; late in life he volunteered at a school for gifted\\nchildren, where he introduced them to literature, music, and nature.\\nKolmogorov became the world’s authority on probability theory. In 1933\\nhe demonstrated that probability is indeed a branch of mathematics, founded\\non basic axioms and far removed from its indecorous gambling origins. So\\nfundamental was Kolmogorov’s approach that any mathematician, frequentist\\nor Bayesian, could legitimately use probability. Kolmogorov himself\\nespoused the frequentist approach.\\nNow the generals were asking him about using Bayes against the German\\nbarrage. Russia’s artillery, like that of the French, had used Bayesian firing\\ntables for years, but the generals were split over an esoteric point about\\naiming. They asked Kolmogorov his opinion.\\n“Strictly speaking,” he told the generals, starting with Bayes’ 50–50 prior\\nodds was “not only arbitrary but surely wrong because it contradicts the main\\nrequirements of the probability theory.”27 But with Germany on Moscow’s\\ndoorstep, Kolmogorov felt he had no choice but to start with equal priors.\\nAgreeing with Joseph Bertrand’s strictly reformed version of Bayes,\\nKolmogorov told the generals they should start with 50–50 odds whenever\\nshooting repeatedly at a small area. Because it was sometimes better to shoot\\nrandomly than aim precisely, the guns in a battery of weapons should aim\\nslightly wide of the mark, the way a hunter shooting at moving birds uses\\npellets for wider dispersion.\\nThat same autumn of 1941, Kolmogorov taught a wartime course at\\nMoscow State University on firing dispersion theory and made the class\\ncompulsory for probability majors. Surprisingly, on September 15, 1941,\\nthree months into the German invasion of Russia, Kolmogorov submitted his\\ntheory of firing to a journal for publication. The article was so mathematical\\nand theoretical that Russia’s censors, not realizing it could help the Germans\\nas well as the Russians, allowed it to be printed in 1942. Fortunately, the\\nenemy did not understand the theory any better than the censors did. After the\\nwar Kolmogorov published two more practical problems of Bayesean\\nartillery that are still in print—in English—for military authorities to study.\\nYears later a general in the Russian artillery recalled that during the invasion\\nKolmogorov “did a lot of useful things for us as well, we remember it, and\\nappreciate him too.”28\\nShortly after Germany attacked Russia, British radio listening posts\\nintercepted a new kind of German army message. Analysts at Bletchley Park\\nthought it came from a teletype machine. They were right. The Germans were\\nencrypting and decrypting at the speed of typing. The new Lorenz machines\\nand their family of ultrasecret codes were technically far more sophisticated\\nthan the Enigmas, which had been built for commercial use in the 1920s. The\\nsupreme command in Berlin relied on its new codes to communicate the\\nhighest level of strategy to army group commanders across Europe. The\\nmessages were so important that Hitler himself signed some of them.\\nCode-naming the new Lorenz machines Tunny for “tuna fish,” a group of\\nBritain’s leading mathematicians began a year of desperate struggle. They\\nused Bayes’ rule, logic, statistics, Boolean algebra, and electronics. They\\nalso began work on designing and building the first of ten Colossi, the\\nworld’s first large-scale digital electronic computers.\\nWhen Good and others started work on the Tunny-Lorenz codes, they\\nincorporated Turing’s Bayesian scoring system and his fundamental units of\\nbans, decibans, and centibans. They employed Bayes’ theorem and a\\nspectrum of priors: honest priors and improper ones; priors that represented\\nwhat was known and sometimes not; and in different places both Thomas\\nBayes’ uniform priors and Laplace’s unequal ones. To deduce the pattern of\\ncams surrounding the wheels of the Tunny-Lorenz machines Turing invented a\\nhighly Bayesian method known as Turingery or Turingismus in July 1942.\\nTuringery was a paper-and-pencil method, “more artistic than mathematical. .\\n. . [You had to rely on what] you felt in your bones,” according to Turingery\\nplayer William T. Tutte.29 The first step was to make a guess and assume, as\\nBayes had suggested, that it had a 50% chance of being correct. Add more\\nand more clues, some good, some bad, and “with patience, luck, a lot of\\nrubbing out, and a lot of cycling back and forth,” the plain text appeared.\\nWhen the odds of being correct reached 50 to 1, a pair of wheel settings was\\ndeclared certain.30\\nAs Bletchley Park analysts worked on Tunny’s wheel patterns and Russia\\nresisted the German onslaught, Japan attacked the United States at Pearl\\nHarbor on December 7, 1941. Supplying Great Britain immediately became\\nmore difficult. When American ships that had protected the convoys\\nsupplying Britain were quickly transferred to the Pacific, 15 German U-boats\\ntook their places in the shipping lanes off the American East Coast. As\\nconvoys of Argentine beef and Caribbean oil hugged the coast, they were\\nsilhouetted at night against shore lights that local communities dependent on\\ntourism refused to dim. Miami’s neon signs, for example, stretched for six\\ndeadly miles. The U-boats, lying in wait at periscope depth, caused three\\nmonths of devastation until the U.S. military ordered coastal lights turned off\\nat dusk.\\nMaking matters worse, the Atlantic U-boats added a fourth wheel to their\\nEnigmas, and the Turing-Welchman bombes were stymied. For most of 1942\\nTuring and his coworkers could not read any message to or from German\\nsubmarines. Bletchley Park called it the Great Blackout. For four months the\\nU-boats ran riot in the Atlantic at large, sinking 43 ships in August and\\nSeptember alone. The average U.S. vessel crossed the Atlantic and back\\nthree times before it was sunk on its fourth trip.\\nFinally, in December 1942, three young British crewmen, Lt. Anthony\\nFasson, Able-Seaman Colin Grazier, and Tommy Brown, swam from their\\nship to a sinking German submarine off Egypt to pinch its vital codebook of\\nencrypting tables. Fasson and Grazier drowned in the attempt, but Brown, a\\n16-year-old canteen assistant, survived to rescue the tables. At last\\nBanburismus was fully operational. Within hours of Bletchley Park’s\\nreceiving the tables, U-boat messages from the Atlantic were being\\ndecrypted and convoys rerouted.\\nThe month before that happened, however, would be the war’s most\\ndangerous month for Allied shipping, and during it Turing sailed for the\\nUnited States on the Queen Elizabeth, a fast ship that traveled without\\nconvoy. Clearance from the White House made Turing a liaison between\\nBletchley Park and the U.S. Navy. The British had been teaching the\\nAmericans about Enigma in general before Pearl Harbor. Now Turing was to\\ntell U.S. officials everything that had been learned, and the United States\\nwould accelerate the production of bombes. Surprisingly, the British planned\\nhis trip rather haphazardly. He arrived with inadequate identification, and\\nU.S. immigration authorities almost confined him to Ellis Island. In addition,\\nhe had not been told whether he could discuss Tunny code breaking with\\nAmericans, and the Americans did not realize he expected to have full access\\nto their voice-scrambling research. Nevertheless, during his stay he held\\nhigh-level meetings in Dayton, Ohio, Washington, and New York City.\\nTuring spent at least one afternoon in Dayton, where the National Cash\\nRegister Company planned to manufacture 336 bombes. He was dismayed to\\ndiscover that the U.S. Navy was ignoring Banburismus and its ability to\\neconomize on bombe usage. The Americans seemed uninterested in the\\nEnigma outside of their obligation to supply bombes for it.\\nIn Washington, Turing discussed Bletchley Park’s methods and bombes\\nwith U.S. Navy cryptographers. According to a previous agreement, the\\nUnited States was concentrating on Japanese navy codes and ciphers while\\nthe British worked on Enigma. Bletchley Park had already sent a detailed\\ntechnical report of its work to the Americans, but a civilian navy\\ncryptographer, Agnes Meyer Driscoll, had sat on it; she had broken many\\nJapanese codes and ciphers before the war and had her own, mistaken\\nnotions about how to solve Germany’s naval Enigma. Turing’s mathematics\\nmay also have been too technical for the Americans. At first he was alarmed\\nthat no one seemed to be working mathematically “with pencil and paper,”\\nand he tried in vain to explain the general principle that confirming\\ninferences suggested by a hypothesis would make the hypothesis itself more\\nprobable.31 Later, he was relieved to meet American mathematicians\\ninvolved in cryptography.\\nFrom Washington, Turing went to the Bell Laboratory in New York City,\\nwhere he and Claude Shannon met regularly at afternoon tea. Shannon, like\\nTuring and Kolmogorov, was a great mathematician and an original thinker,\\nand he was using Bayes’ rule for wartime projects. But Turing and Shannon\\nhad more than Bayes in common. Both were shy, unconventional men with\\ndeep interests in cryptography and machines that could think. As young men,\\nboth had written seminal works combining machines and mathematics. In his\\nmaster’s thesis in mathematics, written at the University of Michigan,\\nShannon showed that Molina’s relay circuits could be analyzed using\\nBoolean algebra. Both Turing and Shannon liked cycling. Turing rode a\\nbicycle for transportation and exercise; Shannon avoided social chitchat by\\nriding a unicycle through Bell Labs’ hallways, sometimes juggling balls\\nalong the way. Both men liked to design equipment, in Shannon’s case\\nwhimsical machines like a robotic mouse to solve mazes or a computer for\\nRoman numerals. His garage was filled with chess-playing machines. Unlike\\nTuring, though, Shannon had a warm family life. His father was a\\nbusinessman, his mother a high school principal, and his sister a mathematics\\nprofessor, and he and his wife had three children.\\nWhen Turing visited Bell Labs, the next cryptographic frontier was\\nspeech. Britain and the United States wanted their best people, Shannon and\\nTuring, working on it. Shannon was already developing the SigSaly voice\\nscrambler; it had a nonsense nursery-rhyme name but by war’s end Franklin\\nD. Roosevelt, Churchill, and their top generals in eight locations around the\\nworld could talk together in total secrecy. With naval Enigma reduced to a\\nlargely administrative problem, Turing would tackle voice communications\\nwhen he returned to Britain. When Turing and Shannon met for tea, they\\nprobably discussed the SigSaly.\\nShannon was also working on a theory of communication and information\\nand its application to cryptography. In a brilliant insight Shannon realized\\nthat noisy telephone lines and coded messages could be analyzed by the same\\nmathematics. One problem complemented the other; the purpose of\\ninformation is to reduce uncertainty while the purpose of encryption is to\\nincrease it. Shannon was using Bayesian approaches for both. He said, “Bell\\nLabs were working on secrecy systems. I’d work on communications systems\\nand I was appointed to some of the committees studying cryptanalytic\\ntechniques. The work on both the mathematical theory of communications and\\nthe cryptography went forward concurrently from about 1941. I worked on\\nboth of them together and I had some of the ideas while working on the other.\\nI wouldn’t say that one came before the other—they were so close together\\nyou couldn’t separate them.”32\\nShannon’s efforts united telegraph, telephone, radio, and television\\ncommunication into one mathematical theory of information. Roughly\\nspeaking, if the posterior in a Bayesian equation is quite different from the\\nprior, something has been learned; but when a posterior is basically the same\\nas the prior guess, the information content is low.\\nCommunication and cryptography were in this sense the reverse of one\\nanother. Shannon called his logarithmic units for measuring information\\nbinary dibits, or bits, a word suggested by John W. Tukey of Bell Labs and\\nPrinceton University. In a confidential report published in 1949 Shannon\\nused Bayes’ theorem and Kolmogorov’s theory of probability from 1933 to\\nshow that, in a perfectly secret system, nothing is learned because the prior\\nand posterior of Bayes’ theorem are equal. Bell Labs communications\\ntheorists were still developing extensions of Shannon’s theory and using\\nBayesian techniques extensively in 2007.\\nReturning home, Turing boarded the Empress of Scotland in New York\\nCity on March 23, 1943. New York was the world’s greatest port during the\\nwar: more than 50 vessels streamed in and out of the city’s harbors each day.\\nTuring was traveling during what would be the second most dangerous month\\nof the war for Allied shipping. The U-boat offensive reached its peak that\\nmonth and would sink 108 Allied ships while losing only 14 subs. Germany\\nhad broken the convoys’ routing cipher, and the U-boats’ four-wheel Enigmas\\nstill had Bletchley Park’s cryptographers stymied. Approximately 1,350\\nmostly unarmed merchant ships were at sea every day that spring. They\\njoined a long coastal shipping line that stretched from Brazil to the mouth of\\nthe St. Lawrence River, where they formed convoys to cross the Atlantic.\\nAllied escort vessels concentrated on protecting convoys carrying troops to\\nBritain for an invasion of Europe, however, so Turing’s ship was one of 120\\nfast-moving ships that traveled unescorted. Speed was no guarantee of safety,\\nthough; the week before, U-boats had sunk the Empress of Scotland’s sister\\nship. Despite the Enigma blackout, Turing made it back to England without\\nincident.\\nClearly, the Allies had to locate and destroy the U-boats, not just evade them.\\nU-boats were tying up thousands of Allied ships, planes, and troops needed\\nto supply Britain and invade Continental Europe. The hunt for U-boats\\ninvolved Bayes’ rule in still another part of the Battle of the Atlantic.\\nApplying scientific techniques to the antisubmarine campaign, the British\\nAir Ministry organized a small group of scientists to improve its operational\\nefficiency. This was a new idea, and the British called it O.R., for\\noperational or operations research. Its statistics were fairly elementary but\\nimbued with Bayesian ideas.\\nO.R. concentrated on boosting the efficiency of torpedo attacks, airplane\\nnavigation, and formation flying by squadrons of planes searching for U-\\nboats. Bayes’ “a priori Method” played “quite a large role in operational\\nresearch,” especially when comparatively few variables were involved,\\nreported O.R.’s chief, the future developmental biologist Conrad H.\\nWaddington.33\\nTypically, O.R. employed Bayes for small, detailed parts of big problems,\\nsuch as the number of aircraft needed to protect a convoy, the length of\\ncrews’ operational tours, and whether an aircraft patrol should deviate from\\nits regular flight pattern. Observing the success of British O.R., Adm. Ernest\\nKing, commander in chief of the U.S. Fleet, assigned 40 civilian physicists,\\nchemists, mathematicians, and actuaries to his staff. This Anti-Submarine\\nWarfare Operations Research Group was headed by physicist Philip M.\\nMorse of MIT and chemist George E. Kimball of Columbia University.\\nThe Allies had built a string of high-frequency direction-finding stations\\nalong the perimeter of the Atlantic. Much of the system was devoted to\\ncapturing encoded radio messages and relaying them to code breakers in the\\nUnited States and at Bletchley Park. With six or seven listening posts\\nintercepting the same message from a particular U-boat, the position of a\\nsubmarine in the Atlantic could be determined within about 10,000 square\\nmiles. This gave patrol planes a good idea of where to look, but 10,000\\nsquare miles still meant a circle some 236 miles across. The Allies needed\\nan efficient method for narrowing the search.\\nSince almost every aspect of searching for targets in the open seas\\ninvolves uncertainties and probabilities, mathematician Bernard Osgood\\nKoopman of Columbia University was assigned the job of finding a workable\\nmethod. After graduating from Harvard in 1922, Koopman had studied\\nprobability in Paris and earned a Ph.D. from Columbia. His dream was to\\nbridge the gap between Bayes’ “intuitive probability . . . of a subjective\\nnature” and the “purely objective” frequency-based probability used in\\nquantum physics and statistical mechanics.34\\nA crusty man with a rough frankness and a pungent wit, Koopman saw no\\nreason to be bashful about Bayes or Bayesian priors. He assumed from the\\nvery beginning that he was dealing with probabilities: “Every operation\\ninvolved in search is beset with uncertainties; it can be understood\\nquantitatively only in terms of . . . probability. This may now be regarded as\\na truism; but it seems to have taken the developments in operational research\\nof the Second World War to drive home its practical implications.”35\\nSearching for a U-boat at sea, Koopman first asked what its heading was\\nlikely to be. To him, this was a classic Bayesian “probability of causes”\\nproblem. Priors would obviously be needed. “No rational prospector would\\nsearch a region for mineral deposits unless a geological study, or the\\nexperience of previous prospectors, showed a sufficiently high probability of\\ntheir presence,” he commented. “Police will patrol localities of high\\nincidence of crime. Public health officials will have ideas in advance of the\\nlikely sources of infection and will examine them first.”36\\nKoopman started right off by assigning Thomas Bayes’ 50–50 odds to the\\npresence of a target U-boat inside the 236-mile circle. Then he added data\\nthat were as objective as possible, as Jeffreys advised. Unlike Turing,\\nKoopman had access to enormous amounts of detailed information that the\\nmilitary had accumulated about U-boat warfare.\\nUnfortunately, a U-boat could spot a destroyer long before the destroyer’s\\nsonar picked up the U-boat. Many U.S. planes were not equipped with\\nwindshield wipers, and crews peered through scratched and soiled\\nwindows. “The need for keeping the windows clean and clear cannot be\\noveremphasized,” Koopman admonished. If a crew was lucky enough to get\\nbinoculars, they were standard navy 7 x 50 issue, hazy at best. Unless crew\\nmembers changed stations frequently to minimize the monotony, they lost\\nfocus. And the best angle for watching was generally 3 or 4 degrees below\\nthe horizon—“a rough and ready rule for finding this locus,” Koopman\\nwrote, “is to extend the fist at arm’s length and look about two or three\\nfingers below the horizon.”37 He figured that most aircraft crews were only a\\nquarter as efficient as lookouts working under laboratory conditions.\\nAs a practical problem, Koopman asked how a naval officer could find a\\nU-boat within a 118-mile radius if he had 4 planes, each of which could fly 5\\nhours at 130 knots up and down 5 search lanes, each 5 miles wide. Although\\nfew O.R. investigations required such intricate mathematics, Koopman found\\na way to answer the question mathematically using logarithmic functions.\\nKnowing only that 3 of the 5 lanes had a 10% probability of success, another\\nhad 30%, and a fourth had 40%, Koopman could do the Bayesian math. The\\nofficer should assign two planes each to the 40% lane and the 30% lane and\\nnone to the least probable areas. He calculated this by hand; his problem was\\nnot calculating but getting appropriate observational data. He later said that\\ncomputers would have been irrelevant.\\nApplying his theories, Koopman wrote a fat manual of precomputed\\nrecipes for conducting a U-boat search. The effort needed for each\\nsubsection of the search area equaled the logarithm of the probability at that\\npoint. The regions to be searched did not have to be boxes or circles; they\\ncould have squiggly, irregular shapes. But using his formulas, he could tell a\\ncommander how many hours of search to devote to each squiggly region.\\nUsing Koopman’s cookbook, a shipboard officer could lay out the optimal\\nway to search given his limited resources: the expected time needed to find\\nthe target; the boundaries beyond which he should not venture; and what he\\nshould do every two hours until either the U-boat was found or the search\\nwas called off. He could plan an eight-hour day, starting off with an optimum\\nsearch for the first four hours; then, if a U-boat had not been found, the\\ncommander could use Bayes’ rule to update the target’s probable location\\nand launch a new plan every two hours to maximize his chance of locating it.\\nAll of the commander’s planning for two-hour sequential searches could\\nbe done ahead of time in his stateroom. Koopman called it a “continuous\\ndistribution of effort.” His U-boat sea searches were theoretically similar to\\nKolmogorov’s artillery problem. Koopman was searching for an unknown U-\\nboat and needed to spread the search effort over an area in an optimal way,\\njust as Kolmogorov figured the optimal amount of dispersion in order to\\ndestroy a German cannon. Minesweepers, who worked with similar\\nproblems, adopted Koopman’s techniques.\\nThree crucial turning points—two of them top secret—occurred in the\\nEuropean war during 1943. First, in what the Russians still call the Great\\nPatriotic War, the Soviets defeated the Germans on the Eastern Front, at a\\ncost of more than 27 million lives. Second, the tide began to turn against the\\nGermans’ U-boats; they sank a quarter million tons in May but 41 subs were\\nlost. Third, Bletchley Park became a giant factory employing almost 9,000\\npeople. As more bombes came online, the laborious Banburismus\\ncardboards were phased out. Barring unforeseen changes by German\\ncryptographers, decoding naval Enigma was under control.\\nBack home safely and free of responsibility for the Enigma and Tunny-\\nLorenz codes, Turing, the great theoretician, was free to dream. During long\\nwalks in the countryside around Bletchley Park, Turing and Good discussed\\nmachines that could think with Donald Michie, who would pioneer artificial\\nintelligence. Michie, who had joined Bletchley Park as an 18-year-old,\\ndescribed the trio as “an intellectual cabal with a shared obsession with\\nthinking machines and particularly with machine learning as the only credible\\nroad to achieving such machines.” They talked about “various approaches,\\nconjectures, and arguments concerning what today we call AI.”38\\nMax Newman, formerly Turing’s mathematics instructor at Cambridge,\\nwanted to automate the British attack on Tunny-Lorenz’s codes, and he,\\nMichie, and Good were already working on new machines to do it. Michie\\nhad refined Turingismus, but it soon became obvious that mechanical\\nswitches would be far too slow. The process would have to be electronic;\\nengineer Thomas H. Flowers suggested using glass vacuum tubes because\\nthey could switch current on and off much faster. With backing from\\nNewman, Flowers built the first Colossus at the Post Office Research\\nStation, which ran Britain’s telephone system. Installed at Bletchley Park,\\nColossus decrypted its first message on February 5, 1944. Flowers’s car\\nbroke down that day but not his Colossus.\\nFlowers had strict orders—no reasons given—to get a second, more\\nadvanced Colossus model operational no later than June 1. Working until\\nthey thought their eyes were dropping out, Flowers and his team had\\nColossus II ready on schedule.\\nAlmost as soon as it began operating, Hitler teletyped an encrypted\\nmessage to his commanding officer in Normandy, Field Marshal Erwin\\nRommel. He ordered Rommel not to move his troops for five days after any\\ninvasion of Normandy. Hitler had decided it would be a diversionary feint to\\ndraw German troops away from the ports along the English Channel and that\\nthe real invasion would take place five days later. Colossus II decoded the\\nmessage, and a courier raced a copy from Bletchley Park to Gen. Dwight\\n“Ike” Eisenhower. As Ike and his staff were trying to decide when to launch\\nthe invasion of Normandy the courier handed him a sheet of paper containing\\nHitler’s order. Unable to tell his staff about Bletchley Park, Eisenhower\\nsimply returned the paper to the courier and announced, “We go tomorrow,”\\nthe morning of June 6.39 He later estimated that Bletchley Park’s decoders\\nhad shortened the war in Europe by at least two years.\\nThe Colossi became the world’s first large-scale electronic digital\\ncomputers, built for a special purpose but capable of making other\\ncomputations too. Flowers would build ten more models during the war.\\nWith the Germans introducing complexities that made manual decrypting\\nmethods useless, the Colossi replaced Turing’s pencil-and-paper Turingery\\nin August 1944. As Michie reported, Turing’s Bayesian scoring system based\\non bans had started “first as a minor mental aid in a variety of jobs” but then\\nturned into “a major aid in the [Colossi’s] wheel pattern breaking.”40\\nTuring’s method also contributed intellectually to the use of the Colossi and\\nproduced procedures that made the machines much more effective. Each new\\nColossus was an improvement over the previous one, and Michie believed\\nthe eleventh “nudged the design further in the direction of ‘programmability’\\nin the modern sense.”41\\nBy 1945 Turing had moved on to voice encryption at a nearby military\\ninstallation at Hanslope Park. Late in the war, others at Bletchley Park,\\nignorant of Turing’s work on Enigma, decided to use Bayesian methods to try\\nto break the Japanese naval codes in the Pacific. Japan’s main naval cipher,\\nJN-25, was becoming increasingly complex, and Bletchley Park began\\nworking on some particularly difficult versions shortly after September\\n1943.\\nA trio of British mathematicians was assigned to work in tandem with\\nWashington. The three were Ian Cassels, later a professor at Cambridge;\\nJimmy Whitworth; and Edward Simpson, who had joined Bletchley Park in\\n1942, immediately after earning a mathematics degree at Queen’s University,\\nBelfast, at the age of 19. Simpson had been working on Italian codes at\\nBletchley Park, but after Italy’s surrender he was switched to JN-25.\\n“The unbelievably tight security ethos” at Bletchley Park prevented the\\ngroup from getting advice from Turing or Good, Simpson explained in 2009\\nafter his wartime work was revealed.42 As a result, the men adopted and\\ndeveloped Bayes on their own. It was a full year before they were able to\\nspeak with Turing’s colleague Alexander, who by that time had begun work\\non Japanese naval codes too.\\nJapanese coding clerks who used the principal code, JN-25, transmitted\\ntheir messages in blocks of five digits. The British mathematicians knew that\\neach block was the result of adding a random five-digit group, called an\\nadditive, to a five-digit code group taken from the JN-25 codebook. In effect,\\nBritish cryptanalysts had to perform the reverse operation—but without the\\nJN code and additive books. First, they identified groups that might be\\nadditives. Then a team composed of civilians and Wrens who, despite being\\nnewcomers to cryptography, had to identify the most probable additives\\nrapidly, objectively, and in a standardized manner. They could judge the\\nplausibility of an additive according to the plausibility or probability of the\\ndeciphered code group produced by the additive. As a measure of their\\nbelief, team members assigned a Bayesian probability to each speculative\\ncode group according to how often it had occurred in already deciphered\\nmessages. The most probable blocks, as well as borderline or especially\\nimportant cases, were studied further.\\n“For practical purposes, it was not necessary to agonise over the prior\\nodds to be assigned to the hypothesis that an additive was true,” Simpson\\nexplained. “Instead, the essential judgment to be made was whether the\\n[weight of] collective evidence . . . was sufficiently convincing for it to be\\naccepted as genuine . . . As always in cryptanalysis, the inspired hunch\\ngrounded in experience could sometimes make the most important\\ncontribution of all.”43\\nAfter October 1944 Alexander, Bletchley Park’s finest Banburismus\\nsolver, developed an elaborate use of Bayes’ theorem and Turing’s decibans\\nfor the Japanese codes.\\nBy 1945 U.S. cryptanalysts were writing memos to one another about\\nBayes’ theorem. Whether the Americans learned about Bayes from Bletchley\\nPark or discovered its usefulness on their own is not known; 65 years after\\nthe war, the British government still refuses to declassify many documents\\nabout wartime cryptography. A young American mathematician, Andrew\\nGleason, who was working on Japanese naval codes and who looked after\\nTuring during his stay in Washington, almost certainly knew about Bayes\\nduring the war. He, Good, and Alexander continued to work on top-secret\\ncryptography for decades after the war. Gleason helped establish a postwar\\ncurriculum for training cryptanalysts at the U.S. National Security Agency\\n(NSA), taught mathematics at Harvard and NSA, and published a probability\\ntextbook that instructed a generation of NSA’s cryptanalysts in how to use\\nBayes’ theorem, Turing’s decibans and centibans, Bayesian inference, and\\nhypothesis testing. Some 20 of his students became leaders in Soviet code\\nbreaking during the 1960s and 1970s. Gleason was deeply knowledgeable\\nbut pragmatic about Bayes; his textbook also discussed methods developed\\nby Neyman, the arch anti-Bayesian.\\nA few days after Germany’s surrender in May 1945 Churchill made a\\nsurprising and shocking move. He ordered the destruction of all evidence that\\ndecoding had helped win the Second World War. The fact that cryptography,\\nBletchley Park, Turing, Bayes’ rule, and the Colossi had contributed to\\nvictory was to be destroyed. Turing’s assistant Good complained later that\\neverything about decryption and the U-boat fight “from Hollerith [punch]\\ncards to sequential statistics, to empirical Bayes, to Markov chains, to\\ndecision theory, to electronic computers” was to remain ultraclassified.44\\nMost of the Colossi were dismantled and broken into unidentifiable pieces.\\nThose who built the Colossi and broke Tunny were gagged by Britain’s\\nOfficial Secrets Acts and the Cold War; they could not even say that the\\nColossi had existed. Books by British and U.S. participants in the U-boat\\nwar were almost immediately classified, confined to high-level military\\ncircles, and not published for years or in some cases decades. Even\\nclassified histories of the war excluded the decryption campaign against the\\nU-boats. Only after 1973 did the story of Bayes, Bletchley Park, and Turing’s\\nnation-saving efforts begin to emerge.\\nWhy was the story concealed for so long? The answer seems to be that the\\nBritish did not want the Soviet government to know they could decrypt\\nTunny-Lorenz codes. The Russians had captured a number of Lorenz\\nmachines, and Britain used at least one of the two surviving Colossi to break\\nSoviet codes during the Cold War. Only when the Soviets replaced their\\nLorenz machines with new cryptosystems was Bletchley Park’s story\\nrevealed.\\nThe secrecy had tragic consequences. Family and friends of Bletchley\\nPark employees went to their graves without ever knowing the contributions\\ntheir loved ones had made during the war. Those connected with Colossus,\\nthe epitome of the British decryption effort, received little or no credit.\\nTuring was given an Order of the British Empire (OBE), a routine award\\ngiven to high civil servants. Newman was so angry at the government’s\\n“derisory” lack of gratitude to Turing that he refused his own OBE.\\nBritain’s science, technology, and economy were losers, too. The Colossi\\nwere built and operational years before the ENIAC in Pennsylvania and\\nbefore John von Neumann’s computer at the Institute for Advance Study in\\nPrinceton, but for the next half century the world assumed that U.S. computers\\nhad come first.\\nObliterating all information about the decryption campaign distorted Cold\\nWar attitudes about the value of cryptanalysis and about antisubmarine\\nwarfare. The war replaced human spies with machines. Decryption was\\nfaster than spying and provided unfiltered knowledge of the enemy’s thinking\\nin real time, yet the Cold War glamorized military hardware and the derring-\\ndo of spydom.\\nThe secrecy also had a catastrophic effect on Turing. At the end of the war\\nhe said he wanted “to build a brain.”45 To do so, he turned down a\\nlectureship at Cambridge University and joined the National Physical\\nLaboratory in London. Because of the Official Secrets Act he arrived as a\\nnobody. Had he been knighted or otherwise honored he would surely have\\nfound it easier to get more than two engineers as support staff. Ignorant of\\nTuring’s achievements, the director of the laboratory, Charles Galton\\nDarwin, a grandson of Charles Darwin, repeatedly reprimanded Turing for\\nmorning tardiness after working late the night before. Once an afternoon\\ncommittee meeting with Darwin and others stretched late in the day. At 5:30\\np.m. Turing promptly stood up and announced to Darwin that he was leaving\\n—“punctually.”46\\nAt the laboratory, Turing designed the first relatively complete electronic\\nstored-program digital computer for code breaking in 1945. Darwin deemed\\nit too ambitious, however, and after several years Turing left in disgust.\\nWhen the laboratory finally built his design in 1950, it was the fastest\\ncomputer in the world and, astonishingly, had the memory capacity of an\\nearly Macintosh built three decades later.\\nTuring moved to the University of Manchester, where Newman was\\nbuilding the first electronic, stored-program digital computer for Britain’s\\natomic bomb. Working in Manchester, Turing pioneered the first computer\\nsoftware, gave the first lecture on computer intelligence, and devised his\\nfamous Turing Test: a computer is thinking if, after five minutes of\\nquestioning, a person cannot distinguish its responses from those of a human\\nin the next room. Later, Turing became interested in physical chemistry and\\nhow huge biological molecules construct themselves into symmetrical\\nshapes.\\nA series of spectacular international events in 1949 and 1950 intruded on\\nthese productive years and precipitated a personal crisis for Turing: the\\nSoviets surprised the West by detonating an atomic bomb; Communists\\ngained control of mainland China; Alger Hiss, Klaus Fuchs, and Julius and\\nEthel Rosenberg were arrested for spying; and Sen. Joseph McCarthy of\\nWisconsin began brandishing his unsubstantiated list of so-called\\nCommunists in the U.S. State Department.\\nEven worse, two upper-crust English spies—an openly promiscuous and\\nalcoholic homosexual named Guy Burgess and his friend from Cambridge\\nstudent days Donald Maclean—evaded arrest by fleeing to the USSR in\\n1950. The United States told British intelligence they had been tipped off by\\nAnthony Blunt, another homosexual graduate of Cambridge, a leading art\\nhistorian, and the queen’s surveyor of paintings. With both the British and\\nAmerican governments panicked by visions of a homosexual spy scandal, the\\nnumber of men arrested for homosexuality in Britain spiked.\\nOn the first day of Queen Elizabeth II’s reign, February 7, 1952, Turing\\nwas arrested for homosexual activity conducted in the privacy of his home\\nwith a consenting adult. As Good protested later, “Fortunately, the authorities\\nat Bletchley Park had no idea Turing was a homosexual; otherwise we might\\nhave lost the war.”47\\nIn the uproar over Burgess and Maclean, Turing was viewed not as the\\nhero of his country but as yet another Cambridge homosexual privy to the\\nmost closely guarded state secrets. He had even worked on the computer\\ninvolved in Britain’s atomic bomb test. As a result of his arrest, Britain’s\\nleading cryptanalyst lost his security clearance and any chance to continue\\nwork on decoding. In addition, because the U.S. Congress had just banned\\ngays from entering the country, he was unable to get a visa to travel or work\\nin the United States.\\nAs the world lionized the Manhattan Project physicists who engineered the\\natomic and hydrogen bombs, as Nazi war criminals went free, and as the\\nUnited States recruited German rocket experts, Turing was found guilty. Less\\nthan a decade after England fought a war against Nazis who had conducted\\nmedical experiments on their prisoners, an English judge forced Turing to\\nchoose between prison and chemical castration. He chose the estrogen\\ninjections. Over the next year he grew breasts. And on June 7, 1954, the day\\nafter the tenth anniversary of the Normandy invasion he helped make\\npossible, Alan Turing committed suicide. Two years later the British\\ngovernment knighted Anthony Blunt, the spy who later admitted tipping off\\nhis friends Burgess and Maclean and precipitating the witch hunt against\\nhomosexuals. Even today, it is difficult to write—or read—about Turing’s\\nend. In 2009, 55 years after Turing’s death, a British prime minister, Gordon\\nBrown, finally apologized.\\nTuring’s Bayesian work lived on in cryptography. Secretly for decades, an\\nAmerican colleague of Turing’s taught Bayes to NSA cryptographers. With\\nTuring’s blessing, Good developed Bayesian methods and theory and became\\none of the world’s leading cryptanalysts and one of the three leaders in the\\nBayesian renaissance of the 1950s and 1960s. He wrote roughly 900 articles\\nabout Bayes’ rule and published most of them.\\nOutside of cryptography, however, no one knew that some of the most\\nbrilliant thinkers of the mid-twentieth century had used Bayes to defend their\\ncountries during the Second World War. It emerged from the war as vilified\\nas ever.\\n5.\\n \\ndead and buried again\\n \\nWith its wartime successes classified, Bayes’ rule emerged from the Second\\nWorld War even more suspect than before. Statistics books and papers\\nstressed repeatedly and self-righteously that they did not use the rule. When\\nJack Good discussed the method at the Royal Statistical Society, the next\\nspeaker’s opening words were, “After that nonsense . . .”1\\n“Bayes” still meant equal priors and did not yet mean making inferences,\\nconclusions, or predictions based on updating observational data. The\\nNational Bureau of Standards suppressed a report to Aberdeen Proving\\nGround, the U.S. Army’s weapons-testing center, during the 1950s because\\nthe study used subjective Bayesian methods. During Sen. Joseph McCarthy’s\\ncampaign against Communists, a bureau statistician half-jokingly called a\\ncolleague “un-American because [he] was Bayesian, and . . . undermining the\\nUnited States Government.”2 Professors at Harvard Business School called\\ntheir Bayesian colleagues “socialists and so-called scientists.”3\\n“There still seems to remain in some quarters a lingering idea that there is\\nsomething ‘not quite nice,’ something unsound, about the whole concept of\\ninverse probability,” a prominent statistician wrote.4 Unless declared\\notherwise, a statistician was considered a frequentist.\\nThe Bayesian community was small and isolated, and its publications\\nwere well-nigh invisible. Prewar theory by Frank Ramsey, Harold Jeffreys,\\nand Bruno de Finetti lay unread. Nearly all the papers published in the\\nAnnals of Mathematical Statistics concerned issues framed by Jerzy\\nNeyman’s frequentist work from the 1930s. Thanks to Ronald Fisher’s\\ngenetics research and the powerful anti-Bayesian stance of an Iowa State\\nUniversity statistician named Oscar Kempthorne, agricultural studies at most\\nland-grant institutions relied on frequentism. When Gertrude Cox, the\\npresident of the American Statistical Society in 1956, spoke about the future\\nof statistics, she barely mentioned Bayes. The first practical article telling\\nscientists how to use Bayesian analysis would not appear until 1963.\\nNot even civilian researchers for the military knew much about Bayes in\\n1950. When an economist was preparing a research budget for the U.S. Air\\nForce at RAND, a California think tank, he asked visiting statistician David\\nBlackwell how to assess the probability that a major war would occur within\\nfive years. Blackwell, who had not yet become a Bayesian, answered, “Oh,\\nthat question just doesn’t make sense. Probability applies to a long sequence\\nof repeatable events, and this is clearly a unique situation. The probability is\\neither 0 or 1, but we won’t know for five years.” The economist nodded and\\nsaid, “I was afraid you were going to say that. I have spoken to several other\\nstatisticians, and they have all told me the same thing.”5\\nThe Bayesian theorist Dennis V. Lindley concluded, “The upstart Bayesian\\nmovement is being contained, largely by being ignored.”6 Another statistician\\nrecalled, “A lot of us thought [Bayes] was dead and buried.”7\\npart III\\n \\nthe glorious revival\\n \\n6.\\n \\narthur bailey\\n \\nAfter the Second World War the first public challenge to the anti-Bayesian\\nstatus quo came not from the military or university mathematicians and\\nstatisticians but from a Bible-quoting business executive named Arthur L.\\nBailey.\\nBailey was an insurance actuary whose father had been fired and black-\\nballed by every bank in Boston for telling his employers they should not be\\nlending large sums of money to local politicians. So ostracized was the\\nfamily that even Arthur’s schoolmates stopped inviting him and his sister to\\nparties. Turning his back on the New England establishment, Bailey enrolled\\nat the University of Michigan in Ann Arbor. There he studied statistics in the\\nmathematics department’s actuarial program, earned a bachelor of science\\ndegree in 1928, and met his wife, Helen, who became an actuary for John\\nHancock Mutual Life before their children were born.1\\nBailey’s first job was, he liked to say, “in bananas,” that is, in the statistics\\ndepartment of the United Fruit Company headquarters in Boston. When the\\ndepartment was eliminated during the Depression, Bailey wound up driving a\\nfruit truck and chasing escaped tarantulas down Boston streets. He was lucky\\nto have the job, and his family never lacked for bananas and oranges.\\nIn 1937, after nine years in bananas, Bailey got a job in an unrelated field\\nin New York City. There he was in charge of setting premium rates to cover\\nrisks involving automobiles, aircraft, manufacturing, burglary, and theft for\\nthe American Mutual Alliance, a consortium of mutual insurance companies.\\nPreferring church and community connections to the fair-weather friends of\\nhis youth, Bailey hid his growing professional success by living quietly in\\nunpretentious New York suburbs. He relaxed by gardening, hiking with his\\nfour children, and annotating a copy of Gray’s Botany with the locations of\\nhis favorite wild orchids. His motto was, “Some people live in the past,\\nsome people live in the future, but the wisest ones live in the present.”\\nSettling into his new job, Bailey was horrified to see “hard-shelled\\nunderwriters” using the semi-empirical, “sledge hammer” Bayesian\\ntechniques developed in 1918 for workers’ compensation insurance.2\\nUniversity statisticians had long since virtually outlawed those methods, but\\nas practical business people, actuaries refused to discard their prior\\nknowledge and continued to modify their old data with new. Thus they based\\nnext year’s premiums on this year’s rates as refined and modified with new\\nclaims information. They did not ask what the new rates should be. Instead,\\nthey asked, “How much should the present rates be changed?” A Bayesian\\nestimating how much ice cream someone would eat in the coming year, for\\nexample, would combine data about the individual’s recent ice cream\\nconsumption with other information, such as national dessert trends.\\nAs a modern statistical sophisticate, Bailey was scandalized. His\\nprofessors, influenced by Ronald Fisher and Jerzy Neyman, had taught him\\nthat Bayesian priors were “more horrid than ‘spit,’” in the words of a\\nparticularly polite actuary.3 Statisticians should have no prior opinions about\\ntheir next experiments or observations and should employ only directly\\nrelevant observations while rejecting peripheral, nonstatistical information.\\nNo standard methods even existed for evaluating the credibility of prior\\nknowledge (about previous rates, for example) or for correlating it with\\nadditional statistical information.\\nBailey spent his first year in New York trying to prove to himself that “all\\nof the fancy actuarial [Bayesian] procedures of the casualty business were\\nmathematically unsound.”4 After a year of intense mental struggle, however,\\nhe realized to his consternation that actuarial sledgehammering worked. He\\neven preferred it to the elegance of frequentism. He positively liked formulae\\nthat described “actual data. . . . I realized that the hard-shelled underwriters\\nwere recognizing certain facts of life neglected by the statistical theorists.”5\\nHe wanted to give more weight to a large volume of data than to the\\nfrequentists’ small sample; doing so felt surprisingly “logical and\\nreasonable.” He concluded that only a “suicidal” actuary would use Fisher’s\\nmethod of maximum likelihood, which assigned a zero probability to\\nnonevents.6 Since many businesses file no insurance claims at all, Fisher’s\\nmethod would produce premiums too low to cover future losses.\\nAbandoning his initial suspicions of Bayes’ rule, Bailey spent the Second\\nWorld War studying the problem. He worked alone, isolated from academic\\nthinkers and from his actuarial colleagues, who scratched their heads at\\nBailey’s brilliance.\\nAfter the war, in 1947, Bailey moved to the New York State Insurance\\nDepartment as the regulatory agency’s chief actuary. An insurance executive\\ncalled him “the keeper of our consciences.” As his colleagues boozed in\\nhotel bars at conferences, Bailey sipped soft drinks and quoted occasionally\\nfrom the Bible. During slack times, he read it. Some actuaries said “all\\nmanner of nasty things about Arthur Bailey,” the executive continued, “but we\\nlearned to respect his integrity and stature from knowing him in the after-\\nhours.”7\\nBailey began writing an article summarizing his tumultuous change in\\nattitude toward Bayes’ rule. Although his old-fashioned notation was\\ndifficult to understand, he was building a mathematical foundation to justify\\nthe use of current rates as the priors in Bayes’ theorem. He started his paper\\nwith a biblical justification for using prior beliefs: “If thou canst believe,” he\\nwrote, quoting the apostle Mark, “all things are possible to him that\\nbelieveth.” Then, reviewing Albert Whitney’s mathematics for workers’\\ncompensation, Bailey affirmed the Bayesian roots of the Credibility theory\\ndeveloped for workers’ compensation insurance years before. Credibility\\nwas central to actuarial thought, and while relative frequencies were\\nrelevant, so were other kinds of information. Bailey worked out\\nmathematical methods for melding every scrap of available information into\\nthe initial body of data. He particularly tried to understand how to assign\\npartial weights to supplementary evidence according to its credibility, that is,\\nits subjective believability. His mathematical techniques would help\\nactuaries systematically and consistently integrate thousands of old and new\\nrates for different kinds of employers, activities, and locales. His working\\nlibrary included a 1940 reprint of Bayes’ articles with a preface by Bell\\nTelephone’s Edward Molina. Like Molina, Bailey used Laplace’s more\\ncomplex and precise system instead of Thomas Bayes’.\\nBy 1950 Bailey was a vice president of the Kemper Insurance Group in\\nChicago and a frequent after-dinner speaker at black-tie banquets of the\\nCasualty Actuarial Society. He read his most famous paper on May 22, 1950.\\nIts title explained a lot: “Credibility Procedures: Laplace’s Generalization of\\nBayes’ Rule and the Combination of Collateral [that is, prior] Knowledge\\nwith Observed Data.”\\nFor actuaries who could concentrate on a long scholarly paper after a\\nheavy (and no doubt alcoholic) meal, Bailey’s message must have been\\nthrilling. First, he praised his colleagues for standing almost alone against the\\nstatistical establishment and for staging the only organized revolt against the\\nfrequentists’ sampling philosophy. Insurance statisticians marched “a step\\nahead” of others. Actuarial practice was an obscure and profound mystery,\\nand it went “beyond anything that has been proven mathematically.” But, he\\ndeclared triumphantly, “it works. . . . They have made this demonstration\\nmany times. It does work!”8\\nThen he announced the startling news that their beloved Credibility\\nformula was derived from Bayes’ theorem. Practical actuaries had thought of\\nBayes as an abstract, temporal solution treating time sequences of priors and\\nposteriors. But Bailey reminded his colleagues that Bayes’ friend and editor,\\nRichard Price, would be considered today an actuary. And he turned Bayes’\\nimaginary table into a frontal attack on frequentists and the contentious\\nFisher. He concluded with a rousing call to reinstate prior knowledge in\\nstatistical theory. His challenge would occupy academic theorists for years.\\nIt was a fighting speech. Reading it later, Professor Richard von Mises of\\nHarvard praised it wholeheartedly. Von Mises wrote Bailey that he hoped his\\nspeech would make “the unjustified and unreasonable attacks on the Bayes\\ntheory, initiated by R. A. Fisher, fade out.”9\\nUnfortunately, Bailey did not live long to campaign for Bayes’ rule. Four\\nyears after giving his most important speech, he suffered a heart attack at the\\nage of 49 and died on August 12, 1954. His son blamed the fact that Bailey\\nhad started smoking in college and been unable to stop.\\nStill, a few practicing actuaries understood his message. The year of\\nBailey’s death, one of his admirers was sipping a martini at the Insurance\\nCompany of North America’s Christmas party when INA’s chief executive\\nofficer, dressed as Santa Claus, asked an unthinkable question: Could anyone\\npredict the probability of two planes colliding in midair?\\nSanta was asking his chief actuary, L. H. Longley-Cook, to make a\\nprediction based on no experience at all. There had never been a serious\\nmidair collision of commercial planes. Without any past experience or\\nrepetitive experimentation, any orthodox statistician had to answer Santa’s\\nquestion with a resounding no. But the very British Longley-Cook stalled for\\ntime. “I really don’t like these things mixed with martinis,” he drawled.\\nNevertheless, the question gnawed at him. Within a year more Americans\\nwould be traveling by air than by railroad. Meanwhile, some statisticians\\nwere wondering if they could avoid using the ever-controversial subjective\\npriors by making predictions based on no prior information at all.\\nLongley-Cook spent the holidays mulling over the problem, and on January\\n6, 1955, he sent the CEO a prescient warning. Despite the industry’s safety\\nrecord, the available data on airline accidents in general made him expect\\n“anything from 0 to 4 air carrier-to-air carrier collisions over the next ten\\nyears.” In short, the company should prepare for a costly catastrophe by\\nraising premium rates for air carriers and purchasing reinsurance. Two years\\nlater his prediction proved correct. A DC-7 and a Constellation collided\\nover the Grand Canyon, killing 128 people in what was then commercial\\naviation’s worst accident. Four years after that, a DC-8 jet and a\\nConstellation collided over New York City, killing 133 people in the planes\\nand in the apartments below.10\\nLater, Arthur Bailey’s son, Robert A. Bailey, used Bayesian techniques to\\njustify offering merit rates to good drivers. Motor vehicle casualty rates\\nsoared so high during the 1960s that half the Americans then alive could\\nexpect to be injured in a car accident during their lifetimes. Americans were\\nbuying more cars and driving more miles, but laws had not kept pace. There\\nwas no uniform road signage; most drivers and vehicles were tested or\\ninspected only once in their lifetimes, if at all; penalties for drunk driving\\nwere light; and cars were designed without safety in mind. Insurers suffered\\nheavy losses. A direct, up-front system to reward good drivers was needed,\\nbut merit rating was regarded as unsound because a single car had inadequate\\ncredibility. Using Bayes’ rule, Robert Bailey and Leroy J. Simon showed that\\nrelevant data from Canada’s safe-driving discounts could be used to update\\nexisting U.S. statistics.\\nRobert Bailey also used Bayesian procedures to rate insurance companies\\nthemselves by incorporating nonstatistical, subjective information such as\\nopinions about a company’s ownership, including the quality and drinking\\nhabits of its managers. In time, the insurance industry accumulated such\\nenormous amounts of data that Bayes’ rule, like the slide rule, became\\nobsolete.\\nTo the few actuaries who understood Arthur Bailey’s work, he was a da\\nVinci or a Michelangelo: he had led their profession out of its dark ages.11\\nNews of his achievement percolated slowly and haphazardly to university\\ntheorists. During the early 1960s an actuarial professor at the University of\\nMichigan, Allen L. Mayerson, wrote about Bailey’s seminal role in\\nCredibility theory. Professor of statistics Jimmie Savage, a new convert to\\nBayesian methods, was working in Ann Arbor at the time and later visited\\nBruno de Finetti, the Bayesian actuarial professor, at his vacation home on an\\nisland off Italy. The two attended a conference together in Trieste, where the\\nItalian spread the word about Bailey and the Bayesian origin of insurance\\nCredibility. It was the first time most statisticians had heard of him.\\nHans Bühlmann, who became a mathematics professor and president of\\nETH Zurich, remembers the excitement of that conference. He had spent a\\nleave of absence studying in Neyman’s statistics department in Berkeley in\\nthe 1950s, “when it was kind of dangerous to pronounce the Bayesian point\\nof view.” Taking up Bailey’s challenge, Bühlmann produced a general\\nBayesian theory of credibility, which statisticians carried far beyond the\\nworld of actuaries and insurance. Carefully renaming the prior a “structural\\nfunction,” Bühlmann believed he helped Continental Europe escape some of\\nthe “religious” quarrels over Bayes’ rule, quarrels that lay ahead for Anglo-\\nAmericans.12\\n7.\\n \\nfrom tool to theology\\n \\nWhile Arthur Bailey was transforming the sledgehammer of Credibility into\\nBayes’ rule for the insurance industry, a postwar boom in statistics was\\nelevating the method’s lowly status. Gradually, Bayes would shed its\\nreputation as a mere tool for solving practical problems and emerge in\\nglorious Technicolor as an all-encompassing philosophy. Some would even\\ncall it a theology.\\nThe Second World War had radically upgraded the stature, financial\\nprospects, and career opportunities of applied mathematicians in the United\\nStates. The military was profoundly impressed by its wartime experience\\nwith statistics and operations research, and during the late 1940s the\\ngovernment poured money into science and statistics. Military funding\\nofficers roamed university hallways trying to persuade often reluctant\\nstatisticians to apply for grants. Naval leaders, convinced that postwar\\nscience needed a jump-start to prime technology’s pump, organized the\\nOffice of Naval Research, the first federal agency formed expressly to\\nfinance scientific research. Until the National Science Foundation was\\ncreated in 1950, the U.S. Navy supported much of the nation’s mathematical\\nand statistical research, whether classified or unclassified, basic or applied.\\nOther funding came from the U.S. Army, the U.S. Air Force, and the National\\nInstitutes of Health.\\nA generation of pure mathematicians who had made exciting, life-or-death\\ndecisions during the war soon switched to applied mathematics and\\nstatistics. As the statistics capital of the world moved from Britain to the\\nUnited States, the field exploded. Amid such spectacular growth, the number\\nof theoretical statisticians increased a hundred-fold. Settling into\\nmathematics departments, they coined new terms like “mathematical\\nstatistics” and “theoretical statistics.”\\nIn these boom times, even Bayesians could get jobs in elite research\\ninstitutions. At one end of the Bayesian spectrum was a small band of\\nevangelists intent on making their theories mathematically and academically\\nrespectable. At the other end were practitioners who wanted to play key\\nroles in science instead of in formalistic mathematical exercises.\\nIn the face of jangling changes and new attitudes, the wartime marriage of\\nconvenience between abstract and applied mathematicians fell apart.\\nStatisticians complained that pure mathematicians regarded useful research\\nas “something for peasants,” akin to washing dishes and sweeping streets.1\\nJack Good claimed the mathematicians at Virginia Tech, home of the nation’s\\nthird largest statistics department in the 1960s, loathed problem solvers.2\\nFrisky with federal funds, statisticians and data analysts divorced\\nthemselves from mathematics departments and formed their own enclaves.\\nYet even there tension sizzled between abstract theorizing and scientific\\napplications, albeit in more decorous privacy. Serial schisms continue to this\\nday, with applied mathematicians occupying—depending on the university—\\ndepartments of mathematics, applied mathematics, statistics, biostatistics,\\nand computer science.\\nJerzy Neyman’s laboratory at Berkeley, then the largest and most important\\nstatistics center in the world, developed fundamental sampling theories and\\nreigned over this fractious profession for years after the Second World War.\\nBut Neyman’s laboratory developed fissures of its own. Unable to compete\\nwith the soaring demand for statisticians, the department hired and promoted\\nits own students and became ingrown. When a student tried to solve a\\nblackboard problem unconventionally, Neyman grabbed his hand and forced\\nit to write the answer Neyman’s way. For 40 years most of his hires were\\nfrequentists, and outsiders called the group “Jesus and his disciples.”3\\nNeyman continued to run his institute into his 80s.\\nAlthough both were fervent anti-Bayesians, Neyman and Fisher battled to\\nthe end, neither willing to admit that the other might be using the technique\\nthat best fit his own needs. For Fisher, the stakes were high: “We are quite in\\ndanger of sending highly trained and intelligent young men out into the world\\nwith tables of erroneous numbers under their arms, and with a dense fog in\\nthe place where their brains ought to be. In this century, of course, they will\\nbe working on guided missiles and advising the medical profession on the\\ncontrol of diseases, and there is no limit to the extent to which they could\\nimpede every sort of national effort.”4 He described Neyman as “some\\nhundred years out of date, . . . partly incapacitated by the crooked\\nreasoning.”5 Neyman called Fisher’s researches “insidious because, in a\\nskillfully hidden manner, they involve unjustified claims of priority.”6 And so\\nit went. At the age of 85, Neyman declared loftily, “[Bayes] does not interest\\nme. I am interested in frequencies.”7\\nTo Bayesian sympathizers, frequentism began to look like a Rube\\nGoldberg cartoon of loosely connected ad hockeries, tests, and procedures\\nthat arose independently instead of growing in a unified, logical manner out\\nof probability. The joke was that if you didn’t like the result of your\\nfrequentist analysis, you just redid it using a different test. By comparison,\\nBayes’ rule seemed to have an overall rationale. As the number of\\nstatisticians, symposia, articles, and journals multiplied, a series of\\npublications issued around 1950 began to attract attention to the heretofore\\ninvisible world of Bayes’ rule.\\nBayes stood poised for another of its periodic rebirths as three\\nmathematicians, Jack Good, Leonard Jimmie Savage, and Dennis V. Lindley,\\ntackled the job of turning Bayes’ rule into a respectable form of mathematics\\nand a logical, coherent methodology. The first publication heralding the\\nBayesian revival was a book by Good, Alan Turing’s wartime assistant. As\\nGood explained, “After the war, he [Turing] didn’t have time to write about\\nstatistics because he was too busy designing computers and computer\\nlanguages, and speculating about artificial intelligence and the chemical\\nbasis of morphogenesis, so with his permission, I developed his idea . . . in\\nconsiderable detail.”8 Good finished the first draft of Probability and the\\nWeighing of Evidence in 1946 but could not get it published until 1950, the\\nsame year Arthur Bailey issued his Bayesian manifesto for actuaries. Much\\nof the delay, Good explained, was caused by the continuation of wartime\\nsecrecy during the Cold War.\\nAt first, his book fell on deaf ears. He was unaccustomed to teaching or\\nexplaining his ideas, and no one knew he had used Bayes to help break the\\nEnigma codes. When he gave a talk about his “neo-Bayesian or neo/ Bayes-\\nLaplace philosophy” at a Royal Statistical Society conference, his style was\\nclipped, and he did not waste words.9 Lindley, who was in the audience,\\nreported, “He did not get his ideas across to us. We should have paid much\\nmore respect to what he was saying because he was way in advance of us in\\nmany ways.”10\\nAfter the war Good continued doing classified cryptography for the British\\ngovernment and frequently used equal priors to help decide what hypotheses\\nhe should follow up. When David Kahn’s bestseller The Codebreakers was\\npublished in 1967, the National Security Agency censored a passage\\nidentifying Good as one of Britain’s top three cryptanalysts. He was at the\\ntime one of the world’s most knowledgeable people about the coding\\nindustry. Good was quick, smart, original, armed with a fabulous memory,\\nand unconventional enough to think about the paranormal and astrology and to\\njoin Mensa, the organization for people with high IQs. He introduced himself\\nwith a handshake and the words, “I am Good.”11\\nFrom the Second World War on, everything technical about cryptography\\nwas classified, and while Good obeyed the restraints, he chafed against them\\nand looked for ways to evade censorship. To reveal an ultraclassified\\ntechnique used by Turing to find pairs and triplets of letters indicating the\\nGerman submariners’ code of the day, Good wrote about a favorite British\\nhobby, bird watching. What if, he suggested, an avid bird watcher spotted\\n180 different bird species? Many of them would be represented by only one\\nbird; logically, the bird watcher must have entirely missed many other\\nspecies. Counting those missing species as zero (as a frequentist would have\\ndone) has the deleterious effect of asserting that missing species can never be\\nfound. Turing decided to assign those missing species a tiny possibility, a\\nprobability that is not zero. He was trying to learn about rare letter groupings\\nthat did not appear in his collection of intercepted German messages. By\\nestimating the frequency of missing species in his sample, he could use Bayes\\nto estimate the probability of those letter groupings appearing in a much\\nlarger sample of messages and in the very next Enigma message he received.\\nDecades later, DNA decoders and artificial intelligence analysts would\\nadopt the same technique.\\nClever as he was, Good could be difficult to get along with, and he moved\\nfrom post to post. After he spent a year at a cryptography think tank, the\\nInstitute for Defense Analyses (then at Princeton University), many\\ncoworkers were relieved to see him go. In 1967 Good moved permanently to\\nVirginia Polytechnic Institute and State University in Blacksburg. At his\\ninsistence, his contract stipulated that he would always be paid one dollar\\nmore than the football coach. He worked far from the Bayesian mainstream,\\nhowever; during the 1960s Bayes’ rule in the United States was concentrated\\nat the universities of Chicago and Wisconsin and at Harvard and Carnegie\\nMellon.\\nSidelined by geography and silenced by the British government’s\\nclassification of his work with Turing, Good mailed unsolicited carbons of\\nhis typed curriculum vitae—what he called his Private List of more than 800\\narticles and four books12—to startled colleagues. He numbered every work\\nand marked a significant portion of them as classified. Only as the British\\nslowly declassified his cryptanalysis work could he reveal Bayes’ success\\nwith the Enigma code. When that happened, he bought a vanity license plate\\nemblazoned with his James Bond spy status and his initials, 007 IJG.\\nHampered by governmental secrecy, his own personality, and an inability\\nto explain his work, Good remained an independent voice within the\\nBayesian community as two others became its intellectual leaders.\\nUnlike Good, Dennis Lindley and Jimmie Savage evolved almost\\naccidentally as Bayesians. When Lindley was a boy during the German\\nbombing of London, a remarkable mathematics teacher named M. P.\\nMeshenberg tutored him in the school’s air raid shelter. Meshenberg\\nconvinced Dennis’s father, a roofer proud to have never read a book, that the\\nboy should not quit school early or be apprenticed to an architect. Because of\\nMeshenberg, Dennis stayed in school and won a mathematics scholarship to\\nattend Cambridge University. Later in the war, when the British government\\nasked mathematicians to learn some statistics, Lindley helped introduce\\nstatistical quality control and inspection into armaments production for the\\nMinistry of Supply.\\nAfter the war he returned to Cambridge, the British center of probability,\\nwhere Jeffreys, Fisher, Turing, and Good had either worked or studied.\\nThere Lindley became interested in turning the statisticians’ collection of\\nmiscellaneous tools into a “respectable branch of mathematics,” a complete\\nbody of thought based on axioms and proven theorems.13 Andrei Kolmogorov\\nhad done the same for probability in general in the 1930s. Since Fisher in\\nparticular often arrived at his ideas intuitively and neglected mathematical\\ndetails, there was plenty of room for another mathematician to straighten\\nthings out logically.\\nIn 1954, a year after publishing a lengthy article summarizing his project,\\nLindley visited the University of Chicago, only to realize that Savage had\\ndone an even better job of it. Although Lindley and Savage would soon\\nbecome leading spokesmen for Bayes’ rule, neither realized at this point he\\nwas headed down a slippery slope toward Bayes. Each thought he had\\nmerely put traditional statistical techniques on a rigorous mathematical\\nfooting. Only later did they realize they could not move logically from their\\nrigorous axioms and theorems to the ad hoc methods of frequentism. Lindley\\nsaid, “We were both fools because we failed completely to recognize the\\nconsequences of what we were doing.”14\\nDespite being almost blind, Savage was immensely learned on an\\nencyclopedic range of topics. His father, a Jewish East European immigrant\\nwith a third-grade education, had changed the family’s name from Ogushevitz\\nto Savage and settled in Detroit. Both Jimmie and his brother Richard were\\nborn with extreme myopia and involuntary eye movements. As an adult,\\nbefore crossing a street Jimmie would wait five or ten minutes to make sure\\nthere were no oncoming cars, and attending lectures he would approach the\\nblackboard and peer at it through a powerful monocular. The brothers could\\nread quite comfortably, however, and as children called themselves “reading\\nmachines”;15 their mother, a high school graduate and nurse, had kept them\\nsupplied with library books. Reading was always a privilege to be\\ncherished, and Jimmie read with a rare intensity and developed the\\nembarrassing habit of questioning everything. His wide-ranging studies and\\ninsatiable curiosity would alter the history of Bayes’ rule.\\nBecause of his eyesight, however, Savage almost missed getting a college\\neducation. His teachers considered him feebleminded and unsuited for higher\\nstudies. He was finally admitted to Wayne (later Wayne State) University in\\nDetroit. From there he transferred to the chemistry department at the\\nUniversity of Michigan, only to be rejected again, this time as unfit for\\nlaboratory work. A kindly mathematics professor, G. Y. Rainich, rescued him\\nby teaching a class of visually impaired students in total darkness. Rainich\\ncalled it “mental geometry . . . just like in Russia,” where many schools\\ncould not afford candles.16 Three students in the class, including Savage,\\nearned doctorates.\\nDuring the Second World War Savage worked in the Statistical Research\\nGroup at Columbia University with the future Nobel Prize–winning\\neconomist Milton Friedman. The experience persuaded Savage to switch\\nfrom pure mathematics to statistics. After the war he moved to the University\\nof Chicago, a center of scientific excitement, thanks in large part to the\\ndazzling Nobel Prize winner Enrico Fermi, the last physicist to excel at both\\nexperimentation and theory. Fermi himself used Bayes. In the autumn of 1953,\\nwhen Jay Orear, one of Fermi’s graduate students, was struggling with a\\nproblem involving three unknown quantities, Fermi told him to use a simple\\nanalytic method that he called Bayes’ theorem and that he had derived from\\nC. F. Gauss. A year later, when Fermi died at the age of 53, Bayes’ rule lost\\na stellar supporter in the physical sciences.\\nFermi was not the only important physicist to use Bayesian methods during\\nthis period. A few years later, at Cornell University, Richard Feynman\\nsuggested using Bayes’ rule to compare contending theories in physics.\\nFeynman would later dramatize a Bayesian study by blaming rigid O-rings\\nfor the Challenger shuttle explosion.\\nDuring this exciting period in 1950s Chicago, Savage and Allen Wallis\\nfounded the university’s statistics department, and Savage attracted a number\\nof young stars in the field. Reading widely, Savage discovered the work of\\nÉmile Borel, Frank Ramsey, and Bruno de Finetti from the 1920s and 1930s\\nlegitimizing the subjectivity in Bayesian methods.\\nSavage’s revolutionary book Foundations of Statistics was the third in the\\nseries of pathbreaking Bayesian publications in the fifties. It appeared in\\n1954, four years after Bailey’s insurance paper and Good’s book and one\\nyear after Lindley’s paper. Because of Ramsey’s early death, it fell to Savage\\nto develop the young philosopher’s ideas about utility and to turn Bayes’ rule\\nfor making inferences based on observations into a tool for decision making\\nand action.\\nAlmost defiantly, Savage proclaimed himself a subjectivist and a\\npersonalist. Subjective probability was a measure of belief. It was something\\nyou were willing to use for a bet, particularly on a horse race, where bettors\\nshare the same information about a horse but come to different conclusions\\nabout its chances and where the race itself can never be precisely replicated.\\nSubjective opinions and professional expertise about science, medicine, law,\\nengineering, archaeology, and other fields were to be quantified and\\nincorporated into statistical analyses.\\nMore than anyone else Savage forced people to think about combining two\\nconcepts: utility (the quantification of reward) and probability (the\\nquantification of uncertainty). He argued that rational people make subjective\\nchoices to minimize expected losses.\\nSavage was confronting the thorniest objection to Bayesian methods: “If\\nprior opinions can differ from one researcher to the next, what happens to\\nscientific objectivity in data analysis?”17 Elaborating on Jeffreys, Savage\\nanswered as follows: as the amount of data increases, subjectivists move\\ninto agreement, the way scientists come to a consensus as evidence\\naccumulates about, say, the greenhouse effect or about cigarettes being the\\nleading cause of lung cancer. When they have little data, scientists disagree\\nand are subjectivists; when they have piles of data, they agree and become\\nobjectivists. Lindley agreed: “That’s the way science is done.”18\\nBut when Savage trumpeted the mathematical treatment of personal\\nopinion, no one—not even he and Lindley—realized yet that he had written\\nthe Bayesian Bible. “Neither of us would have known at the time what was\\nmeant by saying we were Bayesians,” Lindley said. Savage’s book did not\\nuse the term “Bayesian” at all and referred to Bayes’ rule only once.\\nSavage’s views and his book gained popularity slowly, even among those\\npredisposed to Bayes’ rule. Many had hoped for a how-to manual like\\nFisher’s Statistical Methods for Research Workers. Lacking computational\\nmachinery to implement their ideas, Bayesians were limited to a few simple\\nproblems involving easily solved integrals and would spend years adapting\\ncenturies-old methods for calculating them. Savage, though, said he was\\n“little inclined to high speed machines for help. This is no doubt partly due to\\nmy being reactionary . . . but my main interests are in the qualitative. . . .\\nTables of functions depending on several parameters are almost unprintable\\nand, when printed quite unintelligible.”19 Savage continued instead to prove\\nabstract mathematical theorems and work on building a logical foundation for\\nBayesian methods.\\nHis applications were too whimsical to be useful: what is the probability\\nthat aspirin curls rabbits’ ears? what is the most probable speed of neon light\\nthrough beer? Some thought Savage’s failure to tackle serious problems\\nimpeded the spread of Bayesian methods. Lindley complained, “Perhaps\\nstatistics would have benefited more if he had not been so punctilious in\\nreplying to correspondents and so helpful with students, and instead\\ndeveloped more operational methods that the writers and graduates could\\nhave used.”20\\nSome readers were also troubled by the fact that Savage used aspects of\\nfrequentism to argue for Bayes’ subjective priors, taboo since the nineteenth\\ncentury. As Savage explained, when he wrote the book he was “not yet a\\npersonalistic Bayesian.” He thought he came to Bayesian statistics “seriously\\nonly through recognition of the likelihood principle; and it took me a year or\\ntwo to make the transition.”21\\nAccording to the likelihood principle, all the information in experimental\\ndata gets encapsulated in the likelihood portion of Bayes’ theorem, the part\\ndescribing the probability of objective new data; the prior played no role.\\nPractically speaking, the principle greatly streamlined analysis. Scientists\\ncould stop running an experiment when they were satisfied with the result or\\nran out of time, money, and patience; nonBayesians had to continue until\\nsome frequency criterion was met. Bayesians would also be able to\\nconcentrate on what happened, not on what could have happened according\\nto Neyman-Pearson’s sampling plan.\\nThe transition to Bayes took Savage several years, but by the early 1960s\\nhe had accepted its logic wholeheartedly, fusing subjective probability with\\nnew statistical tools for scientific inference and decision making. As far as\\nSavage was concerned, Bayes’ rule filled a need that other statistical\\nprocedures could not. Frequentism’s origin in genetics and biology meant it\\nwas involved with group phenomena, populations, and large aggregations of\\nsimilar objects. As for using statistical methods in biology or physics, the\\nNobel Prize–winning physicist Erwin Schrödinger said, “The individual\\ncase [is] entirely devoid of interest.”22 Bayesians like Savage, though, could\\nwork with isolated one-time events, such as the probability that a chair\\nweighs 20 pounds, that a plane would be late, or that the United States would\\nbe at war in five years.\\nBayesians could also combine information from different sources, treat\\nobservables as random variables, and assign probabilities to all of them,\\nwhether they formed a bell-shaped curve or some other shape. Bayesians\\nused all their available data because each fact could change the answer by a\\nsmall amount. Frequency-based statisticians threw up their hands when\\nSavage inquired whimsically, “Does whiskey do more harm than good in the\\ntreatment of snake bite?” Bayesians grinned and retorted, “Whiskey probably\\ndoes more harm than good.”23\\nAs a movement, Bayes was looking more akin to a philosophy—even a\\nreligion or a state of mind—than to a true-or-false scientific law like plate\\ntectonics. According to David Spiegelhalter of Cambridge University, “It’s\\nmuch more basic. . . . A huge sway of scientists says you can’t use\\nprobability to express your lack of knowledge or one-time events that don’t\\nhave any frequency to it. Probability came very late into civilization . . . [and\\nmany scientists find it] rather disturbing because it’s not a process of\\ndiscovery. It’s more a process of interpretation.”24\\n“Mathematical scientists often sense a combination of harmony and power\\nin certain formulas,” explains Robert E. Kass, a Bayesian at Carnegie\\nMellon University. “There is at once a deep esthetic experience and a\\npragmatic recognition of profound consequences, leading to what Einstein\\ncalled ‘the cosmic religious feeling.’ Bayes Theorem gives such a feeling. It\\nsays there is a simple and elegant way to combine current information with\\nprior experience in order to state how much is known. It implies that\\nsufficiently good data will bring previously disparate observers to\\nagreement. It makes full use of available information, and it produces\\ndecisions having the least possible error rate. Bayes’ Theorem is awe-\\ninspiring.” Unfortunately, Kass continued, “when people are captivated by its\\nspell, they tend to proselytize and become blinded to its fundamental\\nvulnerability. . . . [that] its magical powers depend on the validity of its\\nprobabilistic inputs.”25\\nWith zealots proselytizing Bayes as an all-encompassing panacea, the\\nmethod inspired both religious devotion and dogmatic opposition. The battle\\nbetween Bayesians and their equally fervent foes raged for decades and\\nalienated many bystanders. As one onlooker reflected, “It was a huge food\\nfight. It was devastating. They hated each other.”26 A prominent statistician\\nlamented, “Bayesian statisticians do not stick closely enough to the pattern\\nlaid down by Bayes himself: if they would only do as he did and publish\\nposthumously we should all be saved a lot of trouble.”27\\nSavage became one of the believers. He developed into a full-blown,\\nmessianic Bayesian, “the most extreme advocate of a Bayesian . . . ever\\nseen,” William Kruskal of the University of Chicago said. Savage recast the\\ncontroversy over Bayes’ rule in its most extreme form as subjectivity versus\\nobjectivity. For him, as for Lindley, the rule was the one-and-only, winner-\\ntake-all method for reaching conclusions in the face of uncertainty. Bayes’\\nrule was right and rational, they felt, and other views were wrong, and it was\\nneither necessary nor desirable to admit compromise.\\n“Personal probability . . . became for [Savage] the only sensible approach\\nto probability and statistics,” Kruskal recalled sadly. “If one were not in\\nsubstantial agreement with him, one was inimical, or stupid, or at the least\\ninattentive to an important scientific development. This attitude, no doubt\\nsharpened by personal difficulties and by the mordant rhetoric of some anti-\\nBayesians, exacerbated relationships between Jimmie Savage and many old\\nprofessional friends.”28\\nSavage’s last year at Chicago, 1960, was fraught with turmoil. Although\\nhis department colleagues knew nothing about it, the administration was\\ntrying to abolish the statistics department, and Savage was fighting to get the\\ndecision reversed. His marriage was disintegrating and, hoping to save it, he\\nmoved to the University of Michigan. As he departed, he told his colleagues,\\n“I proved the Bayesian argument in 1954. None of you have found a flaw in\\nthe proof and yet you still deny it. Why?”29 When he tried to return to\\nChicago, members of the department he had formed and chaired voted against\\nrehiring him. At first, no other American or British university would offer\\nhim a position. In 1964 he moved to Yale University, remarried, and\\nachieved some level of tranquility.\\nIn 1971, at the age of 53, Savage died suddenly of a heart attack. His death\\nat midcareer deprived American Bayesians of their leading spokesman. The\\nNew Haven Register had another perspective. Savage had cowritten a book\\ncalled How to Gamble If You Must. For Bayesians, all assumptions about the\\nfuture were risky, and gambling was the paradigm of decision making. The\\nRegister headlined his obituary, “Yale Statistician Leonard Savage Dies;\\nAuthored Book on Gambling.”\\nIn the meantime, Lindley had moved back to Britain, where for many years\\nhe was the only Bayesian in a position of authority. In time he built not just\\nBayesian theory but also strong Bayesian research groups, first at the\\nUniversity College of Wales in Aberystwyth and then at University College\\nLondon. The latter had England’s most important statistical department and\\nwas a temple of frequentism. When Lindley arrived, a colleague said it was\\n“as though a Jehovah’s Witness had been elected Pope.”30 Lindley\\ncomplained that he “inherited” several statisticians who “would not change\\ntheir view of statistics.”31 He said, “The general attitude [was] to turn their\\nheads the other way.”32\\nIn an era when many sneered at Bayes, it took courage to create Europe’s\\nleading Bayesian department. Often the only Bayesian at meetings of the\\nRoyal Statistical Society and certainly the only combative one, Lindley\\ndefended Bayes’ rule like a fearless terrier or a devil’s advocate. In return,\\nhe was tolerated almost as comic relief. “Bayesian statistics is not a branch\\nof statistics,” he argued. “It is a way of looking at the whole of statistics.”\\nLindley became known as a modern-age revolutionary. He fought to get\\nBayesians appointed, professorship by professorship, until the United\\nKingdom had a core of ten Bayesian departments. Eventually, Britain became\\nmore sympathetic to the method than the United States, where Neyman\\nmaintained Berkeley as an anti-Bayesian bunker. Still, the process left scars:\\ndespite Lindley’s landmark contributions he was never named a Fellow of\\nthe Royal Society. In 1977, at the age of 54, Lindley forsook the\\nadministrative chores he hated and retired early. He celebrated his freedom\\nby growing a beard and becoming what he called “an itinerant scholar” for\\nBayes’ rule.33\\nThanks to Lindley in Britain and Savage in the United States, Bayesian\\ntheory came of age in the 1960s. The philosophical rationale for using\\nBayesian methods had been largely settled. It was becoming the only\\nmathematics of uncertainty with an explicit, powerful, and secure foundation\\nin logic. How to apply it, though, remained a controversial question.\\nLindley’s enormous influence as a teacher and organizer bore fruit in the\\ngeneration to come, while Savage’s book spread Bayesian methods to the\\nmilitary and to business, history, game theory, psychology, and beyond.\\nAlthough Savage wrote about rabbit ears and neon light in beer, he\\npersonally encouraged researchers who would apply Bayes’ rule to life-and-\\ndeath problems.\\n8.\\n \\njerome cornfield, lung cancer, and\\nheart attacks\\n \\nBayes came to medical research through the efforts of a single scientist,\\nJerome Cornfield, whose only degree was a B.A. in history and who relied\\non the rule to identify the causes of lung cancer and heart attacks.\\nLung cancer, extremely rare before 1900 and still uncommon in 1930,\\nsprang up as if out of nowhere shortly after the Second World War. By 1952\\nit was killing 321 people per million per year in England and Wales. A year\\nlater approximately 30,000 new cases were diagnosed in the United States.\\nNo other form of cancer showed such a catastrophic leap. Studies in Europe,\\nTurkey, and Japan confirmed the puzzling plague. There seemed to be\\nsomething special about the disease.\\nBut what could it be? Its cause was unknown. Pathologists thought the\\nincrease in lung cancer might be due to improvements in diagnostic methods\\nor to the natural aging of the population. Others blamed exhaust from\\nfactories or the growing number of automobiles, tar particles from modern\\nasphalt pavements, or England’s infamous smog from homes heated with\\nopen coal-burning fires. Cigarettes, mass-produced since the invention of a\\ncigarette-making machine in 1880, had been patriotically shipped to soldiers\\nduring the First World War. Animal studies, though, had failed to demonstrate\\nthat tobacco tar was carcinogenic.\\nAs early as 1937 a small-scale study in Germany had pointed ever so\\ntentatively to cigarette smoke. But there were doubts about that too. While\\n80% of middle-aged men in England and Wales smoked cigarettes, tobacco\\nconsumption per capita had dropped slightly. And fumes from cigarettes,\\nwhich had replaced cigars and pipes, did not seem worse than other smoke.\\nThe world’s most famous biostatistician, Austin Bradford “Tony” Hill,\\nwas intrigued. He called himself an arithmetician rather than a mathematician\\nor statistician and, in a series of articles in The Lancet, used straightforward\\nlogic to persuade the medical community to objectively quantify its research\\nfindings. During the late 1940s, two decades after Ronald Fisher had\\nintroduced randomization to agricultural experimentation, Hill introduced\\nrandomization to medical research. Inaugurating the modern controlled\\nclinical trial, Hill showed that pertussis vaccine reduced children’s\\nwhooping cough cases by 78% and that streptomycin was effective against\\npulmonary tuberculosis. Bradford Hill became so famous that a letter\\naddressed to “Lord Hill, Bradford, England” reached him.\\nTo identify the most probable causes of the catastrophic increase in lung\\ncancer, Hill and a young physician and epidemiologist, Richard Doll,\\norganized interviews with patients with and without lung cancer in 20\\nLondon-area hospitals. All were questioned about their past activities and\\nexposures. The results, published in 1950, were shockingly clear. Of 649\\nmen with lung cancer, only 2 were nonsmokers; a high proportion of the lung\\ncancer patients were heavy cigarette smokers, and their death rate was 20\\ntimes higher than that of nonsmokers. A large American study by Ernst L.\\nWynder and Evarts A. Graham confirmed the British result the same year.\\nThe startling news that cigarettes and lung cancer were linked caused an\\ninstant international uproar. Newspapers, radio, television, and magazines\\ncompeted with medical journals for the latest scoop. With the exception of\\nthe influenza epidemic of 1918, no disease had ever sprung as fast from\\nobscurity to worldwide consciousness. Few have engendered such enormous\\ncontroversy.\\nThe Hill and Doll study remains one of the crowning glories of medical\\nstatistics. It was the first sophisticated case-control study of any\\nnoninfectious disease. And it persuaded Hill and Doll to quit smoking.\\nDespite its dramatic results, their study did not show that smoking cigarettes\\nactually causes lung cancer. No one could say that for sure. Jerome\\nCornfield, an American government bureaucrat at the National Institutes of\\nHealth (NIH), took up the challenge. And with Hill organizing clinical\\nstudies in Britain and Cornfield developing their mathematical defense in the\\nUnited States, the two tackled complementary aspects of the same problem\\nfrom different sides of the Atlantic.\\nThe two men had totally dissimilar backgrounds. Hill’s father was a\\nphysician with a knighthood, and one of his ancestors had invented the\\npostage stamp. Cornfield was the son of Russian Jewish immigrants and had\\nearned a bachelor’s degree from New York University in 1933. The federal\\ngovernment, desperate for economic data during the Depression, had hired\\n“bright guys” to replace the clerks who had traditionally compiled statistics\\non unemployment, national income, housing, agriculture, and industry.1\\nCornfield qualified as a bright guy, so he signed on as a government\\nstatistician for 26.31 a week, 1,368 a year.\\nWashington, D.C., was still a segregated, southern city. “The rule of thumb\\nwas that, if you were Jewish, you could work for the Department of Labor\\nand, if you were Catholic, you could work for the Department of Commerce,”\\nexplained Marvin Hoffenberg, a friend of Cornfield’s and later a UCLA\\nprofessor.2 So Cornfield went to Labor. The U.S. Department of Agriculture\\nran a so-called Graduate School where mathematically inclined government\\nemployees could study statistics, and Cornfield took his only mathematics\\nand statistics courses there.\\nAs Cornfield recalled, “Nobody knew how many unemployed there were,\\nand sampling seemed the way to find out. . . . Statistics had me hooked.”3\\nAlthough both Fisher and Neyman lectured on sampling methods at the\\nGraduate School, its director, W. Edwards Deming, was open-minded; he\\npublished Thomas Bayes’ essay with an introduction by Edward Molina of\\nBell Laboratories.\\nFriends referred to Cornfield’s tenure at the Department of Labor as his\\nserious and exotic phase. He played a major role in revising the Consumer\\nPrice Index and in creating one for occupied Japan after the Second World\\nWar. But he was “a different kind of a guy,” a friend recalled.4 Unable to\\nthink of any good reason for shaving, he grew a little pointed beard, and with\\nhis long gaunt frame and an umbrella over his arm he resembled an elegant\\ndiplomat strolling jauntily to work. At a time when few others would, he\\nshared his office with a woman statistician and an African American\\nstatistical clerk. Next to his mechanical Marchant desktop calculator he\\ninstalled a Turkish water pipe and could be seen puffing nonchalantly from\\nits two-foot tube.\\nCornfield moved to the federal government’s new NIH in 1947. Because\\ninfectious diseases were in decline in the United States, NIH epidemiologists\\nwere attacking chronic diseases, particularly cancer, heart attacks, and\\ndiabetes. To assist them, NIH hired a few people with strong quantitative\\nbackgrounds. Only one of them had so much as a master’s degree.\\nBiostatistics was a professional backwater, and throughout the 1950s and\\n1960s NIH employed only ten or 20 statisticians at any one time. It was this\\nsmall band that introduced statistical methods to NIH researchers in biology\\nand medicine.\\nBy 1950 most men in the United States smoked, and smoking rates were\\nincreasing, especially among women. The favorite brands were unfiltered\\nCamels, Lucky Strikes, Chesterfields, and Philip Morris. When Lorillard\\nTobacco Company introduced filtered Kents in 1952, the filters contained\\nasbestos, which was not removed until 1957. When 14 studies conducted in\\nfive countries showed that lung cancer patients included an alarming\\npercentage of heavy smokers, both Cornfield and his wife quit their 2½-\\npack-a-day habits.\\nCornfield realized that the Hill and Wynder studies did not directly answer\\nthe questions physicians and their frightened patients were asking: what is my\\nrisk? The studies showed the percentages of smokers among groups of\\npeople with and without lung cancer, but they did not say what proportion of\\nsmokers and nonsmokers was likely to develop lung cancer.\\nThe surest and most direct way to answer the public’s fears was to follow\\nlarge groups of smokers and nonsmokers for years, prospectively, to see how\\nmany of each group developed lung cancer. Unfortunately, studies about the\\nfuture of large populations require a great deal of money and time, especially\\nfor relatively rare problems like lung cancer. That is why Hill and Doll had\\norganized their study as a retrospective one, choosing people who already\\nhad lung cancer and asking them about their health histories. Such studies are\\na relatively quick, cheap way to identify potential causes of a particular\\ndisease. As a statistician, however, Cornfield suspected that retrospective\\nstudies like Hill and Doll’s could also be used to answer the individual’s\\nhaunting question, What’s the chance that I or my loved ones will get this\\nfatal disease?\\nIn 1951 Cornfield used Bayes’ rule to help answer the puzzle. As his prior\\nhypothesis he used the incidence of lung cancer in the general population.\\nThen he combined that with NIH’s latest information on the prevalence of\\nsmoking among patients with and without lung cancer. Bayes’ rule provided a\\nfirm theoretical link, a bridge, if you will, between the risk of disease in the\\npopulation at large and the risk of disease in a subgroup, in this case\\nsmokers. Cornfield was using Bayes as a philosophy-free mathematical\\nstatement, as a step in calculations that would yield useful results. He had not\\nyet embraced Bayes as an all-encompassing philosophy.\\nCornfield’s paper stunned research epidemiologists. More than anything\\nelse, it helped advance the hypothesis that cigarette smoking was a cause of\\nlung cancer. Out of necessity, but without any theoretical justification,\\nepidemiologists had been using case studies of patients to point to possible\\ncauses of problems. Cornfield’s paper showed clearly that under certain\\nconditions (that is, when subjects in a study were carefully matched with\\ncontrols) patients’ histories could indeed help measure the strength of the\\nlink between a disease and its possible cause. Epidemiologists could\\nestimate disease risk rates by analyzing nonexperimental clinical data\\ngleaned from patient histories. By validating research findings arising from\\ncase-control studies, Cornfield made much of modern epidemiology\\npossible. In 1961, for example, case-control studies would help identify the\\nantinausea drug thalidomide as the cause of serious birth defects.\\nTwo massive efforts in England and the United States during the mid-\\n1950s confirmed Cornfield’s judgment. Because many people had rejected\\nthe findings of their retrospective study, Hill and Doll had decided to take a\\ndirect approach and conduct a prospective study. They questioned 40,000\\nBritish physicians about their current smoking habits and then followed them\\nfor five years to see who got lung cancer. In a parallel U.S. study, E. Cuyler\\nHammond and Daniel Horn followed 187,783 men aged 50 to 69 in New\\nYork State for more than 3½ years. Death rates in both countries were\\nsimilar: heavy smokers were 22 to 24 times more likely to get lung cancer\\nthan nonsmokers and, in another surprise discovery, were 42% and 57%\\nmore likely to get, respectively, heart and circulatory diseases. Research also\\nshowed that cigarettes were more dangerous than pipes, although the risk\\ndeclined after smoking stopped.\\nSurprisingly, neither Fisher nor Neyman could accept research results\\nshowing that cigarettes caused lung cancer. Both anti-Bayesians were heavy\\nsmokers, and Fisher was a paid consultant to the tobacco industry. But more\\nimportant, neither found epidemiologic studies convincing. And both were\\ncorrect in pointing out that tobacco could be associated with cancer without\\ncausing it. In 1955 they launched a vigorous counterattack, arguing that only\\nexperimental data from strictly controlled laboratory and field experiments\\ncould predict future disease rates. The most eminent American medical\\nstatistician of the day, Joseph Berkson, of the Mayo Clinic in Rochester,\\nMinnesota, joined the attack; Berkson did not believe cigarettes could cause\\nboth cancer and heart disease.\\nFisher kept up a barrage of angry attacks, including a book and two\\narticles published in highly prestigious journals, Nature and the British\\nMedical Journal. According to Doll, Fisher even went so far as to accuse\\nHill of scientific dishonesty. Over the course of three years Fisher developed\\ntwo remarkable hypotheses. The first, believe it or not, was that lung cancer\\nmight cause smoking. The second was that a latent genetic factor might give\\nsome people hereditary predilections for both smoking and lung cancer. In\\nneither case would smoking cause lung cancer.\\nCornfield maintained a running argument with Fisher through the 1950s.\\nCornfield was already thinking deeply about the standards of evidence\\nneeded before observational data could establish cause and effect. Finally, in\\n1959, he raked Fisher over the coals about smoking with a common-sense,\\nnonmathematical paper that reads like a legal brief. In that seminal paper he\\nand five coauthors systematically addressed every one of Fisher’s alternative\\nexplanations for the link between cigarette smoking and lung cancer. They\\nhurled one counterargument after another at Fisher’s hypothetical genetic\\nfactor. If cigarette smokers were nine times more likely than nonsmokers to\\nget lung cancer, Fisher’s latent genetic factor must be even larger—though\\nnothing approaching that had ever been seen.\\nCornfield dismissed out of hand Fisher’s suggestion that cancer might\\ncause smoking: “Since we know of no evidence to support the view that the\\nbronchogenic carcinoma diagnosed after age 50 began before age 18, the\\nmedian age at which smokers begin smoking, we shall not discuss it\\nfurther.”5 Cornfield pointed out that Fisher’s genetic factor would have to\\nspread rapidly and occur more among cigarette smokers than nonsmokers;\\ncause tumors on mouse skin but not on human lungs; weaken with age after a\\nsmoker quit; and be more likely in men than women, 60 times more prevalent\\namong two-pack-a-day smokers, and different in pipe and cigar smokers. Yet\\nnone of these phenomena had ever been observed.\\nFisher wound up looking ridiculous. As Cornfield coolly noted, “A point\\nis reached . . . when a continuously modified hypothesis becomes difficult to\\nentertain seriously.”6 Scientists who can find only one viable explanation for\\nassociations in their data have probably found its causal agent. The existence\\nof possible alternative explanations indicates that the cause has probably not\\nyet been found. Cornfield was laying out the road map for future smoking and\\nlung cancer research.\\nBy now, Cornfield the history major had become the most influential\\nbiomedical statistician in the United States. When the U.S. surgeon general\\nconcluded in 1964 that “cigarette smoking is causally related to lung cancer\\nin men,” he cited Cornfield’s work.7 Nonexperimental studies had helped\\nidentify an association between smoking and lung cancer. With the help of\\nBayes’ rule—what Laplace had called “the probability of causes and future\\nevents, derived from past events”—Cornfield provided the theoretical\\njustification for using case-control studies to estimate the strength of links\\nbetween exposure and disease. Today, thanks to Cornfield, case-control\\nstudies are the primary tool epidemiologists use to identify likely causes of\\nchronic diseases.\\nOver his career, Cornfield would become involved in every major public\\nhealth problem of the day. Most of them, including smoking, the safety of\\npolio vaccines, and the efficacy of diabetes treatments, were fiercely\\ncontroversial.\\nTo calm the statistics phobia of physicians and epidemiologists, Cornfield\\ndeveloped an easygoing bedside manner. Abandoning his serious phase, he\\ncultivated an infectious laugh and an irrepressible air of informality. By\\nmixing humor into conversations, telling stories, and laughing heartily he\\ninspired tremendous confidence. Even his gait and prose became sprightly.\\nSoon every biomedical scientist with a committee and a controversy wanted\\nCornfield on board. By pointing out common elements that everyone shared,\\nhe could unify the most disparate group. After one particularly onerous series\\nof meetings and reports, a committee member asked him, “Did you get my\\nlast letter about sample size?” There was a pause, and Cornfield grinned and\\nsaid, “Christ, I hope so.” When the committee finally produced its massive\\nprocedural manual, Cornfield waved it over his head, declaring, “You know,\\nsay what you will about the Ten Commandments, you must come back to the\\npleasant fact that there were only ten of them.”\\nCornfield typically rose at 5 a.m. to write and make paper-and-pencil\\ncalculations. He came up with clever approximations and computational\\ntricks, much as Laplace had done. He visualized particularly difficult\\ndistributional functions by carving them out of a bar of soap. To collaborate\\nwith biochemists, he studied basic biology. And although he was a brilliant\\nspeaker, he never prepared a talk until the night before. He procrastinated\\neven the day before he was scheduled to speak at 8:30 a.m. at Yale\\nUniversity about the contentious Salk poliomyelitis vaccine tests. “Don’t\\nworry, Max,” he told a friend. “God will provide.”\\nCornfield was a voracious reader but did not own a TV and was blissfully\\nunaware of popular culture. Once a biostatistician who dated Hollywood\\nstars begged him to speed up a morning meeting: “I’ve got to get through\\nbecause at 12 o’clock I have a luncheon date with Kim Novak.” Puzzled,\\nCornfield asked, “Kim Novak? Who’s he?”8 At the time she was Columbia\\nPictures’ answer to Marilyn Monroe.\\nAnother watershed medical study also occupied Cornfield’s attention\\nduring the 1950s. Death rates from cardiovascular disease had been rising\\nsteadily in the United States since 1900. Heart disease had been the nation’s\\nleading cause of death since 1921, and strokes the third leading cause since\\n1938. Yet researchers at the midpoint of the twentieth century were as\\nignorant of the causes of heart disease and stroke as they had been of lung\\ncancer.\\nUnderstanding the causes of deaths from cardiovascular disease would\\nrequire following a population for many years. A prospective study,\\nhowever, was more feasible than with lung cancer because heart problems\\nwere far more common. In 1948 Cornfield helped design the Framingham\\nHeart Study, which has since followed the health of three generations of\\nFramingham, Massachusetts, residents.\\nAs one of the first important studies based on Framingham, Cornfield\\nfollowed 1,329 adult male residents for a decade. Between 1948 and 1958,\\n92 of the group experienced myocardial infarction or angina pectoris.\\nLongitudinal studies like Framingham are designed to investigate a large\\nvariety of variables, both singly and jointly, on the risk of developing a\\ndisease. Traditionally, epidemiologists studied their data by inspecting\\n—“contemplating” was Cornfield’s word—the resulting multiple cross-\\nclassification arrays. Three risk factors, each considered at low, medium,\\nand high levels, would produce a tidy 3x3 table of cells, but as the number of\\nvariables increased and they were considered singly and jointly, the number\\nof cells to be contemplated quickly became impracticable. A cross-\\nclassification study with 10 risk factors at low, medium, and high levels\\nwould produce 59,049 cells. To get even 10 patients per cell, the study\\nwould need a cohort of 600,000 people, more than the population of\\nFramingham.\\nCornfield realized he needed a “more searching form of analysis than\\nsimple inspection.”9 He would have to develop a mathematical model for\\nsummarizing the observations. He chose Bayes’ rule and used cardiovascular\\ndeath rates as the prior. Framingham gave him data about two groups of\\npeople, those who had died of heart disease and those who had not. Within\\neach group he had information about seven risk factors. Calculating Bayes’\\nrule, he got a posterior probability in the form of a logistic regression\\nfunction, which he then used to identify the four most important risk factors\\nfor cardiovascular disease. In addition to age itself, they were cholesterol,\\ncigarette smoking, heart abnormalities, and blood pressure.\\nBayes allowed Cornfield to reframe Framingham’s data in terms of the\\nprobability that people with particular characteristics would get heart\\ndisease. There was no critical level for cholesterol or blood pressure below\\nwhich people were safe and above which they got the disease. And patients\\ncursed with both high cholesterol and high blood pressure were 23% more at\\nrisk for heart attacks than those with low cholesterol and blood pressure\\nrates.\\nCornfield’s identification in 1962 of the most critical risk factors for\\ncardiovascular disease produced one of the most important public health\\nachievements of the twentieth century: a dramatic drop in death rates from\\ncardiovascular disease. Between 1960 and 1996 they fell 60%, preventing\\n621,000 fatalities. His report also showed researchers how to use Bayes’\\nrule to analyze several risk factors at a time; his multiple logistic risk\\nfunction has been called one of epidemiology’s greatest methodologies.\\nTo measure the efficacy of a particular therapy, Cornfield used an early\\nmulticenter trial at NIH to introduce another Bayesian concept—Harold\\nJeffreys’s relative betting odds. Now known as the Bayes’ Factor, it is the\\nprobability of the observed data under one hypothesis divided by its\\nprobability under another hypothesis.\\nWhen Cornfield worked with researchers who used mice to screen for\\nanticancer drugs, the rigidity of frequentist methods struck him like a blow\\nfrom behind. According to their rules, even if their initial test results\\ndisproved their hypothesis, they had to take six more observations before\\nstopping the experiment. Frequentist methods also banned switching a patient\\nto better treatment before a clinical trial was finished. Frequentist\\nexperimenters could not monitor interim results during the clinical trial,\\nexamine treatment effects on subgroups of patients, or follow leads from the\\ndata with further unplanned analyses. When Cornfield discovered that\\nBayesian methods would let him reject some hypotheses after only two\\nsolidly adverse observations, he was converted. He had started out using\\nBayes’ theorem as an enabling tool to solve a particular problem, the way it\\nhad been used for cryptography, submarine hunting, and artillery fire during\\nthe Second World War. But now he was moving gradually toward making\\nBayes’ theorem the foundation of a broad philosophy for handling\\ninformation and uncertainties. As he began thinking about Bayes as a\\nphilosophy rather than just a tool, he became part of the profound conversion\\nthat Jeffreys, Savage, Lindley, and others were also going through in the\\n1950s and 1960s. While Fisher considered a hypothesis significant if it was\\nunlikely to have occurred by chance, Cornfield declared airily, “If\\nmaintenance of [Fisher’s] significance level interferes with the release of\\ninterim results, all I can say is so much the worse for the significance\\nlevel.”10\\nInterestingly, most of NIH’s other statisticians failed to follow their leader\\ninto Bayesian fields. Cornfield published scientifically important papers\\nabout Bayesian inference in mainstream statistics journals. Nevertheless,\\nwhen he included Bayesian methods in some of the trials he worked on, their\\nmain conclusions were based on frequentism. It would be another 30 years\\nbefore NIH started using Bayes for clinical trials. Savage thought that many\\nresearchers were content to reap the benefits of Bayes’ theorem without\\nembracing the method.\\nCornfield declared cheerily, however, “Bayes’ theorem has come back\\nfrom the cemetery to which it has been consigned.”11\\nIn 1967 Cornfield retired from NIH and moved later to George Washington\\nUniversity, where he chaired the statistics department and developed Bayes’\\nrule into a full-scale logical mathematical approach. In one paper he proved\\nto the satisfaction of many Bayesians that, according to frequency rules, any\\nstatistical procedure that does not stem from a prior can be improved upon.\\nDespite his Bayesian conversion, Cornfield was in great demand as a\\nconsultant. He advised the U.S. Army on experimental design; the\\ninvestigating committee critiquing the best-selling Kinsey Report on female\\nsexuality; the U.S. Department of Justice on sampling voting records to\\nreveal bias against black voters; and the State of Pennsylvania after the Three\\nMile Island nuclear power plant incident.\\nIn 1974 the Bayesian biostatistician with a bachelor’s degree in history\\nbecame president of the American Statistical Association. In his presidential\\naddress, the man who used humor and good cheer to reassure physicians\\nabout randomized trials, who gave epidemiologists some of their most\\nimportant methodologies, and who established causes of both lung cancer\\nand heart attacks, asked, “Why should any person of spirit, of ambition, of\\nhigh intellectual standards, take any pride or receive any real stimulation and\\nsatisfaction from serving an auxiliary role [as a statistician] on someone\\nelse’s problem?” Smiling at his own question, Cornfield continued, “No one\\nhas ever claimed that statistics was the queen of the sciences. . . . The best\\nalternative that has occurred to me is ‘bedfellow.’ Statistics—bedfellow of\\nthe sciences—may not be the banner under which we would choose to march\\nin the next academic procession, but it is as close to the mark as I can\\ncome.”12\\nWhen Cornfield was diagnosed with pancreatic cancer in 1979, he knew\\nas well as anyone at NIH the disease’s appalling six-month survival rate.\\nNonetheless, he was determined to continue living to the fullest. Despite\\nserious postoperative complications, his humor remained intact. A friend\\ntold him, “Jerry, I’m so glad to see you.” Smiling, Cornfield replied, “That’s\\nnothing compared to how happy I am to be able to see you.”13 As he was\\ndying he said to his two daughters, “You spend your whole life practicing\\nyour humor for the times when you really need it.”14\\n9.\\n \\nthere’s always a first time\\n \\nBayes’ military successes were still Cold War secrets when Jimmie Savage\\nvisited the glamorous new RAND Corporation in the summer of 1957 and\\nencouraged two young men to calculate a life-and-death problem: the\\nprobability that a thermonuclear bomb might explode by mistake.\\nRAND was the quintessential Cold War think tank. Gen. Curtis E. LeMay,\\nthe commander of the Strategic Air Command (SAC), had helped start it in\\nSanta Monica, California, 10 years earlier as “a gimmick” to cajole top\\nscientists into applying operations research to long-range air warfare.1 But\\nRAND, an acronym for Research ANd Development, considered itself a\\n“university without students” and its 1,000-odd employees “defense\\nintellectuals.” Their mission was to use mathematics, statistics, and\\ncomputers to solve military problems, pioneer decision making under\\nconditions of uncertainty, and save the United States from Soviet attack. The\\nU.S. Air Force, which funded RAND, gave its researchers carte blanche to\\nchoose the problems they wanted to investigate. But since President\\nEisenhower’s “New Look” military policy depended on early nuclear\\nbombing (“massive retaliation”) as the cheapest way to respond to a Soviet\\nattack, RAND’s top issues were nuclear strategy, surviving nuclear attack,\\nand response options. Because SAC bombers had a monopoly on\\ntransporting America’s nuclear arsenal and General LeMay sat at the\\npinnacle of the world’s military might, RAND’s voice was often influential.\\nBy the time Savage visited Santa Monica that summer RAND reports had\\nalready challenged some of SAC’s sacred cows. To drop nuclear weapons\\non Soviet targets, macho air force pilots wanted to fly the new B-52 Strato-\\nfortress jets; RAND recommended fleets of cheaper conventional planes.\\nRAND had also described SAC’s overseas bases for manned bombers as\\nsitting ducks for Soviet attack. A year after Savage’s visit, RAND would\\nchallenge Cold War dogma by arguing that victors typically fare better with\\nnegotiated settlements than with unconditional surrenders. RAND would\\neven urge counterbalancing LeMay’s B-52s with the navy’s submarine-based\\nmissiles. In retaliation, SAC would almost break off relations with RAND on\\nseveral occasions between Savage’s visit in 1957 and 1961.\\nCirculating gregariously among RAND researchers that summer, Savage\\nmet Fred Charles Iklé, a young Swiss-born demographer who had studied the\\nsociological effects of nuclear bombing on urban populations. At 33, Iklé\\nwas seven years younger than Savage and had earned a Ph.D. in 1950 from\\nthe University of Chicago, where Savage was teaching. Seeking a wide-open\\nfield that no one else at RAND was studying, Iklé chose nuclear catastrophes\\nthat an Anglo-American nuclear arsenal would not deter: those caused by\\naccident or by someone mentally deranged. Referring to massive retaliation a\\nfew years later, Iklé would declare, “Our method of preventing nuclear war\\nrests on a form of warfare universally condemned since the Dark Ages—the\\nmass killing of hostages.”2 With SAC poised to expand its bomb-bearing\\nflights, Iklé and Savage talked about assessing their impact on nuclear\\naccidents. Eventually the issue came around to the question, what was the\\nprobability of an accidental H-bomb explosion?\\nAfter a summer of conversations, Savage was preparing to return to\\nacademia when Albert Madansky, a 23-year-old Ph.D. graduate of Savage’s\\nstatistics department, arrived at RAND. Madansky had financed his graduate\\nstudies by working part-time for Arthur Bailey, the Bayesian theorist in the\\ninsurance industry. Until Bailey’s death, he had considered an actuarial\\ncareer. Savage, who had published his book Foundations of Statistics but\\nhad not yet embraced Bayes’ rule, talked over the H-bomb problem with\\nMadansky without considering it in Bayesian terms. As he left Santa Monica,\\nhe handed over the H-bomb study to Madansky but left the young man to do\\nas he saw fit. Madansky would come up with a Bayesian approach on his\\nown.\\nBecause RAND’s report on the project would eventually be classified,\\nMadansky could not talk about his work for 41 years. But when Savage\\nreturned to Chicago he lectured openly about the fundamental statistical\\nissues involved. Bayes’ rule was emerging in fits and starts from the secrecy\\nof the Second World War and the Cold War.\\nThe H-bomb problem facing Madansky was politically and statistically\\ntricky. No atomic or hydrogen weapon had ever exploded accidentally. In the\\n12 years since the United States had dropped atomic bombs on Japan in\\nAugust 1945, nuclear bombs had been detonated, but always deliberately, as\\npart of a weapons test. Barring accidents, the nation’s leaders believed that\\ntheir stocks of nuclear weapons deterred all chance of thermonuclear war—\\nand that accidents could not occur in the future because none had occurred in\\nthe past. Nonetheless, the question remained: could the impossible happen?\\nAccording to more than a century of conventional statistics, the impossible\\ncould not be calculated. Jakob Bernoulli had decreed in 1713 that highly\\nimprobable events do not happen. David Hume agreed, arguing that because\\nthe sun had risen thousands of times in the past it would continue to do so. It\\nwas Thomas Bayes’ friend and editor, Richard Price, who took the contrary\\nview that the highly improbable could still occur. During the nineteenth and\\nearly twentieth centuries, Antoine-Augustin Cournot concluded that the\\nprobability of a physically impossible event was infinitely small and thus the\\nevent would never occur. Andrei Kolmogorov slightly refined “never” by\\nsaying that if the probability of an event is very small, we can be practically\\ncertain that the event will not happen in the very next trial.\\nFisher was no help either. He argued that probability is a simple relative\\nfrequency in an infinitely large population; until a nuclear bomb accident\\noccurred, he had no way of judging its future probability. Mercifully,\\nMadansky did not have an infinitely large population of H-bomb accidents,\\nand further experimentation was out of the question. Fisher’s approach left\\nhim with the banal observation that zero accidents had occurred and that the\\nprobability of a future accident was also zero.\\nMadansky concluded, “As long as you are set that the probability is going\\nto be zero, then nothing’s going to change your mind. If you have decided that\\nthe sun rises each morning because it has always done so in the past, nothing\\nis going to change your mind except one morning when the sun fails to\\nappear.”3\\nHe did not buy the argument that an accident could never occur simply\\nbecause none had happened in the past. First, the political and military\\nestablishment’s assumption that a well-stocked American arsenal of nuclear\\nweapons would deter war rested on increasingly shaky grounds. In the six\\nyears between 1949 and 1955 the Soviets had exploded their first atomic\\nbomb, the United States had detonated the world’s first hydrogen bomb, and\\nBritain had tested both an atomic and a hydrogen bomb. The USSR had\\nlaunched the first man-made satellite into orbit around Earth in 1957.\\nMeanwhile, the United States trained countries in the North Atlantic Treaty\\nOrganization (NATO) to fire nuclear weapons and supplied Britain, Italy,\\nand Turkey with nuclear missiles. By the time the Anglo-American\\nAgreement for Cooperation on the Uses of Atomic Energy for Mutual\\nDefense Purposes was signed in 1958, all hope of preventing the spread of\\nnuclear weapons had evaporated. France tested its first atomic bomb in\\n1960.\\nIn addition to the rapid expansion of nuclear weapons, Madansky had 16\\ntop-secret reasons for doubting that the probability of a future accident was\\nzero. A classified list detailed 16 of “the more dramatic incidents” involving\\nnuclear weapons between 1950 and 1958.4 They included accidental drops,\\njettisons, aircraft crashes, and testing errors. Incidents had occurred off\\nBritish Columbia and in California, New Mexico, Ohio, Florida, Georgia,\\nSouth Carolina, and overseas. RAND’s list omitted accidents that had not\\nattracted public attention.\\nAn atomic or hydrogen bomb consists of a small capsule, or “pit,” of\\nuranium or plutonium inside a case covered with powerful conventional\\nexplosives. Only if these high explosives blow up at the same instant can the\\nuranium or plutonium capsule be sufficiently compressed on all sides to\\ntrigger a nuclear blast. In a few cases these conventional explosives had\\ndetonated, generally on impact in a plane crash. Because the capsule of\\nnuclear material had not been installed inside the weapons, however, there\\nhad been no nuclear accidents. That fact had convinced SAC that its\\nprocedures were sound and that no nuclear accident would occur.\\nStill, scores of people had died when the high explosives in unarmed\\nnuclear weapons blew up. The year 1950 was a banner year for accidents.\\nOn April 11, 1950, 13 people died near Kirtland Air Force Base, outside\\nAlbuquerque, New Mexico, when a B-29 crashed into a mountain; flames\\nfrom the high explosives were visible for 15 miles. On July 13, 16 were\\nkilled when a B-50 nose-dived near Lebanon, Ohio. Nineteen people,\\nincluding Gen. Robert F. Travis, died when a B-29 with mechanical\\nproblems crash-landed in California on August 5, injuring 60 people in a\\nnearby trailer camp. Also that year, two bombs without nuclear capsules\\nwere jettisoned and abandoned in deep water in the Pacific Ocean off British\\nColumbia and in an unnamed ocean outside the United States.\\nNewspaper reporting was meager until an improperly closed lock in a B-\\n47’s bomb bay opened in 1958 and a “relatively harmless” bomb fell into\\nWalter Gregg’s garden in Mars Bluff, South Carolina.5 The conventional\\nexplosives detonated on impact, digging a crater 30 feet deep and 50 to 70\\nfeet across, destroying Gregg’s house, damaging nearby buildings, and killing\\nseveral chickens. No people died, but news coverage was extensive;\\ntypically reporters said that a “TNT triggering device” had exploded. RAND\\nnoted disapprovingly that a Time magazine article was “astonishingly\\naccurate.”6 Congress, Britain’s Labour Party, and Radio Moscow\\ncomplained.\\nThe air force paid the Greggs 54,000, and all B-47 and B-52 flights\\ncarrying nuclear weapons were suspended until new safety measures could\\nbe introduced. SAC also established a new policy: nuclear bombs were to be\\njettisoned on purpose only into oceans or designated “water masses. . . .\\nHence only uncontrolled drops may attract public attention in the future.”7\\nAs the press became increasingly suspicious of the accidents, Iklé and\\nanother RAND researcher, Albert Wohlstetter, became concerned. Iklé\\nrecommended that the government remain silent about the presence of nuclear\\nweapons in aircraft crashes. As Iklé and Madansky worked on their study, an\\naccident occurred that could have provoked an international scandal. A\\nwheel casting on a B-47 failed at the air force’s fueling base in Sidi Slimane,\\nFrench Morocco. High explosives detonated and a fire raged for seven hours,\\ndestroying the nuclear weapon and capsule aboard.\\nGiven all these accidents involving unarmed nuclear weapons, Madansky\\nfelt he could no longer assume, as SAC and frequentist statisticians had, that\\nan accident involving an H-bomb could never occur. Instead, he decided, he\\nneeded “another theology, . . . another brand of inference,” where the\\npossibility of an accident was not necessarily zero.\\nFrequentism was no help. “But, but, but,” Madansky said later, “if you’re\\nwilling to admit a shred of disbelief, you can let Bayes’ theorem work. . . .\\nBayes is the only other theology that you can go to. It’s just sort of natural for\\nthis particular problem. At least that’s how I felt back then.”8 As Dennis\\nLindley had argued, if someone attaches a prior probability of zero to the\\nhypothesis that the moon is made of green cheese, “then whole armies of\\nastronauts coming back bearing green cheese cannot convince him.” In that\\nconnection, Lindley liked to quote Cromwell’s Rule from the Puritan leader’s\\nletter to the Church of Scotland in 1650: “I beseech you, in the bowels of\\nChrist, think it possible you may be mistaken.”9 In the spirit of Cromwell’s\\nRule, Madansky adopted Bayes as his “alternate theology.”\\nMany Cold War statisticians knew it well. They were using it to deal with\\none of their biggest problems, estimating the reliability of the new\\nintercontinental ballistic missiles. “We didn’t know how reliable the missiles\\nwere,” Madansky explained, “and we had a limited amount of test data to\\ndetermine it, and so a number of the people working in reliability applied\\nBayesian methods. The entire field, from North American Rockwell,\\nThompson Ramo Wooldridge, Aerospace, and others, was involved. I’m sure\\nBayesian ideas floated around them too. We all knew about it. . . . It was just\\na natural thing to do.”10\\nMadansky immediately set out to measure how much credence could be\\ngiven to the belief that no unauthorized detonations would occur in the future.\\nHe started with “statistically speaking, this simple commonsense idea based\\non the notion that there is an a priori distribution of the probability of an\\naccident in a given opportunity, which is not all concentrated at zero.”11 The\\ndecision to incorporate a whisper of doubt into his prior was important.\\nOnce a Bayesian considered the possibility that even one small accident\\nmight have occurred in the past 10,000 opportunities, the probability of an\\naccident-free future dropped significantly.\\nPolitically and mathematically, Madansky faced an extremely difficult\\nproblem. As a young civilian challenging one of the military’s fundamental\\nbeliefs about the Cold War, he would have to convince decision makers that,\\nalthough nothing catastrophic had occurred, something might in future. He\\nwould have to explain the Bayesian process to nonspecialists. And because\\nthe military was often suspicious of civilians making unwarranted\\nsuggestions, he would have to make as few initial assumptions as possible. In\\naddition, there was the statistical problem involving the small number of\\naccidents and, fortunately, no Armageddons.\\nNot wanting to stick his neck out, Madansky decided to make his prior\\nodds considerably weaker than 50–50. “I tried to figure out how to avoid\\nmaking any specifications about what the prior should be.”12 To refine his\\nminimally informative prior, he added another common-sense notion: the\\nprobability of an accident-free future depends on the length of the accident-\\nfree past and the number of future accident opportunities. Madansky had no\\ndirect evidence because there had never been a nuclear accident. But the\\nmilitary had plenty of indirect data, and he began using it to modify his prior.\\nHe knew that the military was already developing plans to greatly increase\\nthe number of flights carrying nuclear weapons. SAC was planning a system\\nof 1,800 bombers capable of carrying nuclear weapons; approximately 15%\\nof them would be in the air at all times, armed and ready for attack. At that\\ntime, SAC’s B-52 jet-powered Stratofortress bombers carried up to four\\nnuclear bombs, each with an explosive power between 1 million and 24\\nmillion tons of TNT, or up to 1,850 Hiroshima bombs. The United States was\\nalso planning to outfit intercontinental ballistic missiles with hydrogen\\nwarheads, accelerate the production of intermediate range ballistic missiles,\\nand negotiate with NATO countries for launching rights and military bases.\\nThe military would soon be dealing with shorter alarm times, increased\\nalertness, and more decentralized weaponry, all factors that could increase\\nthe likelihood of a catastrophe.\\nMadansky calculated the number of “accident opportunities” based on the\\nnumber of weapons, their longevity, and the number of times they were\\naboard planes or handled in storage.13 Accident opportunities corresponded\\nto flipping coins and throwing dice. Counting them proved to be an important\\ninnovation.\\n“A probability that is very small for a single operation, say one in a\\nmillion, can become significant if this operation will occur 10,000 times in\\nthe next five years,” Madansky wrote.14 The military’s own evidence\\nindicated that “a certain number of aircraft crashes” was inevitable.\\nAccording to the air force, a B-52 jet, the plane carrying SAC’s bombs,\\nwould average 5 major accidents per 100,000 flying hours. Roughly 3\\nnuclear bombs were dropped accidentally or jettisoned on purpose per 1,000\\nflights that carried these weapons. In that 80% of aircraft crashes occurred\\nwithin 3 miles of an air force base, the likelihood of public exposure was\\ngrowing. And so it went. None of these studies involved a nuclear explosion,\\nbut to a Bayesian they suggested ominous possibilities.\\nComputationally, Madansky was confident that RAND’s two powerful\\ncomputers, a 700 series IBM and the Johnniac, designed by and named for\\nJohn von Neumann, could handle the job. But he hoped to avoid using them\\nby solving the problem with pencil and paper.\\nGiven the power and availability of computers in the 1950s, many\\nBayesians were searching for ways to make calculations manageable.\\nMadansky latched onto the fact that many types of priors and posteriors share\\nthe same probability curves. Bailey had used the same technique in the late\\n1940s, and later it would be known as Howard Raiffa and Robert Schlaifer’s\\nconjugate priors. When Madansky read their book describing them, he was\\npleased to know that his prior had a name and rationale: “I was just doing it\\nad hoc.”15\\nUsing his tractable prior, classified military data, and informed\\nguesswork, Madansky came to a startling conclusion. It was highly probable\\nthat SAC’s expanded airborne alert system would be accompanied by 19\\n“conspicuous” weapon accidents each year.\\nMadansky wrote an elementary summary that high-level military decision\\nmakers could understand and inserted it into RAND’s final report, “On the\\nRisk of an Accidental or Unauthorized Nuclear Detonation. RM-2251 U.S.\\nAir Force Project Rand,” dated October 15, 1958. The report listed Iklé as\\nits primary author in collaboration with Madansky and a psychiatrist, Gerald\\nJ. Aronson. Until then, many RAND reports had been freely published, but\\nair force censors were clamping down on its think tank, and this report was\\nclassified, its initial readership limited to a select few. It was finally\\nreleased more than 41 years later, on May 9, 2000, with numerous passages\\nblacked out.\\nIn view of what would happen a few years later in Spain, much of the\\nreport seems prescient. Madansky could not predict when or where the\\naccident would occur, but he was sure of two things. The likelihood of an\\naccident was rising, and it was in the military’s interest to make its nuclear\\narsenal safer. Given the media’s increasingly savvy coverage of accidents\\ninvolving nuclear weaponry, Iklé foresaw Soviet propaganda, citizens’\\ncampaigns to limit the use of nuclear devices, and foreign powers demanding\\nan end to American bases on their soil. Who knew, but the British Labour\\nParty might even win an election or NATO might crumble?\\nAs a result, Iklé and Madansky advocated safety features that included\\nrequiring at least two people to arm a nuclear weapon; electrifying arming\\nswitches to jolt anyone who touched them; arming weapons only over enemy\\nterritory; installing combination locks inside warheads; preventing the\\nrelease of radioactive material in accidental fires of high-energy missile\\nfuels; and switching the nuclear matter inside weapons from plutonium to\\nuranium because the latter would contaminate a smaller area. The report also\\nrecommended placing reassuring articles in scientific journals to publicize\\nresearch indicating that plutonium emissions were less dangerous to humans\\nthan had been thought; the source of the research was to be disguised.\\nLater, after SAC implemented its airborne alert program and began\\nkeeping significant numbers of nuclear-armed planes aloft at all times, Iklé\\nand Madansky followed up with a more pointed and less mathematical\\nsummary about accident rates. As of 2010 this internal document, meant only\\nfor internal circulation, was still classified. In an appendix to the first report,\\nIklé and Aronson, the psychiatrist who consulted at RAND, tackled the topic\\nof mental illness among military personnel in charge of nuclear bombs. Such\\nconcerns were widespread at the time. Aronson believed that men who\\nworked near the bombs should be psychologically tested by being confined\\nin a chamber by themselves, deprived of sleep and sensory stimuli for\\nseveral hours, and perhaps dosed with hallucinogens such as LSD. He\\npredicted “only between one-third and one-quarter of ‘normal’ volunteer-\\nsubjects would be able to withstand [it] for more than several hours.”16 It\\nwas later learned that the Central Intelligence Agency financed a variety of\\nLSD (lysergic acid diethylamide) experiments on people without their\\nknowledge or consent during the 1950s, although the practice violated ethical\\nstandards even then.\\nAfter the report was issued, Iklé, his knees shaking, went to brief “a\\nsizable audience of Air Force generals.”17 RAND researchers assumed that\\nGeneral LeMay would scorn their conclusions. LeMay had directed the fire-\\nbombing of Japanese cities during the Second World War, his ghostwritten\\nautobiography would propose bombing the Vietnamese “back into the Stone\\nAge” in the mid-1960s, and he was the model for “Buck” Turgidson, the\\ninsanely warlike, cigar-chomping general played by George C. Scott in the\\nfilm Dr. Strangelove. Iklé described LeMay’s attitude about nuclear weapons\\nas one of “injudicious pugnacity.”18\\nBut the general surprised him. The day after RAND presented its report in\\nWashington, LeMay asked for a copy. Iklé said LeMay later issued a\\n“blizzard” of orders, among others calling for the two-man rule and coded\\nlocks. The army and navy followed suit. Iklé put LeMay’s response “in the\\n‘success’ column of my life’s ledger.”19\\nAccording to most reports, however, few of the coded locks were actually\\ninstalled on nuclear weapons until John F. Kennedy became president. Four\\ndays after Kennedy’s inauguration, a SAC B-52 disintegrated in midflight.\\nOne of its two 24-megaton hydrogen bombs smashed into a swamp near\\nGoldsboro, North Carolina, and a large chunk of enriched uranium sank more\\nthan 50 feet, where it presumably remains to this day. Analysis showed that\\nonly one of the bomb’s six safety devices had functioned properly. JFK was\\ntold of scores of nuclear weapon accidents—according to Newsweek, more\\nthan 60 since the Second World War. From then on, the Kennedy\\nadministration vigorously pursued nuclear weapon safety and added coded\\nlocks to nuclear weapons.\\nIklé went on to become a leading hard-line specialist in military and\\nforeign policy and would be awarded two Distinguished Public Service\\nMedals, the Department of Defense’s highest civilian award. Madansky\\nbecame a professor at the University of Chicago, where he developed a\\nreputation as a neutral pragmatist in the battles between Bayesians and\\nfrequentists. RAND gradually weaned itself from air force funding by\\ndiversifying into social welfare research.\\nThe world can be thankful that Madansky’s Bayesian statistics forced the\\nmilitary to tighten safety measures. A number of false alerts suggestive of\\nSoviet nuclear attacks were identified correctly before SAC could launch a\\ncounterattack. Phenomena causing false alerts included the aurora borealis, a\\nrising moon, space debris, false U.S. radar signals, errors in the use of\\ncomputers (such as a mistaken Pentagon warning of incoming Soviet missiles\\nin 1980), routine Soviet maintenance procedures after the Chernobyl\\naccident, a Norwegian weather research missile, and “more hidden problems\\nof unauthorized acts.”\\n10.\\n \\n46,656 varieties\\n \\nIn sharp contrast to the super secrecy of Madansky’s H-bomb report, the\\nschism between entrenched frequentists and upstart Bayesians was getting\\ndownright noisy. As usual, the bone of contention was the subjectivity of\\nThomas Bayes’ pesky prior. The idea of importing knowledge that did not\\noriginate in the statistical data at hand was anathema to the anti-Bayesian duo\\nFisher and Neyman. Since they were making conclusions and predictions\\nabout data without using prior odds, Bayesian theoreticians on the defensive\\nstruggled to avoid priors altogether.\\nBayesian theories mushroomed in glorious profusion during the 1960s, and\\nJack Good claimed he counted “at least 46656 different interpretations,” far\\nmore than the world had statisticians.1 Versions included subjective,\\npersonalist, objective, empirical Bayes (EB for short), semi-EB, semi-\\nBayes, epistemic, intuitionist, logical, fuzzy, hierarchical, pseudo, quasi,\\ncompound, \\nparametric, \\nnonparametric, \\nhyperparametric, \\nand \\nnon-\\nhyperparametric Bayes. Many of these varieties attracted only their own\\ncreators, and some modern statisticians contend that hairsplitting produced\\nlittle pathbreaking Bayesian theory. When asked how to differentiate one\\nBayesian from another, a biostatistician cracked, “Ye shall know them by\\ntheir posteriors.”\\nAlmost unnoticed in the hoopla, the old term “inverse probability” was\\ndisappearing, and a modern term, “Bayesian inference,” was taking its place.\\nAs the English language swept postwar statistical circles, articles by British\\ntheorists began to look more important than Laplace’s French ones. “Much\\nthat’s been written about the history of probability has been distorted by this\\nEnglish-centric point of view,” says Glenn Shafer of Rutgers University.2\\nMore than language may have been involved. In 2008, when the Englishman\\nDennis Lindley was 85 years old, he said he was now almost convinced that\\nLaplace was more important than Thomas Bayes: “Bayes solved one narrow\\nproblem; Laplace solved many, even in probability. . . . My ignorance of the\\nFrenchman’s work may be cultural, since he did not figure prominently in my\\nmathematical education.” Then he added with characteristic honesty, “But I\\nam biased: the French let us down during WW2 and then there was the\\nghastly de Gaulle.”3\\nIn England the ferment over Bayes’ rule extended even into Fisher’s\\nfamily. His son-in-law George E. P. Box was the young chemist who had to\\nsay he was transporting a horse in order to consult Fisher during the Second\\nWorld War. Like Fisher, Box came to believe that statistics should be more\\nclosely entwined with science than with mathematics. This view was\\nreinforced by Box’s later work for the chemical giant ICI in Britain and for\\nthe quality control movement with W. Edwards Deming and the Japanese\\nauto industry.\\nWhen Box organized a statistics department at the University of Wisconsin\\nin 1960, he taught for the first time, a class called Foundations of Statistics.\\n“Week after week,” he said, “I prepared my notes very carefully. But the\\nmore I did, the more I became convinced that the standard stuff I’d studied\\nunder Egon Pearson was wrong. So gradually my course became more and\\nmore Bayesian. . . . People used to make fun of it and say it was all\\nnonsense.”4\\nHelping scientists with scanty data, Box found that traditional statistics\\nproduced messy, unsatisfactory solutions. Still, frequentism worked well for\\nspecial cases where data fell into bell-shaped probability curves and\\nmiddle-values were assumed to be averages. So, as Box said, “Comparing\\naverages looked right to me until Stein.”5\\nStein’s Paradox called those averages into question. Charles Stein, a\\ntheoretical statistician, had been thinking about something that looked quite\\nsimple: estimating a mean. Statisticians do not concern themselves with\\nindividuals; their bread and butter is a midvalue summarizing large amounts\\nof information. The centuries-old question was which midvalue works best\\nfor a particular problem. In the course of his investigation, Stein discovered\\na method that, ironically, produced more accurate predictions than simple\\naverages did. Statisticians called it Stein’s Paradox. Stein called it\\nshrinkage. As a frequency-based theorist, he studiously avoided discussing\\nits relationship with Bayes.\\nStein’s Paradox, however, works for comparisons between related\\nstatistics: the egg production of different chicken breeds, the batting averages\\nof various baseball players, or the workers’ compensation exposure of\\nroofing companies. Traditionally, for example, farmers comparing the egg\\nproduction of five chicken breeds would average the egg yields of each\\nbreed separately. But what if a traveling salesman advertised a breed of\\nhens, and each one supposedly laid a million eggs? Because of their prior\\nknowledge of poultry, farmers would laugh him out of town. Bayesians\\ndecided that Stein, like the farmers, had weighted his average with a sort of\\nsuper-or hyperdistribution about chicken-ness, information about egg laying\\ninherent in each breed but never before considered. And intrinsic to poultry\\nfarming is the fact that one hen never lays a million eggs.\\nIn like manner, Stein’s system used prior information to explain the\\nhitherto mediocre batter who begins a new season hitting a spectacular .400.\\nStein’s Paradox tells fans not to forget their previous knowledge of the sport\\nand the batting averages of other players.\\nWhen Stein and Willard D. James simplified the method in 1961, they\\nproduced another surprise—the same Bayes-based formula that actuaries had\\nused earlier in the century to price workers’ compensation insurance\\npremiums. Whitney’s actuarial Credibility theorem used x = P + z(p–P), and\\nStein and James used z =  + c(y–y): identical formulas but with different\\nsymbols and names. In both cases, data about related quantities were being\\nconcentrated, made more credible or shrunk, until they clustered more tightly\\naround the mean. With it, actuaries made more accurate predictions about the\\nfuture well-being of workers in broad industrial categories. Only Arthur\\nBailey had recognized the formula’s Bayesian roots and realized it would be\\nequally valid for noninsurance situations.\\nDelighted Bayesians claimed Stein was using the prior context of his\\nnumbers to shrink the range of possible answers and make for better\\npredictions. Stein, however, continued to regard Bayes’ philosophical\\nframework as a “negative” and subjective priors as “completely\\ninappropriate.”6\\nBox, who believed Stein should have admitted his method was Bayesian,\\nimmediately thought of other relationships that work the same way. Daily egg\\nyields produced on Monday are related to yields produced on Tuesday,\\nWednesday, and Thursday. In this case, the link between different items is a\\ntime series, and successive observations tend to be correlated with each\\nother just as tomorrow tends to be rather like today. But Box discovered\\ngleefully that analyzing time series with Bayesian methods improved\\npredictions and that without those methods Stein’s Paradox did not work for\\ntime series. As Box explained, “If someone comes into your office with some\\nnumbers and says, ‘Analyze them,’ it’s reasonable to ask where they come\\nfrom and how they’re linked. The quality that makes numbers comparable has\\nto be taken into account. You can’t take numbers out of context.”7\\nFrequentists and Bayesians battled for years over Stein’s Paradox, in part\\nbecause neither side seemed to be all right or all wrong. Box, however, was\\na convinced Bayesian, and he wrote a snappy Christmas party song to the\\ntune of “There’s No Business like Show Business.” One verse went:\\nThere’s no Theorem like Bayes theorem\\nLike no theorem we know\\nEverything about it is appealing\\nEverything about it is a wow\\nLet out all that a priori feeling\\nYou’ve been concealing right up to now.\\n. . . . There’s no theorem like Bayes theorem\\nLike no theorem we know.8\\n \\nAs Bayesian interpretations multiplied like bunnies and cropped up in\\nunlikely places like Stein’s Paradox, cracks formed in Fisher’s favorite\\ntheory, fiducial probability. He had introduced it as an alternative to Bayes’\\nrule during an argument with Karl Pearson in 1930. But in 1958 Lindley\\nshowed that when uniform priors are used, Fisher’s fiducial probability and\\nBayesian inference produce identical solutions.\\nStill another fissure occurred when Allan Birnbaum derived George A.\\nBarnard’s likelihood principle from generally accepted frequentist principles\\nand showed that he needed to take into account only observed data, not\\ninformation that might have arisen from the experiment but had not. Another\\nfrequentist complained that Birnbaum was “propos[ing] to push the clock\\nback 45 years, but at least this puts him ahead of the Bayesians, who would\\nlike to turn the clock back 150 years.”9 Jimmie Savage, however, praised\\nBirnbaum’s work as a “historic occasion.”10\\nSavage also damned Fisher’s fiducial method for using parts of Bayes\\nwhile avoiding the opprobrium attached to priors. Savage considered\\nFisher’s theory “a bold attempt to make the Bayesian omelet without\\nbreaking the Bayesian eggs.”11 Box thought his father-in-law’s fiducial\\nprobability was beginning to look like “a sneaky way of doing Bayes.”12\\nYet another disagreement between Bayesians and anti-Bayesians surfaced\\nin 1957, when Lindley, elaborating on a point made by Jeffreys, highlighted a\\ntheoretical situation when the two approaches produce diametrically\\nopposite results. Lindley’s Paradox occurs when a precise hypothesis is\\ntested with vast amounts of data. In 1987, Princeton University aeronautics\\nengineering professor Robert G. Jahn conducted a large study which he\\nconcluded supported the existence of psychokinetic powers. He reported that\\na random event generator had produced 104,490,000 trials testing the\\nhypothesis that someone on a couch eight feet away cannot influence their\\nresults any more than random chance would. Jahn reported that the random\\nevent generator produced 18,471 more examples (0.018%) of human\\ninfluence on his sensitive microelectronic equipment than could be expected\\nwith chance alone. Even with a p-value as small as 0.00015, the frequentist\\nwould reject the hypothesis (and conclude in favor of psychokinetic powers)\\nwhile the same evidence convinces a Bayesian that the hypothesis against\\nspiritualism is almost certainly true.\\nSix years later, Jimmie Savage, Harold Lindman, and Ward Edwards at the\\nUniversity of Michigan showed that results using Bayes and the frequentist’s\\np-values could differ by significant amounts even with everyday-sized data\\nsamples; for instance, a Bayesian with any sensible prior and a sample of\\nonly 20 would get an answer ten times or more larger than the p-value.\\nLindley ran afoul of Fisher’s temper when he reviewed Fisher’s third\\nbook and found “what I thought was a very basic, serious error in it: Namely,\\nthat [Fisher’s] fiducial probability doesn’t obey the rules of probability. He\\nsaid it did. He was wrong; it didn’t, and I produced an example. He was\\nfurious with me.” A sympathetic colleague warned Lindley that Fisher was\\nlivid, but “it was not until the book of Fisher’s letters was published that I\\nrealized the full force of his fury. He was unreasonable; he should have\\nadmitted his mistake. Still, I was a bumptious young man and he was entitled\\nto be a bit angry.” Lindley compounded his tactlessness by turning his\\ndiscovery into a paper. The journal editor agreed that the article had to be\\npublished because it was correct, but asked Lindley if he knew what he was\\ndoing: “We would have the wrath of Fisher on our heads.”13 For the next\\neight months Fisher’s letters to friends included complaints about Lindley’s\\n“rather abusive review.”14\\nBayes frayed Neyman’s nerves too. When Neyman organized a symposium\\nin Berkeley in 1960, Lindley read a paper about prior distributions that\\ncaused “the only serious, public row that I can recall having had in statistics.\\nNeyman was furious with me in public. I was very worried, but Savage leapt\\nto my defense and dealt with the situation, I think very well.”15\\nOne day in the mid-1960s Box dared to tackle his irascible father-in-law\\nabout equal priors. Fisher had come to see his new granddaughter, and\\nfriends had warned Box he could get only so far with Fisher before he\\nexploded. Walking up the hill to the University of Wisconsin in Madison, Box\\ntold the old man, “I’ll give them equal probabilities, so if I have five\\nhypotheses, each has a probability of one-fifth.”16\\nFisher responded in a rather annoyed way, as if to say, “This is what I’m\\ngoing to say and then you’re going to shut up.” He declared, “Thinking that\\nyou don’t know and thinking that the probabilities of all the possibilities are\\nequal is not the same thing.”17 That distinction, which Box later agreed with,\\nprevented Fisher from accepting Bayes’ rule. Like Neyman, Fisher agreed\\nthat if he ever saw a prior he could believe, he would use Bayes-Laplace.\\nAnd in fact he did. Because he knew the pedigrees of his laboratory animals\\ngenerations back, he could confidently specify the initial probabilities of\\nparticular crosses. For those experiments Fisher did use Bayes’ rule. Later,\\nBox said sadly that he divorced Fisher’s daughter because she had inherited\\na temper much like her father’s.\\nA compromise between Bayesian and anti-Bayesian methods began to\\nlook attractive. The idea was to estimate the initial probabilities according to\\ntheir relative frequency and then proceed with the rest of Bayes’ rule.\\nEmpirical Bayes, as it was called, seemed like a breakthrough. Egon Pearson\\nhad made an early stab at it in 1925, Turing had used a variant during the\\nSecond World War, Herbert Robbins proposed it in 1955, and when Neyman\\nrecommended it, a flurry of publications appeared. Empirical Bayesians had\\nlittle impact on mainstream statistical theory, however, and almost none on\\napplications until the late 1970s.\\nAt the same time, others tackled one of the practical drawbacks to Bayes:\\nits computational difficulty. Laplace’s continuous form of Bayes’ rule called\\nfor integration of functions. This could be complicated, and as the number of\\nunknowns rose, integration problems became hopelessly difficult given the\\ncomputational capabilities of the time. Jeffreys, Lindley, and David Wallace\\nwere among those who worked on developing asymptotic approximations to\\nmake the calculations more manageable.\\nAmid this mathematical fervor, a few practical types sat down in the\\n1960s to build the kind of institutional support that frequentists had long\\nenjoyed: annual seminars, journals, funding sources, and textbooks. Morris\\nH. DeGroot wrote the first internationally known text on Bayesian decision\\ntheory, the mathematical analysis of decision making. Arnold Zellner at the\\nUniversity of Chicago raised money, founded a conference series, and began\\ntesting standard economics problems one by one, solving them from both\\nBayesian and nonBayesian points of view. Thanks to Zellner’s influence,\\nSavage’s subjective probability would have one of its biggest impacts in\\neconomics. The building process took decades. The International Society for\\nBayesian Analysis and the Bayesian section of the American Statistical\\nAssociation were not formed until the early 1990s.\\nThe excitement over Bayesian theory extended far beyond statistics and\\nmathematics though. During the 1960s and 1970s, physicians, National\\nSecurity Agency cryptanalysts, Central Intelligence Agency analysts, and\\nlawyers also began to consider Bayesian applications in their fields.\\nPhysicians began talking about applying Bayes to medical diagnosis in\\n1959, when Robert S. Ledley of the National Bureau of Standards and Lee B.\\nLusted of the University of Rochester School of Medicine suggested the idea.\\nThey published their article in Science because medical journals were\\nuninterested. After reading it, Homer Warner, a pediatric heart surgeon at the\\nLatter-day Saints Hospital and the University of Utah in Salt Lake City,\\ndeveloped in 1961 the first computerized program for diagnosing disease.\\nBasing it on 1,000 children with various congenital heart diseases, Warner\\nshowed that Bayes could identify their underlying problems quite accurately.\\n“Old cardiologists just couldn’t believe that a computer could do something\\nbetter than a human,” Warner recalled.18 A few years after Warner introduced\\nhis battery of 54 tests, Anthony Gorry and Otto Barnett showed that only\\nseven or eight were needed, as long as they were relevant to the patient’s\\nsymptoms and given one at a time in proper sequence. Few physicians used\\nthe systems, however, and efforts to computerize diagnostics lapsed.\\nBetween 1960 and 1972 the National Security Agency educated\\ncryptanalysts about advanced Bayesian methods with at least six articles in\\nits in-house NSA Technical Journal. Originally classified as “Top Secret\\nUmbra,” an overall code word for high-level intelligence, they were\\npartially declassified at my request in 2009, although the authorship of three\\nof the six was suppressed. (At least one of those three has the earmarks of a\\nJack Good article.) In another article, an agency employee named F. T. Leahy\\nquoted the assertion in Van Nostrand’s Scientific Encyclopedia that Bayes’\\ntheorem “has been found to be unscientific, to give rise to various\\ninconsistencies, and to be unnecessary.” In fact, Leahy declared in 1960,\\nBayes is “one of the more important mathematical techniques used by\\ncryptanalysts . . . [and] was used in almost all the successful cryptanalysis at\\nthe National Security Agency. . . . It leads to the only correct formulas for\\nsolving a large number of our cryptanalytic problems,” including those\\ninvolving comparisons among a multiplicity of hypotheses.19 Still, “only a\\nhandful of mathematicians at N.S.A. know about all the ways” Bayes can be\\nused. The articles were presumably intended to remedy the situation.\\nAt the CIA, analysts conducted dozens of experiments with Bayes. The\\nCIA, which must infer information from incomplete or uncertain evidence,\\nhad failed at least a dozen times to predict disastrous events during the 1960s\\nand 1970s. Among them were North Vietnam’s intervention in South Vietnam\\nand the petroleum price hike instituted by the Organization of Petroleum\\nExporting Countries (OPEC) in 1973. Agency analysts typically made one\\nprediction and left it at that; they ignored unlikely but potentially catastrophic\\npossibilities and failed to update their initial predictions with new evidence.\\nAlthough the CIA concluded that Bayes-based analyses were more insightful,\\nthey were judged too slow. The experiments were abandoned for lack of\\ncomputer power.\\nThe legal profession reacted differently. After several suggestions that\\nBayes might be useful in assessing legal evidence, Professor Laurence H.\\nTribe of Harvard Law School published a blistering and influential article\\nabout the method in 1971. Drawing on his bachelor’s degree in mathematics,\\nTribe condemned Bayes and other “mathematical or pseudo-mathematical\\ndevices” because they are able to “distort—and, in some instances, to\\ndestroy—important values” by “enshrouding the [legal] process in\\nmathematical obscurity.”20 After that, many courtroom doors slammed shut on\\nBayes.\\nThe extraordinary fact about the glorious Bayesian revival of the 1950s\\nand 1960s is how few people in any field publicly applied Bayesian theory\\nto real-world problems. As a result, much of the speculation about Bayes’\\nrule was moot. Until they could prove in public that their method was\\nsuperior, Bayesians were stymied.\\npart IV\\n \\nto prove its worth\\n \\n11.\\n \\nbusiness decisions\\n \\nWith new statistical theories cropping up almost daily during the 1960s, the\\npaltry number of practical applications in the public arena was becoming a\\nprofessional embarrassment.\\nHarvard’s John W. Pratt complained that Bayesians and frequentists alike\\nwere publishing “too many minor advances extracted from real or mythical\\nproblems, sanitized, rigorized, polished, and presented in pristine\\nmathematical form and multiple forums.”1\\nBayesians in particular seemed unwilling to apply their theories to real\\nproblems. Savage’s rabbit ears and 20-pound chairs were textbook\\nshowpieces, even less substantial than Egon Pearson’s chestnut foals and\\npipe-smoking males of 30 years before. They were “dumb,” a Bayesian at\\nHarvard Business School protested later;2 they lacked the practical world’s\\nring of truth. When analyzing substantial amounts of data even diehard\\nBayesians preferred frequency. Lindley, already Britain’s leading Bayesian,\\npresented a paper about grading examinations to the Harvard Business\\nSchool in 1961 without mentioning Bayes; only later did he analyze a similar\\nproblem using wine statistics and Bayesian methods.\\nMathematically and philosophically, the rule was simplicity itself. “You\\ncan’t have an opinion afterwards,” said Pratt, “without having had an opinion\\nbefore and then updating it using the information.”3 But making a belief\\nquantitative and precise—there was the rub.\\nUntil their logically appealing system could prove itself as a powerful\\nproblem solver in the workaday world of statistics, Bayesians were doomed\\nto minority status. But who would undertake a cumbersome, complex,\\ntechnically fearsome set of calculations to explore a method that was\\nprofessionally almost taboo? At the dawn of the electronic age, powerful\\ncomputers were few and far between, and packaged software nonexistent.\\nBayesian techniques for dealing with practical problems and computers\\nbarely existed. Brawn—lots of it—would have to substitute for computer\\ntime. The faint of heart need not apply.\\nNevertheless, a few hardy, energetic, and supremely inventive\\ninvestigators tried to put Bayes to work for business decision makers, social\\nscientists, and newscasters. Their exploits dramatize the formidable\\nobstacles that faced anyone trying to use Bayes’ rule.\\nThe first to try their luck with Bayes was an unlikely duo at Harvard\\nBusiness School, Robert Osher Schlaifer and Howard Raiffa. They were\\npolar opposites. Schlaifer was the school’s statistical expert, but, in a sign of\\nthe times, he had taken only one mathematics course in his life and was an\\nauthority on ancient Greek slavery and modern airplane engines. Raiffa was\\na mathematical sophisticate who became the legendary Mr. Decision Tree, an\\nadvisor to presidents and a builder of East–West rapprochement. Together\\nthey tackled the problem of turning Bayes into a tool for business decision\\nmakers.\\nFortunately, Schlaifer enjoyed using his laserlike mind, hyperlogic, and\\noutsider status to bludgeon through convention and orthodoxy. Years later,\\nwhen Raiffa was asked to describe his colleague, he did so in two words,\\n“imperious and hierarchical.”\\nSchlaifer was an opinionated perfectionist. Plunging into a topic, he saw\\nnothing else. When his passion turned to bicycle racks, he persuaded a\\nHarvard dean to install his new design on campus. Because he loved old\\nengines, an MIT physicist volunteered to come each week to maintain his\\nModel A Ford and hi-fi to his exacting standards. And when he studied\\nconsumer behavior, his faculty colleagues pondered instant coffee as soberly\\nas they would have nuclear fusion. Like an autocrat atop an empire, Schlaifer\\nbestowed nicknames on his colleagues: “Uncle Howard” for Raiffa, “Great\\nMan Pratt” for John W. Pratt, and, most memorably, “Arturchick” for his\\ngraduate student and near namesake, Arthur Schleifer Jr. All three survived\\nto become chaired professors at Harvard.\\nWhatever else, the man had panache and fun. Few Harvard professors\\ninvited research assistants for Sunday dinners and bottles of 1938 Clos\\nVougeot, but Schlaifer did. And few took off an entire month or sabbatical\\nyear to relax in Greece or France, as he did with his French-born wife,\\nGeneviève, whom he publicly referred to as Snuggle Buggle.\\nSchlaifer was not to the manor born. He was born in Vermillion, South\\nDakota, in 1914 and grew up near Chicago, in a small town where his father\\nwas superintendent of schools. At Amherst College he majored in classics\\nand ancient history and took courses in economics and physics. He enrolled\\nin calculus, his only formal math class, solely to capture a large cash prize\\nfor the best student. After graduating Phi Beta Kappa at the age of 19, he\\nstudied in Athens at the American School of Classical Studies between 1937\\nand 1939 and earned a Ph.D. in ancient history at Harvard in 1940. Over the\\nnext few years he published several articles about religious cults and slavery\\nin ancient Greece. Schlaifer was a quick study, and he filled in for Harvard\\nhistorians, economists, and physicists as they left for defense work during the\\nSecond World War.\\nEventually, Schlaifer was assigned to the university’s Underwater Sound\\nLaboratory, where sonar was developed. He and theoretical physicist Edwin\\nKemble tried to silence submarine torpedo propellers the better to attack\\nGerman U-boats. Schlaifer understood the scientific issues well enough to\\nsolve equations using Marchant or Frieden electromechanical calculators and\\nto turn technical reports into prose. The war gave him a voracious appetite\\nfor practical, real-world problems, and he abandoned ancient history.\\nAfter the war Schlaifer’s physics impressed the Harvard Business School\\nenough to hire him to fulfill a departmental obligation: a study of the aircraft\\nengine industry. He turned the low-status assignment into a triumph, a\\n600page classic on aviation history, Development of Aircraft Engines,\\nDevelopment of Aircraft Fuel.\\nBetween his war work and the book, Schlaifer acquired a usefully\\nintimidating campus reputation as a physicist, later cemented by his obituary\\nin the New York Times. He was teaching accounting and production when the\\nbusiness school, despite his spectacularly unsuitable training, assigned him\\nto teach statistical quality control. Knowing nothing about statistics, Schlaifer\\ncrammed by reading the dominant theoreticians of the day, Fisher, Neyman,\\nand Egon Pearson. Wartime operations research had mathematized problem\\nsolving for two common business problems, inventory control and\\ntransportation scheduling. But frequentism offered businesses no help when it\\ncame to issues like launching a new product or changing a price.\\nSchlaifer’s publications later described modest pleas for help from a\\nnewsstand owner unsure of how many copies of the Daily Racing Form to\\nstock, and from a wholesaler worried about allocating his ten delivery trucks\\nbetween two warehouses. With luck, business owners might make the right\\ndecisions. But given the uncertainties involved in even these simple\\nproblems, Schlaifer wondered how they could ever hope to systematically\\nmake the best possible choices. Even if they could collect additional\\ninformation by sampling or experimentation, would it be worth the cost?\\nAccording to frequentists, objective statistics were synonymous with long-\\nrun relative frequency, and probabilities were invalid unless based on\\nrepeatable observations. Frequentists dealt with a rich abundance of directly\\nrelevant data and took samples to test hypotheses and draw inferences about\\nunknowns. The method worked for repetitive, standardized phenomena such\\nas successive grain crops, genetics, gambling, insurance, and statistical\\nmechanics.\\nBut business executives often had to make decisions under conditions of\\nextreme uncertainty, without sample data. As Schlaifer realized, “Under\\nuncertainty, the businessman is forced, in effect, to gamble, . . . hoping that he\\nwill win but knowing that he may lose.”4 Executives needed a way to assess\\nprobabilities without the repeated trials required by frequentist methods.\\nSchlaifer said teaching frequentism made him feel like a jackass. It simply\\ndid not address the main problem in business: decision making under\\nuncertainty.\\nThinking through the problem, Schlaifer wondered how executives could\\nmake decisions based on no data. Whatever prior information they had about\\nthe demand for their product was obviously better than none. From there,\\nSchlaifer got to the problem of how sample data should be used and how\\nmuch money should be spent getting it. Updating prior information with\\nsample data got him to Bayes’ rule because it could combine subjectively\\nassessed prior probabilities with objectively attained data. It was a\\nfundamental insight that changed his life.\\nSchlaifer did not have much mathematics. Innocent of the raging\\nphilosophical divide between objectivists and subjectivists, Schlaifer threw\\naway his books and reinvented Bayesian decision theory from scratch. As a\\nself-made statistician working in a business school, he owed nothing to the\\nstatistical establishment. And given his iconoclastic zeal, he brazenly\\nchallenged giants in the field. Like Savage, Schlaifer was combining\\nuncertainty with economics in order to make decisions. Savage thought\\nSchlaifer was “hot as a pistol, sharp as a knife, clear as a bell, quick as a\\nwhip, and as exhausting as a marathon run.”5\\nSchlaifer realized that his mathematical competence was almost nil, “of\\norder of magnitude epsilon.”6 To compensate, he worked 75 to 80 hours a\\nweek, puffed through four packs of unfiltered cigarettes a day, and traced his\\nthoughts with different colored chalk across the blackboard in his\\nsmokefilled office. Single-mindedly pursuing what he thought was relevant to\\nthe real world, he would lurch into one theory, back off, try it another way,\\nand race on to yet another. His voice boomed down the hall almost hourly\\n—“Oh, my God!” or “How could I have been so dumb?”—as he overturned\\none firmly held opinion with another. Ever curious, he demanded the\\nabsolute, best possible analyses. He realized he needed mathematical help.\\nHearing about a young closet Bayesian named Howard Raiffa at Columbia\\nUniversity, Schlaifer scouted him out and persuaded Harvard to hire him. For\\nthe next seven years Raiffa and Schlaifer collaborated closely. Raiffa went\\non to become an international negotiator who wielded enormous influence on\\neducation, business, the law, and public policy in the United States and\\nabroad. But he always regarded Schlaifer as “the great man. . . . I revered\\nhim; I was in awe of him. . . . He was so positive, so certain, so opinionated,\\nbut so smart, so smart. . . . [He was] “a man—a real man—who\\nindependently discovered Bayesianism, mocked those who didn’t agree with\\nhim, and not only theorized and philosophized but applied the approach to\\nreal problems.” Raiffa called him “the—not a but the—most important\\nperson in my intellectual development.”7\\nBoth Schlaifer and Raiffa were elite intellectuals, but Schlaifer’s style\\nwas arrogant while Raiffa was, in the words of a collaborator, “a\\nsweetheart, a very warm, open, embracing person.”8 Schlaifer was Phi Beta\\nKappa in the Ivy League; Raiffa attended City College of New York, “the\\ncollege of choice for poor and middle-income students in New York—I was\\non the poor side.”9 During the Second World War, a misplaced template for\\ngrading the air force’s arithmetic and elementary algebra test flunked Raiffa\\nand doomed the future advisor to U.S. presidents—not to a prestigious\\nresearch laboratory like the one where Schlaiffer spent the war but to three\\nrounds of basic training and to grunt assignments in cooks-and-bakers school,\\nmeteorology, and a radar blind-landing system.\\nAnti-Semitism finally determined Raiffa’s career choice. One day he\\noverheard his army sergeants saying they wanted to line up America’s Jews\\non a beach and use them for target practice. Later, real estate agents in Fort\\nLauderdale, Florida, refused to find housing for Raiffa and his wife because\\nthey were Jewish. When a friend told him that engineering and science also\\ndiscriminated against Jews, Raiffa was prepared to believe it. Then he\\nlearned that insurance actuaries were graded on objective, competitive\\nexaminations. Seeking a field where competence counted more than religion,\\nRaiffa enrolled in the University of Michigan’s actuarial program, where\\nArthur Bailey had studied.\\nTo Raiffa’s great surprise, he became a superb and “deliriously happy”\\nstudent who raced through a bachelor’s degree in mathematics, a master’s\\ndegree in statistics, and a doctorate in mathematics in six years between\\n1946 and 1952. “In the year I studied statistics, I don’t think I heard the word\\n‘Bayes.’ As a way of inference, it was nonexistent. It was all strictly\\nNeyman-Pearson, classical, objectivistic (frequency-based) statistics.”10\\nAlthough Schlaifer had embraced Bayes in one fell swoop, Raiffa inched\\ngrudgingly toward its subjectivity. But reading John von Neumann and Oskar\\nMorgenstern’s book Game Theory (1944), he instinctively assessed how\\nothers would play in order to determine how he himself should compete: “In\\nmy naiveté, without any theory or anything like that. . . . [I began] assessing\\njudgmental probability distributions. I slipped into being a subjectivist\\nwithout realizing how radically I was behaving. That was the natural thing to\\ndo. No big deal.”11\\nWhen Raiffa gave a series of seminars on Abraham Wald’s new book\\nStatistical Decision Functions, he discovered it was full of Bayesian\\ndecisionmaking rules for use in a frequentist framework. Independently of\\nTuring and Barnard, Wald had discovered sequential analysis for testing\\nammunition while working with the Statistical Research Group in the Fire\\nControl Division of the National Defense Research Committee. Though a\\nconfirmed frequentist, he sometimes solved problems in a curiously\\nroundabout manner. After inventing a Bayesian prior, he would solve the\\nBayesian version of his problem and then analyze its frequentist properties.\\nHe also said that every good decision procedure is Bayesian and confided to\\nthe statistician Hilda von Mises that he was a Bayesian but did not dare say\\nso publicly. His work would have a large impact on many mathematical\\nstatisticians and decision theorists, including Raiffa.\\nUntil Wald’s book appeared, the word “Bayesian” had referred only to\\nThomas Bayes’ controversial suggestion about equal priors, not to his\\ntheorem for solving inverse probability problems. After Wald died in a plane\\ncrash in India in 1950, the Columbia University statistics department hired\\nRaiffa to teach Wald’s course. Raiffa kept a day ahead of his students by\\nreading the textbook every night. He was moving gradually toward a\\nviewpoint opposed by almost every statistics department in the country,\\nincluding Columbia’s. Giving up “scientific” objectivity and embracing\\nsubjectivity would not be easy.\\nAt first, like Schlaifer, Raiffa taught straight frequentism, using the\\nthencanonical Neyman-Pearson theory, tests of hypotheses, confidence\\nintervals, and unbiased estimation. But by 1955, Raiffa, like Schlaifer, no\\nlonger believed these concepts were central. Columbia faculty members\\nwere auditing Raiffa’s lectures, and his transformation into a closet Bayesian\\nleft him a nervous wreck. He did not “come out” because colleagues whom\\nhe admired greatly were vociferously opposed to Bayesianism. “Look,\\nHoward, what are you trying to do?” they asked. “Are you trying to introduce\\nsquishy judgmental, psychological stuff into something which we think is\\nscience?”12\\nHe and his Columbia colleagues were working on totally different kinds of\\nproblems. Empowered by the Second World War, statisticians like Raiffa and\\nSchlaifer were increasingly interested in using statistics not just to analyze\\ndata but to make decisions. In contrast, Neyman and Pearson considered the\\nerrors associated with various strategies or hypotheses and then decided\\nwhether to accept or reject them; they could not infer what to do based on an\\nobserved sample outcome without thinking about all the potential sample\\noutcomes that could have occurred but had not. This was Jeffreys’s objection\\nto using frequentism for scientific inference. Raiffa felt the same way for\\ndifferent reasons; he wanted to make decisions tied to “real economic\\nproblems; not phony ones.”13\\nRaiffa was interested in concrete, one-of-a-kind decisions requiring quick\\njudgments about how much of a product to stock or how to price it. Like\\nSchlaifer at Harvard, he wanted to help businesses resolve uncertainties and\\nuse indirectly relevant information. As Raiffa put it, anti-Bayesians “would\\nnever—and I mean never—assign probabilities to some such statement as\\n‘the probability that p falls in the interval from .20 to .30.’”\\nBayesian subjectivists, on the other hand, actually wanted answers\\nexpressed in terms of probabilities. They did not want to merely accept or\\nreject a hypothesis. As Raiffa realized, a business owner wanted to be able\\nto say that “on the basis of my formerly held beliefs . . . and of the specific\\nsample outcomes, I now believe there is a .92 probability that  is greater\\nthan .25.”14\\nThis was verboten for frequentists, who recognized only those sample\\noutcomes that were “significant at the .05 level.” Raiffa regarded their focus\\nas “a very, very cursory description of the distribution. I wanted my students\\nto think probabilistically about [the entire distribution of p, about] where the\\nuncertain p could be, and then figure out from the decision point of view\\nwhere the correct action would be. So the whole question of a test of\\nhypotheses seemed to me to be leading students in a wrong direction.”15\\nThe chasm between the two schools of statistics crystallized for Raiffa\\nwhen Columbia professors discussed a sociology student named James\\nColeman. During his oral examination Coleman seemed “confused and fuzzy .\\n. . clearly not of Ph.D. quality.”16 But his professors were adamant that he\\nwas otherwise dazzling. Using his new Bayesian perspective, Raiffa argued\\nthat the department’s prior opinion of the candidate’s qualities was so\\npositive that a one-hour exam should not substantially alter their views. Pass\\nhim, Raiffa urged. Coleman became such an influential sociologist that he\\nappeared on both the cover of Newsweek and page one of the New York\\nTimes.\\nSo far, Raiffa regarded his transformation from a Neyman-Pearsonite to a\\nBayesian as an intellectual conversion; his emotional conversion was still to\\ncome.\\nIn a campaign to raise the intellectual standards of business schools, the\\nFord Foundation donated money to Harvard to hire a mathematical\\nstatistician in 1957. The university made Raiffa an attractive offer: joint\\nposts in its new department of statistics and in the business school. When the\\nstatistics department learned about Raiffa’s conversion to Bayesian ideas, the\\nchair, Frederick Mosteller, seemed tolerant but lukewarm, and another\\nprominent professor, William Cochran, said, “Well, you’ll grow up.”17 At the\\nbusiness school, though, Schlaifer welcomed Raiffa with open arms.\\nSchlaifer was “the most opinionated person I ever met,” Raiffa recalled.\\nAt first, he did not realize “how wonderful Schlaifer was. . . . I didn’t realize\\nthat Schlaifer was as great a man as he was. He was already focused on the\\nreal business decision problems, not on testing hypotheses. He said they\\nwere getting it wrong.” Then Raiffa corrected himself: “No, no, he didn’t say\\nthat. He said they’re getting it wrong for business decisionmaking under\\nuncertainty.”18\\nEach morning Raiffa tutored Schlaifer in calculus and linear algebra,\\nvectors, transformations, and the like. The next morning Schlaifer would\\nconjecture new theorems, and the day after that apply what he had learned to\\na concrete problem. “His mind was receptive, razor-sharp, tenacious,\\npersistent, creative,” Raiffa discovered.19 Both men were workaholics, but\\nSchlaifer worked longer hours than anyone else. As Raiffa recalled, “He was\\nreally a fabulous student. . . . He had raw mathematical abilities provided he\\ncould see how it might be put to use.”20 The two never referred to journals or\\nbooks. Everything they did together was self-generated.\\nSchlaifer did not know nearly as much statistics as Raiffa, but he was\\nmuch better read. Raiffa had not studied the great prewar theorists Jeffreys,\\nFisher, and Egon Pearson. Later, when he discovered Savage’s work, he was\\namazed at its clarity. Raiffa took the advice of his colleagues and named his\\nHarvard chair for Frank Ramsey without ever having read the young man’s\\nwork.\\nWriting articles with Schlaifer, Raiffa always produced the first draft.\\nThen Schlaifer “analyzed everything seven ways to Sunday and changed the\\ntext endlessly, putting in commas, and taking them out again,” recalled John\\nPratt, who wrote several important works with them.21 Schlaifer almost\\nrefused to let Harvard Business School Press publish one of his books\\nbecause its editors put quotation marks outside the punctuation instead of\\ninside. (Thus the battle raged over “over.” and “over”.)\\n“The unsettling part of him,” Raiffa said, “. . . was that he made so much\\nsense—as long as he stayed away from politics!”22 So Raiffa argued\\nstatistics with his collaborator but closed his ears when Schlaifer inveighed\\nagainst the income tax and advocated solving Haiti’s problems by turning all\\nthe Haitians in the United States into soldiers and sending them back home.\\nTo Schlaifer, Bayes’ rule was not just something to use, it was something\\nto believe in—fervently. A true believer, he refused to accept that there might\\nbe several ways to approach a problem. He used “sheer brutal insistence and\\nintellectual discourse by finding holes in every argument that Howard used,”\\nrecalled his student Arthur Schleifer Jr. “He would show that these\\nalternative ways led to untenable paradoxes. . . . Robert’s approach was that\\nthere was this one way to do it, you have to do it this way, and if you do it\\nany other way, I’ll show you you’re wrong.”23\\nRaiffa wanted to expose his students to both frequentist and Bayesian\\nmethods so that if some read the establishment’s point of view they would not\\nget confused. But Schlaifer regarded this as teaching falsehood. Anyway, he\\npronounced loftily, “businessmen don’t read the literature.”24\\nBy 1958 Raiffa had also converted passionately to subjectivism. It seemed\\nobvious that four businesses serving four different markets could use the\\nsame information to produce four different nonstatistical priors and four\\ndifferent conclusions. Although this still bothers some scientists and\\nstatisticians, others were content to overwhelm their initial nonstatistical\\nprior opinions with large amounts of new statistical information. Just as\\nmany Americans remember where they were when they heard about\\nKennedy’s assassination or the 9/11 attack, so many Bayesians of Raiffa’s\\ngeneration remember the exact moment when Bayes’ overarching logic\\nsuddenly hit them like an irresistible epiphany. Critics began to call Harvard\\nBusiness School “a Bayesian hothouse.”\\nBetting—assigning different probabilities to the same phenomenon—\\nbecame the tangible expression of Bayesian beliefs. “Every day there’d be a\\nhalf dozen bets around [Schlaifer’s group] about anything—elections and\\nsports. Dollar bills were changing hands all the time. It was part of the\\ningrained way of life. You really believed this stuff,” Schleifer said.25\\nSchlaifer and Raiffa were developing reputations as zealots with a cause.\\nSchlaifer sent 700 pages of his first textbook to McGraw-Hill for\\npublication as Probability and Statistics for Business Decisions: An\\nIntroduction to Managerial Economics under Uncertainty. Then he\\ndiscovered his usual host of errors and infelicities and insisted that\\nMcGraw-Hill withdraw the first printing and replace it with a second. It was\\na classic case of placing intellectual rigor above business economics, and\\nSchlaifer won. The book sold for 11.50 in 1959, and Harvard promoted its\\nformer tutor to a professorship in business administration.\\nProbability and Statistics for Business Decisions was the first textbook\\nwritten entirely and wholeheartedly from the Bayesian point of view.\\nStudents could solve inventory, marketing, and queuing problems using\\nsimple arithmetic, slide rules, or, at most, a desk calculator. The book\\nacknowledged few previous authorities. Schlaifer had come to his\\nsubjectivist position independently of Ramsey, de Finetti, and Savage. In\\nturn, Savage recognized that Schlaifer had developed his ideas “wholly\\nindependently” and was more “down to earth and less spellbound by\\ntradition.”26\\nMulling over the state of Bayes’ rule, Schlaifer and Raiffa realized that\\nBayesians, unlike frequentists, had no bookshelves of mathematical tools\\nready for use. As a result, Bayesian methods were regarded as impractically\\ncomplicated, \\nparticularly \\nby \\nbusiness \\nstudents, \\nwho \\nwere \\noften\\nmathematically unprepared. While theoreticians like Savage and Lindley\\ntried to make Bayes mathematically respectable, Raiffa and Schlaifer set out\\nin 1958 to make it fully operational and easy to use for bread-and-butter\\nproblems. Like George Box, they parodied a popular song, this one from\\nAnnie Get Your Gun, claiming that anything a frequentist could do, they could\\ndo better.\\nTo make calculations easier, they introduced decision trees, tree-flipping,\\nand conjugate priors. “I began using decision tree diagrams that depicted the\\nsequential nature of decision problems faced by business managers,” Raiffa\\nsaid. “Should I, as decision maker, act now or wait to collect further\\nmarketing information (by sampling or further engineering)? . . . I never made\\nany claim to being the inventor of the decision tree but . . . I became known\\nas Mr. Decision Tree.”27 Soon the diagrams of Bayes’ decisionmaking\\nprocess were, like many-branched trees, rooted in undergraduate business\\ncurricula. The trees are probably the best-known practical application of\\nBayes’ rule.\\nTree-flipping began as a simplification to help one of Raiffa’s graduate\\nstudents who was interested in wildcat drilling for oil. Normally, a\\nwildcatter decided whether to test a particular site before deciding to drill or\\nnot drill. To avoid some messy algebra, Raiffa flipped the order of the\\nwildcatter’s decision. He dealt with the probability that test results would be\\npositive or negative before he considered whether or not to conduct the test.\\nWorking through the diagram produced information about x’s followed by\\ny’s. Tree-flipping put the y’s first. It amounted to using Bayes’ rule because\\nthe probability of x given y and the probability of y given x are the two\\ncritical elements of its formula.\\n“So you flip trees,” Raiffa said. “We didn’t call it Bayes. The worst thing\\nyou can do is to use Bayes’ theorem. It’s too complicated. Just use common\\nsense and play around with these things, then it was pretty easy. We had\\npeople doing complicated things that could have been done by Bayes, but we\\ndidn’t do it by Bayes. We did it by tree-flipping.”28\\nRaiffa also developed a handy shortcut for updating priors and posteriors.\\nCalled conjugate prior distributions, it used the fact that in many cases the\\nshape or curve of a probability’s distribution is the same in both prior and\\nposterior. Thus, if you start with normal Gaussians, you’ll end up with\\nnormal Gaussians. Conjugate priors paid dividends with the repeated\\nupdating called for by Bayes’ method. Albert Madansky used a similar\\nconcept for his H-bomb study. The shortcut would later become unnecessary\\nwith the adoption of Monte Carlo Markov Chain methods.\\nIn a further simplification, some business Bayesians even dropped the\\nprior odds called for by Bayes’ rule. Schleifer said, “My take on it was to\\nforget the priors unless there was overwhelming prior evidence that you\\nreally know a lot about the parameter you’re interested in.”29\\nToday, when TV and radio are filled with talking heads, it is hard to\\nimagine that the use of expert opinion was terra incognita in the early 1960s.\\nNo one knew whether business executives would be willing to offer their\\nopinions for incorporation into a mathematical formula. And no one was sure\\nwhether an expert’s subjective judgment would be valid. John Pratt asked his\\nwife, Joy, whose job was promoting films in local theaters, to estimate their\\ndaily attendance. At first, her estimates fell into too narrow a range. By\\ncomparing them with actual attendance figures—hundreds of data points\\ntaken night after night at two local theaters—Joy Pratt learned to make such\\naccurate predictions that her husband became convinced that expert opinion\\ncould be useful. Bayesians objected that Pratt and Schlaifer analyzed the data\\nusing frequentist techniques. Bayesian methods—comparing different kinds\\nof movies, the length of time they played, the popularity of their stars, and so\\non—would have been too complex. The use of expert opinion for decision\\nmaking later became a major field of study.\\nIt turned out that Joy and John Pratt were right: marketing executives\\nrisked a lot of money on the basis of very little information and loved being\\nasked for their professional judgment. Accustomed to waiting until the end of\\na frequentist study to voice their opinions, they actually liked having their\\n“managerial intuition” or “feel for a situation” folded into preliminary\\nassessments.\\nRaiffa and Schlaifer began exploring such nitty-gritty questions as how to\\ninterview experts and measure their expertise. DuPont, trying to decide how\\nbig a factory to build for artificial shoe leather in 1962, was delighted to\\nassess the prior odds of the demand for its new product. Design engineers at\\nFord Motor Company were equally pleased that incorporating their opinions\\ninto Bayes’ prior let Ford use smaller opinion samples. Their work opened\\nup just about any business problem to mathematical analysis. An engineering\\nproblem might have 20 sources of uncertainty; of these, perhaps 12 could be\\nhandled by single guesses; 5 needed more testing; and 2 might be so critical\\nthat experts had to be interviewed. Bayes’ rule was solving far more\\ncomplex problems than Savage’s mental exercises about curling rabbit ears.\\nBetween 1961 and 1965 an exciting weekly seminar, generally followed\\nby drinks in Schlaifer’s office, focused on decision making under uncertainty\\n(DUU for short). The seminar explored utility analysis, portfolio analysis,\\ngroup decision processes, theory of syndicates, behavioral anomalies, and\\nways to ask about uncertainties and values. Said Raiffa, “We helped shape a\\nfield.”30 The seminar and two books Raiffa and Schlaifer cowrote during this\\nperiod spurred the Bayesian revival of the 1960s. Raiffa was later surprised\\nto realize that the most fertile period of his collaboration with Schlaifer had\\nlasted only four years.\\nRaiffa’s and Schlaifer’s classic book for advanced statisticians, Applied\\nStatistical Decision Theory, was published in 1961. Its careful, detailed\\nanalytical methods set the direction of Bayesian statistics for the next two\\ndecades. Today it sits on almost every decision analyst’s bookshelf.\\nWhen Pratt joined Raiffa and Schlaifer to write Introduction to Statistical\\nDecision Theory, he soon realized that what was easy for him to do\\nmathematically was quite difficult for Schlaifer, who could understand the\\nmathematics but not produce it himself. By the time the book was ready for\\nediting, Schlaifer and Raiffa had moved on to other interests. They received\\nso many requests for their preliminary manuscript, however, that McGraw-\\nHill published it as a typescript in 1965. Thirty years later, Pratt and Raiffa\\nfinished it, and MIT published it as an 875-page book.\\nTo introduce business school professors to mathematical methods, Raiffa\\nran an 11-month-long Ford Foundation program in 1960 and 1961. As a\\nresult, the next generation of business school deans at Harvard, Stanford,\\nNorthwestern, and elsewhere had received a heavy dose of Bayesian\\nsubjectivism for decision making, and the gospel radiated outward to schools\\nof management. Raiffa even gave his students an 84-page handout, “An\\nIntroduction to Markov Chains,” more than 30 years before their widespread\\nadoption by the statistical profession. By 2000 Bayesian methods were often\\ncentered in university business schools rather than statistics departments.\\nRaiffa and Schlaifer drifted apart after 1965. Raiffa still called himself a\\nBayesian who, “roughly speaking. . . . wish[es] to introduce intuitive\\njudgments and feelings directly into the formal analysis of a decision\\nproblem.”31 Broadening what he knew about subjective probability, game\\ntheory, and Bayes’ rule, he left Harvard’s statistics department to take a joint\\nchair in the business school and the economics department. There he pursued\\nsocietal, rather than primarily statistical, issues in medicine, law,\\nengineering, international relations, and public policy.\\nBy any measure Raiffa’s move was a success. As a pioneer in decision\\nanalysis, he was one of four organizers of the Kennedy School of\\nGovernment at Harvard; the founder and director of a joint East–West think\\ntank to reduce Cold War tensions long before perestroika; a founder of\\nHarvard Law School’s widely replicated role-playing course in negotiations;\\nand scientific adviser to McGeorge Bundy, the national security assistant\\nunder Presidents Kennedy and Johnson. Raiffa also supervised more than 90\\nPh.D. dissertations at Harvard in business and economics and wrote 11\\nbooks—no articles, only books—one of which has been in print for more\\nthan fifty years. As a Bayesian, Raiffa would cast a long shadow.\\nUltimately, however, Raiffa and Schlaifer failed in their bold attempt to\\npermeate business curricula, statistical theory, and American business life\\nwith Bayes’ rule. Schlaifer built managerial economics into a strong program\\nat the Harvard Business School, but Bayesian decision analysis faded from\\nits curriculum, and Bayes’ rule never supplanted “the old stuff” in American\\nclassrooms. Since the 1970s, when all the top business schools emphasized\\nBayesian decision theory, it has been compressed into a few weeks’ study.\\nBusiness students no longer do their own calculations; presumably they can\\nhire a consultant or buy a computer program.\\nMany theoretical statisticians also ignored Raiffa’s and Schlaifer’s\\ncontributions; they were, after all, outsiders working in a business school.\\nFrom his vantage point in Britain, Lindley was astonished that the statistical\\ncommunity paid so little attention to Schlaifer. “I was bowled over by him.\\nThe book with Raiffa is wonderful,” and Schlaifer’s 1971 book had\\ncomputer methods “in advance of their time.” Lindley considered Schlaifer\\n“one of the most original minds that I have ever met [with] extraordinarily\\nwide knowledge.”32\\nPart of their failure lay in the fact that Schlaifer remained a confirmed\\nuniversity theoretician. When confronted with a problem he could not solve,\\nhe set it aside and worked on something else, something business managers\\ncannot afford to do. Nor did he consider long-term solutions and their\\nconsequences over time; he dealt in short-term results. He did little\\nconsulting work, and his lack of experience selling complicated ideas to busy\\nexecutives limited the impact of Bayes’ rule on working business people. He\\nspent weeks exploring a marketing case about cottage cheese packaging in all\\nits abstract complexities but stripped off all the textural surroundings that\\nmost caseworkers would have brought back from a field trip to a dairy. He\\nturned his only graduate student’s thesis about all the messy glory of IBM’s\\nquality control problems into a dry theoretical paper about two-stage\\nsampling. The student’s thesis ended up piled so high with abstract issues\\nthat it was not until Schlaifer went on sabbatical that Raiffa could intervene\\nand secure the young man’s Ph.D. Schlaifer was a passionate intellectual\\nwith a deep interest in narrow topics and all the time in the world for\\ndisputation.\\nAfter Raiffa moved on to other projects, Schlaifer threw himself into\\ndesigning a new introductory course for Harvard’s first-year students in\\nmanagerial economics. Naturally, it would be based on Bayesian methods, a\\nfirst in any business school. He wrote a text and titled it Managerial\\nEconomics Reporting Control, which he nicknamed MERC. Students hated\\nit, called it Murk, and burned their copies on the front steps of Baker Library.\\nWhen a reporter for the Harvard newspaper asked for a comment, Schlaifer\\nreplied, “Well, I’d rather be among those whose books are burned than those\\nwho burn books.”\\nThen Schlaifer leaned intently forward: “Tell me. There is one thing that\\nreally interests me. This book is printed on very good, very glossy paper. It\\nmust have burned very poorly. How do you burn them?”\\n“Well, sir,” the student answered respectfully, “we burn them page by\\npage.”33\\nSchlaifer, farseeing to the last, spent the remaining years of his life trying\\nto write computer software for practitioners, even though teams of\\nmathematically sophisticated programmers were already taking over the\\nfield. In 1994, at the age of 79, Schlaifer died of lung cancer. After his death,\\nRaiffa and Pratt finished the trio’s 30-year-old opus, Introduction to\\nStatistical Decision Theory. Dedicating it to their former colleague, Pratt\\nand Raiffa hailed Schlaifer as “an original, deep, creative, indefatigable,\\npersistent, versatile, demanding, sometimes irascible scholar, who was an\\ninspiration to us both.”34\\n12.\\n \\nwho wrote the federalist?\\n \\nAlfred C. Kinsey’s explosive bestseller Sexual Behavior in the Human\\nMale was published in 1948, the same year pollsters failed to predict Harry\\nTruman’s victory over Thomas Dewey in the presidential election. With the\\npublic crying foul, fraud, and debauchery, social scientists feared for the\\nfuture of their profession. Opinion polling was one of their basic tools, so the\\nSocial Science Research Council, representing seven professional societies,\\nappointed statistician Frederick Mosteller of Harvard University to\\ninvestigate the scandals.\\nMosteller’s forthright report on Truman’s election blamed the nation’s\\npollsters for rejecting randomized sampling and for clinging to outdated\\nsampling designs that underrepresented blacks, women, and the poor—all of\\nwhom voted more heavily Democratic than the population reached by the\\npollsters.\\nIn the case of Kinsey’s research, powerful men—including John Foster\\nDulles, secretary of state under Eisenhower; Arthur Sulzberger, publisher of\\nthe New York Times; Harold W. Dodds, president of Princeton University;\\nand Henry P. Van Dusen, president of the liberal Union Theological Seminary\\n— were demanding an end to funding for research on human sexuality. But\\nMosteller underwent Kinsey’s standard interview about his sexual history\\nand emerged impressed. Kinsey’s lack of randomized sampling was\\nstatistically damning, but his work was far better than anyone else’s in the\\nfield, and the country did not have 20 statisticians who could have done\\nbetter. It was quietly arranged that when Kinsey wrote his next study, on the\\nsexuality of women, Jerome Cornfield of the National Institutes of Health\\nwould help with the statistics.\\nBoth \\nscandals \\ninvolved \\ndiscrimination \\nproblems, \\nalso \\ncalled\\nclassification problems, which struck at the heart of polling, science, social\\nscience, and statistics. Researchers tended to assign people or things to\\ncategories without being totally sure that the assignments were accurate or\\nthat the categories were well defined. Pollsters classified people as\\nRepublicans or Democrats; marketers divided consumers into users of one\\ndetergent or another; scientists classified plants in biology and skulls in\\nanthropology; and social scientists categorized individuals according to\\npersonality.\\nFinishing up with the Kinsey committee, Mosteller looked around for a\\nresearch topic involving classification issues. He had a feet-on-the-ground\\nattitude, perhaps the result of having been raised by his divorced mother,\\nwho never graduated from high school but who had insisted, over the\\nobjections of her ex-husband, that Fred get an education. Mosteller had\\nearned his bachelor’s and master’s degrees in mathematics from Carnegie\\nInstitute of Technology (now Carnegie Mellon University) in Pittsburgh and\\nenrolled in graduate statistics at Princeton University’s highly abstract\\nmathematics department. As the primary liaison between Princeton and\\nColumbia statisticians working on military research, he learned that he loved\\nworking on deadline on real-world problems. After the war, in 1946,\\nMosteller finished his Ph.D. at Princeton and, driven by his interest in health,\\neducation, and baseball, moved to Harvard. The investigations of campaign\\npolling and sexual research left him ripe for a problem of his own choosing.\\nMosteller began looking around for a large database to use for developing\\nways to discriminate between two cases. He began thinking—not about\\nBayes’ rule—but about a minor historical puzzle: The Federalist papers.\\nBetween 1787 and 1788, three founding fathers of the United States,\\nAlexander Hamilton, John Jay, and James Madison, anonymously wrote 85\\nnewspaper articles to persuade New York State voters to ratify the American\\nConstitution. Historians could attribute most of the essays, but no one agreed\\nwhether Madison or Hamilton had written 12 others.\\nMosteller had learned about the problem during a summer job he held as a\\ngraduate student in 1941. Counting the number of words in each sentence of\\nThe Federalist papers with psychologist Frederick Williams, he discovered\\n“an important empirical principle—people cannot count, at least not very\\nhigh.” He also learned that, stylistically, Hamilton and Madison were\\npractically twins, skilled in a complicated oratorical style popularized in\\n1700s England. Mosteller agreed to “leave general style as a poor bet and\\npay attention to words.”1 The job was daunting because he would need a lot\\nof single words to supply a pool of thousands of variables. When the summer\\njob ended and the Second World War intervened, Mosteller forgot about The\\nFederalist.\\nAfter the war, he decided that The Federalist might fill the bill for his\\nclassification project. By 1955 he was far enough along to rope in David L.\\nWallace, a young statistician at the University of Chicago. In his disarmingly\\ncasual way, Mosteller asked Wallace, “Why don’t you come up and spend\\nsome time in New England this summer, and work on this little project I’ve\\nsort of started?”2 The two wound up spending more time studying The\\nFederalist papers than Hamilton and Madison did writing them—“a horrible\\nthought,” Wallace said later.\\nWallace urged Mosteller to use Bayes’ rule for the project. Wallace had\\nearned a Ph.D. in mathematics from Princeton in 1953 and would become a\\nprofessor at the University of Chicago. But in 1955, his first year at Chicago,\\nSavage was teaching from his recently published book on Bayes’ rule.\\nDespite the hostility of most American statisticians, Wallace had been\\nreceptive to Bayesian ideas.\\nWallace thought The Federalist might be an application where Bayes\\ncould be very helpful. “If you stick to relatively simple problems,” he\\nexplained, “like the ones taught in elementary statistics books, you can do it\\nby Bayesian or nonBayesian methods, and the answers are not appreciably\\ndifferent.” Laplace had investigated such problems in the early 1800s and\\ndiscovered the same thing. “I’m not really a Bayesian,” Wallace said. “I\\nhaven’t done much more than The Federalist, but . . . when you have large\\nnumbers of parameters, of unknowns to deal with, the difference between\\nBayes and non-Bayes grows immense.”\\nMosteller was open to suggestion. Unlike Savage, Lindley, Raiffa, and\\nSchlaifer, he was no fervent Bayesian. He was an eclectic problem solver\\nwho liked any technique that worked. He accepted the validity of both kinds\\nof probability: probability as degrees of belief and probability as relative\\nfrequency. The problem, as he saw it, was that treating a unique event like\\n“Hamilton wrote paper No. 52” was difficult with sampling theory. Bayes’\\ndegrees of belief would be harder to specify but more widely applicable.\\nIn addition, Mosteller liked grappling with critical social issues, not\\navoiding controversy by taking refuge in textbook examples. Reality added a\\ncertain frisson to a problem. As he put it, difficulties found “in the armchair”\\nseldom resembled those in the field or scientific laboratory. In later years,\\nwhen asked why he spent so much time on The Federalist papers, Mosteller\\nwould point to “that Bayesian hothouse” in the Harvard Business School and\\nto the fact that Raiffa and Schlaifer did not deal with difficult problems or\\ncomplex data. The discrepancy between too many Bayesian theories and too\\nfew practical applications disturbed Mosteller.\\nWith Savage’s encouragement, Mosteller and Wallace started their quest to\\n“apply a 200-year-old mathematical theorem to a 175-year-old historical\\nproblem.” In the process, Mosteller would organize the largest civilian\\napplication of Bayes’ rule since Laplace studied babies and Jeffreys\\nanalyzed earthquakes. Not coincidentally, Wallace and Mosteller would\\nresort to so-called high-speed computers.\\nThey had seemingly vast amounts of data: 94,000 words definitely written\\nby Hamilton and 114,000 by Madison. Of these, they would ignore\\nsubstantive words like “war,” “executive,” and “legislature” because their\\nuse varied by essay topic. They would keep “in,” “an,” “of,” “upon,” and\\nother context-free articles, prepositions, and conjunctions. As work\\nprogressed, however, they became dissatisfied with their “rather catch-as-\\ncatch-can methods.” In a critical decision, they decided to turn their bagatelle\\nof a historical problem into a serious empirical comparison between\\nBayesian and frequentist methods of data analysis. The Federalist papers\\nwould become a way to test Bayes’ rule as a discrimination method.\\nBy 1960 Wallace was working full-time on developing a Bayesian\\nanalysis of The Federalist, working out the details for a mathematical model\\nof their data. Given so many variables, Wallace and Mosteller would be\\nmining the papers like low-grade ore, successively sifting, processing text in\\nwaves, and discarding words of no help. They would use numerical\\nprobabilities to express degrees of belief about propositions like “Hamilton\\nwrote paper No. 52” and then use Bayes’ theorem to adjust these\\nprobabilities with more evidence.\\nInitially, they assumed 50–50 odds for the authorship of each paper. Then\\nthey used the frequencies of 30 words—one at a time—to improve their first\\nprobability estimate. In a two-stage analysis, they first looked at the 57\\npapers of known authorship and then used that information to analyze the 12\\npapers of unknown parentage. As their calculations became increasingly\\ncomplicated, Wallace developed new algebraic methods for dealing with\\ndifficult integrals; his asymptotic approximations would form much of the\\nproject’s statistical meat.\\nMosteller and Wallace adopted another important simplification. In-stead\\nof using the mathematical vocabulary of probabilities, they adopted the\\neveryday language of odds. They were expert mathematicians, but they found\\nodds easier computationally and intuitively.\\nDuring the decade it took to analyze The Federalist, Mosteller kept busy\\non a number of fronts. His back-to-back investigations of the Truman election\\nand the Kinsey report had turned him into the person to call when something\\nwent wrong. Over the years Harvard would ask Mosteller to chair four\\ndepartments: social relations (as acting chair); statistics (as its founder); and,\\nin the university’s School of Public Health, first biostatistics and then health\\npolicy and management.\\nHe persuaded Harvard (“VERY SLOWLY,” he wrote a friend)3 to\\nestablish the statistics department. Joining the 1950s and 1960s push to apply\\nmathematical models to social problems, he researched game theory,\\ngambling, and learning, where Bayes’ theorem itself was not used but served\\nas a metaphor for thinking and accommodating new ideas. Eventually,\\nMosteller’s interest in those fields waned, and he moved on to other\\npastures. Education remained a major interest. As part of the government’s\\npost-Sputnik push to teach students at every level about probability,\\nMosteller wrote two textbooks about frequentism and Bayes’ rule for high\\nschool students. In 1961 he taught probability and statistics on NBC’s early-\\nmorning Continental Classroom series; his lectures were viewed by more\\nthan a million people and taken for credit by 75,000. In medical research\\nMosteller pioneered meta-analysis and strongly advocated randomized\\nclinical trials, fair tests of medical treatments, and data-based medicine. He\\nwas one of the first to conduct large-scale studies of placebo effects,\\nevaluations of many medical centers, collaborations between physicians and\\nstatisticians, and the use of large, mainframe computers.\\nHow did Mosteller juggle a massive Bayesian analysis on top of his other\\nwork? He looked tubby and rumpled, but he was a superb organizer and\\nutterly unfazed by controversy. He was genial; he engaged critics with a\\ntouch of humor, and he seemed to believe they were entitled to opinions he\\ndisagreed with. He was also patience itself and, with a “Gee, golly, shucks\\nsmile,” explained things over and over again.4 Doctrinaire only about\\ngrammar and punctuation, he once wrote a student about his paper, “I am in a\\nlonely hotel room, surrounded by whiches.”5\\nMosteller was also very hard working. He once posted a sign in his office,\\n“What have I done for statistics in the past hour?”6 For a short time he\\nrecorded what he did every 15 minutes in the day. He was also, as he himself\\npointed out, the beneficiary of a bygone era. His wife cared for everything in\\nhis life except his professional work, and several women at Harvard devoted\\ntheir careers to his success, including his longtime secretary and Cleo Youtz,\\nhis statistical assistant for more than 50 years.\\nMosteller was also said to involve in his research any student who\\nstepped within 50 feet of his office. Persi Diaconis, a professional magician\\nfor several years after he ran away from home at the age of 14, met Mosteller\\non his first day as a graduate student. Mosteller interviewed him in his low-\\nkey, friendly way: “I see you’re interested in number theory. I’m interested in\\nnumber theory. Could you help me do this problem?”7 They published the\\nresult together, and Diaconis went on to have a stellar career at Stanford\\nUniversity. It was said that Mosteller’s last collaborator on Earth was a\\nmountaintop hermit and that Mosteller climbed the peak and persuaded him\\nto cowrite a book. In truth, Mosteller collaborated only with people he\\nconsidered worth his time, including Diaconis, John Tukey, the future U.S.\\nsenator Daniel Patrick Moynihan, economist Milton Friedman, and\\nstatisticians like Savage. Finally, Mosteller credited his success to the fact\\nthat “somewhere along the road I got this new way of doing scholarly work\\nin little groups of people.”8 Colleagues and research assistants would divide\\nup an interesting topic, meet every week or two, pass memos back and forth,\\nand in four or five years publish a book. Working four or five such groups at\\na time, Mosteller wrote or cowrote 57 books, 36 reports, and more than 360\\npapers, including one with each of his children.\\nFour years into The Federalist project, he and Wallace had a\\nbreakthrough. A historian, Douglass Adair, tipped them off to a study from\\n1916 showing that Hamilton used “while” whereas Madison wrote “whilst.”\\nAdair’s news told them that screening for words in the anonymous 12 papers\\nmight pan out.\\nThe problem was that “while” and “whilst” were not used often enough to\\nidentify all 12 papers, and a printer’s typographical error or an editor’s\\nrevision could have tainted the evidence. Single words here and there would\\nnot suffice. Wallace and Mosteller would have to accumulate a large number\\nof marker words like “while” and “whilst” and determine their frequency in\\neach and every Federalist paper.\\nMosteller started The Federalist project armed with a slide rule, a Royal\\nmanual typewriter, an electric 10-key adding machine, and a 10-bank electric\\nMonroe calculator that multiplied and divided automatically. He greatly\\nmissed a device he had enjoyed using at MIT: an overhead projector. He and\\nWallace soon realized they would have to use computers. Harvard had no\\ncomputer facilities of its own and relied on a cooperative arrangement with\\nMIT. Mosteller and Wallace wound up using a substantial chunk of Harvard’s\\nallocation. Today, a desktop computer would be faster. Also slowing them\\ndown was the fact that Fortran was only two years old, awkward, and hard to\\nprogram for words. They were “straddling the introduction of the computer\\nfor linguistic counts and the old hand-counting methods, with the\\ndisadvantages of both.”\\nSubstituting student brawn for computer power, Mosteller organized an\\narmy of 100 helpers—80 Harvard students plus 20 others. For several years,\\nhis soldiers punched cards for the supposedly high-speed computer.\\nProgramming proceeded so slowly that Youtz speeded up the search for\\nmarker words by organizing a makeshift concordance by hand. Threading\\nelectric typewriters with rolls of adding machine tape, students transcribed\\none word to a line, cut the tape into strips with one word per strip, sorted\\nthem alphabetically, and counted the strips. Once someone, forever unnamed,\\nexhaled deeply and blew a cloud of statistical confetti. Within a few days,\\nhowever, Youtz’s typists discovered that Hamilton used “upon” twice per\\npaper while Madison seldom used it at all.\\nSoon thereafter, students punching computer cards found a fourth marker\\nword, “enough,” also used by Hamilton but never by Madison. By now,\\nMosteller had four words pointing to Madison as the author of the disputed\\npapers. But here again, by editing one another’s papers, Madison and\\nHamilton could have melded their styles. As Mosteller and Wallace\\nconcluded, “We are not faced with a black-or-white situation, and we are not\\ngoing to provide an absolutely conclusive settlement. . . . Strong confidence\\nin conclusions is the most an investigation can be expected to offer.” They\\nneeded to extend their evidence and measure its strength.\\nVenturing beyond the simplest Bayesian applications, they found\\nthemselves knee-deep “in a welter of makeshifts and approximations.”\\nBayesian methods for data analysis were in their infancy, so they had to\\ndevelop new theory, computer programs, and simple techniques, like those\\nfrequentists had developed before 1935. Discarding whatever did not work,\\nthey wound up tackling 25 difficult technical problems and publishing four\\nmeaty, parallel studies comparing Bayes, frequentism, and two simplified\\nBayesian approaches. The calculations became so complicated that they\\nchecked their work by hand, largely on slide rules. “Upon” was their single\\nbest discriminator by a factor of four. Other good makers were “whilst,”\\n“there,” and “on.” “Even a motherly eye,” Mosteller wrote, could see\\ndisparities between “may” and “his.”\\nTheir biggest surprise was that prior distributions—the bête noir of\\nBayes’ rule—were not of major importance. “This was awesome,”\\nMosteller said. “We went in thinking that everything depended on what sort\\nof prior information you used. Our finding says that statisticians should\\nremove some attention from the choice of prior information and pay more\\nattention to their choice of models for their data.”9\\nIn the end, they included prior odds only because Bayes’ theorem called\\nfor them, and they arbitrarily assigned equal odds to Madison and Hamilton.\\nThe prior odds turned out to be so unimportant that Mosteller and Wallace\\ncould have let their readers name them. In a timely analogy, Mosteller noted\\nthat a single measurement by an astronaut on the moon would be enough to\\noverwhelm any expert’s prior opinion about the depth of the dust on the lunar\\nsurface. So why include the prior at all? Because with controversial or\\nscanty data, enormous amounts of observational material might be needed to\\ndecide the issue.\\nWhen Mosteller and Wallace published their report in 1964 they\\nannounced happily that “we tracked the problems of Bayesian analysis to\\ntheir lair and solved the problem of the disputed Federalist papers.” The\\nodds were “satisfyingly fat” that Madison wrote all 12 of them. Their\\nweakest case was No. 55, where the odds were 240 to 1 in Madison’s favor.\\nTheir publication was the fourth about Bayes’ rule to appear in a three-\\nyear period. It followed works by Jeffreys, Savage, and Raiffa and Schlaifer.\\nOf all these works, only Mosteller and Wallace’s had dared treat real issues\\nwith Bayesian statistics and modern computers. Mosteller had thought about\\nThe Federalist papers for 23 years and worked on them for ten. It would\\nlong remain the largest problem publicly attacked by Bayesian methods.\\nThe work is still admired as a profound analysis of a difficult problem.\\nReviewers used words like “ideal,” “impressive,” “impeccable,” and\\n“Herculean.” As late as 1990 it was considered the greatest single Bayesian\\ncase study.\\nDespite the razzle-dazzle, no one followed it up. No one—not even\\nMosteller and Wallace—tried to confirm its results by reanalyzing the\\nmaterial using nonBayesian methods. Who else could organize committees of\\ncollaborators and armies of students to empower a 1960s computer to solve\\nlarge and complex problems?\\nAs for Mosteller himself, what was his reaction? Satisfaction, of course.\\nBut also the feeling that, as a friend said, “Hey, here’s a good application, a\\nnew technique, let’s try it, and then find others too.” A number of his books\\ndescribed Bayesian techniques, and to this day Diaconis regards Mosteller\\nas a committed Bayesian who tried hard to get social scientists to accept\\nBayesian methods. Yet Mosteller never again devoted an entire project to\\nBayes. While his famous study of poverty in collaboration with Senator\\nMoynihan influenced public policy, it did not make major use of Bayes’ rule.\\nWhen a student won a prize for a Bayesian Ph.D. thesis, Mosteller wrote a\\ncongratulatory note: “I think Bayesian methods are about to take off. But then\\nI’ve been saying that for twenty-five years.”10\\n13.\\n \\nthe cold warrior\\n \\nThe Federalist project impressed the still small world of professional\\nstatisticians, but John Tukey, a star from the world of Cold War spying,\\nwould give Bayes’ rule the opportunity to demonstrate its prowess before 20\\nmillion American television viewers. But would the statistical community\\nlearn from Tukey’s example that Bayes had come of age? That was the\\nquestion.\\nBayes’ big chance at fame commenced in 1960 with the race between\\nSenator Kennedy and Vice President Richard M. Nixon to succeed\\nEisenhower as president. The election was far too close to call, but the\\nnation’s three major television networks competed fiercely to be the first to\\ndeclare the victor. Winning the race would translate into prestige and\\nadvertising dollars. For the National Broadcasting Corporation (NBC), there\\nwas a bonus: the opportunity to show off the latest computers made by its\\ncorporate owner, Radio Corporation of America (RCA).\\nNBC’s Huntley–Brinkley Report, the nation’s top-rated TV news program,\\nreached 20 million viewers each weeknight. Co-anchors Chet Huntley,\\nbroadcasting from New York, and David Brinkley, from Washington, were\\ncelebrities; more people could recognize them than Cary Grant or James\\nStewart. NBC’s fast-paced format and informal nightly sign-off—“Good\\nnight, Chet,” “Good night, David”—transformed TV news.\\nDespite the program’s popularity, memories of the polling industry’s\\nspectacularly poor performances in the 1936 and 1948 elections as well as\\nthe extraordinarily close Nixon–Kennedy race made network executives\\nnervous. In preparation for Election Day, NBC went looking for someone to\\nhelp it predict the winner. In the first of a series of surprises, the network\\napproached a Princeton University professor, John W. Tukey.\\nToday Tukey is best known for the terms “bit” and “software,” and few\\noutside statistics and engineering recognize his name. But he was a man of\\nstaggering accomplishments in the cloak-and-dagger world of military\\nresearch, especially in code breaking and high-tech weaponry. He worked\\ntwo jobs 30 miles apart: at Princeton University, where he was a professor\\nof statistics, and at AT&T’s Bell Laboratories, then widely considered the\\nfinest industrial research laboratory in the world. From these vantage points,\\nhe advised five successive U.S. presidents, the National Security Agency,\\nand the Central Intelligence Agency.\\nTo appreciate the audacity of NBC’s job offer to Tukey, one needs to\\nunderstand how deeply he was embedded in Cold War secrets. He had done\\nresearch on topology in the late 1930s and military analysis in the 1940s. As\\na young man during the Second World War, Tukey worked in Princeton with\\nthe Operations Research Group that computed how a B-29 bomber speeding\\nover Europe should aim its machine-gun fire. With pencil and paper during\\nthe Cold War, he broad-brushed the aerodynamics, trajectory, and warhead\\nfor the Nike, the first antiaircraft surface-to-air missile system. He also\\nhelped persuade Eisenhower to build the U-2, the spy plane that flew from\\n1956 until 1960, the year a U-2 pilot Francis Gary Powers was shot down\\nover the USSR.\\nWhen NBC News approached Tukey in 1960, he had been a member of the\\nCIA’s Science and Technology Advisory Panel and the National Security\\nAgency’s Science Advisory Board for eight years. His most famous advisory\\nrole had occurred the year before, when, as a delegate to the US–USSR\\nConference on the Discontinuance of Nuclear Weapon Tests, he surprised the\\nSoviet delegation by showing that seismogram data could distinguish\\nunderground nuclear explosions from earthquakes. Once both sides knew\\nthey could police each other’s compliance, they signed the Partial Test Ban\\nTreaty in 1963 to ban nuclear tests in the atmosphere, space, and sea.\\nTukey also helped establish a super-secret cryptography think tank at\\nPrinceton University. The communications research division of the Institute\\nof Defense Analyses (IDA) moved into Von Neumann Hall, a new campus\\nbuilding surrounded by an eight-foot-high brick wall. IDA, which had “the\\nmost intimate ties” to the National Security Agency, was created to solve\\nadvanced cryptographic problems.1 Although the position did not appear on\\nhis curriculum vitae, Tukey served on IDA’s board of trustees for decades.\\nStudent protests against secret research in universities forced IDA off\\ncampus in 1970, despite Tukey’s personal appeal to Princeton’s president,\\nRobert F. Goheen.\\nMany university faculty did classified work as part of their regular duties\\nduring the 1950s and 1960s. John Pratt and Stephen Fienberg, for example,\\nwere cleared for such work at the University of Chicago. Said Fienberg,\\n“When I joined the faculty in the Department of Statistics in 1968, it had a\\ndual contract with the Navy office of research. One part supported basic\\nstatistical research, and the other was for statistical consulting. We had a safe\\nin the basement where they kept the classified consulting work, although I do\\nnot know which faculty had been working on it.”2\\nTukey also worked closely with members of Princeton’s physics\\ndepartment, which was “highly involved in the design of the atomic and later\\nhydrogen bombs.”3 After the United States dropped atomic bombs on Japan\\nin 1945, the director of the Manhattan Project, Gen. Leslie R. Groves, asked\\nthe Princeton physics chair Henry Smyth to write the official explanation of\\nthe bomb, Atomic Energy for Military Purposes. In 1951 Princeton launched\\na secret undertaking, Project Matterhorn, to design thermonuclear weapons at\\nits nearby Forrestal Research Center. Tukey evaluated Edward Teller’s and\\nStanislaw Ulam’s design for the first H-bomb early that year. According to\\nhis curriculum vitae, Tukey served Forrestal Research Center as “supervisor,\\nMilitary Systems Analyst” from 1951 until 1956.4 Physics professor John A.\\nWheeler, who headed the weapons program, stated, “I believe that the whole\\ncountry—scientifically, industrially, financially—is better off because of him\\nand bears evidence of his influence.”5\\nIn addition to his military research at Princeton, Tukey taught classes and\\nsupervised more than 50 graduate students. In appearance he could be “a\\nbouncy and beefy extrovert” and “sort of cherubic looking with a pleasant\\nmanner.” But his lecture style was oblique at best. Invited to speak at\\nImperial College in London in 1977, Tukey looked like a great bear of a man\\nin old baggy pants. Sitting in a cross-legged Buddha pose on the podium, he\\nbegan his lecture by asking slowly and deliberately, “Comments, queries,\\nsuggestions?”6 During the long wait that ensued, he ate prunes—12 of them,\\none by one—until someone in the audience finally asked if he could explain\\nsomething or other. Only then did Tukey begin speaking. When a graduate\\nstudent asked one January for an appointment to discuss his Ph.D. thesis,\\nTukey checked his diary and said he was going to a meeting in two months\\nand if the student drove him there they could talk about it in the car.\\nTukey also advised the federal government on a wide range of civilian\\nproblems: air quality, chemical pollution, ozone layer depletion, acid rain,\\ncensus methodology, and educational testing.\\nHow did he manage all this? Stories are legion about Tukey sitting in the\\nback row at a seminar, dozing, reading mail, scanning newspapers, or editing\\narticles, but then rising at the end of the talk to critique it. Tukey drafted\\narticles in pencil while listening to baroque brass recordings, topped the\\narticle with the words “By ____ and John W. Tukey,” gave the manuscript to\\none of his two longtime secretaries, and then searched for a collaborator to\\nfinish the piece. He put his name to about 800 publications and worked with\\nmore than 105 coauthors, including Jerome Cornfield at NIH, but most\\nfrequently with his friend Fred Mosteller at Harvard.\\nAs a result of Tukey’s heavy military and teaching workloads, his future\\nfather-in-law fully expected him to whip out pad and pencil while waiting at\\nthe altar to be married. His bride, Elizabeth R. Rapp, was personnel director\\nof the three-year-old Educational Testing Service. Later, she confided that\\n“as the wife of [a] dedicated workaholic, I understand the selfless love and\\ndevotion, accommodation and deprivation required to ‘keep them on the\\nroad.’” After Elizabeth’s death in 1998, Tukey said, “One is so much less\\nthan two.”7\\nAccording to Elizabeth, Tukey organized and simplified his personal life\\nlike “a New Englander through and through.”8 His conversation was quiet\\nand measured and excluded personal comments and idle chatter. His nephew\\nFrank R. Anscombe contended that Tukey had few wants, although they\\nincluded a house near the sea, a convertible, a small catamaran, classical\\nmusic recordings, and mince or apple pie. Tukey traveled with his personal\\ntable tennis paddle; collected some 14,000 mystery, sci-fi, and adventure\\npaperbacks; lunched on fistfuls of cheese and six glasses of skim milk; and\\ndrove a 1936 wood-paneled station wagon until the passenger door fell off\\nand his papers flew onto Nassau Street in Princeton. For 40 years he wore\\nthe same style of black polo shirt, so wrinkled that students sometimes\\nmistook him for a janitor. But he always seemed able to squeeze in one more\\nproject, provided it was sufficiently intriguing.\\nSo how, given Tukey’s eminence and his time commitments, could NBC\\nconvince him that the Huntley–Brinkley news program warranted his\\nattention? First, the reputation of opinion surveys, the mainstay of social\\nscience, was abysmal. Although sampling forms the foundation of statistics,\\ncommercial pollsters were painfully slow to adopt probabilistic random\\nsampling. Serving on the Kinsey Report study committee with Mosteller,\\nTukey said he would prefer a random sample of three to a Kinsey sample of\\n300; Kinsey’s wife said she wanted to poison him. If Tukey aimed to\\nimprove statistical practices in the polling industry, NBC News was a high-\\nprofile place to start.\\nSecond, NBC’s RCA computers may have been a draw. If Tukey accepted\\nNBC’s offer, he would not need an army of students to snip pieces of adding\\nmachine paper. RCA was a major military contractor as well as a giant in\\ncommunications; it manufactured highly regarded mainframe computers for\\nthe military and big business. During the 1940s the company’s large research\\nlaboratory had designed and built the Selectron memory tube for early\\ncomputers, including von Neumann’s Johnniac.\\nThe opportunity to use RCA’s computers to analyze election data must\\nhave been tempting. Tukey had foreseen the intimate connection between\\ncomputers and statistics years earlier. When von Neumann designed an\\nelectronic computer for the Institute for Advanced Studies at Princeton in late\\n1945, Tukey was the only Princeton University representative on the\\ncommittee and helped design the computer’s architecture and electronic\\nadding circuit. Still, Tukey’s “most striking relationship with the computer\\nwas that he didn’t use it”; his hardware consisted of pencil and paper.9\\nPolling reform and powerful computers, however, may have paled in\\nimportance next to the allure of NBC’s vast amounts of voting data. As an\\nundergraduate at Brown University, Tukey had majored in chemistry with\\ndoses of physics and geology, and his Ph.D. from Princeton, earned in 1939,\\nwas in topology, among the purest branches of abstract mathematics. Military\\nresearch during the Second World War turned him into a “data analyst”\\ncommitted to fighting the “mental rigidity” and “ossifications” of pure\\nmathematics and abstract statistics and to bridging the gap between\\nmathematics and science.10 The war moved him far beyond the statistician’s\\nearly role as a passive observer.\\nAfter the war Tukey decided he wanted to drive “the rocky road of real\\nproblems in preference to the smooth road of unreal assumptions, arbitrary\\ncriteria, and abstract results without real attachments.”11 To do so, he\\naccepted joint positions a half hour apart at Princeton University and Bell\\nLabs. Later, whenever he was offered professorships at other universities he\\nwould ask, “Where could I ever find another Bell Labs?”12 Like Mosteller,\\nhe preferred exploring reality, and NBC News had plenty of that.\\nBut of all the enticements NBC could offer—restoring polling’s reputation,\\nfast computers, and real data—the most important must have been the thrill of\\nthe chase. To beat other networks to the draw, he would have to work at top\\nspeed under international scrutiny to make sense of vast amounts of\\nincomplete, uncertain information. It would be, as he put it later, “the best\\neducation in real-time statistics that anybody could have.”13 So the military\\nconsultant to presidents joined NBC’s Huntley–Brinkley Report.\\nTukey’s first evening on the job, November 8, 1960, started smoothly. The\\nrace between Kennedy and Nixon was the tightest since 1916, and Kennedy\\nwould win by 120,000 votes out of 70 million cast. By 2:30 a.m., though,\\nTukey and his colleagues were ready to call him the winner. The pressure\\nwas too much for NBC. Network executives hustled the statisticians into a\\nroom without telephones, locked them in and refused to let them out until 8\\na.m. Tukey and his team twiddled their thumbs all night, unable to release\\ntheir results until morning, when it was clear Kennedy had won. Still, Tukey\\nhad prevented NBC from mistakenly declaring Nixon the winner. Relieved\\nand impressed, the network asked him to assemble a team for the\\ncongressional election in 1962. He would work for NBC News for 18 years.\\nTukey’s handpicked group eventually included ENIAC coinventor John\\nMauchly; Cornfield of NIH; Richard F. Link, Tukey’s first graduate student\\nand pollster Louis Harris’s chief statistician; Yale psychology professor\\nRobert Abelson; and David Brillinger, later a professor of statistics at\\nBerkeley. When David Wallace finished Mosteller’s analysis of The\\nFederalist papers, he too joined the group.\\nWallace arrived expecting a vacation from Bayes’ rule because Tukey was\\nthought to look down on it. Tukey is not known to have ever published\\nanything using Bayes’ rule, and in an often-quoted remark, he said, “There\\nare many classes of problems where Bayesian analyses are reasonable,\\nmainly classes with which I have little acquaintance.”14 Among those were\\nbusiness decision making, the bailiwick of Howard Raiffa and Robert\\nSchlaifer. The lack of methodology for quantifying Bayes’ initial prior\\nespecially irritated Tukey. Publicly, he was a data analyst who was anti-\\nBayesian and even antiprobability.\\nThus when Wallace joined Tukey’s NBC team in 1964 he was surprised to\\nfind Bayes’ rule securely ensconced in the computing program: “I\\nimmediately thought, this is all very Bayesian. Also, I did a lot of the coding\\nfor a lot of the models over the next decade and a half, and, as far as I’m\\nconcerned, I was using Bayesian things.”15 Those who agree include\\nBrillinger, who later became Tukey’s biographer and the editor of his papers,\\nPratt from Harvard, and Fienberg from Carnegie Mellon. Said Fienberg,\\nNBC polling used “a form of empirical Bayes, where the past results were\\nused to construct the prior distribution.”16\\nNevertheless, in almost two decades of election forecasting Tukey never\\nadmitted to using Bayes’ rule. Why would someone who publicly disdained\\nBayes’ rule and seemed to look down on it use it for something as important\\nas announcing the next president of the United States?\\nMany colleagues stress that, despite appearances, Tukey was “a very\\nprivate man.” His nephew called him an “elliptical and enigmatic Delphic\\nOracle in a black polo shirt.” Wallace agreed: “Tukey could be close-\\nmouthed. . . . He was a man of extreme power and brilliance and in some\\nways enigmatic about himself. . . . He didn’t always let everyone know what\\nhis left hand was doing. He’d deny anything Bayesian in the NBC polling.”17\\nHis dominating personality could be intimidating. While George Box was\\ngiving a seminar at Princeton University, Tukey thought he knew what Box\\nwas going to say and kept chiming in with his own commentary. Box finally\\nasked for a show of hands. Who wanted Tukey to continue interrupting, and\\nwho wanted him to stop? When Box won, Tukey looked surprised. “In some\\nways, he was a very clever eight-year-old,” Box recalled. “He didn’t seem\\nto understand very much about interpersonal relations.” Some colleagues\\npointed to his early years as a child prodigy home-schooled by his mother\\nand said that his wife, Elizabeth, helped “warm him up.” Edgar Gilbert from\\nBell Labs concluded, “He was a very likeable personality but he was hard to\\nunderstand.” Peter McCullagh, an Irish statistician at the University of\\nChicago, called him a “constructive scientific anarchist, . . . a cultural\\nphenomenon, revered by some, feared by others, understood by few.” Part of\\nthe problem, Pratt said, was that “Tukey could argue on both sides of\\nanything, and you didn’t know where he stood.”18\\nAdding to the confusion was Tukey’s acceptance of one of Savage’s most\\ncontroversial tenets: subjectivity. Tukey called objectivity “an heirloom” and\\n“a fallacy. . . . Economists are not expected to give identical advice in\\ncongressional committees. Engineers are not expected to design identical\\nbridges—or aircraft. Why should statisticians be expected to reach identical\\nresults from examinations of the same set of data?”19\\nIf Tukey could be hard on Bayes’ rule, he was even tougher on Fisher.\\nTukey believed that Fisher’s frequency-based ideas dated from “the world of\\ninfancy . . . the childhood of experimental statistics, a childhood spent in the\\nschool of agronomy. . . . Almost invariably, when closely inspected, data are\\nfound to violate [the] standard assumptions” required by frequency. “Far\\nbetter an approximate answer to the right question, which is often vague,\\nthan an exact answer to the wrong question, which can always be made\\nprecise.” Tukey publicized how even slight deviations from the normal\\nmodel could muddle the methods of Fisher, Neyman, and Egon Pearson. He\\nparticularly scorned frequentist “techniques for assessing significance and\\nasserting confidence. . . . By and large, the great innovations in [frequency-\\nbased] statistics have not had correspondingly great effects upon data\\nanalysis.” Hard words indeed.20\\nSo where did Tukey stand? Anti-Bayes and anti-frequentism? Friends\\ncontend that, like Mosteller, he opposed any monolithic philosophy.\\nBrillinger thought Tukey was annoyed, “not with Bayesian arguments per se; .\\n. . [but] with some of the Bayesians.” Tukey said, “Discarding Bayesian\\ntechniques would be a real mistake; trying to use them everywhere, however,\\nwould in my judgment, be a considerably greater mistake.” The issue was\\nknowing when and where. He often complained about “a natural, but\\ndangerous desire for a unified approach,” explaining that “the greatest\\ndanger I see from Bayesian analysis stems from the belief that everything that\\nis important can be stuffed into a single quantitative framework.”21\\nTukey used almost the same language about Fisher’s fiducial alternative to\\nBayes. While courting his wife, Tukey confided that his mission in life was\\nto emulate Fisher by developing methods for analyzing experimental science.\\nBut after writing 64 pages in a search for the logical foundations of Fisher’s\\nfiducial probability, Tukey decided that “the belief in a unified structure for\\ninference is a dangerous form of hubris.” When Tukey visited Fisher at his\\nhome in England and began asking questions about his methods, Fisher\\nstalked angrily away, leaving the Tukeys to find their way out of his house\\nalone. In another version of the story, Fisher threw Tukey out of his office\\nafter telling the young man that his paper was a “long screed” and that he\\nwould understand probability statements only “if you could ever get your\\nbullheaded mind to stop and think.” In both stories, an unstoppable force met\\nan immovable object.22\\nFor Tukey the only thing that mattered was the data—shorn of\\ncomputerization, mathematization, probability, and theory. He named his\\napproach exploratory data analysis (EDA). Like Bayesians, many of its\\nproponents were ridiculed and had trouble finding jobs.\\nSo how did Tukey resolve his paradoxical use of Bayes’ rule without\\nadmitting it? He called it something else. While Brillinger and Wallace\\ncalled their NBC polling Bayesian, Tukey said it was “borrowing\\nstrength.”23\\n“Anything he did, he’d call something else,” Wallace said, even if it\\nalready had a straightforward, well-established name. New names drew\\nattention to ideas, and a colleague counted 50 terms coined by Tukey. Among\\nthose that stuck are linear programming, ANOVA, and data analysis. In one\\narticle, Mosteller had difficulty talking him out of using musical notation—\\nsharps, flats, and naturals. Another colleague threatened to call him J. W.\\nCutie for terms such as “saphe cracking,” “quefrency,” and “alanysis.” As\\nWallace said, “It was not always the best way to win friends and influence\\npeople. . . . But when I talked to Tukey, I essentially tried to use his\\nterminology.”\\nStill, Bayes’ rule by any other name is Bayes’ rule. And both Tukey and\\nMosteller were willing to use whatever statistical tool was needed, even if it\\nwas Bayesian. Beginning work long before Election Day, Wallace built a\\nbase of initial information by combining data from preelection polls;\\nnonstatistical, expert opinion from political scientists; and the voting\\nhistories of precincts, counties, cities, and states. Preelection opinion polls\\ndid not always ask the right questions, so they often failed to elicit all the\\ninformation needed. The work of sampling people, surveying them, analyzing\\ntheir answers, and summarizing the results was complex.\\nOn election night, as partial returns from counties and complete returns\\nfrom selected precincts flowed in, Tukey and his colleagues watched for\\nswings and deviations from past voting behavior and from political\\nscientists’ opinions. Then they modified their initial odds with the new\\ninformation.\\nAs Wallace relived the moment, he said, “Say we’re working at a county\\nlevel with data coming in. Suppose you had no returns from one county. A\\nstrict nonBayesian would say, ‘I can’t tell you anything there,’ but a slightly\\nBayesian person would say, ‘I don’t know what’s happening in county A, but\\ncounty B is very similar and it’s showing a swing 5% toward Republicans.’\\nYou might say that county A might be going the same way, but not give it\\ngreat weight, because you do have to come up with a number. . . . ‘Okay,’\\nsays Tukey, ‘go down low, take a group of counties that are similar, weight\\nthe data you get in these counties, give zero weight to non-data counties, and\\nupgrade, update it all the time.’” Like Schlaifer at the Harvard Business\\nSchool, Tukey had concluded that since he had to make a decision with\\ninadequate information, whatever knowledge existed was better than nothing.\\nWallace continued: “You take information where you have it and compute\\nit with a lot of error bounds on it into places where you don’t have data. . . .\\nYou first of all work at rural area counties, then urban areas, north, south\\nareas, or whatever, do it separately and play this game of upward regions\\nand across states. It’s ‘borrowing strength,’ but I’d say it’s Bayesian. . . .\\nYou’re using historical data, from previous elections, to show variability\\nbetween counties and that’s the source of your priors, so it’s very Bayesian,\\nwith a hierarchical model and historically based prior variances.”\\nDespite weeks of planning and rehearsals, election nights did not always\\nproceed as hoped. Studio 8H in Rockefeller Center, where Huntley sat, was\\nsacrosanct and off-limits to anyone without a special ID badge. But when\\nBrillinger saw that the ID tag resembled the sugar packets in NBC’s canteen,\\nhe paperclipped a packet to his shirt and wandered happily around. For the\\nelection of 1964 between Lyndon Johnson and Barry Goldwater, NBC show-\\ncased seven of its mainframe computers on Studio 8H’s stage floor: several\\nof RCA’s early 301 models and two spanking new 3301’s. All evening\\nviewers could see their imposing large black boxes on screen behind\\nHuntley. Unfortunately, the computers did not work that night, either because\\ntheir operating system was unfinished or because the heat of the recording\\nstudio’s lights fried them. So there they sat all night long, like so many limp\\nrags, Link thought, impressive but useless. With voting results pouring in\\nfrom around the country, Tukey’s team punched furiously away at old-\\nfashioned hand calculators and adding machines. Fortunately, the work was\\nsimple that night because LBJ’s victory was a foregone conclusion, and\\nJohnson won with a record 61% of the popular vote.\\nIn another election, the team called the winners early for California and\\nNew York. Then, late-arriving figures came in contradicting their\\nannouncement. Two tense hours passed before voting patterns moved back in\\nline with their predictions. Another extremely tight election kept them at\\nwork from Tuesday afternoon straight through to Thursday afternoon. Tukey\\nand Wallace realized they needed to improve their technique.\\n“It turned out that the problem of projecting turnout was more difficult than\\nthat of projecting candidate percentage,” Wallace discovered. “The quality of\\ndata you get is dubious, and you have clear biases of reporting coming in\\nfrom one part of the county, and if you’re lucky, they might do it randomly but\\nmachine votes come in faster than non-machine votes. Sometimes there’s\\nchicanery as well. The turnout is very hard to predict and that has a startling\\neffect, so Bayes was not a total serving. I had a conversation with a student\\nwho was consulting with one of the other networks and he said to me, ‘This\\nis just so wonderful because it’s the first place in statistics where all your\\nassumptions are totally valid.’ I was appalled. . . . It’s a highly biased\\nsample. And you’re going to get yourself into serious trouble if you don’t\\nrealize that.”24\\nTukey continued to work for NBC through the election in 1980. After that,\\nNBC switched to exit polls based on interviews of voters emerging from\\ntheir precincts. Exit polls were cheaper, more photogenic, personal, and\\nchatty. They were the polar opposite of Tukey’s secret, highly complex,\\nmathematized approach.\\nThen came the biggest surprise of all. Like Churchill’s muzzle on postwar\\nBletchley Park, Tukey refused to let any of his colleagues write or even give\\ntalks about their polling methods. He never wrote about them either. He said\\nthey were proprietary to RCA.\\nWhy the secrecy? Why did Tukey scorn Bayes’ rule in public but use it\\nprivately for two decades? Toward the end of his life he conceded that\\n“probably the best excuse for Bayesian analysis is the need . . . to combine\\ninformation from other bodies of data, the general views of experts, etc., with\\nthe information provided by the data before us.”25 He even defended\\nSavage’s subjectivist gospel, that people could look at the same information\\nyet reach different conclusions. Reject “the fetish of objectivity,” Tukey\\ndeclared.26 He also used a Bayesian argument when testifying before\\nCongress that the U.S. Census should adjust for its undercounts of minorities\\nin some areas by incorporating information from other, similar regions. As of\\n2010, the Census Bureau had not done so.\\nSo why didn’t—or couldn’t—Tukey use the B-word? As Brillinger noted,\\n“Bayes is an inflammatory word.”27 Certainly, Tukey’s term “borrowing\\nstrength” allowed him to avoid it. Perhaps sidestepping it carved out a\\nneutral workspace. Perhaps he felt the need to put his own stamp on another\\nperson’s work. Or perhaps there was another reason. Given Tukey’s\\npersonality, it’s difficult to know. Halfway through his stint with NBC, RCA\\ngave up trying to compete with IBM and sold off its computer division to\\nSperry Rand. After that, why would RCA care whether Tukey’s system went\\npublic? Could RCA’s military sponsors have classified Tukey’s methods, and\\nwas he using Bayes’ rule for his classified cryptographic research?\\nMany details of Tukey’s national security career remain “murky,\\ndeliberately so on his part,” his nephew Anscombe concluded.28 But as\\nWallace says, “If you go to the secret coding agencies, you’d find that Bayes\\nhad a larger history. I’m not in a position to speak of that but I. J. Good is the\\nprincipal contributor to the Bayesian group and he was taking that\\nposition.”29 Good was Alan Turing’s cryptographic assistant during the\\nSecond World War. So did Tukey use Bayes’ rule for decoding for the\\nNational Security Agency? And could he have been distancing himself from\\nBayesian methods in order to protect work there?\\nThe ties between Tukey, Bayes, and top-secret decoding are many and\\nclose. Bayes’ rule is a natural for decoders who have some initial guesses\\nand must minimize the time or cost to reach a solution; it has been widely\\nused for decoding ever since Bletchley Park. Tukey’s ties to American\\ncryptography were particularly tight. According to William O. Baker, then\\nhead of Bell Labs, Tukey was part of the force that helped decrypt Germany’s\\nEnigma system during the Second World War and Soviet codes during the\\nCold War. Tukey served on NSA’s Science Advisory Board, which was\\ndevoted to cryptography. It was a ten-member panel of scientists from\\nuniversities, corporate research laboratories, and think tanks; they met twice\\nyearly at Fort Meade, Maryland, to discuss the application of science and\\ntechnology to code breaking, cryptography, and eavesdropping. Baker,\\nTukey’s close friend, was probably the committee’s most important member.\\nBaker chaired a long study of America’s coding and decoding resources for\\nthe NSA and called for a Manhattan Project–like effort to focus, not on\\npublishable and freely available research, but on top-secret studies. Whether\\nTukey actually did hands-on cryptography is not known, but as a professional\\nvisiting-committee consultant, he was certainly aware of all the statistical\\nmethods being used.\\nTukey’s relationship with Good, one of the leading Bayesians and\\ncryptographers of the 1950s and 1960s, is also suggestive. Tukey visited\\nGood in Britain and invited him to lecture at Bell Labs in October 1955. The\\nday after Good’s talk he was surprised to find that Tukey, lying on the floor to\\nrelax, had obviously understood it all. Tukey was also sympathetic enough\\nwith Good’s Bayesian methods to introduce him to Cornfield at NIH and\\nsuggest that Good might help with statistical methods there; Cornfield\\nbecame a prominent Bayesian.\\nClaude Shannon was also in the audience during Good’s talk. Shannon had\\nused Bayes’ rule at Bell Labs for his pathbreaking cryptographic and\\ncommunications studies during the Second World War. Tukey was close to\\nShannon; in 1946 Tukey coined the word “bit” for Shannon’s “binary digit.”\\nTukey, Shannon, and John R. Pierce applied together for a patent for a\\ncathode ray device in 1948.\\nThe evidence is substantial enough to convince some of Tukey’s\\ncolleagues, including Judith Tanur and Richard Link, that he probably did use\\nBayes’ rule for decoding at Bell Labs. Brillinger, Tukey’s biographer and\\nNBC polling colleague, concluded, “I have no problem thinking that he might\\nhave.”30\\nWhatever the motivation, Tukey’s secrecy edict played a major role in the\\nhistory of Bayes’ rule. As Wallace observed, “It’s important to the\\ndevelopment of Bayesian statistics that a lot was under wraps.”31 Tukey’s\\ncensorship of his polling methods for NBC News, like the highly classified\\nstatus of Bayesian cryptography during and after the Second World War, is\\none reason so few realized how much Bayes’ rule was being used.\\nTukey’s Bayesian polling—conducted in the glare of international\\npublicity for two of the most popular TV anchors of the day—could have\\nspread the news of Bayes’ power and effectiveness and reinforced it at\\nregular intervals. But his ban on speaking or writing about it meant that\\nBayes’ rule played a starring role on TV for almost two decades—without\\nmost statisticians knowing about it.\\nAs a result, the only large computerized Bayesian study of a practical\\nproblem in the public domain during the Bayesian revival of the 1960s was\\nthe Mosteller–Wallace study of The Federalist in 1964. It would be 11 years\\nbefore the next major Bayesian application appeared in public. And after\\nTukey stopped consulting for NBC in 1980, it would be 28 years before a\\npresidential election poll utilized Bayesian techniques again.\\nWhen Nate Silver at FiveThirtyEight.com used hierarchical Bayes during\\nthe presidential race in November 2008, he combined information from\\noutside areas to strengthen small samples from low-population areas and\\nfrom exit polls with low response rates. He weighted the results of other\\npollsters according to their track records and sample size and how up to date\\ntheir data were. He also combined them with historical polling data. That\\nmonth Silver correctly predicted the winner in 49 states, a record unmatched\\nby any other pollster. Had Tukey publicized the Bayesian methods used for\\nNBC, the history of political polling and even American politics might have\\nbeen different.\\n14.\\n \\nthree mile island\\n \\nAfter years of working together, the two old friends Fred Mosteller and John\\nTukey reminisced in 1967 about how “the battle of Bayes has raged for more\\nthan two centuries, sometimes violently, sometimes almost placidly, . . . a\\ncombination of doubt and vigor.” Thomas Bayes had turned his back on his\\nown creation; a quarter century later, Laplace glorified it. During the 1800s it\\nwas both employed and undermined. Derided during the early 1900s, it was\\nused in desperate secrecy during the Second World War and afterward\\nemployed with both astonishing vigor and condescension.1 But by the 1970s\\nBayes’ rule was sliding into the doldrums.\\nA loss of leadership, a series of career changes, and geographical moves\\ncontributed to the gloom. Jimmie Savage, chief U.S. spokesman for Bayes as\\na logical and comprehensive system, died of a heart attack in 1971. After\\nFermi’s death, Harold Jeffreys and American physicist Edwin T. Jaynes\\ncampaigned in vain for Bayes in the physical sciences; Jaynes, who said he\\nalways checked to see what Laplace had done before tackling an applied\\nproblem, turned off many colleagues with his Bayesian fervor. Dennis\\nLindley was slowly building Bayesian statistics departments in the United\\nKingdom but quit administration in 1977 to do solo research. Jack Good\\nmoved from the super-secret coding and decoding agencies of Britain to\\nacademia at Virginia Tech. Albert Madansky, who liked any technique that\\nworked, switched from RAND to private business and later to the University\\nof Chicago Business School, where he claimed to find more applications\\nthan in statistics departments. George Box became interested in quality\\ncontrol in manufacturing and, with W. Edwards Deming and others, advised\\nJapan’s automotive industry. Howard Raiffa also shifted gears to negotiate\\npublic policy, while Robert Schlaifer, the nonmathematical Bayesian, tried to\\nprogram computers.\\nWhen James O. Berger became a Bayesian in the 1970s, the community\\nwas still so small he could track virtually all of its activity. The first\\ninternational conference on Bayes’ rule was held in 1979, in Valencia, Spain,\\nand almost every well-known Bayesian showed up—perhaps 100 in all.\\nGone was the messianic dream that Bayes’ rule could replace frequentism.\\nEcumenical pragmatists spoke of synthesizing Bayesian and nonBayesian\\nmethods. The least controversial ideal, Mosteller and Tukey agreed, was\\neither a frequency-based prior or a “gentle” prior based on beliefs but ready\\nto be overwhelmed by new information.\\nWhen Box, J. Stuart Hunter, and William G. Hunter wrote Statistics for\\nExperimenters in 1978, they intentionally omitted any reference to Bayes’\\nrule: too controversial to sell. Shorn of the big bad word, the book was a\\nbestseller. Ironically, an Oxford philosopher, Richard Swinburne, felt no\\nsuch compunctions a year later: he inserted personal opinions into both the\\nprior hunch and the supposedly objective data of Bayes’ theorem to conclude\\nthat God was more than 50% likely to exist; later Swinburne would figure the\\nprobability of Jesus’ resurrection at “something like 97 percent.” These were\\ncalculations that neither the Reverend Thomas Bayes nor the Reverend\\nRichard Price had cared to make, and even many nonstatisticians regarded\\nSwinburne’s lack of careful measurement as a black mark against Bayes\\nitself.\\nThroughout this period Jerzy Neyman’s bastion of frequentism at Berkeley\\nremained the premiere statistical center of the United States. Stanford’s large\\nstatistics department, bolstered by Charles Stein and other University of\\nCalifornia professors who had refused to sign a McCarthy-era loyalty oath,\\nwas also enthusiastically frequentist, and anti-Bayesian signs adorned\\nprofessors’ office doors.\\nBayesians were treading water. Almost without knowing it they were\\nwaiting until computers could catch up. In the absence of powerful and\\naccessible computers and software, many Bayesians and anti-Bayesians alike\\nhad given up attempts at realistic applications and retreated into theoretical\\nmathematics. Herman Chernoff, whose statistical work often grew out of\\nOffice of Naval Research problems, got so impatient with theoreticians\\nspinning their wheels on increasingly elaborate generalizations that he moved\\nfrom Stanford to MIT in 1974 and then on to Harvard. “We had reached a\\nperiod,” he wrote, “where we had to confront the computer much more\\nintensively and we also had to do much more applied work . . . I thought, for\\nthe future, the field needed a lot more contact with real applications in order\\nto provide insights into which way we should go, rather than concentrating on\\nfurther elaborations on theory.” Chernoff was no Bayesian, but he told\\nstatistician Susan Holmes, then beginning her career, how to face difficult\\nproblems: “Start out as a Bayesian thinking about it, and you’ll get the right\\nanswer. Then you can justify it whichever way you like.”2\\nWithin Bayesian circles, opinions were still defended passionately.\\nAttending his first Bayesian conference in 1976, Jim Berger was shocked to\\nsee half the room yelling at the other half. Everyone seemed to be good\\nfriends, but their priors were split between the personally subjective, like\\nSavage’s, and the objective, like Jeffreys’s—with no definitive experiment to\\ndecide the issue. Good moved eclectically between the two camps.\\nIn a frustrated circle of blame, Persi Diaconis was shocked and angry\\nwhen John Pratt used frequentist methods to analyze his wife’s movie theater\\nattendance data, because there was too much for the era’s computers to\\nhandle. But one of the low moments in Diaconis’s life occurred in a Berkeley\\ncoffee shop, where he was correcting galley proofs of an article and Lindley\\nblamed him for using frequency methods in the article. “And you’re our\\nleading Bayesian,” Lindley complained.3 Lindley, in turn, upset Mosteller by\\npassing up a chance to do a big project using Bayes instead of frequency.\\nEvery opportunity lost for Bayes was a blow to the cause and a reason for\\nrecrimination. By 1978 the Neyman–Pearson frequentists held “an uneasy\\nupper hand” over the Bayesians, while a third, smaller party of Fisherians\\n“snipe[d] away at both sides.”4\\nFew theorems could boast such a history. Bayesians had developed a\\nbroad system of theory and methods, but the outlook for proving their\\neffectiveness seemed bleak. De Finetti predicted a paradigm shift to\\nBayesian methods—in 50 years, post-2020. The frequentist Bradley Efron of\\nStanford estimated the probability of a Bayesian twenty-first century at a\\nmere .15.\\nPoliticking for Bayes in Britain, Lindley said, “The change is happening\\nmuch more slowly than I expected. . . . It is a slow job. . . . I assumed in a\\nnaïve way that if I spent an hour talking to a mature statistician about the\\nBayesian argument, he would accept my reasoning and would change. That\\ndoes not happen; people don’t work that way. . . . I think that the shift will\\ntake place through applied statisticians rather than through the theoreticians.”\\nAsked how to encourage Bayesian theory, he answered tartly, “Attend\\nfunerals.”5\\nWith Bayesian theory in limbo, its public appearances were few and far\\nbetween. Consequently, when the U.S. Congress commissioned the first\\ncomprehensive study of nuclear power plant safety, the question arose:\\nwould anyone dare mention Bayes by name, much less actually use Bayes’\\nrule?\\nPresident Eisenhower had launched the nuclear power industry with his\\nAtoms for Peace speech in 1953. Twenty years later, although no\\ncomprehensive study of safety risks to the public or the environment had been\\nmade, private corporations owned and operated 50 nuclear power plants in\\nthe United States. When Congress began debating whether to absolve plant\\nowners and operators of all liability for accidents, the U.S. Atomic Energy\\nCommission finally ordered a safety study.\\nSignificantly, as it turned out, the man appointed to lead the study was not\\na statistician but a physicist and engineer. Born in Harrisburg, Pennsylvania,\\nin 1927, Norman Carl Rasmussen had served a year in the navy after the\\nSecond World War, graduated from Gettysburg College in 1950, and earned a\\nPh.D. in experimental low-energy nuclear physics at MIT in 1956. He taught\\nphysics there until MIT formed one of the first departments of nuclear\\nengineering, in 1958.\\nWhen Rasmussen was appointed to assess the safety of the nuclear power\\nindustry, there had never been a nuclear plant accident. Believing that any\\nsuch accident would be catastrophic, engineers designed the plants\\nconservatively, and the government regulated them tightly.\\nLacking any data about core melts, Rasmussen decided to do as Madansky\\nhad done at RAND when studying H-bomb accidents. He and his coauthors\\nwould deal with the failure rates of pumps, valves, and other equipment.\\nWhen these failure rates did not produce enough statistics either, the\\nRasmussen group turned to a politically incendiary source of information:\\nexpert opinion and Bayesian analysis.\\nEngineers had long relied on professional judgment, but frequentists\\nconsidered it subjective and not reproducible and banned its use. Further-\\nmore, the Vietnam War had ended America’s enchantment with expert oracles\\nand think tanks. Confidence in leaders plummeted, and a “radical\\npresumption of institutional failure” took its place. Faith in technology\\ndropped too; in 1971 Congress canceled its participation in the supersonic\\npassenger plane, the SST, one of the few times the United States has rejected\\na major new technology. “No Nukes” activists were demonstrating across the\\ncountry.\\nLacking direct evidence of nuclear plant accidents, Rasmussen’s team felt\\nit had no choice but to solicit expert opinion. But how could they combine\\nthat with equipment failure rates? Normally, Bayes’ theorem provided the\\nway. But Rasmussen’s panel already had enough controversy on its hands\\ndealing with nuclear power. The last thing they needed was an argument over\\nmethods.\\nTo avoid using Bayes’ equation, they employed Raiffa’s decision trees.\\nRaiffa was a Bayesian missionary, and his trees had Bayesian roots, but that\\ndid not matter. Panel members avoided even the words “Bayes’ rule”; they\\ncalled it a subjectivistic approach. They thought that keeping clear of Bayes’\\ntheorem would absolve them of being Bayesians.\\nThe committee’s final report, issued in 1974, was loaded with Bayesian\\nuncertainties and probability distributions about equipment failure rates and\\nhuman mistakes. Frequentists did not assign probability distributions to\\nunknowns. The only reference to Bayes’ rule, however, was tucked into an\\ninconspicuous little corner of appendix III: “Treating data as random\\nvariables is sometimes associated with the Bayesian approach . . . the\\nBayesian interpretation can also be used.”6\\nBut avoiding the use of the word “Bayes” did not acquit the report of\\nblame. Although several later studies approved of its use of “subjective\\nprobabilities,” some of the report’s statistics were roundly damned. Five\\nyears later, in January 1979, the U.S. Nuclear Regulatory Commission\\nwithdrew its support for the study. The Rasmussen Report seemed doomed to\\noblivion.\\nDoomed, that is, until two months later when the core of the Three Mile\\nIsland-2 nuclear generating unit was damaged in a severe accident. At almost\\nthe same time, Jane Fonda debuted a blockbuster movie, The China\\nSyndrome, about the coverup of an accident at a nuclear power plant. The\\ncivilian nuclear power industry collapsed in one of the most remarkable\\nreversals in American capitalism. Although approximately 20% of U.S.\\nelectric power came from 104 nuclear power plants in 2003, at this writing\\nno new facility has been ordered since 1978.\\nThree Mile Island revived the Rasmussen Report and its use of\\nsubjectivistic analysis. After the accident the committee’s insights seemed\\nprescient. Previous experts had thought that the odds of severe core damage\\nwere extremely low and that the effects would be catastrophic. The\\nRasmussen Report had concluded the reverse: the probability of core damage\\nwas higher than expected, but the consequences would not always be\\ncatastrophic. The report had also identified two significant problems that\\nplayed roles in the Three Mile Island accident: human error and the release\\nof radioactivity outside the building. The study had even identified the\\nsequence of events that ultimately caused the accident.\\nNot until 1981 did two industry-supported studies finally employ Bayes’\\ntheorem—and admit it. Analysts used it to combine the probabilities of\\nequipment failures with specific information from two particular power\\nplants: Zion Nuclear Power Station north of Chicago and Indian Point reactor\\non the Hudson River, 24 miles north of New York City. Since then,\\nquantitative risk analysis methods and probabilistic safety studies have used\\nboth frequentist and Bayesian methods to analyze safety in the chemical\\nindustry, nuclear power plants, hazardous waste repositories, the release of\\nradioactive material from nuclear power plants, the contamination of Mars\\nby terrestrial microorganisms, the destruction of bridges, and exploration for\\nmineral deposits. To industry’s relief, risk analysis is also now identifying\\nso-called unuseful safety regulations that can presumably be abandoned.\\nSubjective judgment still bothers many physical scientists and engineers\\nwho dislike mixing objective and subjective information in science.\\nAvoiding the word “Bayes,” however, is no longer necessary—or an option.\\n15.\\n \\nthe navy searches\\n \\nSurprisingly, given Bayes’ success in fighting U-boats during the Second\\nWorld War, the U.S. Navy embraced the method slowly and grudgingly\\nduring the Cold War. High-ranking officers turned to Bayes almost\\naccidentally, hoping at first to garner only the trappings of statistics. Later,\\nthe navy would move with increasing confidence and growing computer\\npower to fine-tune the method for antisubmarine warfare. Meanwhile, the\\nCoast Guard eyed the method for rescuing people lost at sea. As was often\\nthe case with Bayes’ rule, a series of spectacular emergencies forced the\\nissue.\\nThe navy’s flirtation with the approach began at dusk on January 16, 1966,\\nwhen a B-52 jet armed with four hydrogen bombs took off from Seymour Air\\nForce Base near Raleigh, North Carolina. Each bomb was about ten feet long\\nand as fat as a garbage can and had the destructive power of roughly one\\nmillion tons of TNT. The jet’s captain, known for smoking a corncob pipe in\\nthe cockpit, and his six-man crew were scheduled to fly continuously for 24\\nhours and refuel several times in midair.\\nIn a controversial program called Operation Chrome Dome, SAC under\\nGen. Curtis LeMay kept jets equipped with nuclear weapons flying at all\\ntimes to protect against Soviet attack. In a costly and hazardous process,\\ntankers refueled the jets in midair.\\nThe jet made the scheduled rendezvous for its third refueling with a SAC\\nKC-135 tanker jet on the morning of January 17. Bomber and tanker\\nmaneuvered in tandem over Spain’s southeastern coast, six miles above the\\nisolated hamlet of Palomares, Spanish for Place of the Doves. They used a\\ntelescoping boom that required the two planes to fly three or four meters\\napart at 600 miles per hour for up to half an hour. In a split-second\\nmiscalculation, the tanker’s fuel nozzle struck the metal spine of the bomber,\\nand at 10:22 a.m. local time 40,000 gallons of fuel burst into flame. Seven of\\nthe planes’ 11 crew members perished.\\nAirmen, the four bombs, and 250 tons of aircraft debris rained down from\\nthe sky. Fortunately, it was a holiday, and most of the area’s 1,500 residents\\nwere taking time off from working their fields, so no one was hit. Even more\\nimportant, no nuclear explosion occurred; the bombs had not been “cocked,”\\nor activated. However, the parachutes on two of them failed to open, and\\nwhen the bombs hit the ground their conventional explosives detonated,\\ncontaminating the area with an aerosol of radioactive plutonium. Three of the\\nbombs were located within 24 hours, but the fourth was nowhere to be found.\\nAdding to the crisis was the fact that, unknown to the public, the incident at\\nPalomares was at least the twenty-ninth serious accident involving the air\\nforce and nuclear weapons. Ten nuclear weapons involved in eight of these\\naccidents had been jettisoned and abandoned at sea or in swamps, where\\nthey presumably remain to this day. The missing weapons, none of which\\ninvolved a nuclear detonation, included two lost over water in 1950; two\\nnuclear capsules in carrying cases in a plane that disappeared over the\\nMediterranean in 1956; two jettisoned into the Atlantic Ocean off New\\nJersey near Atlantic City in 1957; one left at the mouth of the Savannah River\\noff Tybee Beach in Georgia in 1958; the one that fell in Walter Gregg’s\\ngarden near Florence, South Carolina, in 1958; one in Puget Sound in\\nWashington State in 1959; uranium buried in Goldsboro, North Carolina, in\\n1961; and a bomb from a plane that rolled off an aircraft carrier into the\\nPacific in 1965. It was an unenviable record that was only slowly attracting\\nmedia attention.\\nWhen it became obvious that the latest H-bomb to fall from a SAC jet must\\nhave landed in the Mediterranean Sea, the Defense Department phoned John\\nPiña Craven, the civilian chief scientist in the U.S. Navy’s Special Projects\\nOffice.\\nCraven had a bachelor’s degree from Cornell University’s naval science\\ntraining program and a master’s in physics from Caltech. While working on a\\nPh.D. in applied physics at the University of Iowa he spent his spare time\\ntaking advanced courses of every kind, from journalism and philosophy of\\nscience to partial differential equations. Notably, in view of what was to\\ncome, he took statistics and got a C. In 1951 Craven graduated “sort of\\neducated in everything.”1 These were the years when the military was\\ndeveloping crash programs for using navigational satellites and for building\\nballistic missiles and guidance systems to counter the Soviets. In such an\\natmosphere, the Pentagon regarded any Caltech grad as a technological whiz\\nkid.\\nAt 31, Craven became what he called the navy’s “Oracle at Delphi, . . . an\\napplied physicist advising the Navy whenever they have mission or\\nequipment problems that they cannot handle.” His first job was inventing\\ntechnology to locate Soviet mines blocking Wonson Harbor during the\\nKorean War. Three years later he became chief scientist of the Special\\nProjects Office developing the Polaris Fleet Ballistic Missile Submarine\\nSystem. When the nuclear submarine USS Thresher burst and sank off Cape\\nCod in 1963 with 129 men on board, he was ordered to develop ways to find\\nobjects lost or sunk in deep water. To the military looking for an H-bomb in\\nthe Mediterranean Sea, Craven sounded like the man for the job.\\n“We’ve just lost a hydrogen bomb,” W. M. “Jack” Howard, the assistant\\nsecretary of defense for atomic energy, said when he telephoned Craven.\\n“Oh, we’ve just lost a hydrogen bomb,” Craven recalls saying. “That’s\\nyour problem, not mine.”\\nThe deputy secretary persisted: “But one of the bombs fell in the ocean, so\\nwe don’t know how to find it; three others are on land.”\\nCraven shot back, “You called the Navy all right but you called the wrong\\nguy. The Supervisor of Salvage is the guy responsible for that.” Within hours,\\nthough, Craven and the salvage chief, Capt. William F. Searle Jr., formed a\\njoint committee of rejects: Craven had failed twice to get into the naval\\nacademy, and Searle graduated from Annapolis before poor vision shunted\\nhim into underwater salvage work, where, wits said, everyone is more or\\nless blind.\\n“Craven, I want a search doctrine,” Searle barked. He needed the doctrine\\n—naval-ese for a plan—so he could start work the next morning to send\\nships and other materiel to Spain. That night Craven kept telling himself,\\n“Jesus, I’ve got to come up with a search doctrine.”\\nCraven already knew something about Bayesian principles. His mine-\\nsweeping mentor during the Korean War in 1950–52 was the navy physicist\\nand applied mathematician Rufus K. Reber, who had translated Bernard\\nKoopman’s Bayesian antisubmarine studies into practical but classified\\ntables for sea captains planning mine-searching sweeps. Craven had also\\nlearned about Bayes while visiting MIT professors doing classified research\\nfor the government. Most important, he had heard about Howard Raiffa, who\\nwas pioneering the use of subjective probabilistic analyses for business\\ndecision making, operational analysis, and game theory at the Harvard\\nBusiness School.2\\nAs Craven understood it, Raiffa used Bayesian probability to discover that\\nhorse race bettors accurately predict the odds on horses winning first,\\nsecond, and third place. For Craven, the key to Raiffa’s racetrack culture was\\nits reliance on combining the opinions of people “who really know what’s\\ngoing on and who can’t verbalize it but can have hunches and make bets on\\nthem.” Later, Raiffa commented that he was pleased if he had influenced\\nCraven to assess subjective probabilities and pool them across experts. But\\nhe emphasized that Bayes does not get into the act until those subjective\\nviews are updated with new information. Furthermore, he remembered\\ntalking about weather prediction, not horse races.\\n“I’m very good at grasping concepts,” Craven explained later. “I’m lousy\\non detail. I got the betting on probabilities and also got the connection with\\nBayes’s conditional probabilities. But I also understand the politics of getting\\nthings done in the Navy, and I say I’ve got to get a search doctrine.”\\nCraven had experts galore at his disposal. Some knew about B-52s while\\nothers were familiar with the characteristics of H-bombs; bomb storage on\\nplanes; bombs dropping from planes; whether the bomb would stay with the\\nplane wreckage; the probability that one or both of a bomb’s two parachutes\\ndeploys; wind currents and velocity; whether the bomb will be buried in\\nsand; how big it would look wrapped in its chute, and so on. Craven figured\\nthat his experts could work out hypotheses as to where the bomb would fall\\nand then determine the probability of each hypothesis.\\nMost academic statisticians would have thrown in the towel. They would\\nhave believed, with Fisher and Neyman, that sources of information should\\nbe confined to verifiable sample data. Craven, of course, had no wish to\\nrepeat the experiment. He needed to find the bomb. “At that point, I wasn’t\\nlooking at the mathematics, I was just remembering what I got from Raiffa.”\\nThen reality intervened. With only a few hours and the assistance of one\\ntechnician, Craven was forced to be “the guy who interviewed each one of\\nthese experts to make the bets. I’m the guy who decides who the bettors are,\\nand I’m also the guy—let’s be honest about it—who imagines what I’d say if\\nI were the guy I can’t get in touch with. So I’m doing a lot of imagineering. . .\\n. I didn’t have time to call together these people.” Craven’s use of expert\\nguessing would be spectacularly subjective.\\nBlending hurried phone calls to experts, reports of on-site witnesses, and\\nhis own “imagineering,” Craven came up with seven hypotheses he called\\nscenarios:\\n1. The missing H-bomb had remained in the bomber and would be found\\nin the bomber’s debris.\\n2. The bomb would be found in bomb debris along the path of the\\ncollision.\\n3. The bomb had fallen free and was not in the plane’s debris.\\n4. One of the bomb’s two parachutes deployed and carried it out to sea.\\n5. Both of the bomb’s parachutes deployed and carried it farther out to\\nsea.\\n6. None of above.\\n7. A Spanish fisherman had seen the bomb enter the water. (This\\nhypothesis came later, after naval commanders talked with one\\nFrancisco Simo Orts.)\\nIdeally, at this point, Craven would have gotten “all these scenarios and all\\nthese cats [his experts] in a room and have them make bets on them.” But\\nwith only one night before the search doctrine was needed, Craven realized,\\n“I’m going to invent the scenarios myself and guess what an expert on that\\nscenario would bet.”\\nThe emergency forced Craven to cut through years of theoretical doubts\\nabout building a Bayesian prior and estimating the probability of its success:\\n“As I did this, I knew immediately that I wouldn’t be able to sell this concept\\nto any significant operator in the field. So I thought what the hell am I going\\nto do? I’m going to tell them that this is based on Bayes’s subjective\\nprobability. And second, I’m going to hire a bunch of mathematicians, tell\\nthem I want you to put the cloak of authenticity on using Bayes’s theorem. . . .\\n. So I hired Daniel H. Wagner, Associates to do this.”\\nDaniel H. Wagner was a mathematician so absent-minded that his car once\\nran out of gas three times in one day. He had earned a Ph.D. in pure\\nmathematics—none of it applied—from Brown University in 1957. Several\\nyears of working for defense contractors convinced him that rigorous\\nmathematics could be applied to antisubmarine warfare and to search and\\ndetection work. The fact that both involved innumerable uncertainties made\\nBayes’ rule appealing. As Wagner put it, “Bayes’ rule is sensitive to\\ninformation of all kinds . . . but every clue has some error attached because,\\nwere there no error, there would be no search problem: You would just go to\\nthe target and find it immediately. The problem is that . . . you will rarely be\\ngiven the value of the expected error and so you will have to deduce the\\nlocation error from other information.”3\\nOperations research was new, but Wagner came recommended by two\\nauthorities: Capt. Frank A. Andrews (ret.), the officer who had commanded\\nthe Thresher search, and Koopman, by then an influential division head of the\\nInstitute for Defense Analyses, the campus-based organization for academics\\ndoing secret military research.\\nGoing to Craven’s office to learn more about the missing H-bomb, Wagner\\ntook along the youngest and greenest of his three-man staff, Henry R.\\n(“Tony”) Richardson, who had earned a Ph.D. in probability theory from\\nBrown all of seven months earlier. He would be Bayes’ point man at\\nPalomares.\\nAs Wagner reconstructed the scene, Craven showed the mathematicians an\\ninteresting chart of the waters off Palomares. The seabed had been divided\\ninto discrete rectangular cells, and after interrogating air force experts\\nCraven postulated the first six of his seven scenarios. Then he drew on\\nstatistical theory to weight each scenario as to its relative likelihood. His\\nideas were not quantitative; he had drawn a contour map with mountains of\\nhigh probabilities and valleys of unlikely regions. Nor was he forthcoming\\nabout the reasons for each hypothesis. Richardson realized that, as far as\\nCraven was concerned, he and Wagner were just number crunchers.\\nFor Richardson, the fascinating feature of Craven’s probability map was\\nthat it was all based on initial information before any searching began.\\nCraven had constructed a rule-of-thumb prior, the first component of Bayes’\\nrule. Richardson was familiar with Koopman’s search theory, but Craven’s\\nmultiple-scenario priors and the promise of Bayesian updating looked\\nintriguing. By assuming that their probabilities would fall into bell shapes,\\nCraven made it possible to use slide rules and desktop electromechanical\\ncalculators to develop a map of the bomb’s possible locations based on the\\nprior information available to him. Like Laplace, he assigned different\\nprobability weights to each scenario.\\nWagner and Richardson went to work in the company’s headquarters in\\nPaoli, Pennsylvania, verifying and refining Craven’s rough calculations. A\\ncoworker, Ed P. Loane, constructed a more precise probability distribution\\nfor the H-bomb’s location by punching data into paper tape and feeding it\\nover public telephone lines into an electronic computer in the nearby office\\nof the Burroughs Corporation. Turning typewriter characters into graphical\\ndisplays on a teletype machine was challenging. A probability map might\\nwind up looking like this:\\n## #&\\n& &&#\\n# ##\\n \\nwhere # meant a probability between 0 and .05;  was a probability between\\n.06 and .10, and so forth. Loane worked for Wagner, Associates full time\\nwhile he was a part-time graduate student in applied mathematics at the\\nUniversity of Pennsylvania, and he wanted desperately to go to Palomares in\\nRichardson’s place. Meanwhile, Craven gathered data from the Pentagon for\\nRichardson to take to Spain. The young man was amazed to see Craven and\\nother senior officers milling around, opening doors for him.\\nAlmost daily planning sessions with the military soon convinced the\\nmathematicians that their goal—using Bayes’ rule and updating to find the H-\\nbomb—was not the reason they were hired. Bayes was window dressing. If\\nthe H-bomb was not found, the navy wanted to be able to prove statistically\\nthat it was not there. “The general thrust seemed to be to come up with a\\ncredible certification to the President that the H-bomb could not be found,\\nrather than proceeding with an expectation that it could be found. Indeed, the\\nformer purpose,” Wagner concluded, “is the main reason we were brought\\ninto the act.”4\\nRichardson agreed: “My recollection of my marching orders was to\\nstatistically document the search that was being carried out and, in the event\\nthat the bomb was not found, to be able to certify to the President and\\nCongress that everything possible was done and that it was done in a\\nscientifically accurate and careful way. So that was pretty much what I was\\nsent out to do. Having read Koopman’s work, and knowing that there was\\nsuch a thing as optimal search based on Bayesian ideas, I was hoping to do\\nmore.”5\\nRichardson was not interested in using Bayes as a mathematical excuse for\\na failed expedition. He wanted to find the bomb. He flew to Spain with\\nCaptain Andrews, who had a physics Ph.D. from Yale and, after the Thresher\\nsearch, had retired from the navy to join Catholic University’s faculty.\\nAndrews knew the Pentagon had big doubts that the navy search team would\\never find the bomb. In addition, he had been warned that, if the bomb was not\\nlocated, the entire world would know that the search team “had failed\\nprofessionally.” In short, the navy was on the hot seat, and careers were on\\nthe line. “The implication was, of course, that if we did not find the weapon,\\nnobody else could,” Andrews recalled later.6\\nDuring the flight, Richardson briefed Andrews on Bayesian search theory.\\nAndrews exclaimed, “Oh, if we’d only had that during the Thresher search.”7\\nOnce a large search area was divided into small cells, Bayes’ rule said that\\nthe failure to find something in one cell enhances the probability of finding it\\nin the others. Bayes described in mathematical terms an everyday hunt for a\\nmissing sock: an exhaustive but fruitless search of the bedroom and a cursory\\nlook in the bath would suggest the sock is more likely to be found in the\\nlaundry. Thus, Bayes could provide useful information even if the search was\\nunsuccessful.\\nArriving in Palomares, the men found an impoverished village so small it\\nhad no telephone and did not appear on maps or in Spain’s census. Beginning\\nin 3500 BC, mining and smelting for lead and silver had pockmarked the\\ndesert area with open shafts and, cursed with less than eight inches of rain\\nannually and a saline water supply, agriculture was limited to winter\\ntomatoes grown for export. The B-52’s aerial explosion and wind had dusted\\n558 acres of the town and its fields with radioactive plutonium.\\nIn addition to these problems, the village was under siege from a military\\ncamp of 750 Americans, complete with field laundries, bakeries, and a\\nmovie theater; an offshore fleet of up to 18 ships at a time; a Soviet trawler\\nsnooping in international waters; and scores of international reporters\\nincensed by a blackout on news. Applying Bayes’ rule would not be a\\ntextbook exercise in abstractions; it would be a high-wire operation\\nconducted under intense scrutiny.\\nFor four days, the U.S. and Spanish governments refused to admit that the\\nbomber might have carried nuclear weapons of any kind. News of nuclear\\nbombs and radioactivity leaked out only after an American sergeant shouted\\nto the first reporter on the scene, “Hey, buddy, can you speak Spanish?”\\n“Sure.”\\n“Well, tell that peasant over there to get out of that field, for God’s sake. I\\ncan’t make him understand a damned thing. There’s radioactivity there and\\nwe’ve got to keep the people cleared out.”\\nA public relations catastrophe was in the making. This was the first\\naccident involving the widespread dispersal of radioactive material and the\\nfirst that attracted widespread, highly critical scrutiny from the world’s\\nmedia. Within three days, reporters in Palomares knew that a nuclear bomb\\nwas missing, but six weeks passed before the U.S. Department of Defense\\nwould confirm it. Censorship by Spain’s dictator, Francisco Franco, kept\\nnews of the radioactivity off local radio stations, while broadcasts from\\nCommunist Eastern Europe spread the word. Radio Moscow announced that\\n“the bomb is still in the sea, irradiating the water and the fish,” and the\\nSoviet government complained that the United States had broken the nuclear\\ntest-ban treaty of 1963. The on-site press corps fumed at being scooped by\\nRadio Moscow, Pentagon-based reporters, and even Stars and Stripes.\\nLocals were understandably terrified. Tourism and exports of Spanish fruit\\nand tomatoes collapsed. Demonstrators in Mexico City, Frankfurt, and the\\nPhilippines updated a popular song from My Fair Lady, “The bomb in Spain\\nlies mainly in the drain.”8 Adding to the pressure, the Vietnam War was\\nescalating and U.S. military bases around the world were at stake. President\\nJohnson phoned the Department of Defense every day demanding news on the\\nsearch.\\nArriving in this hotbed of tension, Captain Andrews immediately\\nintroduced Richardson to RAdm. William S. Guest, commander of the navy\\ntask force looking for the bomb. Guest was celebrated as the first U.S.\\naircraft carrier pilot to sink an enemy ship during the Second World War. He\\nwas notoriously stubborn and, behind his back, people called him Bull Dog.\\nGuest understood airplanes and budgets, but not Bayes. However, he did\\nunderstand Washington’s message: “You will listen to Dr. Richardson and we\\nwill listen to him, so basically . . . for that reason you should pay attention\\nyourself.” Expecting an august authority, Guest had assigned the\\nmathematician a captain’s stateroom and steward. When he met Richardson,\\nwho looked even younger than his 26 years, Bull Dog harrumphed, “I didn’t\\nthink we were getting a teenager.”\\nThe first thing Guest told Richardson was tongue-in-cheek—but not really.\\nThe mathematician was to prove that the missing bomb was on land because\\nGuest’s job was to look in the sea, and if it was on land, finding it would be\\nsomeone else’s job. Right off, Richardson declared, “I don’t think I have the\\nability to do that.”\\nGuest commanded 125 swimmers and scuba divers eyeballing the shallow\\ncoastline, minesweepers cruising deeper water in heavy surf, 3,000 navy\\npersonnel, 25 navy ships, 4 research submersibles, and a host of civilian\\nresearchers and contractors. The entire search, called Aircraft Salvops Med,\\nwould cost 12 million in 1966 dollars.\\nGuest wanted to save money by using the equipment where it was best\\nsuited and then returning it as soon as possible. This meant he wanted to\\nsearch some areas that were actually unlikely sites for the H-bomb.\\nCraven’s initial hypotheses were based on prevailing winds, so the early\\nhunt focused on a large rectangular area called Alpha II off the beach of\\nPalomares. Guest ordered his swimmers, divers, and minesweepers to\\nsearch there over and over again.\\nRichardson began work immediately by combing the charts of the search to\\ndate. The first weakness he saw was that, although there were tracks of\\nwhere the ships had gone back and forth, there was no mention of\\neffectiveness. “Just going back and forth wouldn’t do you much good if you\\ncouldn’t see the bottom of the ocean,” he said. “And that in fact was the case.\\nSome of their sensors couldn’t penetrate deep water, so they were basically\\nout there running around but not contributing anything to the effectiveness of\\nthe search. . . . None of this is criticism. It was just a horrible situation to be\\nin. With the whole world looking at you, you can’t tie boats up in a dock and\\nsay they’re useless.” So, inspired by a conversation with Andrews,\\nRichardson coined the term “Search Effectiveness Probability” (SEP).\\nLooking at the map of the ocean bottom broken into a grid of little squares,\\nRichardson computed for each of the squares the probability that, if the bomb\\nwere there, it would have been found by the amount of search effort applied\\nto that area. “If the Search Effectiveness Probability came in at 95%, you\\ncould say to the Admiral, ‘This area has been searched pretty thoroughly, and\\nmaybe you want to go somewhere else,’” Richardson said.\\nBy then he probably knew as much as anyone about the ongoing search.\\nQuarantined from the curious reporters on land, he worked nights in the\\nship’s accounting office. His luggage, filled with reference books and\\nReber’s declassified tables for minesweepers, had been lost in Madrid, so\\nhe painstakingly recreated some of the tables, overlaying bits of paper to\\nsuperimpose curves. He had no alternative. Portable computers did not exist,\\nand even IBM mainframes had only 32 kilobytes (not gigabytes or even\\nmegabytes) of memory. Armed with his paper cutouts, his slide rule, and an\\nadding machine that could also multiply, he computed the effectiveness of\\neach day’s operations. Each morning he greeted Bull Dog Guest with new\\nprobabilities. The admiral enjoyed joking about Richardson’s boyish\\nappearance, but the probabilities unsettled him.\\n“I began computing SEPs—the probability you’d have found the bomb if it\\nwere there—and a lot of zeros showed up indicating that, even if it had been\\nthere, you probably wouldn’t have seen it because your capabilities weren’t\\nup to the task.” At the other end of the SEP scale, a “one” would have\\nsignified that the bomb would have been found, had it been there. Richardson\\nwas calculating very few ones: “All those zeroes. When Guest saw them—\\nremember this is some young teenager talking to him—the minute he saw\\nzeroes, he was quite outspoken in his questions. ‘Why are you giving me\\nzeroes when we’ve been out there for two weeks?’”\\nGuest began using the search effectiveness evaluations as quantitative\\nguides for moving equipment. He wanted to document that his equipment had\\nconducted their investigations thoroughly; he was not interested in using\\nBayesian updating to find new, more probable places to inspect. Even when\\na more likely site for the H-bomb appeared, Admiral Guest stuck to his “plan\\nof squares.”\\nYears later, Craven complained that “the least informed and\\nknowledgeable was Admiral Guest, the on-scene commanding officer.” The\\nadmiral was furious “because he thinks we’re out of our noggin.” Richardson\\nis more forgiving. Guest “had other concerns. Bayes was a little bit high-\\nfalutin’. SEP was understandable. But you start getting into Bayesian\\nupdating and these funny words like priors and posteriors, admirals tend not\\nto be patient with this stuff.” As a result, evaluating the search’s effectiveness\\nbecame the focus of the H-bomb search. The idea of using effectiveness data\\nto update the first Bayesian component—Craven’s presearch scenarios—\\nfaded into the background.\\nMeanwhile, the eyewitness testimony of the veteran fisherman Francisco\\nSimo Orts was gaining credibility fast. The morning of the crash Orts had\\nwatched a large parachute pass over his boat and splash down 100 yards\\naway. He called it “half a man, with the insides trailing.” Despite the odd\\ndescription, his report sounded authentic. Strangely stiff in air, the object\\nsank fast, within 30 seconds, parachute and all. Moreover, Orts said the chute\\nwas grayish; air force chutes were orange and white for personnel but gray-\\nwhite for bombs. Navy personnel had interviewed Orts shortly after the crash\\nbut had discounted him because he did not use standard procedures to\\ntriangulate the spot. Having fished those waters all his life, he could make a\\nseaman’s eye calculation of familiar mountains and villages along the shore\\nand identify the location.\\nLt. Cdr. J. Brad Mooney, assistant operations officer for deep\\nsubmersibles, thought Orts might know what he was talking about. Mooney,\\nlater promoted to commander and chief of naval research, came from New\\nHampshire, where lobstermen used similar methods to find their submerged\\npots. He and Jon Lindberg, a commercial diving consultant, commandeered a\\njeep, found Orts in a bar, and took him to sea. When Orts twice pointed\\nminesweepers to the same spot in the Mediterranean, Moony believed him.\\nSoon Orts’s testimony formed the basis for a high-likelihood hypothesis:\\nwith one parachute deployed, the bomb had plunged into a steep, deep-water\\ncanyon filled with tailings from an old lead mine. Mooney drew a one-mile\\nradius around Orts’s spot and named it Alpha I.\\nAs Craven recalled, “We didn’t find the bomb for a long period of time\\nbecause the place of highest probability is a place we can’t get to. It’s in a\\nnarrow crevasse, too deep.” Much of the military’s equipment needed for a\\ndeep-sea search was inadequate: navigational charts dated from the early\\n1900s; detectors were “grossly inaccurate” with errors up to 1,000 yards;\\nand many of the most useful devices were available only from commercial or\\nresearch sources. They included three small submarines: the mini Alvin from\\nWoods Hole Oceanographic Institution, the Aluminaut from the Reynolds\\nAluminum Company, and a little yellow sub called the Perry Cub.\\nOf Guest’s entire squadron, only the two- or three-man sub Alvin could\\npenetrate the rugged depths of the highest probability site. But Alvin’s battery\\nwas fading, and to rejuvenate its power the submersible had to be lifted out\\nof the water and docked for long periods.\\nSix weeks after the plane crash, Captain Andrews hitched a ride down the\\ncrevasse with the Alvin crew. Peering through its five-inch portholes, they\\nsuddenly spied a strange track leading down a slope, “totally different from\\nanything there,” Andrews recalled, “basically like somebody dragging a\\nheavy log or barrel down the slope.” Alvin’s battery was running low again,\\nso they had to abandon the skid marks and surface. Then, for two weeks a\\nlarge storm circled in, grounded, and thwarted the Alvin.\\nDuring all this time President Johnson was telephoning the Department of\\nDefense every day, only to be told, “We cannot tell you when we’ll recover\\nthe bomb. We can only tell you the probability of when we’ll recover it.”\\nFuming, LBJ replied that he did not want a probability; he wanted a date.\\nPrivately, Craven added, “I’m sure his response was profane.”\\nFinally, Johnson’s volcanic temper exploded: “I want you to get a series of\\ntop-level academics to look at this search plan and tell me what’s wrong\\nwith it. I don’t want this probability stuff. I want a plan that tells me exactly\\nwhen we’re going to find this bomb.”\\nCraven convened a committee of Cornell, Harvard, and MIT professors to\\ncome to the Pentagon on the morning of March 15, 1966. Number crunchers\\nfrom Wagner, Associates presented “a mathematical model whose\\ncomplexity defied understanding by mere mortals.”9 The professors endorsed\\nthe Bayesian plan and adjourned for lunch.\\nOn their return they learned that Alvin’s crew, during its nineteenth dive off\\nPalomares, had just spotted the bomb with its enormous parachute strewn\\nover the seafloor rocks. Alvin had telephoned the surface that the H-bomb\\nlooked “like a ghost down there . . . like a big body in a shroud.”10 It had hit\\nground in 1,300 feet of water and been dragged by currents down a steep\\nslope almost 2,850 feet deep. It lay within a mile of where Orts had pointed.\\nAfter the bomb was safely retrieved, the fisherman sued for 5 million in\\nsalvage prize money. At the government’s request, Richardson again used\\noptimal search theory based on Bayes’ rule to estimate the value of Orts’s\\ntestimony: he had saved the government at least a year’s hard work. In 1971\\nan admiralty court in New York awarded Orts 10,000. The United States\\nhad already settled 600,000 on Palomares residents and given the town a \\n200,000 desalting plant.\\nJust as the RAND Corporation’s Bayesian study had warned eight years\\nearlier, SAC’s crash over Palomares diminished the authority of the U.S. Air\\nForce. Military flights over Spain were forbidden, the number of SAC air-\\nalert missions was halved, and responsibility for American air bases in\\nSpain was transferred from SAC to the U.S. Tactical Air Command in\\nGermany. In return for allowing the United States to keep its bases, Franco\\ndemanded American help in getting Spain into NATO and the Common\\nMarket.\\nSAC’s next accident involving nuclear weapons, two years after\\nPalomares, was the last straw for Operation Chrome Dome. The accident\\noccurred when a B-52 loaded with four nuclear bombs crashed onto sea ice\\noutside a U.S. air base at Thule, Greenland. The weapons were destroyed by\\nfire, but, as at Palomares, radioactivity contaminated the area. As a result of\\nthe two accidents, the rising cost of keeping SAC’s planes in the air, and the\\nadvent of intercontinental ballistic missiles, Secretary of Defense Robert\\nMcNamara ended SAC’s airborne alert program in 1968.\\nIn 2002, almost four decades after the Palomares accident, Spanish\\nauthorities said they had found no danger in the area from surface radiation.\\nSpanish and U.S. health officials reported that no radiation-related cancers\\nhad been detected in Palomares’s residents. They also said the 1,600 air\\nforce personnel who shipped 1,000 cubic meters of Palomares soil in 4,810\\nmetal drums for burial in South Carolina had been exposed to insignificant\\namounts of radiation, 1/10 the current limit for radiation workers. Even\\nthough the public perceives plutonium as being extremely hazardous,\\ngovernment studies showed that its alpha rays are so weak they do not\\npenetrate skin or clothing and, if ingested, pass out of the body in feces. The\\ngreatest danger posed by plutonium occurs when it is inhaled. Despite more\\nthan 30 years of living and working in a plutonium-contaminated\\nenvironment, official reports say, the residents of Palomares have inhaled far\\nless than the maximum safe dose identified by the International Committee on\\nRadiological Protection.\\nRadioactive snails discovered in 2006, however, prompted fears of\\ndangerous levels of plutonium below ground. A joint Spanish–U.S. study was\\nannounced, and children were warned not to play in fields near the explosion\\nsites or to eat the snails, a local delicacy.\\nBut what about Bayes? What did it contribute to the H-bomb search?\\nRichardson concluded that “the numbers I computed were coverage numbers\\nso that [Guest] could say we’d covered these areas. . . . Scientifically, the big\\nthing in my mind was that Bayes was a sidelight to the H-bomb search.”11\\nThe H-bomb hunt could have been a full-blown Bayesian exercise. The\\nprior probabilities of Craven’s prehunt scenarios could have been updated\\nwith Richardson’s shipboard data to guide the search. However, they were\\nnever combined in time to be of any use in locating the lost bomb. And\\nwithout updating, there was no Bayes. Instead of Bayes, the heroes were Orts\\nand the Alvin. The H-bomb search did develop the methodology for\\ncomputing SEPs (later called LEPs, for “local effectiveness probability”),\\nbut Richardson could not get an article about using probability to find the H-\\nbomb published in an academic journal. The H-bomb hunt was a striking\\ndemonstration of how difficult it would be to win operational support for\\nBayes’ rule, even when something as tangible and terrifying as a missing\\nthermonuclear bomb was concerned.\\nStill, although Bayesian updating was not used at Palomares, the success\\nof the search strengthened Craven’s faith in scientific searches and the\\npotential of Bayes’ rule. He and his team had learned how to compute\\nsubjective presearch hypotheses and weight their importance. They realized\\nthat the future of Bayesian search methods depended crucially on computer\\npower and the portability of computerized information. This was not an\\ninsignificant realization. Richardson had been the only member of his\\ngraduate class in pure mathematics to take a computer course, and computer\\ncomputation was still thought of as cowardly. Within months, though, Wagner,\\nAssociates acquired a punched-tape terminal, its first direct access to\\nelectronic computation. The next time they were called, the Bayesians would\\nhave better tools.\\nThe navy got a dramatic opportunity to use Bayes’ rule two years later, in the\\nspring of 1968, when two attack submarines, one Soviet and the other U.S.,\\ndisappeared with their crews within weeks of each other. As head of the\\nDeep Submergence Systems Project, Craven was responsible for the search\\nfor both subs. Despite Bayes’ limited role in the H-bomb search, both\\nCraven and Richardson remained convinced the method was scientifically\\nvalid.\\nThe first submarine to disappear was a diesel-fueled and missile-armed\\nSoviet K-129, the source of Tom Clancy’s fictionalized bestseller The Hunt\\nfor Red October. The U.S. Navy was alerted to its loss by a massive Soviet\\nsearch in the Pacific off the Kamchatka peninsula along a major route\\nfrequented by its submarines. About the same time, U.S. underwater sensors\\nrecorded a “good-sized bang.” The noise was far less than the sound of a sub\\nimploding upon itself, but it occurred at a curious place, far from the Soviet\\nsearch operation and on the International Date Line, at 40 degrees north and\\nprecisely 180 degrees longitude. Because the date line is a human artifact,\\nthe noise suggested a man-made event. Craven, one of a handful of U.S.\\npersonnel who knew of the “extremely classified” affair, hired Wagner,\\nAssociates for a full-scale probability analysis without ever telling them\\nwhat they were looking for. Forty years later, Richardson still did not know\\nhe had worked on the search for the Soviet submarine.\\nCraven could think of only three plausible scenarios for the K-129’s\\ndisappearance: “First, that the sound had nothing to do with the lost\\nsubmarine. Second, that the sound was made by the submarine but that it did\\nnot sink and like Jules Verne’s Nautilus was still gliding beneath the sea.”\\nThird, that the sub’s watertight compartments were open when the crisis\\noccurred and the vessel flooded so fast it did not collapse. Craven reasoned\\nthat if the sound recorded on the International Date Line came from the\\nsubmarine, “then it was indeed not where it was supposed to be, which was\\nwhy the Soviets could not find it.”\\nJohnson, distracted during the tumultuous last months of his presidency,\\nauthorized a search for the Russian sub on the hypothesis that it might be a\\nrogue, even though the prospect of finding it was slim. Eventually Craven\\nconcluded that the sub—armed with ballistic missiles and crewed by about\\n100 people—was indeed “a rogue, off on its own, in grave disobedience of\\nits orders . . . [and possibly planning to attack Hawaii]. Since the Soviets\\ndidn’t know how far off course their sub had been, the Soviets would have\\nhad no idea that their ship was a rogue unless we told them.”12 U.S.\\nauthorities informed the Soviet leader, Leonid Brezhnev, of the bang’s\\nlocation, and in the face of evidence that his military might be out of control\\nhe could see détente as an attractive option. Later, Americans photographed\\nthe K-129 but were unable to raise it.\\nIn May 1968, a few weeks after the Soviet sub sank, the U.S.S. Scorpion,\\na nuclear-powered attack sub, disappeared with its crew of 99 in the Atlantic\\nOcean. The Scorpion was cruising west, toward home, somewhere along a\\n3,000-mile submarine route between Spain and the East Coast of the United\\nStates. It was reportedly armed with two nuclear torpedoes. According to a\\nstudy made in 1989, Scorpion’s reactor and torpedos would be among at\\nleast eight nuclear reactors and 50 nuclear warheads to have been lost at sea;\\nof these, 43 were on sunken Soviet submarines and eight originated with U.S.\\nmilitary activities. With the Scorpion’s final resting place unknown, the\\nmilitary launched a full-scale search.\\nCraven and Andrews, by now the world’s leading search experts, rapidly\\nreassembled their H-bomb search crew. At first, the hunt stretched across the\\nAtlantic Ocean. After some bureaucratic sleuthing, though, Craven learned\\nthat an ultrasecret listening post for “an unnamed agency” had recorded\\nmysterious “blips” in extremely deep water about 400 miles southwest of the\\nAzores. The location of the blips corresponded with the sub’s expected\\nitinerary and drastically narrowed the search area from a 3,000-mile-long\\nrectangle to three or four square miles. Thanks to Craven, the investigation\\ntook a spectacular leap forward.\\nCraven organized a full-blown Bayesian hunt for Scorpion from the very\\nbeginning. When the H-bomb was lost off the Spanish coast, Craven had\\nturned almost accidentally to Bayes in the hope of deflecting Congressional\\ndispleasure in case of failure. This time, the navy moved tentatively but with\\ngrowing faith to exploit the method.\\n“Craven had confidence in the scientific approach from the very beginning\\nbut, to put it mildly, that wasn’t everybody’s thing,” Richardson said.\\n“Tough” is the word most often used to describe Craven, and for the next five\\nmonths, from June to October 1968, he staunchly defended Bayes against\\nskeptics. Although the H-bomb search in Palomares had failed to combine\\nBayesian priors and SEPs, Craven was enthusiastic when Richardson\\nproposed doing so this time. A powerful computer in the United States would\\ncompute the probabilities of the various presearch hypotheses. Then this\\nprior was to be combined and updated on shipboard with daily search\\nresults.\\nShortly after the sub disappeared, Richardson was flown to the Azores to\\nobserve the surface search for Scorpion and to visit the USNS Mizar, a\\nresearch ship conducting underwater operations. Personnel from the Naval\\nResearch Laboratory, the Navy Oceanographic Office, and various\\nequipment makers were aboard the Mizar, working 12-hour shifts around the\\nclock. Over the next five months, they cruised through the area for weeks at a\\ntime, dragging across the ocean bottom a sledlike platform covered with a\\nwide-angle camera, sonars, and magnetometers. The chief scientist on board\\nthe Mizar, Chester L. “Buck” Buchanan, had originally designed the\\nequipment to find the Thresher and had improved it greatly since. He vowed\\nnot to shave until the Scorpion was found.\\nScorpion searchers faced even more uncertainties than the H-bomb hunters\\nhad along the Mediterranean coast: a remote location 400 miles from land-\\nbased navigation systems, an ocean floor two miles down, and no eye-\\nwitness accounts pinpointing the Scorpion’s location. Navigational systems\\nalso introduced large errors and uncertainties. Two land-based radio\\nnetworks, Loran and the new global Omega, were too imprecise to be useful,\\nsatellite fixes were available only irregularly, and transponders anchored to\\nthe ocean bottom were often indistinguishable from one another.\\nWhen Richardson arrived on board the Mizar, he found the ship following\\norders from Washington to search off Point Oscar—over and over again.\\nCraven’s early analysis of acoustic data suggested that the Scorpion might\\nhave settled near Oscar. Using Bayes, however, Richardson tried to show\\ngraphically that they had oversearched Point Oscar and that very little\\nprobability remained of finding Scorpion there. Despite his brilliant\\ndemonstration, the search around Oscar continued. Washington would have to\\nissue orders to change operations, and this would require persuasion based\\nupon calculation of a detailed probability map, that is, a Bayesian prior.\\n“In all the operations that I’ve ever operated in you have strong\\npersonalities with their own ideas, and you have to argue—unless somebody\\n[like Craven] in Washington shoves it down their throat,” Richardson said.\\n“Otherwise, you have to convince people. And they have to come to their\\nown conclusions that it’s the right way to do it.” Besieged by Craven,\\nauthorities in Washington later ordered that the prior probability map be\\ntreated as an important factor in the search.\\nOn July 18, 1968, a month after the Scorpion’s disappearance, Craven\\ngave “a brain dump” for Richardson and a new Wagner employee, Lawrence\\nD. (“Larry”) Stone. Craven reported everything he had learned from his\\nexperts, and Captain Andrews presented a submariner’s view of what a sub\\nmight do under various circumstances. Working in Washington, Craven and\\nAndrews outlined nine scenarios that might explain how Scorpion sank. Then\\nthey assigned a weight to each according to how believable it was. This was\\nthe same approach Craven had used in the H-bomb search. Each scenario\\nsimulated Scorpion’s movements and multiple uncertainties as to its course,\\nspeed, and position at the time of the blip.\\nOne high-priority scenario was based on a mysterious piece of bent metal\\nfound by the Mizar during a quick survey of the region before the start of\\nsystematic searching. The metal was so shiny that it could not have lain very\\nlong on the sea bottom, and it was far away from the overly investigated\\nPoint Oscar.\\nRichardson and Stone carried their copious notes to Wagner, Associates’\\nheadquarters to quantify Craven and Andrews’s assumptions and compute a\\nprior “probability map” of the sub’s location on the ocean floor. First, they\\nestablished a search grid around the blip that Craven had identified as the\\nprobable location of the Scorpion’s explosion. Each cell in the grid\\nmeasured one mile north–south and 0.84 miles east–west, for a total of 140\\nsquare miles.\\nAt Richardson’s suggestion, the stateside search team made a key decision\\nto use Monte Carlo methods to model the sub’s movements before and after\\nthe accident. Physicists on the Manhattan Project had pioneered Monte Carlo\\ntechniques for tracking the probable paths of neutrons in a chain reaction\\nexplosion. Richardson substituted “little hypothetical submarines” for the\\nneutrons. Academic Bayesians would not adopt Monte Carlo methods for\\nanother 20 years.\\nStarting with Craven’s probable location of the explosion (the blip), a\\nmainframe computed the probabilities that, in its death throes, the submarine\\nchanged course and traveled, for example, another mile in any of several\\nrandom directions. Using Thomas Bayes’ simplification, Richardson began\\nby considering each of those directions as equally probable. Then, making a\\npoint at each new possible location, the computer repeated the process to\\nproduce new points, reiterating the procedure 10,000 times to make 10,000\\npoints on the seafloor where the sub might have settled.\\nThe use of Monte Carlo simulation to generate numbers based on Craven’s\\npresearch scenarios and weighting represented a big advance in search work.\\nAccording to Richardson, “The nice thing with Monte Carlo is that you play\\na game of let’s pretend, like this: first of all there are ten scenarios with\\ndifferent probabilities, so let’s first pick a probability. The dice in this case\\nis a random number generator in the computer. You roll the dice and pick a\\nscenario to work with. Then you roll the dice for a certain speed, and you\\nroll the dice again to see what direction it took. The last thing is that it\\ncollided with the bottom at an unknown time so you roll dice for the unknown\\ntime. So now you have speed, direction, starting point, time. Given them all, I\\nknow precisely where it [could have] hit the bottom. You have the computer\\nput a point there. Rolling dice, I come up with different factors for each\\nscenario. If I had enough patience, I could do it with pencil and paper. We\\ncalculated ten thousand points. So you have ten thousand points on the bottom\\nof the ocean that represent equally likely positions of the sub. Then you draw\\na grid, count the points in each cell of the grid, saying that 10% of the points\\nfall in this cell, 1% in that cell, and those percentages are what you use for\\nprobabilities for the prior for the individual distributions.”\\nThe 10,000 points were calculated on a mainframe computer in a small\\nPrinceton company that encoded classified data and punched it into paper\\ntape. Such computers were available only on the mainland in the 1960s. Still\\nin the future were so-called portable modems, 45-pound backbreakers for\\ndialing into phone lines.\\nAs cumbersome as it seems today, the time-shared mainframe made Bayes’\\nrepetitive calculations feasible. It calculated the coordinates of Scorpion’s\\n10,000 possible locations and then counted the number of points that fell in\\neach cell of the search grid. Lacking any sort of display screens, the\\ncomputer printed out the numbers on ordinary teletype paper tape. Then the\\ndata were relayed over insecure public telephone lines to Richardson and\\nStone in Paoli. It was the only practical way of incorporating all the\\npresearch data accumulated by Craven and Andrews in Washington into a\\ndetailed probability map.\\nRichardson later felt guilty about calculating only a “skimpy” 10,000\\npoints, but at the time it seemed like a big number. Today’s computers refine\\ndetail even in low-probability areas. When the 10,000-point map was\\nfinished, it described the initial probabilities in 172 cells covering 140\\nsquare miles. Two cells, E5 and B7, stood out like rock stars under\\nspotlights. With presearch simulation “hits” of 1,250 and 1,096, respectively,\\nthey were by far the most likely resting places for Scorpion and its crew. The\\nnext 18 most likely cells had far lower probabilities, between 100 and 1,000;\\nand most cells (which had scores below 100) seemed almost irrelevant. The\\nmap was based on hours of conversations with Craven and Andrews, their\\nscenarios, and their weighting. Unlike the H-bomb analyses of two years\\nbefore, this map represented a real scientific advance, primarily because of\\nthe Monte Carlo calculations of the Scorpion’s possible movements.\\nBy late July, the map was ready, and Washington ordered that it be treated\\nas an important factor in the search. It was now time for Bayesian updating,\\nwith data on the effectiveness of the fleet’s search effort in each cell.\\nAboard the Mizar, mathematicians from Wagner, Associates accumulated\\nand recorded the effectiveness of each day’s search. Stone and, later, two\\nyoung students—Steven G. Simpson, a mathematics Ph.D. candidate from\\nMIT, and James A. Rosenberg, a Drexel University undergraduate co-op\\nstudent—worked on the area identified by Craven’s scenarios about 2,000\\nyards from Buchanan’s shiny piece of metal. Calculating by hand, they\\nestimated the capabilities of the fleet’s cameras, sonars, and magnetometers\\nand combined them into a single number expressing the effectiveness of the\\nsearch conducted in each cell of the sea-bottom grid. These numbers would\\neventually become the second component in Bayes’ formula. Each morning\\nthe students had the unenviable task of tactfully advising a succession of\\nnaval commodores on the effectiveness of their searches: “Well, sir, I think it\\nwould be better if you did this rather than that.”\\nPsychologically, a search can be difficult. Until the target is found, every\\nday represents a failure. As Stone put it, “Bayes says that the longer you\\nsearch without finding the target, the worse your prospects are, because the\\nremaining time to detect the target gets longer, not shorter.”13 On the other\\nhand, those with confidence in Bayes’ rule could trace their progress. “Areas\\nthat you search go down in probability,” Richardson explained, “and areas\\nthat you haven’t searched go up. So your updated probabilities get higher\\nwhere you haven’t been looking. . . . And generally, it’s always most optimal\\nto keep looking in the highest probability area. The next day you have a high\\nprobability area somewhere else, probably not where you searched, and they\\npop up somewhere else the third day, and you just keep doing it and doing it\\nand doing it. And unless you’ve made some drastic mistake, you’ll eventually\\nfind what you’re looking for.”\\nAs it was during the H-bomb hunt, the biggest problem turned out to be\\noverestimates of the sensors’ capabilities. Most of them had never been\\ntested or evaluated systematically for how well they could detect a piece of\\nmetal to the left or right of their detectors. Thinking over the problem,\\nRichardson realized, “So you had two uncertainties and, if your objective is\\nto come up with the mathematical expression for how to allocate resources\\noptimally, that’s an interesting point.”\\nAs naval commanders came and went during the Mizar’s five cruises to\\nthe search site, Bayes’ rule became the group memory of the search and its\\ncoordinating principle. For the first time, the rule was used from beginning to\\nend of a long search. Unfortunately, not everyone saw the Monte Carlo prior\\nmap as a powerful tool for directing Mizar’s search. It took almost a month\\nto get the map to the scene of operations for its Bayesian updating.\\nCommunications between land and sea were so poor that Stone finally hand-\\ncarried the map to the Azores on August 12. Not until the research ship’s\\nfourth and fifth cruises in October—five months after Scorpion disappeared\\n—did the detailed prior distributions based on Craven’s and Andrews’\\nscenarios become available.\\nThe Mizar’s fifth and last cruise was originally planned to test the sensors,\\nrefine the underwater tracking system, and study the contours of the ocean\\nbottom. By this time Craven had organized acoustical studies to more\\nprecisely calibrate the location of the blip recorded by the supersecret\\nsensors. Small depth charges were exploded in the ocean at precisely known\\npositions, and their sounds were used to refine the information recorded by\\nnaval listening posts during the Scorpion’s last moments. Every day Craven’s\\nacoustical analyses edged the most likely spot for the Scorpion closer to\\nBuchanan’s shining piece of metal.\\nIn late October the increasingly impatient and by now heavily bearded\\nBuchanan finally got approval to investigate the shiny metal. As Mizar’s sled\\nmade its 74th run over the ocean floor, its magnetometer spiked high at\\nseveral anomalies in cell F6. Returning to the area on October 28, Mizar\\nstruggled to pinpoint the spot again. Finally its cameras revealed, lying on the\\nsea bottom, partially buried in sand, the submarine Scorpion. A poorly\\nfunctioning sonar detector had previously passed right over the sub without\\nfinding it. Word that Buchanan was shaving his beard spread rapidly to the\\nUnited States.\\nRichardson was back in the States when he got the phone call. “They gave\\nme the location in code,” he said, “and I plotted it up, and at first I thought it\\nwas going to plot right smack in the middle of that high probability square,\\nand I was really excited.” Instead, it was 260 yards away, close to the\\nmysterious piece of shiny metal found at the beginning of the search. The\\nscrap was later determined to be a Scorpion fragment. Still, Richardson\\njoked ruefully, 260 yards off in a 140-square mile area of open sea was\\n“close enough for government work.”\\nYears later, Captain Andrews argued that Bayes was only one day and a\\nhalf mile behind Buchanan. If Buchanan had not returned the Mizar to the\\nshiny metal that day, Craven’s presearch probabilities, updated with his later\\nacoustical studies, would have found Scorpion first.\\nOn November 1, five months after the search began, Rosenberg, the co-op\\nstudent from Drexel, hand-carried the photos of Scorpion back to the United\\nStates. Excluding time spent studying a misleadingly magnetic, hull-shaped\\nrock, the search sled had located the submarine after scanning 1,026 miles of\\nocean bottom at a speed of one knot for the equivalent of 43 days, two days\\nearlier than Bayesian predictions.\\nPresident Johnson was told “the highest probability was that the sinking\\nwas caused by an accident on board the submarine.”14 This time he may have\\nlistened to probabilities.\\nAnalyses of the sounds made by the Scorpion suggested that it had been\\ntraveling east, rather than west, when it sank. Twenty years later Craven\\nlearned that the sub could have been destroyed by a “hot-running torpedo.”\\nOther subs in the fleet had replaced their defective torpedo batteries, but the\\nnavy wanted Scorpion to complete its mission first. If Scorpion had fired a\\ndefective torpedo, it would have missed its target and probably turned back\\nand struck the sub that had launched it.\\nAnxious to document the methods used in the search for Scorpion, the\\nOffice of Naval Research commissioned Stone to write Theory of Optimal\\nSearch. Published in 1975, it is an unabashedly Bayesian book incorporating\\napplied mathematics, statistics, operations research, optimization theory, and\\ncomputer programs. Cheaper and more powerful computers were\\ntransforming Bayesian searches from mathematical and analytical problems\\nto algorithms for software programs. Stone’s book became a classic,\\nimportant for the military, the Coast Guard, fishermen, police, oil explorers,\\nand others.\\nWhile Stone was writing his book, the United States agreed to help Egypt\\nclear the Suez Canal of unexploded ammunition from the Yom Kippur war\\nwith Israel in 1973. The explosives made dredging dangerous. Using the\\nSEPs developed in Palomares, it was possible to measure the search\\neffectiveness to get the probability that, if a bomb had been there, it would\\nhave been spotted. But how could anyone estimate the number of bombs\\nremaining in the canal when no one knew how many were there to begin\\nwith? Wagner, Associates chose three priors with different probability\\ndistributions to express high, middle, and low numbers. Next, using the handy\\nsystem of conjugate priors described by Raiffa and Schlaifer in 1961, they\\ndeclared that each prior would have a posterior with the same class of\\nprobability distributions. This produced three tractable distributions\\n(Poisson, binomial, and negative binomial) complete with those statistical\\ndesiderata, mean values and standard deviations. Computing became “a\\npiece of cake,” Richardson reported, but it proved impossible to explain the\\nsystem to hardened ordinance-disposal specialists with missing fingers. In\\nthe end, no one talked about Bayes at Suez.\\nUp to this point, postwar Bayes had searched only for stationary objects like\\nbombs in a canal, or H-bombs and submarines on the ocean floor.\\nTechnically, these were simple problems. But shortly after the Suez Canal\\nwas cleared and Theory of Optimal Search was published, intensive efforts\\nwere made to adapt Bayesian methods to moving targets: civilian boats adrift\\nin predictable currents and winds.\\nThe technology was a perfect match for U.S. Coast Guard rescue\\ncoordinators like Joseph Discenza, whose job in the late 1960s was to\\nanswer the telephone when someone called saying, “My husband went out\\nfishing with my son, and they’re not back.”15 After checking area ports of call\\nfor the boat, he used a Coast Guard Search and Rescue Manual to estimate by\\nhand the target’s location and its probable drift.\\n“Like a dog with a bone in his teeth,” Discenza started to computerize the\\nCoast Guard’s manual.16 He studied search theory and earned a master’s\\ndegree at the Naval Postgraduate School in Monterey, California, and a Ph.D.\\nat New York University. Along the way Discenza discovered that ever since\\nthe Second World War the Coast Guard had been using the Bayesian search\\ntheory developed by Koopman to find U-boats in the open ocean. Discenza\\nfilled in the corporate memory gap between the 1940s and the 1970s. “The\\nCoast Guard was very Bayesian. Even when they’re doing it manually,\\nthey’re doing Bayes,” Stone said. But until Discenza, they were like early\\ncasualty actuaries, using Bayes’ rule without realizing it.\\nJoining forces with Discenza, Wagner’s company designed a computerized\\nsearch system based on Bayesian principles for the Coast Guard. A natural\\noutgrowth of the H-bomb and Scorpion searches, it combined clues about a\\nvessel’s original location and subsequent movements into a series of self-\\nconsistent scenarios and then weighted them as to their likelihood.\\nThe Coast Guard ruled that estimating probabilities and weights should be\\na group decision. Each individual involved should weight the scenarios\\nprivately before they were averaged or combined by consensus. Above all,\\nno scenario should be discarded. “To leave out subjective information is to\\nthrow away valuable information because there is no unique or ‘scientific’\\nway to quantify it,” Stone urged.17\\nWhat if a ship in distress radioed its position but a small plane reported\\nseeing it an hour later a hundred miles away? One or the other had made an\\nerror in position, but neither report should be ignored; both should be\\nassigned relative reliabilities. As Stone commented, “Discarding one of the\\npieces of information is in effect making the subjective judgment that its\\nweight is zero and the other weight is one.”\\nBayesian updating and, at Richardson’s insistence, Monte Carlo\\ntechniques were incorporated into the Coast Guard system in 1972, almost\\ntwo decades before university theorists popularized the method or the term\\n“filters.” The Monte Carlo methods estimated an enormous number of\\npossible latitudes, longitudes, velocities, times, and weights for each lost\\nship to pinpoint 10,000 possible target locations.\\nStone also used a Bayesian procedure, an early version of a Kalman filter,\\nto separate and concentrate the data or signals according to specified criteria\\nand to weigh each possible path of a target’s motion according to its\\nbelievability. The technique did not become popular among academics until\\nthe 1990s, but it saved military and space contractors immense amounts of\\ntime in the 1960s because their computers had little memory or power.\\nBefore Rudolf E. Kalman and Richard Bucy invented the procedure in 1961,\\neach original observation had to be completely recalculated every time a\\nnew one appeared; with the filter, new observations could be added without\\nhaving to do everything all over again. Kalman vehemently denied that\\nBayes’ theorem had anything to do with his invention, but Masanao Aoki\\nproved mathematically in 1967 that it can be derived directly from Bayes’\\nrule. Today, it is known as a Kalman or a Kalman-Bucy filter.\\nOnce Monte Carlo methods and filters were adopted, even untenable and\\nhighly improbable paths produced valuable information and helped searchers\\ndetermine which of the remaining paths were more likely. As more\\ninformation arrived from sensors, Coast Guard aircraft, weather reports, tide\\ntables, and charts of prevailing currents and winds, the data were converted\\ninto likelihood functions and then combined with priors about the target’s\\nmovements to predict its probable location. As data accumulated with each\\niteration, the filter concentrated a relatively small number of highly probable\\npaths.\\nThe Coast Guard’s system was up and running in 1974 when a tuna boat\\nsank off Long Beach, California. Two days later, purely by chance, a\\nfreighter found 12 of its survivors in a lifeboat. Using their new technology,\\nthe Coast Guard calculated backward from the chance rescue to the tuna\\nboat’s probable capsize point and then forward again using probability maps\\nof ocean currents and Bayesian updating. Armed with a Bayesian probability\\nmap, the Coast Guard rescued three more men the next day. Another\\nsuccessful search took place two years later after a ship capsized and sank\\nwhile crossing the Pacific. Five sailors took to sea in two life rafts. Twenty-\\ntwo days later, also by chance, two survivors were found in one of the rafts.\\nSix days after that, the same Coast Guard program found a third survivor,\\nwho had been adrift for 28 days.\\nBayes had found stationary objects lodged on the seafloor and had tracked\\nboats drifting with predictable ocean currents and the wind. But what about\\nlocating and following evasive prey, a Soviet submarine, say, or a moving\\ntarget operated by human beings? Could Bayes accommodate human\\nbehavior?\\n“It’s the Cold War, and there are submarines out there that are a threat to\\nthe U.S.,” recalled Richardson. “They’re moving targets, so why not do\\nsomething in antisubmarine warfare. . . . It started in the 1970s and continued\\nfor two decades, and I personally did a lot of work searching for subs in the\\nAtlantic Ocean and the Mediterranean.”\\nWhen the future vice admiral John “Nick” Nicholson took command of the\\nU.S. submarine fleet in the Mediterranean in 1975, he secured a 100,000\\ngrant from the ONR to bring Richardson to Naples for a year. It was one of\\nONR’s biggest contracts, and navy accountants considered it a waste of\\nmoney. But the Mediterranean was full of Soviet and NATO ships and\\nsubmarines eyeing one another; the Soviets alone had 50 vessels, including\\nten submarines. By the early 1970s the “Med” was so crowded that the U.S.\\nand Soviet governments signed a pact to reduce collisions. When the U.S.\\nNavy began routine tracking of Soviet subs in the Mediterranean in 1976,\\nNicholson thought Richardson and Bayes’ rule could help.\\nStarting from scratch, Richardson cranked intelligence information into an\\nantiquated computer in Naples: previous submarine tracks; particular types\\nof Soviet sub that were apt to take a particular route and perform certain\\nmaneuvers; and reports from sonobuoys, passive acoustic listening devices\\nthat were dropped by aircraft into fixed underwater surveillance systems.\\nUnlike Koopman’s purely objective analysis of radio transmissions and\\nsubmarine tracks during the Second World War, Richardson was making\\nsubjective assessments of the behavior of Soviet officers. He was also using\\nreal-time feedback of actual search results, something that submarine hunters\\nin the Second World War would have regarded as science fiction. To all this\\nintelligence data Richardson added the islands, sea mounts, and tight\\npassages in the region’s constricted geography. These natural obstacles\\nbecame surprisingly helpful features.\\nBy definition, tracking involves uncertainties and estimations that are far\\nfrom ideal. Parameters change as new data appear, and “to make matters\\nworse, the data can be remarkably uninformative and obtained from a number\\nof different sources,” as Stone wrote.18 An optical scanner might spot a\\ndistant periscope emerging a foot above the horizon for 10 seconds but fail to\\nidentify it as a submarine. Operators watching radar signals on their\\ncomputer screens could not always distinguish a sub from a surface ship.\\nArrays of acoustic hydrophones extended over the seafloor for hundreds of\\nmiles to detect low-frequency acoustic signals emitted by submarines, but\\ntheir data were often highly ambiguous. Different targets, for example,\\nradiated acoustic signals at the same or nearly the same frequency. Even the\\nocean distorted sounds. Sound waves bend with every change in water\\ntemperature, and the roar of breaking waves affects noise-to-signal ratios.\\nBayes’ common currency—probabilities—fused information gathered from\\nthese various sources. Amid such vague and ephemeral reports, Bayes’ rule\\nwas in its element.\\nOne summer day in 1976 a Soviet nuclear-powered submarine slipped\\nthrough the Strait of Gibraltar and entered the Mediterranean. It was a\\n5,600ton Echo II class vessel, armed with cruise missiles that could be fired\\nfrom the surface. The U.S. fleet tracked it as far as Italy before losing it. No\\none could tell when it would pass through the Sicily Straits into the eastern\\nMediterranean.\\nBesides the submarines under his command, Nicholson had been assigned\\nfour antisubmarine destroyers that pulled experimental sleds packed with\\ntrailing-wire sonar detectors. Arranging his forces across the Sicily Straits\\nso the destroyers would have a chance to detect the Soviet sub passing\\nthrough, Nicholson waited tensely. “The wait went on longer and longer than\\nall of our operations [intelligence] people were expecting,” Nicholson\\nrelated years later. “Tony kept working his program and he kept saying, ‘I\\nstill think there’s an x percent possibility that it hasn’t gone through yet.’”19\\nNicholson’s superiors were pressuring him to move his submarines and\\nsurface ships over to the eastern Mediterranean to look for the sub there. But\\nhe was an old hand at pressure; he had been executive officer and navigator\\nof the second nuclear submarine to go under the Arctic ice cap to the North\\nPole and had commanded the first nuclear sub to go from the Pacific to the\\nNorth Pole in the winter.\\nRichardson, still poring over the old computer, urged Nicholson to ignore\\nhis commander. “I think we should take at least one to two more days,” he\\nsaid. He estimated the probability that the sub had not yet slipped through the\\nstraits at about 55%. Nicholson didn’t know how much confidence to place\\nin Richardson’s system. It was new, it included subjective assessments of\\nhuman behavior, and it was being used for real-time decision making. But\\nRichardson was filling a void other intelligence and operations experts could\\nnot. Making a bold decision that could have destroyed his career, Nicholson\\ndecided to wait. “And, lo and behold, we made contact and were able to\\ntrack the guy through the Strait.” The Sixth Fleet was jubilant, and, as\\nRichardson described the reaction of the brass, “most everyone became a\\nbeliever” in Bayesian search methods.\\nThanks to the trailing-wire sonar detectors, every time the Soviet\\nsubmarine came to the surface in the eastern Mediterranean one of\\nNicholson’s destroyers was cruising nearby. Their skippers were under\\norders not to come too close to the sub, but, as Nicholson says, “These\\ndestroyer guys don’t listen very well.”\\nOne rather clear Sunday morning the Soviet submarine surfaced with its\\nsail (a metallic structure covering periscopes and masts) about four feet out\\nof the water. Waiting nearby was one of Nicholson’s destroyers, the 3,400ton\\nVoge. To everyone’s surprise, the Soviet sub turned toward the Voge and\\ncharged at full speed.\\nAs Nicholson recounts the story, “Everybody on the ship was taking\\npictures of this thing, the submarine moving along at 20 knots with its sail out\\nof the water, when the skipper of the surface ship slowed for some reason.\\nThe submarine skipper apparently didn’t keep his eye right on it, and the first\\nthing you know, the submarine rammed right into the Voge. We believe the\\nSoviet captain was trying to cut the trailing-wire sonar that had given him\\nsuch fits.”\\nThe sub was badly damaged, and its captain was relieved of his command\\nthat same night. The Voge was towed to France for repairs. The incident\\nproved the value of Richardson’s tracking and of trailing-wire sonar systems\\non surface ships. Later, Bayesian methods tracked Soviet submarines in the\\nAtlantic and Pacific, although after the breakup of the USSR in 1991 Russian\\nout-of-area submarine deployments were greatly reduced.\\n“The antisub warfare work was pretty much the highlight of things that\\nwere really Bayesian,” Richardson reflected. “. . . It was like being back in\\nSpain again. I was ten or fifteen years older, sitting up all night, running my\\ncomputer and briefing the admiral in the morning. . . . That’s kind of the\\nultimate happiness, when you can make things move around in the world\\nbased on your ideas.”\\nMeanwhile, the military that had been so slow to embrace Bayesian search\\ntheory was exploring its use for identifying asteroids speeding toward Earth\\nand for locating Soviet satellites as they orbited in space. In 1979 NATO\\nheld a symposium in Portugal to encourage the solution of “real problems”\\nwith Bayesian methods.\\nMost of the attendees were from the military, but Richardson and Stone\\ngave talks about their submarine hunts, while others spoke about search and\\nrescue and oil deposit exploration. Among the civilian attendees was Ray\\nHilborn, a newly minted zoology Ph.D. who was interested in saving the fish\\npopulations in the world’s oceans. He had gotten his first exposure to simple\\nBayesian applications at the East–West think tank run by Raiffa in Vienna six\\nyears earlier.\\nHilborn was struck by the fact that people at the NATO conference dealt\\nwith practical problems that required making decisions. His own job\\ninvolved setting legal limits on fishing for particular species, and, listening\\nto the speeches, he said to himself, “God, this really is the way to ask the\\nquestions I want to ask. Everyone who is actually involved in the real world\\ndoes things in a Bayesian way. The limit of [frequentist] approaches just isn’t\\nobvious until you actually have to make some decisions. You have to be able\\nto ask, ‘What are the alternative states of nature, and how much do I believe\\nthey’re true?’ [Frequentists] can’t ask that question. Bayesians, on the other\\nhand, can compare hypotheses.”20 It would take him almost 10 years to find a\\nfisheries problem for Bayes, but Hilborn was a patient man.\\npart V\\nvictory\\n \\n16.\\n \\neureka!\\n \\nAs the computer revolution flooded the modern world with data, Bayes’ rule\\nfaced one of its biggest crises in 250 years. Was an eighteenth-century theory\\n—discovered when statistical facts were scarce and computation was slow\\nand laborious—doomed to oblivion? It had already survived five near-fatal\\nblows: Bayes had shelved it; Price published it but was ignored; Laplace\\ndiscovered his own version but later favored his frequency theory;\\nfrequentists virtually banned it; and the military kept it secret.\\nBy 1980 anyone studying the environment, economics, health, education,\\nor social science was tap-tapping data into a terminal connected to a\\nmainframe computer. “Input” became a verb. Medical records, for example,\\nincluded dozens of measurements of every patient, ranging from age, gender,\\nand race to blood pressure, weight, heart attacks, and smoking history. Wine\\nstatistics included chemical measurements and quality scores for every\\nvintner, varietal, and vintage.\\nBut who knew which of the 20-odd attributes of a patient or a wine were\\nimportant? Researchers needed to analyze more than one unknown at once,\\ncalculate the relationships among multiple variables, and determine the effect\\nthat a change in one had on others. Yet real-life facts did not fall into tidy\\nbell-shaped curves, and each time the variables were refined, more\\nunknowns cropped up. Computers were generating a multivariate revolution\\nand spawning a plague of unknowns called the curse of high-dimensionality.\\nStatisticians had to wonder whether a method ideal for tossing a few gold\\ncoins could adapt to the new world.\\nBayesians were still a small and beleaguered band of a hundred or more in\\nthe early 1980s. Computations took forever, so most researchers were still\\nlimited to “toy” problems and trivialities. Models were not complex enough.\\nThe title of a meeting held in 1982, “Practical Bayesian Statistics,” was a\\nlaughable oxymoron. One of Lindley’s students, A. Philip Dawid of\\nUniversity College London, organized the session but admitted that\\n“Bayesian computation of any complexity was still essentially impossible. . .\\n. Whatever its philosophical credentials, a common and valid criticism of\\nBayesianism in those days was its sheer impracticability.”1\\nThe curse of dimensionality plagued both Bayesians and frequentists.\\nMany in the academic statistical community still debated whether to indulge\\nin computer-intensive analysis at all. Most statisticians of the era were\\nmathematicians, and many confused their beloved old calculators—their\\nmanual Brunsvigas and electric Facits—with the new electronic computers.\\nThey tried to analyze the new data with methods designed for old calculating\\ntools. One statistician boasted that his calculating procedure consisted of\\nmarching into his university’s computer center and saying, “Get on with it.”2\\nThanks to pioneers like Robert Schlaifer and Howard Raiffa, Bayesians held\\nsway in business schools and theoretical economics, while statistics\\ndepartments were dominated by frequentists, who focused on data sets with\\nfew unknowns rather than on those packed with unknowns.\\nAs a result, many statistics departments watched from the sidelines as\\nphysical and biological scientists analyzed data about plate tectonics,\\npulsars, evolutionary biology, pollution, the environment, economics, health,\\neducation, and social science. Soon engineers, econometricians, computer\\nscientists, and information technologists acquired the cachet that humdrum\\nstatisticians seemed to lack. Critics sniffed that statistics departments were\\nisolated, defensive, and on the decline. Leading statistical journals were said\\nto be so mathematical that few could read them and so impractical that few\\nwould want to. The younger generation seemed to think that computers and\\ntheir algorithms could replace mathematics entirely.\\nIn what could have been a computational breakthrough, Lindley and his\\nstudent Adrian F. M. Smith showed Bayesians how to develop models by\\nbreaking complex scientific processes into stages called hierarchies. The\\nsystem would later become a Bayesian workhorse, but at the time it fell flat\\non its face. The models were too specialized and stylized for many scientific\\napplications. It would be another 20 years before Bayesian textbooks taught\\nhierarchical models. Mainstream statisticians and scientists simply did not\\nbelieve that Bayes could ever be practical. Indicative of their attitude is the\\nfact that while Thomas Bayes’ clerical ancestors were listed in Britain’s\\nDictionary of National Biography he himself was not.\\nYet amazingly, amid these academic doubts, a U.S. Air Force contractor\\nused Bayes to analyze the risk of a Challenger space shuttle accident. The\\nair force had sponsored Albert Madansky’s Bayesian study at the RAND\\nCorporation during the Cold War, but the National Aeronautics and Space\\nAdministration (NASA) still distrusted subjective representations of\\nuncertainty. Consequently, it was the air force that sponsored a review in\\n1983 of NASA’s estimates of the probability of a shuttle failure. The\\ncontractor, Teledyne Energy Systems, employed a Bayesian analysis using\\nthe prior experience of 32 confirmed failures during 1,902 rocket motor\\nlaunches. Using “subjective probabilities and operating experience,”\\nTeledyne estimated the probability of a rocket booster failure at 1 in 35;\\nNASA’s estimate at the time was 1 in 100,000. Teledyne, however, insisted\\nthat “the prudent approach is to rely on conservative failure estimates based\\non prior experience and probabilistic analysis.”3 On January 28, 1986,\\nduring the shuttle’s twenty-fifth launch, the Challenger exploded, killing all\\nseven crew members aboard.\\nThe disparity between the military’s sometime acceptance of Bayes and the\\nacademic statistical community’s refusal to embrace it is still puzzling. Did\\nthe military’s top-secret experience with Bayes during the Second World War\\nand the Cold War give it confidence in the method? Was the military less\\nafraid of using computers? Or did it simply have easier access to powerful\\nones? Given that many sources dealing with the Second World War and the\\nCold War are still classified, we may never know the answers to these\\nquestions.\\nSeveral civilian researchers tackling hitherto intractable problems\\nconcerning public health, sociology, epidemiology, and image restoration did\\nexperiment during the 1980s with computers for Bayes. A major controversy\\nabout the effect of diesel engine emissions on air quality and cancer inspired\\nthe first attempt. By the 1980s cancer specialists had solid data about the\\neffects of cigarette smoke on people, laboratory animals, and cells but little\\naccurate information about diesel fumes. William H. DuMouchel from MIT’s\\nmathematics department and Jeffrey E. Harris from its economics department\\nand Massachusetts General Hospital teamed up in 1983 to ask, “Could you\\nborrow and extrapolate and take advantage of information from non-human\\nspecies for humans?”4 Such meta-analyses, combining the results of similar\\ntrials, were too complex for frequentists to address, but DuMouchel was a\\ndisciple of Smith and his hierarchical work with Lindley. Harris was not a\\nstatistician and did not care what method he used as long as it answered the\\nquestion. Adopting hierarchical Bayes, they borrowed information from\\nlaboratory tests on mice, hamster embryo cells, and chemical substances.\\nThey even incorporated experts’ opinions about the biological relevance of\\nnonhumans to humans and of cigarette to diesel smoke. Bayes let them\\naccount formally for their uncertainties about combining information across\\nspecies.\\nMicrocomputers were not widely available. Many of the researchers\\nstudying the new acquired immune deficiency syndrome (AIDS) epidemic,\\nfor example, were making statistical calculations by hand, and mathematical\\nshortcuts were still being published for them. Harris programmed the diesel\\nproject in APL, a language used for matrix multiplications, and sent it via\\nteletype to MIT’s computer center. He drew illustrations on poster boards,\\nadded captions by pressing on wax letters, and arranged for an MIT\\nphotographer to take their pictures.\\nThanks to mice and hamster studies, DuMouchel and Harris were able to\\nconclude that even if light-duty diesel vehicles captured a 25% market share\\nover 20 years, the risk of lung cancer would be negligible for the typical\\nurban resident compared to the typical pack-a-day cigarette smoker. The\\nsmoker’s risk was 420,000 times worse. Today, Bayesian meta-analyses are\\nstatistically old hat, but DuMouchel and Harris made Bayesians salivate for\\nmore big-data methods—and for the computing power to deal with them.\\nWhile lung cancer researchers explored Bayes, Adrian Raftery was\\nworking at Trinity College in Dublin on a well-known set of statistics about\\nfatal coal-dust explosions in nineteenth-century British mines. Previous\\nresearchers had used frequency techniques to show that coal mining accident\\nrates had changed over time. They assumed, however, that the change had\\nbeen gradual. Raftery wanted to check whether it had been gradual or abrupt.\\nFirst, he developed some heavy frequentist mathematics for analyzing the\\ndata. Then, out of curiosity, he experimented with Bayes’ rule, comparing a\\nvariety of theoretical models to see which had the highest probability of\\ndetermining when the accidents rates actually changed. “I found it very easy.\\nI just solved it very, very quickly,” Raftery recalled. And in doing so he\\ndiscovered a remarkable, hitherto unknown event in British history. Raftery’s\\nBayesian analysis revealed that accident rates plummeted suddenly in the late\\n1880s or early 1890s. A historian friend suggested why. In 1889, British\\nminers had formed the militant Miners’ Federation (which later became the\\nNational Union of Mine Workers). Safety was their number one issue. Almost\\novernight, coal mines got safer.\\n“It was a Eureka moment,” Raftery said. “It was quite a thrill. And without\\nBayesian statistics, it would have been much harder to do a test of this\\nhypothesis.”5 Frequency-based statistics worked well when one hypothesis\\nwas a special case of the other and both assumed gradual behavior. But when\\nhypotheses were competing and neither was a special case of the other,\\nfrequentism was not as helpful, especially with data involving abrupt\\nchanges—like the formation of a militant union.\\nRaftery wound up publishing two papers in 1986 about modeling abrupt\\nrate changes. His first, frequentist paper was long, dense, and virtually\\nunread. His second, Bayesian paper was shorter, simpler, and had a much\\ngreater impact. Raftery’s third 1986 paper ran just 1-1/4 pages and had an\\nimmediate effect on sociologists. The article appeared just as many\\nsociologists were about to give up on frequentism’s controversial p-values.\\nA typical sociologist might work with data sets about thousands of\\nindividuals, each with hundreds of variables such as age, race, religion,\\nclimate, and family structure. Unfortunately, when researchers tried to\\ndetermine the relevance of those variables using frequentist methods\\ndeveloped by Karl Pearson and R. A. Fisher for 50 to 200 cases, the results\\nwere often bizarre. Obscure effects became important, or went in opposite\\ndirections, or were disproved by later studies. By selecting a single model\\nfor large samples, frequentists ignored uncertainties about the model. Yet few\\nsocial scientists could repeat their surveys or rerun experiments under\\nprecisely the same conditions. By the early 1980s many sociologists had\\nconcluded that, for testing hypotheses, their intuition was more accurate than\\nfrequentism.\\nBayes, on the other hand, seemed to produce results that corresponded\\nmore closely to sociologists’ intuition. Raftery told his colleagues, “The\\npoint is that we should be comparing the models, not just looking for\\npossibly minor discrepancies between one of them and the data.”6\\nResearchers really want to know which of their models is more likely to be\\ntrue, given the data. With Bayes, researchers could study sudden shifts from\\none stable form to another in biological growth phases, trade deficits and\\neconomic behavior, the abandonment and resettlement of archaeological\\nsites, and clinical conditions such as rejection and recovery in organ\\ntransplantation and brain waves in Parkinson’s disease. Bayesian hypothesis\\ntesting swept sociology and demography, and Raftery’s short paper is still\\namong the most cited in sociology.\\nMeanwhile, image processing and analysis had become critically\\nimportant for the military, industrial automation, and medical diagnosis.\\nBlurry, distorted, imperfect images were coming from military aircraft,\\ninfrared sensors, ultrasound machines, photon emission tomography,\\nmagnetic resonance imaging (MRI) machines, electron micrographs, and\\nastronomical telescopes. All these images needed signal processing, noise\\nremoval, and deblurring to make them recognizable. All were inverse\\nproblems ripe for Bayesian analysis.\\nThe first known attempt to use Bayes to process and restore images\\ninvolved nuclear weapons testing at Los Alamos National Laboratory. Bobby\\nR. Hunt suggested Bayes to the laboratory and used it in 1973 and 1974. The\\nwork was classified, but during this period he and Harry C. Andrews wrote\\na book, Digital Image Restoration, about the basic methodology; the\\nlaboratory declassified the book and approved its publication in 1976. The\\nU.S. Congress retained Hunt in 1977 and 1978 to analyze images of the\\nshooting of President Kennedy. In his testimony, Hunt did not refer to Bayes.\\n“Too technical for a Congressional hearing,” he said later.\\nAt almost the same time that Hunt was working on image analysis for the\\nmilitary, Julian Besag at the University of Durham in England was using\\ndiseased tomato plants to study the spread of epidemics. Bayes helped him\\ndiscern local regularities and neighborly interactions among plants growing\\nin pixel-like lattice systems. Looking at one pixel, Besag realized he could\\nestimate the probability that its neighbor might share the same color, a useful\\ntool for image enhancement. But Besag was not a card-carrying Bayesian,\\nand his work went largely unnoticed at the time.\\nA group of researchers with Ulf Grenander at Brown University was\\ntrying to design mathematical models for medical imaging by exploring the\\neffect one pixel could have on a few of its neighbors. The calculations\\ninvolved easily a million unknowns. Grenander thought that once Bayes was\\nembedded in a realistic problem, philosophical objections to it would fade.\\nStuart Geman was attending Grenander’s seminar in pattern theory, and he\\nand his brother Donald Geman tried restoring a blurry photograph of a\\nroadside sign. The Gemans were interested in noise reduction and in finding\\nways to capture and exploit regularities to sharpen the lines and edges of\\nunfocused images. Stuart had majored in physics as an undergraduate and\\nknew about Monte Carlo sampling techniques. So the Geman brothers\\ninvented a variant of Monte Carlo that was particularly suited to imaging\\nproblems with lots of pixels and lattices.\\nSitting at a table in Paris, Donald Geman thought about naming their\\nsystem. A popular Mother’s Day gift at the time was a Whitman’s Sampler\\nassortment of chocolate bonbons; a diagram inside the box top identified the\\nfilling hidden inside each candy. To Geman, the diagram was a matrix of\\nunknown but enticing variables. “Let’s call it Gibbs sampler,” he said, after\\nJosiah Willard Gibbs, a nineteenth-century American physicist who applied\\nstatistical methods to physical systems.7\\nThe dots were starting to connect. But the Gemans, like Besag, operated in\\na small niche field, spatial statistics. And instead of nibbling at their problem\\na pixel at a time, the Gemans tried gobbling it whole. Working at pixel levels\\non a 64 x 64-cell fragment of a photo, they produced too many unknowns for\\ncomputers of the day to digest. They wrote up their sampler in a formidably\\ndifficult paper and published it in 1984 in IEEE Transactions on Pattern\\nAnalysis and Machine Intelligence. Specialists in image processing, neural\\nnetworks, and expert systems quickly adopted the method, which, with\\ncomputers gaining more power every year, also sparked the interest of some\\nstatisticians. The brothers spent the next year racing around the globe giving\\ninvited talks.\\nDonald Geman used the Gibbs sampler to improve satellite images; Stuart\\nused it for medical scans. Several years later, statisticians outside the small\\nspatial imaging community began to realize that more general versions could\\nbe useful. The Gibbs sampler’s flexibility and reliability would make it the\\nmost popular Monte Carlo algorithm. Still later the West learned that a\\nRussian dissident mathematician, Valentin Fedorovich Turchin, had\\ndiscovered the Gibbs sampler in 1971, but his work had been published in\\nRussian-language journals, did not involve computers, and was overlooked.\\nBy 1985 the old argument between Bayesians and frequentists was losing\\nits polarizing zing, and Glenn Shafer of Rutgers University thought it had\\n“calcified into a sterile, well-rehearsed argument.” Persi Diaconis made a\\nsimilar but nonetheless startling observation, one that no one familiar with\\nthe battles between Bayesians, Karl Pearson, Ronald Fisher, and Jerzy\\nNeyman could have imagined. “It’s nice that our field is so noncompetitive,”\\nDiaconis said. “If you take many other fields, like biology, people just slice\\neach other up.”8\\nStill, the conviction remained that without more powerful and accessible\\ncomputers and without user-friendly and economical software, computing\\nrealistic problems with Bayes was impossible.\\nLindley had been programming his own computers since 1965 and\\nregarded Bayes as ideal for computing: “One just feeds in the axioms and the\\ndata and allows the computer to follow the laws of arithmetic.” He called it\\n“turning the Bayesian crank.” But his student Smith saw something the older\\nman did not: the key to making Bayes useful in the workplace would be\\ncomputational ease, not more polished theory. Later Lindley wrote, “I\\nconsider it a major mistake of my professional life, not to have appreciated\\nthe need for computing rather than mathematical analysis.”9\\nIgnoring the defensive posture of many statistics departments, Smith\\nlaunched an offensive in a radically new direction. Smith’s friends think of\\nhim as a lively, practical man with street smarts, people skills, and a can-do\\npersonality, the kind of person more comfortable in running shorts than\\nacademic garb. He was certainly willing to do the dirty work needed to make\\nBayes practical. He learned Italian to help translate de Finetti’s two-volume\\nTheory of Probability and then got it published. For the first time de Finetti’s\\nsubjectivist approach was widely available to Anglo-American statisticians.\\nSmith also developed filters, practical computer devices that would ease\\nBayesian computations enormously.\\nNext, Smith and three others—Lindley, José M. Bernardo, and Morris\\nDeGroot—organized an international conference series for Bayesians in\\nValencia, Spain. It has been held regularly since 1979. Smith expected “the\\nusual criticism from nonBayesians in reaction to whatever I say.” Sure\\nenough, frequentists accused Bayesians of sectarian habits, meetings in\\nremote locations, and mock cabarets featuring skits and songs with Bayesian\\nthemes. Other disciplines have done the same, of course. The conferences\\nplayed a vital role in helping to build camaraderie in a small field under\\nattack.\\nIn 1984 Smith issued a manifesto—and italicized it for emphasis:\\n“Efficient \\nnumerical \\nintegration \\nprocedures \\nare \\nthe \\nkey \\nto \\nmore\\nwidespread use of Bayesian methods.”10 With computerized data collection\\nand \\nstorage, \\nhand \\nanalyses \\nwere \\nbecoming \\nimpossible. \\nWhen\\nmicrocomputers appeared, attached to fast networks with graphics and vast\\nstorage capabilities, data analysts could finally hope to improvise as easily\\nas they had with pencil and paper. With characteristic practicality, Smith set\\nhis University of Nottingham students to work developing efficient, user-\\nfriendly software for Bayesian problems in spatial statistics and\\nepidemiology.\\nIntrigued with Smith’s projects, Alan Gelfand at the University of\\nConnecticut asked Smith if he could spend his sabbatical year at Nottingham.\\nWhen Gelfand arrived, Smith suggested they start something new. Gelfand\\nrecalled, “He gave me this Tanner and Wong paper, saying, ‘This is kind of\\nan interesting paper. There must be something more to it.’” Wing Hung Wong\\nand Martin A. Tanner, at the Universities of Chicago and Wisconsin,\\nrespectively, were interested in spatial image analysis for identifying genetic\\nlinkages and for scanning the brain using positron emission tomography\\n(PET). Wong had been adapting for Bayesians the EM algorithm, an iterative\\nsystem secretly developed by the National Security Agency during the\\nSecond World War or the early Cold War. Arthur Dempster and his student\\nNan Laird at Harvard discovered EM independently a generation later and\\npublished it for civilian use in 1977. Like the Gibbs sampler, the EM\\nalgorithm worked iteratively to turn a small data sample into estimates likely\\nto be true for an entire population.\\nGelfand was studying the Wong paper when David Clayton from the\\nUniversity of Leicester dropped by and said, “Oh, the paper by Geman and\\nGeman has something to do with it, I think.” Clayton had written a technical\\nreport which, although never published, concerned Gibbs sampling. The\\nminute Gelfand saw the Gemans’ paper, the pieces came together: Bayes,\\nGibbs sampling, Markov chains, and iterations. A Markov chain can be\\ncomposed of scores of links, and for each one a range of possible variables\\nmust be sampled and calculated one after another. Anyone studying a rare and\\nsubtle effect must compute each chain over and over again to get a big enough\\nnumber to reveal the rarity. The numbers involved become enormous, and the\\nlength and tediousness of the calculations turned off most researchers.\\nBut Gelfand and Smith saw that replacing difficult integration with\\nsampling would be a wonderful computational tool for Bayesians. “It went\\nback to the most basic things you learn in an introductory statistics course,”\\nGelfand explained. “If you want to learn about a distribution or a population,\\nyou take samples from it. But don’t sample directly.” Imaging and spatial\\nstatisticians had been looking at local models as a whole, but Gelfand and\\nSmith realized they should build long chains, series of observations\\ngenerated one or two at a time, one after another. As Gelfand explained, “The\\ntrick was to look at simple distributions one at a time but never look at the\\nwhole. The value of each one depended only on the preceding value. Break\\nthe problem into tiny pieces that are easy to solve and then do millions of\\niterations. So you replace one high-dimensional draw with lots of low-\\ndimensional draws that are easy. The technology was already in place. That’s\\nhow you break the curse of high-dimensionality.”11\\nSmith and Gelfand wrote their article as fast as they could. The elements\\nof their system were already known, but their grand synthesis was new. Once\\nothers thought about it, they’d realize the importance of the method too.\\nWhen Smith spoke at a workshop in Quebec in June 1989, he showed that\\nMarkov chain Monte Carlo could be applied to almost any statistical\\nproblem. It was a revelation. Bayesians went into “shock induced by the\\nsheer breadth of the method.”12 By replacing integration with Markov chains,\\nthey could finally, after 250 years, calculate realistic priors and likelihood\\nfunctions and do the difficult calculations needed to get posterior\\nprobabilities.\\nTo outsiders, one of the amazing aspects of Bayes’ history is that physicists\\nand statisticians had known about Markov chains for decades. To illustrate\\nthis puzzling lapse, some flashbacks are required. Monte Carlo began in\\n1906, when Andrei Andreyevich Markov, a Russian mathematician, invented\\nMarkov chains of variables. The calculations took so long, though, that\\nMarkov himself applied his chains only to the vowels and consonants in a\\nPushkin poem.\\nThirty years later, with the beginning of nuclear physics in the 1930s, the\\nItalian physicist Enrico Fermi was studying neutrons in collision reactions.\\nFermi fought insomnia by computing Markov chains in his head to describe\\nthe paths of neutrons in collision reactions. To the surprise of his colleagues\\nthe next morning, Fermi could predict their experimental results. With a small\\nmechanical adding machine, Fermi built Markov chains to solve other\\nproblems too. Physicists called the chains statistical sampling.\\nFermi did not publish his methods, and, according to Jack Good,\\ngovernment censorship kept Markov chains under tight wraps during the\\nSecond World War. After the war Fermi helped John von Neumann and\\nStanislaw Ulam develop the technique for hydrogen-bomb developers using\\nthe new ENIAC computer at the University of Pennsylvania. To calculate the\\ncritical mass of neutrons needed to make a thermonuclear explosion, Maria\\nGoeppert Mayer, a future Nobel Prize–winning physicist, simulated the\\nprocess with Markov chains, following one neutron at a time and making\\ndecisions at various places as to whether the neutron was most likely to get\\nabsorbed, escape, die, or fission. The calculation was too complicated for\\nexisting IBM equipment, and many thought the job was also beyond\\ncomputers. But Mayer reported that it did “not strain the capacity of the\\nEniac.”13 In 1949 she spoke at a symposium organized by the National\\nBureau of Standards, Oak Ridge National Laboratory, and RAND for\\nphysicists to brief mathematicians and statisticians on hitherto classified\\napplications.\\nThat same year Nicholas Metropolis, who had named the algorithm Monte\\nCarlo for Ulam’s gambling uncle, described the method in general terms for\\nstatisticians in the prestigious Journal of the American Statistical\\nAssociation. But he did not detail the algorithm’s modern form until 1953,\\nwhen his article appeared in the Journal of Chemical Physics, which is\\ngenerally found only in physics and chemistry libraries. Moreover, he and his\\ncoauthors—two husband-and-wife teams, Arianna and Marshall Rosenbluth\\nand Augusta and Edward Teller—were concerned strictly with particles\\nmoving around a square. They did not generalize the method for other\\napplications. Thus it was physicists and chemists who pioneered Monte\\nCarlo methods. Working on early computers with between 400 and 80,000\\nbytes of memory, they dealt with memory losses, unreadable tapes, failed\\nvacuum tubes, and programming in assembly language. Once it took literally\\nmonths to track down a small programming error. In the 1950s RAND\\ndeveloped a lecture series on Monte Carlo techniques and used them in a\\nspecially built simulation laboratory to test case after case of problems too\\ncomplex for mathematical formulas.\\nDuring this difficult period, statisticians were advised several more times\\nto use Monte Carlo either with or without computers. In 1954 two\\nstatisticians associated with the British Atomic Energy Research\\nEstablishment recommended that readers of the Journal of the Royal\\nStatistical Society consult “Poor Man’s Monte Carlo” for pen-and-paper\\ncalculations; John M. Hammersley and Keith W. Morton said Monte Carlo\\nwas as easy as “simple knitting.” Lindley described Markov chains in 1965\\nin a text for college students.\\nIn a particularly poignant case, W. Keith Hastings, a mathematician at the\\nUniversity of Toronto, was approached by chemists who were studying 100\\nparticles interacting with each other while subject to outside forces. Because\\nof the 600 variables in the case, Hastings said he immediately realized the\\nimportance of Markov chains for mainstream statistics and devoted all his\\ntime to them: “I was excited because the underlying idea goes way back to\\nMetropolis. As soon as I realized it, it was off to the races. I just had to work\\non it. I had no choice.” In 1970 he published a paper generalizing\\nMetropolis’s algorithm in the statistical journal Biometrika. Again,\\nBayesians ignored the paper. Today, computers routinely use the Hastings–\\nMetropolis algorithm to work on problems involving more than 500,000\\nhypotheses and thousands of parallel inference problems.\\nHastings was 20 years ahead of his time. Had he published his paper when\\npowerful computers were widely available, his career would have been very\\ndifferent. As he recalled, “A lot of statisticians were not oriented toward\\ncomputing. They take these theoretical courses, crank out theoretical papers,\\nand some of them want an exact answer.”14 The Hastings–Metropolis\\nalgorithm provides estimates, not precise numbers. Hastings dropped out of\\nresearch and settled at the University of Victoria in British Columbia in\\n1971. He learned about the importance of his work after his retirement in\\n1992. Why did it take statisticians so long to understand the implications of\\nan old method? And why were Gelfand and Smith first? “The best thing I can\\nsay for us is that we just sort of stumbled on it. We got lucky,” Gelfand says\\ntoday. “It was just sort of sitting there, waiting for people to put the pieces\\ntogether.”\\nTiming was important too. Gelfand and Smith published their synthesis just\\nas cheap, high-speed desktop computers finally became powerful enough to\\nhouse large software packages that could explore relationships between\\ndifferent variables. Bayes was beginning to look like a theory in want of a\\ncomputer. The computations that had irritated Laplace in the 1780s and that\\nfrequentists avoided with their variable-scarce data sets seemed to be the\\nproblem—not the theory itself.\\nYet Smith and Gelfand still thought of Monte Carlo as a last resort to be\\nused in desperation for complicated cases. They wrote diffidently, careful to\\nuse the B-word only five times in 12 pages. “There was always some\\nconcern about using the B-word, a natural defensiveness on the part of\\nBayesians in terms of rocking the boat,” Gelfand said. “We were always an\\noppressed minority, trying to get some recognition. And even if we thought\\nwe were doing things the right way, we were only a small component of the\\nstatistical community and we didn’t have much outreach into the scientific\\ncommunity.”15\\nThe Gelfand–Smith paper was an “epiphany in the world of statistics,” as\\nBayesians Christian P. Robert and George Casella reported. And just in case\\nanyone missed their point, they added: “Definition: epiphany n. A spiritual\\nevent . . . a sudden flash of recognition.” Years later, they still described its\\nimpact in terms of “sparks,” “flash,” “shock,” “impact,” and “explosion.”16\\nShedding their diffidence, Gelfand and Smith wrote a second paper six\\nmonths later with Susan E. Hills and Amy Racine-Poon. This time they\\npunctuated their mathematics exuberantly with words like “surprising,”\\n“universality,” “versatility,” and “trivially implemented.” They concluded\\ngrandly, “The potential of the methodology is enormous, rendering\\nstraightforward the analysis of a number of problems hitherto regarded as\\nintractable from a Bayesian perspective.”17 Luke Tierney at Carnegie Mellon\\ntied the technique to Metropolis’s method, and the entire process—which\\nphysicists had called Monte Carlo—was baptized anew as Markov chain\\nMonte Carlo, or MCMC for short. The combination of Bayes and MCMC has\\nbeen called “arguably the most powerful mechanism ever created for\\nprocessing data and knowledge.”18\\nWhen Gelfand and Smith gave an MCMC workshop at Ohio State\\nUniversity early in 1991, they were astonished when almost 80 scientists\\nappeared. They weren’t statisticians, but they had been using Monte Carlo in\\narchaeology, genetics, economics, and other subjects for years.\\nThe next five years raced by in a frenzy of excitement. Problems that had\\nbeen nightmares cracked open as easily as eggs for an omelet. A dozen years\\nearlier the conference title “Practical Bayesian Statistics” had been a joke.\\nBut after 1990 Bayesian statisticians could study data sets in genomics or\\nclimatology and make models far bigger than physicists could ever have\\nimagined when they first developed Monte Carlo methods. For the first time,\\nBayesians did not have to oversimplify “toy” assumptions.\\nOver the next decade, the most heavily cited paper in the mathematical\\nsciences was a study of practical Bayesian applications in genetics, sports,\\necology, sociology, and psychology. The number of publications using\\nMCMC increased exponentially.\\nAlmost instantaneously MCMC and Gibbs sampling changed statisticians’\\nentire method of attacking problems. In the words of Thomas Kuhn, it was a\\nparadigm shift.19 MCMC solved real problems, used computer algorithms\\ninstead of theorems, and led statisticians and scientists into a world where\\n“exact” meant “simulated” and repetitive computer operations replaced\\nmathematical equations. It was a quantum leap in statistics.\\nWhen Smith and Gelfand published their paper, frequentists could do a\\nvast amount more than Bayesians. But within years Bayesians could do more\\nthan frequentists. In the excitement that followed, Stanford statistician Jun S.\\nLiu, working with biologist Charles E. Lawrence, showed genome analysts\\nthat Bayes and MCMC could reveal motifs in protein and DNA. The\\ninternational project to sequence the human genome, launched in 1990, was\\ngenerating enormous amounts of data. Liu showed how a few seconds on a\\nworkstation programmed for Bayes and iterative MCMC sampling could\\ndetect subtle, closely related patterns in protein and nucleic acid sequences.\\nThen he and Lawrence could infer critical missing data pointing to common\\nancestors, structures, and functions. Soon genomics and computational\\nbiology were so overrun with researchers that Gelfand decided to look\\nelsewhere for another research project.\\nBetween 1995 and 2000 Bayesians developed particle filters like the\\nKalman filter and real-time applications in finance, image analysis, signal\\nprocessing, and artificial intelligence. The number of attendees at Bayesian\\nconferences in Valencia quadrupled in 20 years. In 1993, more than two\\ncenturies after his death, Thomas Bayes finally joined his clerical relatives\\nin the Dictionary of National Biography.\\nAmid the Bayesian community’s frenzy over MCMC and Gibbs sampling, a\\ngeneric software program moved Bayesian ideas out into the scientific and\\ncomputer world.\\nIn an example of serendipity, two groups 80 miles apart worked\\nindependently during the late 1980s on different aspects of the same problem.\\nWhile Smith and Gelfand were developing the theory for MCMC in\\nNottingham, Smith’s student, David Spiegelhalter, was working in\\nCambridge at the Medical Research Council’s biostatistics unit. He had a\\nrather different point of view about using Bayes for computer simulations.\\nStatisticians had never considered producing software for others to be part of\\ntheir jobs. But Spiegelhalter, influenced by computer science and artificial\\nintelligence, decided it was part of his. In 1989 he started developing a\\ngeneric software program for anyone who wanted to use graphical models\\nfor simulations. Once again, Clayton was an important influence.\\nSpiegelhalter unveiled his free, off-the-shelf BUGS program (short for\\nBayesian Statistics Using Gibbs Sampling) in 1991.\\nBUGS caused the biggest single jump in Bayesian popularity. It is still the\\nmost popular software for Bayesian analyses, and it spread Bayesian\\nmethods around the world.\\n“It wasn’t a very big project,” Spiegelhalter admits. “It was a staggeringly\\nbasic and powerful idea, relating Gibbs sampling to a graph to write generic\\nprograms.”20 Its simple code remains almost exactly the same today as it was\\nin 1991.\\nEcologists, sociologists, and geologists quickly adopted BUGS and its\\nvariants, WinBUGS for Microsoft users, LinBUGS for Linux, and\\nOpenBUGS. But computer science, machine learning, and artificial\\nintelligence also joyfully swallowed up BUGS. Since then it has been\\napplied to disease mapping, pharmacometrics, ecology, health economics,\\ngenetics, archaeology, psychometrics, coastal engineering, educational\\nperformance, \\nbehavioral \\nstudies, \\neconometrics, \\nautomated \\nmusic\\ntranscription, sports modeling, fisheries stock assessment, and actuarial\\nscience. A Bayesian visiting a marine laboratory was surprised to discover\\nall its scientists using BUGS with nary a statistician in sight.\\nMedical research and diagnostic testing were among the earliest\\nbeneficiaries of Bayes’ new popularity. Just as the MCMC frenzy appeared\\nto be moderating, Peter Green of Bristol University showed Bayesians how\\nto compare the elaborate hypotheses that scientists call models. Before 1996\\nanyone making a prediction about the risk of a stroke had to focus on one\\nmodel at a time. Green showed how to jump between models without\\nspending an infinite time on each. Previous studies had identified 10 possible\\nfactors involved in strokes. Green identified the top four: systolic blood\\npressure, exercise, diabetes, and daily aspirin.\\nMedical testing, in particular, benefited from Bayesian analysis. Many\\nmedical tests involve imaging, and Larry Bretthorst, a student of the Bayesian\\nphysicist Ed Jaynes, improved nuclear magnetic resonancing, or NMR, signal\\ndetection by several orders of magnitude in 1990. Bretthorst had studied\\nimaging problems to improve the detection of radar signals for the Army\\nMissile Command.\\nIn 1991 a public frightened about the AIDS epidemic demanded universal\\nscreening for human immunodeficiency virus (HIV). Biostatisticians quickly\\nused Bayes to demonstrate that screening the entire population for a rare\\ndisease would be counterproductive. Wesley O. Johnson and Joseph L.\\nGastwirth showed that a sensitive test like that for HIV virus would tell many\\npatients they were infected with HIV when in fact they were not. The media\\npublicized several suicides of people who had received a positive HIV test\\nresult but not realized they did not necessarily have the virus. Scaring healthy\\npeople and retesting them with more sophisticated procedures would have\\nbeen extremely costly.\\nIn much the same way, but more controversially, a Bayesian approach\\nshowed that an expensive MRI test for breast cancer might be appropriate for\\na woman whose family had many breast cancer patients but inappropriate for\\ngiving every woman between 40 and 50 years of age. A woman who has a\\nmammogram every year for 10 years can be almost 100% sure of getting one\\nfalse positive test result, and the resulting biopsy can cost 1,000 to 2,000.\\nIn the case of prostate cancer, the screening test for high blood levels of\\nprostate-specific antigen (PSA) is highly accurate when it comes to\\nidentifying men with the cancer. Yet the disease is so rare that almost\\neveryone who gets a positive test result is found not to have the cancer at all.\\n(See appendix B for how to calculate a Bayesian problem involving breast\\ncancer.)\\nOn the other hand, Bayes also showed that people with negative test\\nresults for breast and prostate cancer cannot feel carefree. The PSA test is so\\ninsensitive that good news provides almost no assurance that a man does not\\nactually have prostate cancer. The same is true to a lesser extent of\\nmammography: its sensitivity is about 85 to 90%, meaning that a woman who\\nfinds a lump only a few months after getting a negative mammogram should\\nstill see a doctor immediately. A strict Bayesian gives patients their\\nprobabilities for cancer instead of a categorical yes or no.\\nBecause genetics involves extremely rare diseases, imperfect tests, and\\ncomplicated problems where tiny errors in the data or calculations can affect\\ndecisions, Bayesian probabilities are expected to become increasingly\\nimportant for diagnostic test assessment.\\nSpiegelhalter spent more than 10 years trying to sell the medical\\ncommunity on BUGS as the mathematical way to learn from experience. He\\nargued that “advances in health-care typically happen through incremental\\ngains in knowledge rather than paradigm-shifting breakthroughs, and so this\\ndomain appears particularly amenable to a Bayesian perspective.” He\\ncontended that “standard statistical methods are designed for summarizing the\\nevidence from single studies or pooling evidence from similar studies, and\\nhave difficulties dealing with the pervading complexity of multiple sources\\nof evidence.”21 While frequentists can ask only certain questions, a Bayesian\\ncan frame any question.\\nWith the introduction of high-performance workstations in the 1980s it\\nbecame possible to use Bayesian networks to handle medicine’s many\\ninterdependent variables, such as the fact that a patient with a high\\ntemperature will usually also have an elevated white blood count. Bayesian\\nnetworks are graphs of nodes with links revealing cause-and-effect\\nrelationships. The “nets” search for particular patterns, assign probabilities\\nto parts of the pattern, and update those probabilities using Bayes’ theorem.\\nA number of people helped develop Bayesian networks, which were\\npopularized in 1988 in a book by Judea Pearl, a computer scientist at UCLA.\\nBy treating cause and effect as a quantifiable Bayesian belief, Pearl helped\\nrevive the field of artificial intelligence.\\nRon Howard, who had become interested in Bayes while at Harvard, was\\nworking on Bayesian networks in Stanford’s economic engineering\\ndepartment. A medical student, David E. Heckerman, became interested too\\nand for his Ph.D. dissertation wrote a program to help pathologists diagnose\\nlymph node diseases. Computerized diagnostics had been tried but\\nabandoned decades earlier. Heckerman’s Ph.D. in bioinformatics concerned\\nmedicine, but his software won a prestigious national award in 1990 from\\nthe Association for Computing Machinery, the professional organization for\\ncomputing. Two years later, Heckerman went to Microsoft to work on\\nBayesian networks.\\nThe Federal Drug Administration (FDA) allows the manufacturers of\\nmedical devices to use Bayes in their final applications for FDA approval.\\nDevices include almost any medical item that is not a drug or biological\\nproduct, items such as latex gloves, intraocular lenses, breast implants,\\nthermometers, home AIDS kits, and artificial hips and hearts. Because they\\nare usually applied locally and improved a step at a time, new models of a\\ndevice should come equipped with objective prior information.\\nPharmaceuticals are different. Unlike devices, pharmaceuticals are\\ngenerally one-step, systemic discoveries so that potentially an industry could\\nsubjectively bias Bayes’ prior hunch. Thus the FDA has long resisted\\npressure from pharmaceutical companies that want to use Bayes when\\napplying for approval to sell a drug in the United States.\\nAccording to Spiegelhalter, however, the same battle seems to have\\nsubsided in England. Drug companies use WinBUGS extensively when\\nsubmitting their pharmaceuticals for reimbursement by the English National\\nHealth Service. The process is, in Spiegelhalter’s words, “very Bayesian\\nwithout using the B-word” because it uses judgmental priors about a drug’s\\ncost effectiveness. International guidelines also allow Bayesian drug\\napplications, but these guidelines are widely considered too vague to be\\neffective.\\nOutside of diagnostic and medical device testing, Bayes’ mathematical\\nprocedures have had little impact on basic clinical research or practice.\\nWorking doctors have always practiced an intuitive, nonmathematical form of\\nBayes for diagnosing patients. The biggest unknown in medicine, after all, is\\nthe question, What is causing the patient’s symptoms? But traditional\\ntextbooks were organized by disease. They said that someone with, for\\ninstance, measles probably has red spots. But the doctor with a speckled\\npatient wanted to know the inverse: the probability that the patient with red\\nspots has measles. Simple Bayesian problems—for example, What is the\\nprobability that an exercise echocardiogram will predict heart disease?—\\nstarted appearing on physicians’ licensing examinations in 1992.\\nOne of the few times physicians make even rough Bayesian calculations\\noccurs when a patient has symptoms that could involve a life-threatening\\nheart attack, a deep venous thrombosis, or a pulmonary embolism. To assess\\nthe danger, a physician assigns points for each of the patient’s risk factors\\nand adds the points. In the heart attack algorithm, the score determines the\\nprobability that within the next two weeks the patient will die, have a heart\\nattack, or need coronary arteries opened. The points for thrombosis and\\nembolism tell whether a patient has a low, medium, or high risk of\\ndeveloping a clot and which test can best produce a diagnosis. It is expected\\nthat software will be available soon to automatically tell doctors and patients\\nthe effect of a particular test result on a diagnosis.\\nOutside of medicine, endangered populations of ocean fish, whales, and\\nother mammals were among the first to benefit from Bayes’ new\\ncomputational heft. Despite the U.S. Marine Mammal Protection Act of 1972,\\nonly a few visible and highly publicized species of whales, dolphins, and\\nother marine mammals had been protected. Some exploited populations,\\nincluding several whale species in the Antarctic, collapsed while being\\n“managed.” Having strong, abundant information about a species, frequentists\\nand Bayesians could reach similar decisions, but when evidence was weak\\n—as it often is in the case of marine mammals—only Bayes incorporated\\nuncertainties about the data at hand and showed clearly when more\\ninformation was needed.\\nMost whale populations rebounded during the 1980s, but in 1993 two\\ngovernment biologists, Barbara L. Taylor and Timothy Gerrodette, wrote,\\n“At least part of the blame for the spectacular [past] overexploitation of the\\ngreat whales can be placed on scientists being unable to agree . . . [on a]\\nclear way to treat uncertainty. . . . In certain circumstances, a population\\nmight go extinct before a significant decline could be detected.”22 During the\\nadministration of Bill Clinton, the Wildlife Protection Act was amended to\\naccept Bayesian analyses alerting conservationists early to the need for more\\ndata.\\nScientists advising the International Whaling Commission were\\nparticularly worried about the uncertainty of their measurements. Each year\\nthe commission establishes the number of endangered bowhead whales\\nEskimos can hunt in Arctic seas. To ensure the long-term survival of the\\nbowheads, scientists compute 2 numbers each year: the number of bowheads\\nand their rate of increase. The whales, perhaps the longest-lived mammals on\\nEarth, can grow to more than 60 feet in length, weigh more than 60 tons, and\\neat 2 tons of food a day. They spend only about 5% of their time on the ocean\\nsurface because they can submerge for 30 minutes at a time, and they use\\ntheir enormous heads to ram through ice when they need to surface for air. In\\nspring, teams of scientists stood on tall perches to spot bowheads rounding\\nPoint Barrow, Alaska, on their annual migration into the western Arctic. The\\ncount was fraught with uncertainties.\\nScientists representing an entire spectrum of opinion, from Greenpeace to\\nwhaling nations, worried that a lack of trustworthy data on bowhead\\npopulations was opening the species to too much risk. During a weeklong\\nmeeting to discuss the problem in 1991, their chair asked, “What can we\\ndo?”23 There was complete silence. The scientists were the world’s leading\\nbowhead experts, but none of them could answer the question.\\nWhen Judith Zeh, the committee chair, got back to the department of\\nstatistics at the University of Washington in Seattle, she talked with Raftery,\\nwho had recently moved there from Dublin. Not surprisingly, after his\\nexperience analyzing coal mining accidents, Raftery thought Bayes might\\nhelp. Using it, the committee could assign uncertainties to all their data and\\naugment visual sightings with recordings of whales vocalizing near\\nunderwater hydrophones.\\nProvidentially, the spring of 1993 was a rewarding year for bowhead\\ncounting, and sightings plus vocalizing showed that the whales were almost\\nassuredly increasing at a healthy rate. Their recovery indicated that\\nprotecting other great whale populations from commercial whaling might\\nhelp them recover too.\\nThe entire process—involving rival Bayesian and frequentist methods and\\nwhaling factions that often profoundly disagreed—could have been wildly\\ncontentious. But times were changing. Pragmatism ruled. Making fullscale\\nBayesian analyses to combine visual and acoustical data was expensive, and\\nthus, because they confirmed previous frequentist studies, they were\\ndiscontinued. Raftery moved on to using Bayes for 48-hour weather\\nforecasting.\\nOther wildlife researchers picked up the Bayesian banner. When Paul R.\\nWade decided in 1988 to use Bayes for his Ph.D. thesis, he said, “I was off\\nin this small area of marine mammal biology but I felt as if I were in the\\ncenter of a revolution in science.” Ten years later, at the National Oceanic\\nand Atmospheric Administration, he was comparing frequentist and Bayesian\\nanalyses of a small, isolated population of 200 or 300 beluga whales in the\\nArctic and Sub-Arctic waters of Cook Inlet, Alaska. The legal take by native\\nhunters was roughly 87 whales a year. Frequentist methods would have\\nrequired seven years of data collection to assess whether this catch was\\nsustainable. With Bayes, five years of data showed that the beluga population\\nwas almost certainly declining substantially, and the experiment could stop.\\n“With a small population, even a two-year delay can be important,” Wade\\nsaid.24 In May 1999 a hunting moratorium went into effect for the Cook Inlet\\nbelugas.\\nMeanwhile, a committee of the National Research Council in the National\\nAcademy of Sciences strongly recommended the aggressive use of Bayesian\\nmethods to improve estimates of marine fish stocks too. Committee members\\nemphasized in 1998 that, because the oceans are vast and opaque, wildlife\\nmanagers need realistic measurements of the uncertainties in their\\nobservations and models. Otherwise, policymakers cannot gauge potential\\nrisks to wildlife. Today many fisheries journals demand Bayesian analyses.\\nLindley had predicted that the twenty-first century would be a Bayesian era\\nbecause the superior logic of Bayes’ rule would swamp frequency-based\\nmethods. David Blackwell at Berkeley disagreed, saying, “If the Bayesian\\napproach does grow in the statistical world, it will not be because of the\\ninfluence of other statisticians but because of the influence of actuaries,\\nengineers, business people, and others who actually like the Bayesian\\napproach and use it.”25 It appeared that Blackwell was right: pragmatism\\ncould drive a paradigm shift. Philosophies of science had not changed. The\\ndifference was that Bayes finally worked.\\nDiaconis had been wondering for years, “When is our time?” In 1997, he\\ndecided, “Our time is now.”26\\nSmith became the first Bayesian president of the Royal Statistical Society\\nin 1995. Three years later he stunned his friends by quitting statistics to\\nbecome an administrator of the University of London. A proponent of\\nevidence-based medicine, he wanted to help develop evidence-based public\\npolicy too. Dismayed colleagues chastised him for abandoning Bayes’ rule.\\nBut Smith told Lindley that all the problems of statistics had been solved. We\\nhave the paradigm, he said, and with MCMC we know how to implement it.\\nHe told Diaconis that there was nothing else to do with statistical problems\\nbut to plug them into a computer and turn the Bayesian crank.\\nIn 2008, when Smith became scientific adviser to the United Kingdom’s\\nMinister of Innovation, Universities, and Skills, a Royal Society spokesman\\nvolunteered that three statisticians have become prime ministers of Great\\nBritain.27\\n17.\\n \\nrosetta stones\\n \\nTwo and a half centuries after Bayes and Laplace discovered a way to apply\\nmathematical reasoning to highly uncertain situations, their method has taken\\nwing, soaring through science and the Internet, burrowing into our daily\\nlives, dissolving language barriers, and perhaps even explaining our brains.\\nGone are the days when a few driven individuals searched orphanages and\\ncoded messages for data and organized armies of women and students to\\nmake tedious calculations. Today’s Bayesians revel in vast archives of\\nInternet data, off-the-shelf software, tools like MCMC, and computing power\\nso cheap it is basically free.\\nThe battle between Bayesian and frequentist forces has cooled.\\nBayesianism as an all-encompassing framework has been replaced by\\nutilitarian applications and computation. Computer scientists who joined the\\nBayesian community cared about results, not theory or philosophy. And even\\ntheorists who once insisted on adhering strictly to fundamental principles\\nnow accept John Tukey’s view from the 1950s: “Far better an approximate\\nanswer to the right question, . . . than an exact answer to the wrong question.”\\nResearchers adopt the approach that best fits their needs.\\nIn this ecumenical atmosphere, two longtime opponents—Bayes’ rule and\\nFisher’s likelihood approach—ended their cold war and, in a grand\\nsynthesis, supported a revolution in modeling. Many of the newer practical\\napplications of statistical methods are the results of this truce.\\nAs a collection of computational and statistical machinery, Bayes is still\\ndriven by Bayes’ rule. The word “Bayes” still entails the idea, shared by de\\nFinetti, Ramsey, Savage, and Lindley, that probability is a measure of belief\\nand that it can, as Lindley put it, “escape from repetition to uniqueness.” That\\nsaid, most modern Bayesians accept that the frequentism of Fisher, Neyman,\\nand Egon Pearson is still effective for most statistical problems: for simple\\nand standard analyses, for checking how well a hypothesis fits data, and as\\nthe foundation of many modern technologies in areas such as machine\\nlearning.\\nProminent frequentists have also moderated their positions. Bradley Efron,\\na National Medal of Science recipient who wrote a classic defense of\\nfrequentism in 1986, recently told a blogger, “I’ve always been a Bayesian.”\\nEfron, who helped develop empirical Bayesian procedures while remaining\\na committed frequentist, told me that Bayes is “one of the great branches of\\nstatistical inference. . . . Bayesians have gotten more tolerant these days, and\\nfrequentists are seeing the need to use Bayesian kinds of reasoning, so maybe\\nwe are headed for some kind of convergence.”\\nBayes’ rule is influential in ways its pioneers could never have\\nenvisioned. “Neither Bayes nor Laplace,” Robert E. Kass of Carnegie\\nMellon observed, “recognized a fundamental consequence of their approach,\\nthat the accumulation of data makes open-minded observers come to\\nagreement and converge on the truth. Harold Jeffreys, the modern founder of\\nBayesian inference for scientific investigation, did not appreciate its\\nimportance for decisionmaking. And the loyalists of the 1960s and 1970s\\nfailed to realize that Bayes would ultimately be accepted, not because of its\\nsuperior logic, but because probability models are so marvelously adept at\\nmimicking the variation in realworld data.”\\nBayes has also broadened to the point where it overlaps computer science,\\nmachine learning, and artificial intelligence. It is empowered by techniques\\ndeveloped both by Bayesian enthusiasts during their decades in exile and by\\nagnostics from the recent computer revolution. It allows its users to assess\\nuncertainties when hundreds or thousands of theoretical models are\\nconsidered; combine imperfect evidence from multiple sources and make\\ncompromises between models and data; deal with computationally intensive\\ndata analysis and machine learning; and, as if by magic, find patterns or\\nsystematic structures deeply hidden within a welter of observations. It has\\nspread far beyond the confines of mathematics and statistics into high\\nfinance, astronomy, physics, genetics, imaging and robotics, the military and\\nantiterrorism, Internet communication and commerce, speech recognition, and\\nmachine translation. It has even become a guide to new theories about\\nlearning and a metaphor for the workings of the human brain.\\nOne of the surprises is that Bayes, as a buzzword, has become chic.\\nStanford University biologist Stephen H. Schneider wanted a customized\\ncancer treatment, called his logic Bayesian, got his therapy, went into\\nremission, and wrote a book about the experience. Stephen D. Unwin\\ninvented a personal “faith-belief factor” of 28% to boost the 67% “Bayesian\\nprobability” that God exists to 95%, and his book hit the bestseller list. A\\nfashionable expression, “We’re all Bayesians now,” plays on comments\\nmade years ago by Milton Friedman and President Richard Nixon that\\n“We’re all Keynesians now.” And the CIA agent in a Robert Ludlum thriller\\ntells the hero, “Lucky? Obviously you haven’t heard anything I’ve said. It\\nwas a matter of applying Bayes’ Theorem to estimate the conditional\\nprobabilities. Giving due weight to the prior probabilities and . . .”1\\nIt must be conceded that not everyone shares this enthusiasm. Some\\nimportant fields of endeavor remain opposed. Perhaps the biggest irony is\\nthat partisan politics have kept the American census anti-Bayesian, despite\\nLaplace’s vision that enlightened governments would adopt it.\\nAnglo-American courtrooms are also still largely closed to Bayes. Among\\nthe few exceptions was a case in 1994 where Bayes was used to demonstrate\\nthat New Jersey state troopers singled out African American drivers for\\ntraffic stops. During a rape trial in the 1990s, British lawyers tried teaching\\njudges and juries how to assess evidence using Bayesian probability; judges\\nconcluded that the method “plunges the jury into inappropriate and\\nunnecessary realms of theory and complexity.”2 Forensic laboratory science\\nin Great Britain and Europe is a different story. Unlike the FBI Laboratory in\\nthe United States, the Forensic Sciences Services in Britain have followed\\nLindley’s advice and now employ Bayesian methods extensively to assess\\nphysical evidence. Continental European laboratories have developed a\\nquantitative measure for the value of various types of evidence, much as\\nTuring and Shannon used Bayes to develop bans and bits as units of\\nmeasurement for cryptography and computers. Bayes—tactfully referred to in\\nforensic circles as the “logical” or “likelihood ratio” approach—has been\\napplied successfully in cases where numbers were available, particularly in\\nDNA profiling. Because DNA databanks involve probabilities about almost\\nunimaginably tiny numbers—one in 20 million, say, or one in a billion—they\\nmay eventually open more courtroom doors to Bayesian methods.\\nBayes made headlines in 2000 by augmenting DNA evidence with\\nstatistical data to conclude that Thomas Jefferson had almost certainly\\nfathered six children by his slave Sally Hemings. DNA evidence from\\nJefferson’s and Hemings’s families had already offered strong evidence that\\nthe third president and the author of the Declaration of Independence fathered\\nHemings’s youngest son. But Fraser D. Neiman, the director of archaeology\\nat Jefferson’s Monticello plantation, studied whether Hemings’s other\\nconceptions fell during or close to one of Jefferson’s sporadic visits to\\nMonticello. Then he used Bayes to combine the prior historical testimony\\nand DNA evidence with probable hypotheses based on Jefferson’s calendar.\\nAssuming a 50–50 probability that the prior evidence was true, Fraiser\\nconcluded it was nearly certain—99% probable—that Jefferson had fathered\\nHemings’s six children.\\nIn economics and finance Bayes appears at multiple levels, ranging from\\ntheoretical mathematics and philosophy to nitty-gritty money making. The\\nmethod figured prominently in three Nobel Prizes awarded for theoretical\\neconomics, in 1990, 1994, and 2004. The first Nobel involved the Italian\\nBayesian de Finetti, who anticipated the Nobel Prize–winning work of Harry\\nMarkowitz by more than a decade. Mathematical game theorists John C.\\nHarsanyi and John Nash (the latter the subject of a book and movie, A\\nBeautiful Mind) shared a Bayesian Nobel in 1994. Harsanyi often used\\nBayes to study competitive situations where people have incomplete or\\nuncertain information about each other or about the rules. Harsanyi also\\nshowed that Nash’s equilibrium for games with incomplete or imperfect\\ninformation was a form of Bayes’ rule.\\nIn 2002 Bayes won perhaps not an entire Nobel Prize but certainly part of\\none. Psychologists Amos Tversky, who died before the prize was awarded,\\nand Daniel Kahneman showed that people do not make decisions according\\nto rational Bayesian procedures. People answer survey questions depending\\non their phrasing, and physicians choose surgery or radiation for cancer\\npatients depending on whether the treatments are described in terms of\\nmortality or survival rates. Although Tversky was widely regarded as a\\nphilosophical Bayesian, he reported his results using frequentist methods.\\nWhen James O. Berger of Duke asked him why, Tversky said it was simply a\\nmatter of expedience. During the 1970s it was more difficult to publish\\nBayesian research. “He just took the easy way out,” Berger said.\\nAlan Greenspan, former chairman of the Federal Reserve, said he used\\nBayesian ideas to assess risk in monetary policy. “In essence, the\\nriskmanagement approach to monetary policymaking is an application of\\nBayesian decisionmaking,” Greenspan told the American Economic\\nAssociation in 2004.3 The audience of academic and government economists\\ngasped; few experts in finance analyze empirical data with Bayes.\\nEconomists were still catching their breaths when Martin Feldstein,\\nprofessor of economics at Harvard, stood up at the same meeting and\\ndelivered a crash course in Bayesian theory. Feldstein had been President\\nRonald Reagan’s chief economic advisor and was president of the National\\nBureau of Economic Research, a leading research organization. He learned\\nBayesian theory at the Howard Raiffa–Robert Schlaifer seminars at Harvard\\nBusiness School in the 1960s. Feldstein explained that Bayes lets the Federal\\nReserve weigh a low-probability risk of disaster more heavily than a higher-\\nprobability risk that would cause little damage. And he likened Bayes to a\\nman who has to decide whether to carry an umbrella even when the\\nprobability of rain is low. If he carries an umbrella but it does not rain, he is\\ninconvenienced. But if he does not carry an umbrella and it pours, he will be\\ndrenched. “A good Bayesian,” Feldstein concluded, “finds himself carrying\\nan umbrella on many days when it does not rain.”4\\nFour years later rain flooded the financial markets and banking.\\nGreenspan, who by then had retired from the Federal Reserve, told Congress\\nhe had not foreseen the collapse of the real-estate lending bubble in 2008. He\\ndid not blame the theory he used but his economic data, which “generally\\ncovered only the past two decades, a period of euphoria . . . [instead of]\\nhistoric periods of stress.”5\\nBut did Greenspan actually employ Bayesian statistics to quantify\\nempirical economic data? Or were Bayesian concepts about uncertainty only\\na handy metaphor? Former Reserve Board governor Alan S. Blinder of\\nPrinceton thought the latter, and when he said so during a talk, Greenspan\\nwas in the audience and did not object.\\nIn pragmatic contrast to abstract Bayes at the Nobel ceremonies and\\nphilosophical Bayes at the Federal Reserve, the rule stands behind one of the\\nmost successful hedge funds in the United States. In 1993 Renaissance\\nTechnologies hired away from IBM a Bayesian group of voice recognition\\nresearchers led by Peter F. Brown and Robert L. Mercer. They became\\ncomanagers of RenTech’s portfolio and technical trading. For several years,\\ntheir Medallion Fund, limited to former and current employees, averaged\\nannual returns of about 35%. The fund bought and sold shares so rapidly one\\nday in 1997 that it accounted for more than 10% of all NASDAQ trades.\\nTo search for the nonrandom patterns and movements that will help predict\\nmarkets, RenTech gathers as much information as possible. It begins with\\nprior knowledge about the history of prices and how they fluctuate and\\ncorrelate with each other. Then the company continuously updates that prior\\nbase. As Mercer explained, “RenTec gets a trillion bytes of data a day, from\\nnewspapers, AP wire, all the trades, quotes, weather reports, energy reports,\\ngovernment reports, all with the goal of trying to figure out what’s going to be\\nthe price of something or other at every point in the future. . . . We want to\\nknow in three seconds, three days, three weeks, three months. . . . The\\ninformation we have today is a garbled version of what the price is going to\\nbe next week. People don’t really grasp how noisy the market is. It’s very\\nhard to find information, but it is there, and in some cases it’s been there for a\\nlong, long time. It’s very close to science’s needle-in-a-haystack problem.”\\nLike investors at RenTech, astronomers, physicists, and geneticists use\\nBayes to discern elusive phenomena almost drowning in unknowns. A\\nscientist may face hundreds of thousands of variables without knowing which\\nproduce the best predictions. Bayes lets them estimate the most probable\\nvalues of their unknowns.\\nWhen Supernova 1987A exploded, astronomers detected precisely 18\\nneutrinos. The particles originated from deep inside the star and were the\\nonly clues about its interior, so the astronomers wanted to extract as much\\ninformation as possible from this minuscule amount of data. Tom Loredo, a\\ngraduate student at the University of Chicago, was told to see what he could\\nlearn. Because the supernova was a one-of-a-kind opportunity, frequency-\\nbased methods did not apply. Loredo began reading papers by Lindley, Jim\\nBerger, and other leading Bayesians and discovered that Bayes would let him\\ncompare various hypotheses about his observations and choose the most\\nprobable. His Ph.D. thesis from 1990 wound up introducing modern\\nBayesian methods to astronomy.\\nSince then, Bayes has found a comfortable niche in high-energy\\nastrophysics, x-ray astronomy, gamma ray astronomy, cosmic ray astronomy,\\nneutrino astrophysics, and image analysis. In physics, Bayes is hunting for\\nelusive neutrinos, Higgs-Boson particles, and top quarks. All these problems\\ndeal with needles in haystacks, and Loredo now uses Bayes at Cornell\\nUniversity in a new field, astrostatistics.\\nIn much the same way, biologists who study genetic variation are limited\\nto tiny snippets of information almost lost among huge amounts of\\nmeaningless and highly variable data in the chromosomes. Computational\\nbiologists searching for genetic patterns, leitmotifs, markers, and disease-\\ncausing misspellings must extract the weak but important signals from the\\ndeafening background noise that masquerades as information.\\nSusan Holmes, a professor in Stanford’s statistics department, works in\\ncomputational and molecular biology on amino acids. Some are extremely\\nrare, and if she used frequentist methods she would have to quantify them\\nwith a zero. Adopting the cryptographic technique used by Turing and Good\\nat Bletchley Park, she tries to crack the genetic code by assigning missing\\nspecies a small possibility.\\nGiven that the DNA in every biological cell contains complete instructions\\nfor making every kind of protein in the body, what differentiates a kidney cell\\nfrom a brain cell? The answer depends on whether a particular gene is turned\\non or off and whether the genes work together or not. Holmes assembles huge\\nmicroarrays of genetic data filled with noise and other distractions that may\\nhide a few important signals from the turned-on genes. Each microarray\\nconsists of many genes arrayed in a regular pattern on a small glass slide or\\nmembrane; with it, she can analyze the expression of thousands of genes at\\nonce.\\n“It’s very tenuous,” she says. “[Imagine that] you have a city at night like\\nToronto or Paris with a very dense population and lots of buildings, and at 2\\na.m. you look at which lights are lit up in all the buildings. Then at 3 and 4\\na.m., you look again. So you develop a pattern of which rooms are lit up, and\\nfrom that you infer who in the city knows who. That’s how sparse the signal\\nis and how far you have to jump, to see which genes are working together.\\nYou don’t even have phone connections. But the image of something lighting\\nup is a little bit like the image of microarrays. Microarrays have so much\\nnoise, it seems crazy. You just have rustles, whispers of signals, and then lots\\nof noise. You spend a lot of time looking at a lot of data.” Because prior\\ninformation is needed to assemble the networks, many microarrays are\\nanalyzed using Bayesian methods.\\nDaphne Koller, a leader in artificial intelligence and computational\\nbiology at Stanford, also works on microarrays. She wanted to see not only\\nwhich genes have turned on or off, but also what controls and regulates them.\\nBy looking at the activity levels of genes in yeast, she figured out how they\\nare regulated. Then she switched to mouse and human cells to determine the\\ndifferences in genetic regulation between healthy people and patients with\\ncancer or Type II diabetes, particularly the metabolic (insulin resistance)\\nsyndrome.\\nOn the vexed issue of priors, Koller considers herself a relaxed middle-\\nof-the-roader. In contrast, Bayesian purists like Michael I. Jordan of\\nBerkeley and Philip Dawid of Cambridge object to the term “Bayesian\\nnetworks”; they regard Judea Pearl’s nomenclature as a misnomer because\\nBayesian networks do not always have priors and Bayes without priors is not\\nBayes. But Koller insists that her networks fully qualify as Bayesian because\\nshe carefully constructs priors for their variables.\\nKoller’s fascination with uncertainty has led her from genetics to imaging\\nand robotics. Images typically have variable and ambiguous features that are\\nembedded in background clutter. The human visual system sends ten million\\nsignals per second to the brain, where a billion neurons strip off random\\nfluctuations and irrelevant, ambiguous information to reveal shape, color,\\ntexture, shading, surface reflections, roughness, and other features. As a\\nresult, human beings can look at a blurry, distorted, noisy pattern and\\ninstantly recognize a tomato plant, a car, or a sheep. Yet a state-of-the-art\\ncomputer trained to recognize cars and sheep may picture only nonsensical\\nrectangles. The difference is that the human brain has prior knowledge to\\nintegrate with the new images.\\n“It’s mind-boggling,” says Koller. The problem is not computer hardware;\\nit is writing the software. “A computer can easily be trained to distinguish a\\ndesert from a forest, but where the road is and where it’s about to fall off a\\ncliff, that’s much harder.”\\nTo explore such imaging problems, Sebastian Thrun of Stanford built a\\ndriverless car named Stanley. The Defense Advanced Research Projects\\nAgency (DARPA) staged a contest with a 2 million prize for the best\\ndriverless car; the military wants to employ robots instead of manned\\nvehicles in combat. In a watershed for robotics, Stanley won the competition\\nin 2005 by crossing 132 miles of Nevada desert in seven hours.\\nWhile Stanley cruised along at 35 mph, its camera took images of the route\\nand its computer estimated the probability of various obstacles. As the robot\\nnavigated sharp turns and cliffs and generally stayed on course, its computer\\ncould estimate with 90% probability that a wall stood nearby and with a\\n10% probability that a deep ditch was adjacent. In the unlikely event that\\nStanley fell into the ditch, it would probably have been destroyed. Therefore,\\nlike the Bayesian economist who carries an umbrella on sunny days, Stanley\\nslowed down to avoid even unlikely catastrophes. Thrun’s artificial\\nintelligence team trained Stanley’s sensors, machine-learning algorithms, and\\ncustom-written software in desert and mountain passes.\\nThrun credited Stanley’s victory to Kalman filters. “Every bolt of that car\\nwas Bayesian,” Diaconis said proudly. After the race, Stanley retired in\\nglory to its own room in the Smithsonian National Museum of American\\nHistory in Washington.\\nThe next year a Bayesian team from Carnegie Mellon University and\\nGeneral Motors won another 2 million from DARPA by maneuvering a\\nrobot through city traffic while safely avoiding other cars and obeying traffic\\nregulations. Urban planners hope driverless cars can solve traffic congestion.\\nAnother Carnegie Mellon team relied on Bayes’ rule and Kalman filters to\\nwin international robotic soccer championships involving fast-moving\\nmultirobot systems.\\nThe U.S. military is heavily involved in imaging issues. Its Automatic\\nTarget Recognition (ATR) technology is a heavy user of Bayesian methods\\nfor robotic and electronic warfare, combat vehicles, cruise missiles,\\nadvanced avionics, smart weapons, and intelligence, surveillance, and\\nreconnaissance. ATR systems employ radar, satellites, and other sensors to\\ndistinguish between, for example, a civilian truck and a missile launcher.\\nSome ATR computer programs start with Bayes’ controversial 50–50 odds,\\neven though these can have a strong impact on rare events and better\\ninformation may be available. Echoing generations of critics, at least one\\nanonymous ATR analyst regards Bayes as “an affront, a cheap easy trick. It\\ndepends on an initial hunch. And yet it turns out to be an effective\\napproximation that seems to solve many of the world’s problems. So Bayes’\\nrule is wrong . . . except for the fact that it works.” Other approaches have\\nbeen computationally more expensive and did not produce better answers.\\nBesides imaging problems, the military involves Bayes in tracking,\\nweapons testing, and antiterrorism. Reagan’s Ballistic Missile Defense\\napplied a Bayesian approach to tracking incoming enemy ballistic missiles.\\nOnce it was sufficiently probable that a real missile had been detected,\\nBayes allowed sensors to communicate only their very latest data instead of\\nrecalculating an entire problem from scratch each time. The National\\nResearch Council of the National Academy of Sciences strongly urged the\\nU.S. Army to use Bayesian methods for testing weapons systems, specifically\\nthe Stryker family of light, armored vehicles. Many military systems cannot\\nbe tested in the large sample sizes required by frequentist methods. A\\nBayesian approach allows analysts to combine test data with information\\nfrom similar systems and components and from earlier developmental tests.\\nTerrorist threats are generally estimated with Bayesian techniques. Even\\nbefore the attacks of September 11, 2001, Digital Sandbox of Tyson’s\\nCorner, Virginia, used Bayesian networks to identify the Pentagon as a\\npossible target. Bayes combined expert and subjective opinions about\\npossible events that had never occurred.\\nThe United States is not the only country trying to predict terrorism. As\\nBritain considered building a national data bank to detect potential terrorists,\\nBayes raised the same alarm it had against mass HIV screening. Terrorists\\nare so rare that the definition of a terrorist will have to be extremely accurate\\nor else many, many people will be identified as dangerous when they are, in\\nfact, not at all.\\nOn the Internet Bayes has worked its way into the very fiber of modern life. It\\nhelps to filter out spam; sell songs, books, and films; search for web sites;\\ntranslate foreign languages; and recognize spoken words. David Heckerman,\\nwho used Bayesian networks to diagnose lymph node diseases for his Ph.D.\\nthesis, has the modern practitioner’s wide-open attitude about Bayes: “The\\nwhole thing about being a Bayesian is that all probability represents\\nuncertainty and, anytime you see uncertainty, you represent it with\\nprobability. And that’s a lot bigger than Bayes’ theorem.”\\nIn 1992 Heckerman moved from Stanford to Microsoft, where he founded\\nand manages the Machine Learning and Applied Statistics Group of\\nMicrosoft Research. The problems there are very different. Because Stanford\\nhad plenty of experts but little data, he says he built Bayesian nets with priors\\nbased on expert opinion: “But Microsoft had lots of data and only a few\\nexperts, so we got into combining expert knowledge with data.” One of\\nMicrosoft’s first Bayesian applications helped parents with sick children\\ntype in their children’s symptoms and learn the best course of action. In 1996\\nBill Gates, cofounder of Microsoft, made Bayes headline news by\\nannouncing that Microsoft’s competitive advantage lay in its expertise in\\nBayesian networks.\\nThat same year Heckerman, Robert Rounthwaite, Joshua Goodman, Eric\\nHorwitz, and others began investigating Bayesian antispam techniques.\\nRemember \\nvVi-@-gra, \\nl0w \\nmOrtg@ge \\nrates, \\nPARTNERSHIP\\nINVESTMENT, and !!!! PharammcyByMAIL? Advertisements that are\\nunwanted and often pornographic and fraudulent are sent to millions without\\ntheir permission. Spam soon accounted for more than half of all mail on the\\nInternet, and some e-mail users spent half an hour a day weeding it out.\\nBayesian methods attack spam by using words and phrases in the message\\nto determine the probability that the message is unwanted. An e-mail’s spam\\nscore can soar near certainty, 0.9999, when it contains phrases like “our\\nprice” and “most trusted”; coded words like “genierc virgaa”; and uppercase\\nletters and punctuation like !!! or \\n. High-scoring messages are\\nautomatically banished to junk mail files. Users refine their own filters by\\nreading low-scoring messages and either keeping them or sending them to\\ntrash and junk files. This use of Bayesian optimal classifiers is similar to the\\ntechnique used by Frederick Mosteller and David Wallace to determine who\\nwrote certain Federalist papers.\\nBayesian theory is firmly embedded in Microsoft’s Windows operating\\nsystem. In addition, a variety of Bayesian techniques are involved in\\nMicrosoft’s handwriting recognition; recommender systems; the question-\\nanswering box in the upper right corner of a PC’s monitor screen; a\\ndatamining software package for tracking business sales; a program that\\ninfers the applications that users will want and preloads them before they are\\nrequested; and software to make traffic jam predictions for drivers to check\\nbefore their commute.\\nBayes was blamed—unfairly, say Heckerman and Horwitz—for\\nMicrosoft’s memorably annoying paperclip, Clippy. The cartoon character\\nwas originally programmed using Bayesian belief networks to make\\ninferences about what a user knew and did not know about letter writing.\\nAfter the writer reached a certain threshold of ignorance and frustration,\\nClippy popped up cheerily with the grammatically improper observation, “It\\nlooks like you’re writing a letter. Would you like help?” Before Clippy was\\nintroduced to the world, however, nonBayesians had substituted a cruder\\nalgorithm that made Clippy pop up irritatingly often. The program was so\\nunpopular it was retired.\\nBayes and Laplace would probably be appalled to learn that their work is\\nheavily involved in selling products. Much online commerce relies on\\nrecommender filters, also called collaborative filters, built on the assumption\\nthat people who agreed about one product will probably agree on another. As\\nthe e-commerce refrain goes, “If you liked this book/song/movie, you’ll like\\nthat one too.” The updating used in machine learning does not necessarily\\nfollow Bayes’ theorem formally but “shares its perspective.” A 1-million\\ncontest sponsored by Netflix.com illustrates the prominent role of Bayesian\\nconcepts in modern e-commerce and learning theory. In 2006 the online film-\\nrental company launched a search for the best recommender system to\\nimprove its own algorithm. More than 50,000 contestants from 186 countries\\nvied over the four years of the competition. The AT&T Labs team organized\\naround Yehuda Koren, Christopher T. Volinsky, and Robert M. Bell won the\\nprize in September 2009.\\nInterestingly, although no contestants questioned Bayes as a legitimate\\nmethod, almost none wrote a formal Bayesian model. The winning group\\nrelied on empirical Bayes but estimated the initial priors according to their\\nfrequencies. The film-rental company’s data set was too big and too filled\\nwith unknowns for anyone to—almost instantaneously—create a model,\\nassign priors, update posteriors repeatedly, and recommend films to clients.\\nInstead, the winning algorithm had a Bayesian “perspective” and was laced\\nwith Bayesian “flavors.” However, by far the most important lesson learned\\nfrom the Netflix competition originated as a Bayesian idea: sharing.\\nVolinsky had used Bayesian model averaging for sharing and averaging\\ncomplementary models while working in 1997 on his Ph.D. thesis about\\npredicting the probability that a patient will have a stroke. But the Volinsky\\nand Bell team did not employ the method directly for Netflix. Nevertheless,\\nVolinsky emphasized how “due to my Bayesian Model Averaging training, it\\nwas quite intuitive for me that combining models was going to be the best\\nway to improve predictive performance. Bayesian Model Averaging studies\\nshow that when two models that are not highly correlated are combined in a\\nsmart way, the combination often does better than either individual model.”\\nThe contest publicized Bayes’ reputation as a fertile approach to learning far\\nbeyond mere Bayesian technology.\\nWeb users employ several forms of Bayes to search through the billions of\\ndocuments and locate what they want. Before that can happen, though, each\\ndocument must be profiled or categorized, organized, and sorted, and its\\nprobable interconnectedness with other documents must be calculated. At\\nthat point, we can type into a search engine the unrelated keywords we want\\nto appear in a document, for example, “parrots,” “madrigals,” and “Afghan\\nlanguage.” Bayes’ rule can winnow through billions of web pages and find\\ntwo relevant ones in 0.31 seconds. “They’re inferential problems,” says\\nPeter Hoff at the University of Washington. “Given that you find one\\ndocument interesting, can you find other documents that will interest you\\ntoo?”\\nWhen Google starts projects involving large amounts of data, its giant\\nsearch engines often try naïve Bayesian methods first. Naïve Bayes assumes\\nsimplistically that every variable is independent of the others; thus, a\\npatient’s fever and elevated white blood cell counts are treated as if they had\\nnothing to do with each other. According to Google’s research director, Peter\\nNorvig, “There must have been dozens of times when a project started with\\nnaïve Bayes, just because it was easy to do and we expected to replace it\\nwith something more sophisticated later, but in the end the vast amount of\\ndata meant that a more complex technique was not needed.”\\nGoogle also uses Bayesian techniques to classify spam and pornography\\nand to find related words, phrases, and documents. A very large Bayesian\\nnetwork finds synonyms of words and phrases. Instead of downloading\\ndictionaries for a spelling checker, Google conducted a full-text search of the\\nentire Internet looking for all the different ways words can be spelled. The\\nresult was a flexible system that could recognize that “shaorn” should have\\nbeen “Sharon” and correct the typo.\\nWhile Bayes has helped revolutionize modern life on the web, it is also\\nhelping to finesse the Tower of Babel that has separated linguistic\\ncommunities for millennia. During the Second World War, Warren Weaver of\\nthe Rockefeller Foundation was impressed with how “a multiplicity of\\nlanguages impedes cultural interchange between the peoples of the earth and\\nis a serious deterrent to international understanding.”6 Struck by the power of\\nmechanized cryptography and by Claude Shannon’s new information theory,\\nWeaver suggested that computerized statistical methods could treat\\ntranslation as a cryptography problem. In the absence of computer power and\\na wealth of machine-readable text, Weaver’s idea lay fallow for decades.\\nEver since, the holy grail of translators has been a universal machine that\\ncan transform written and spoken words from one language into any other. As\\npart of this endeavor, linguists like Noam Chomsky developed structural\\nrules for English sentences, subjects, verbs, adjectives, and grammar but\\nfailed to produce an algorithm that could explain why one string of words\\nmakes an English sentence while another string does not.\\nDuring the 1970s IBM had two competing teams working on a similar\\nproblem, speech recognition. One group, filled with linguists, studied the\\nrules of grammar. The other group, led by Mercer and Brown, who later went\\nto RenTech, was filled with mathematically inclined communications\\nspecialists, computer scientists, and engineers. They took a different tack,\\nreplaced logical grammar with Bayes’ rule, and were ignored for a decade.\\nMercer’s ambition was to make computers do intelligent things, and voice\\nrecognition seemed to be the way to make this happen. For both Mercer and\\nBrown speech recognition was a problem about taking a signal that had\\npassed through a noisy channel like a telephone and then determining the\\nmost probable sentence that the speaker had in mind. Ignoring grammar rules,\\nthey decided to figure out the statistical probability that words and phrases in\\none language would wind up as particular words or phrases in another. They\\ndid not have to know any language at all. They were simply computing the\\nprobability of a single word given all the words that preceded it in a\\nsentence. For example, by looking at pairs of English words they realized\\nthat the word after “the” was highly unlikely to be “the” or “a,” somewhat\\nmore likely to be “cantaloupe,” and still more likely to be “tree.”\\n“It all hinged on Bayes’ theorem,” Mercer recalled. “We were given an\\nacoustic output, and we’d like to find the most probable word sequence,\\ngiven the acoustic sequence that we heard.” Their prior knowledge consisted\\nof the most probable order of the words in an English sentence, which they\\ncould get by studying enormous amounts of English text.\\nThe big problem throughout the 1970s was finding enough data. They\\nneeded bodies of text focused on a fairly small topic, but nothing as adult as\\nthe New York Times. At first they worked their way through old, out-of-\\ncopyright children’s books; 1,000 words from a U.S. Patent Office\\nexperiment with laser technology; and 60 million words of Braille-readable\\ntext from the American Printing House for the Blind.\\nAt an international acoustic, speech, and signal meeting the group wore\\nidentical T-shirts printed with the words “Fundamental Equation of Speech\\nRecognition” followed by Bayes’ theorem. They developed “a bit of\\nswagger, I’m ashamed to say,” Mercer recalled. “We were an obnoxious\\nbunch back in those days.”\\nIn a major breakthrough in the late 1980s they gained access to French and\\nEnglish translations of the Canadian parliament’s daily debates, about 100\\nmillion words in computer-readable form. From them, IBM extracted about\\nthree million pairs of sentences, almost 99% of which were actual\\ntranslations of one another. It was a Rosetta Stone in English and French.\\n“You had a day’s worth of English and the corresponding day’s worth of\\nFrench, so things were lined up to that extent, but we didn’t know that this\\nsentence or word went with this or that sentence or word. For example,\\nwhile the English shouted, ‘Hear! Hear!,’ the French said, ‘Bravo!’ So we\\nbegan working on getting a better alignment of the sentences. We were using\\nthe same methods as in speech recognition: Bayes’ theorem and hidden\\nMarkov models.” The latter are particularly useful for recognizing patterns\\nthat involve likely time sequences, for example, predicting one word in a\\nsentence based on the previous word.\\nIn a landmark paper in 1990 the group applied Bayes’ theorem to full\\nsentences. There was a small probability that the sentence, “President\\nLincoln was a good lawyer,” means “Le matin je me brosse les dents” but a\\nrelatively large probability that it means “Le president Lincoln était un bon\\navocat.” After that paper, several of the leading machine translation systems\\nincorporated Bayes’ rule.\\nIn 1993, lured by lucre and the challenge, Mercer and Brown moved from\\nIBM and machine translation to RenTech, where they became vice presidents\\nand co–portfolio managers for technical trading. So many members of IBM’s\\nspeech recognition group joined them that critics complain they set back the\\nfield of machine translation five years.\\nAfter the 9/11 disaster and the start of the war in Iraq, the military and the\\nintelligence communities poured money into machine translation. DARPA,\\nthe U.S. Air Force, and the intelligence services want to ease the burden on\\nhuman translators working with such little-studied languages as Uzbek,\\nPashto, Dari, and Nepali.\\nMachine translation got still another boost when Google trawled the\\nInternet for more Rosetta Stone texts: news stories and documents published\\nin both English and another language. United Nations documents alone\\ncontributed 200 billion words. By this time the web was churning out\\nenormous amounts of text, free for the asking. Combing English words on the\\nweb, Google counted all the times that, for example, a two-word sequence in\\nEnglish meant “of the.” To determine which words in the English sentence\\ncorrespond to which words in the other language, Google uses Bayes to align\\nthe sentences in the most probable fit.\\nThe blue ribbons Google won in 2005 in a machine language contest\\nsponsored by the National Institute of Standards and Technology showed that\\nprogress was coming, not from better algorithms, but from more training data.\\nComputers don’t “understand” anything, but they do recognize patterns. By\\n2009 Google was providing online translations in dozens of languages,\\nincluding English, Albanian, Arabic, Bulgarian, Catalan, Chinese, Croatian,\\nCzech, Danish, Dutch, Estonian, Filipino, Finnish, and French.\\nThe Tower of Babel is crumbling.\\nEven as Bayes’ rule was improving human communications, it was returning\\nfull circle to the fundamental question that had occupied Bayes, Price, and\\nLaplace: How do we learn? Using Bayes’ rule, more than half a million\\nstudents in the United States learn the answer to that question each year: we\\ncombine old knowledge with new. Approximately 2,600 secondary schools\\nteach algebra and geometry with Bayesian computer programs developed at\\nCarnegie Mellon University since the late 1980s. The software also teaches\\nFrench, English as a second language, chemistry, physics, and statistics.\\nThe programs, called Cognitive Tutors, are based on John R. Anderson’s\\nidea that Bayes is a surrogate for the way we naturally learn, that is to say,\\ngradually. The ability to accumulate evidence is an optimal survival strategy,\\nbut our brains cannot assign a high priority to everything. Therefore, most\\nstudents must see and work many times with a mathematical concept before\\nthey can retrieve and apply it at will. Our ability to do so depends on how\\nfrequently and recently we studied the concept.\\nIn addition to viewing Bayes as a continuous learning process, Cognitive\\nTutors depend on Bayes’ theorem for calculating each student’s\\n“skillometer,” the probability that the individual has mastered a topic and is\\nready for a new challenge. Ten years after this double-edged Bayesian\\napproach was launched, its students were learning as much or more than\\nconventionally taught pupils—in a third the time.\\nThe flowering of Bayesian networks, neural nets, and artificial intelligence\\nnets has helped neuroscientists study how the brain’s neurons process\\ninformation that arrives directly and indirectly, a little at a time, in tiny, often\\ncontradictory packets. As a computational tool and learning theory, Bayes\\nhas been involved in mapping the brain and analyzing its circuitry as well as\\nin decoding signals from neurons and harnessing them to make better\\nprostheses and robots.\\nHundreds of megabits of sensory information bombard the waking brain\\nevery second. From that stream of data, 10 billion nerve cells extract\\ninformation and correct prior understanding several times every 100\\nmilliseconds. Discerning which sensory stimulus has caused which neuronal\\nresponse is a difficult problem: the neurons fire unpredictably, scientists\\ncannot monitor all of them at once, and the brain combines cues from\\nmultiple sources. The vision regions of our brains, for example, create three-\\ndimensional objects and scenes. To do so, they rely on our prior knowledge\\nabout the regularities in our environment—for example, that light generally\\nshines from above and that straight lines and 90-degree angles are apt to be\\nman-made. But our brains refine that knowledge with new data pouring in\\nabout depth, contours, symmetry, lines of curvature, texture, shading,\\nreflectance, foreshortening, and motion.\\nIn 1998 the neurostatistician Emery N. Brown of MIT and Massachusetts\\nGeneral Hospital realized that Bayesian methods might deal with these\\nuncertainties. Using Kalman filters, he and the MIT neuroscientist Matthew\\nA. Wilson described a rat’s brain as it processed information about the\\nanimal’s location in its environment. Approximately 30 so-called place\\nneurons in the hippocampus keep a rat informed about its location. As a\\nlaboratory rat foraged in a box scattered randomly with chocolate tidbits,\\nelectrodes implanted in its brain imaged some of the place neurons as they\\nfired. A Bayesian filter sequentially updated the rat’s position in the box. The\\nresearchers could see neither the rat nor its box, but by watching the neurons\\nfire they could track the rat’s movements. Thanks to Bayes, Brown could\\nreconstruct the path of the chocolate-loving rat with only a fifth or a tenth of\\nthe neurons that previous methods had required.\\nTo explore the practicality of using the living brain to power prostheses\\nand robots, Brown’s statistical method was replicated with a few dozen\\nmotor neurons, Bayesian algorithms, and Bayesian particle filters. The goal\\nis to develop an artificial arm that can smoothly reach, rotate the hand, move\\nfingers independently, and grasp and retrieve objects. Illustrating the\\npossibilities of the approach, a rhesus monkey in Andrew B. Schwartz’s\\nlaboratory at the University of Pittsburgh gazed longingly at an enticing treat.\\nWith his arms immobilized in plastic tubes and his mouth salivating, the\\nmotor neurons in his brain fired repeatedly, activating a robotic arm. The\\nmonkey’s control was so precise it could reach out with the robotic arm, nab\\nthe treat, and fetch it back to eat. Frequentist methods can deal with simple\\nbackwards-and-forwards motion, but Bayesian neurostatisticians believe\\ntheir algorithms will be powerful and flexible enough to control a robotic\\narm’s position, rotation, acceleration, velocity, momentum, and grasp.\\nThese attempts to capitalize on all the information available in neurons\\nraise questions: What does the brain itself do? Does it maximize the\\ninformation it gets from an uncertain world by performing Bayesian-like\\ncomputations? In discussions of these questions, Bayes has become more\\nthan just an aid for data analysis and decision making. It has become a\\ntheoretical framework for explaining how the brain works. In fact, as such,\\nthe “Bayesian Brain” has become a metaphor for a human brain that mimics\\nprobability.\\nIn our struggle to survive in an uncertain and changing world, our sensory\\nand motor systems often produce signals that are incomplete, ambiguous,\\nvariable, or corrupted by random fluctuations. If we put one hand under a\\ntable and estimate its location, we can be off by up to 10 centimeters. Every\\ntime the brain generates a command for action, we produce a slightly\\ndifferent movement. In this confusing world, Bayes has emerged as a useful\\ntheoretical framework. It helps explain how the brain may learn. And it\\ndemonstrates mathematically how we combine two kinds of information: our\\nprior beliefs about the world with the error-fraught evidence from our\\nsenses.\\nAs Lindley emphasized years ago, if we are certain about the evidence\\nrelayed by our senses, we rely on them. But when faced with unreliable\\nsensory data, we fall back on our prior accumulation of beliefs about the\\nworld.\\nWhen Daniel Wolpert of Cambridge University tested the theory with a\\nvirtual tennis game, he showed that players unconsciously combine their\\nprior knowledge of bouncing balls in general with sensory data about a\\nparticular ball coming over the net. In short, they unconsciously behave like\\ngood Bayesians. In addition, Wolpert said, the nice thing about Bayes was\\nthat it did not produce a single number. It made multiple predictions about\\nevery possible state given the sensory data. Thus, the tennis ball would most\\nprobably bounce in a particular spot—but there was also a reasonable\\nchance it would fall elsewhere.\\nAccording to Bayes, the brain stores a wide range of possibilities but\\nassigns them high and low probabilities. Color vision is already known to\\noperate this way. We think we perceive red, but we actually see an entire\\nspectrum of colors, assign the highest probability to red, and keep in mind\\nthe outside possibilities that the color could be pink or purple.\\nWolpert concluded that Bayesian thinking is basic to everything a human\\ndoes, from speaking to acting. The biological brain has evolved to minimize\\nthe world’s uncertainties by thinking in a Bayesian way. In short, growing\\nevidence suggests that we have Bayesian brains.\\nGiven Bayes’ contentious past and prolific contributions, what will the future\\nlook like? The approach has already proved its worth by advancing science\\nand technology from high finance to e-commerce, from sociology to machine\\nlearning, and from astronomy to neurophysiology. It is the fundamental\\nexpression for how we think and view our world. Its mathematical simplicity\\nand elegance continue to capture the imagination of its users.\\nBut what about the years to come? Brute computer force can organize\\nstunning quantities of information, but it clusters and searches for documents\\ncrudely, according to keywords. Only the brain examines documents and\\nimages according to their meaning and their content. Which approach will be\\nmore useful? Will computers become so powerful that huge amounts of data\\nalone will teach us everything? Will scientists no longer need to theorize or\\nhypothesize before experimenting or gathering their data? Or will Bayesian\\norganizational principles remain fundamental? Current strategies for\\ndesigning computers that could perform at biological levels exploit such\\nancient principles as reusable parts, hierarchical structures, variations on\\nthemes, and regulatory systems.\\nThe jumping off point for this debate is Bayes and its priors, says Stuart\\nGeman, whose Gibbs sampler helped launch the modern Bayesian\\nrevolution: “In this debate, there is no more powerful argument for Bayes\\nthan its recognition of the brain’s inner structures and prior expectations.”\\nThe old controversies between Bayesians and frequentists have been\\nreframed in terms of, Do we use probabilities or not? Old or new, the issues\\nare similar, if not identical, Geman says. And in its new guise, Bayesian\\nlearning and its priors occupy the heart of the debate.\\nCan we look forward to a time when computers can compete with our\\nbiological brains for understanding? Will they be programmed with Bayes?\\nOr with something else?\\nWhatever the outcome of the revolution, Diaconis insists that Bayes will\\nplay a role. “Bayes is still young. Probability did not have any mathematics\\nin it until 1700. Bayes grew up in data-poor and computationally poor\\ncircumstances. It hasn’t settled down yet. We can give it time.\\n“We’re just starting.”\\nappendix a\\n \\ndr fisher’s casebook: the doctor sees the\\nlight\\n \\nby michael j. campbell\\n \\nAs one gets older one’s thoughts turn naturally to religion and I have been\\npondering the religious metaphors in statistics. Clearly the frequentists are\\nmetaphorical \\nCatholics; \\ndividing \\nresults \\ninto \\n“significant” \\nand\\n“nonsignificant” instead of dividing sins into “mortal” (i.e. significant) and\\nvenial. Randomisation is the grace that saves the world. In confession the\\npriest is interested in the frequency with which one committed a sin (I can\\nimagine passing the priest a bar-chart of how many times I swore, or was\\nuncharitable, rather than giving him a verbal list—so much more\\ninformative!) After confession frequentists/Catholics are forgiven and so,\\nhaving rejected a null hypothesis at p < 0.05, once it is published they are\\nfree to use 0.05 as the limit again. The frequentist prayer is “Our Fisher, who\\nart in Heaven”. Their saints are Pearson and Neyman. Instead of Heaven and\\nHell they have the Null and Alternative hypotheses, and in their Creed\\ninstead of “Do you reject Satan?” they have “Do you reject the null\\nhypothesis?”.\\nOn the other hand Bayesians are born-again fundamentalists. One must be\\na “believer” and Bayesians can often pinpoint the day when Bayes came into\\ntheir lives, when they dropped these childish frequentist ways (or even\\n“came out”). Clearly the Reverend Thomas Bayes is their spiritual guide and\\nleader, and he even imitated the Christian God by not publishing in his own\\nlifetime (mind you, I have heard non-Bayesians wish that some of his\\nfollowers had done likewise). Bayesians divide the world into people who\\nbelieve and those who do not and will ask complete strangers at statistics\\nconferences “are you a Bayesian?” as if it were an important defining\\ncharacteristic. On finding a non-Bayesian, they will express amazement at the\\nthings the nonBayesian does, point out the certainties of their own beliefs and\\nattempt to convert the non-believer.\\nThen there are the sects. The agnostics are those who think that\\nnonparametric statistics are the answer to everything. Similarly the\\nbootstrappers cannot see why you need to bring God into it at all. There is\\nthe “bell-curve” cult, who think everything can be explained by reference to\\nthe Normal distribution. The simulators think God is purely a human\\ninvention.\\nWhere do I put myself? Well, in typically woolly English fashion, I regard\\nmyself as Anglican. I believe in statistics as a way of finding the truth and am\\nhappy to adopt whatever means will help me to get there. I can see dangers in\\nextremism in either direction and so try to steer a “middle way”. I still use p-\\nvalues and confidence intervals but temper them with prior beliefs. I like the\\nidea of “empirical Bayes” where one uses earlier studies to inform one’s\\npriors. I can see the advantages of Bayesian methods for modelling complex\\nsystems and attaching uncertainty to parameters and think that in many ways it\\nreflects scientific inference better. However, I prefer simply to call myself a\\nbeliever, and not to attach labels to these beliefs.\\nTalking of religion, I am reminded of a strip of cartoons about Bayesians\\nthat appeared some time ago. They showed a series of monks. One was\\nlooking lost, one was dressed as a soldier, one was holding a guide book and\\none had his tongue stuck out. They were, respectively, a vague prior, a\\nuniform prior, an informative prior and, of course, an improper prior . . .\\nappendix b\\n \\napplying bayes’ rule to mammograms and\\nbreast cancer\\n \\nIn 2009 a U.S. government task force on breast cancer screening advised\\nmost women in their forties not to have annual mammograms. The public\\nreaction was immediate—and in large part—enraged. Here’s a simple\\nversion of the Bayesian calculation that lay at the very heart of the\\ncontroversy.\\nA 40-year-old woman without any symptoms or family history of breast\\ncancer has a mammogram as part of a routine checkup. A week later she\\nreceives a letter saying her test result was abnormal. She needs additional\\ntesting. What is the probability she actually has breast cancer?\\nQuite low.\\nMany beginning statistics students—and many physicians—find this\\nsurprising because mammograms, as a screening test, are reasonably\\naccurate. They identify roughly 80% of 40-year-old women who have breast\\ncancer at the time of their exam, and they provide positive test results to only\\nabout 10% of women without the disease.\\nHowever, breast cancer is relatively rare. And Bayes’ rule takes back-\\nground disease rates into account as prior knowledge. As a result, Bayes\\nhighlights the fact that not everyone who gets a positive test for a disease\\nactually has that disease. It also underscores the fact that the probability of\\nbreast cancer is higher in a woman who finds a lump in her breast than in a\\nwoman who has a mammogram as part of a routine checkup.\\nTo illustrate:\\n \\nAccording to this formula, we need three pieces of information, which\\nwill all go on the right-hand side of the equation:\\n1. The probability of having breast cancer: This is our prior knowledge\\nabout the background disease rate of breast cancer among women in\\ntheir forties at the time they get a mammogram. Ac-cording to Cancer\\nand Jama, this is approximately 4/10 of 1%. Thus out of every\\n10,000 women in their forties who have mammograms, we can\\nestimate that approximately 40 actually have the disease. The\\nnumber: 40/10,000.\\n2. The probability of a breast cancer patient getting a positive\\nmammogram: According to the National Cancer Institute and\\nevidence from mammography, approximately 32 of those 40 women\\nwith breast cancer will get a positive test result from the\\nmammogram. The number: 32/10,000.\\n3. The probability of getting a positive mammogram: The total number\\nof women who get positive results (whether or not cancer is present)\\ninclude women with cancer and women who are falsely informed that\\nthey have the disease. Mammograms give a positive (“abnormal”)\\nresult to some women who do not have the disease; they are called\\nfalse positives. For mammography, this rate is quite high,\\napproximately 10%, according to the New England Journal of\\nMedicine. Thus out of 10,000 women in their forties, 996 will get a\\nletter telling them they have an abnormal test result. To rule out breast\\ncancer, these women will need more mammography, ultrasound, or\\ntissue sampling, perhaps even a biopsy. To this number must be\\nadded the 32 breast cancer patients per 10,000 who will get a\\npositive mammogram. The total number: 1028/10,000 or a little more\\nthan 10% of the women screened.\\nInserting these numbers into the formula, we get the following:\\n \\nDoing the arithmetic produces 0.03, or 3%. Thus the probability that a\\nwoman who tests positive has breast cancer is only 3%. She has 97 chances\\nout of 100 to be disease free.\\nNone of this is static. Each time more research data become available,\\nBayes’ rule should be recalculated.\\nAs far as Bayes is concerned, universal screening for a disease that affects\\nonly 4/10 of 1% of the population may subject many healthy women to\\nneedless worry and to additional treatment which in turn can cause its own\\nmedical problems. In addition, the money spent on universal screening could\\npotentially be used for other worthwhile projects. Thus Bayes highlights the\\nimportance of improving breast cancer screening techniques and reducing the\\nnumber of false positives. Another fact also points to the need for better\\nmammography: negative test results miss 1 in 5 cancers.\\nTo apply Bayes’ rule to other problems, here is the general equation:\\n \\nwhere A is a hypothesis and B is data.\\nnotes\\n \\n1. Causes in the Air\\n \\n1. Two errors about Bayes’ death and portrait have been widely\\ndisseminated. First, Bayes died on April 7, 1761, according to\\ncemetery records and other contemporaneous documents gathered by\\nBayes’ biographers, Andrew Dale and David Bellhouse. Bayes was\\ninterred on April 15, which is often called the date of his death. The\\ndegraded condition of his vault may have contributed to the\\nconfusion.\\nSecond, the often-reproduced portrait of Thomas Bayes is almost\\nassuredly of someone else named “T. Bayes.” The sketch first appeared\\nin 1936 in History of Life Insurance in its Formative Years by Terence\\nO’Donnell. However, the picture’s caption on page 335 says it is of\\n“Rev. T. Bayes, Improver of the Columnar Method developed by\\nBarrett,” and Barrett did not develop his method until 1810, a half-\\ncentury after the death of “our” Rev. Thomas Bayes.\\nBellhouse (2004) first noticed that the portrait’s hairstyle is\\nanachronistic. Sharon North, curator of Textiles and Fashion at the\\nVictoria and Albert Museum, London, agrees: “The hairstyle in this\\nportrait looks very 20th century. . . . Clerical dress is always difficult as\\nthe robes and bands (collars) change very little over time. However, I\\nwould say that the hair of the man . . . is quite wrong for the 1750s. He\\nwould have been wearing a wig for a portrait. Clergymen wore a style\\nof the bob wig (which eventually became known as a ‘clerical wig’), a\\nshort very bushy wig of horsehair powdered white.”\\n2. Dale (1999) 15.\\n3. All of Bayes’ and Price’s quotations come from their essay.\\n2. The Man Who Did Everything\\n \\n1. For details of Laplace’s personal life, I rely on Hahn (2004, 2005).\\nAll documents about Laplace’s life were thought to have been lost\\nwhen a descendant’s home was destroyed by fire in 1925, but Hahn\\npainstakingly located many original documents that revealed new\\nfacts and corrected previous assumptions about Laplace’s life and\\nwork.\\n2. “A dizzying expansion of curiosity” is Daniel Roche’s original\\nphrase in his classic, France in the Enlightenment.\\n3. Voltaire 24.\\n4. Koda and Bolton 21.\\n5. Stigler (1978) 234–35.\\n6. Laplace (1774) OC (8) 27; Laplace (1783/1786) OC (11) 37, and\\nStigler (1986) 359.\\n7. Laplace (1776) 113. For English translation, see Hahn in Lindberg\\nand Numbers (1986) 268–70.\\n8. Laplace (1783) OC (10) 301.\\n9. Laplace in Dale’s translation (1994) 120, in section titled “Historical\\nnote on the probability calculus.”\\n10. Gillispie (1997) 23.\\n11. Laplace (1782–85) OC (10) 209–340.\\n12. Laplace (1778–81) OC (9) 429 and (1783/1786) OC (10) 319.\\n13. Laplace (1778–81) OC (9) 429.\\n14. “Easy to see . . . obvious:” Laplace (1778/1781) OC (9) 383–485.\\nThe student was Jean-Baptiste Biot.\\n15. Stigler (1986) 135.\\n16. Gillispie (1997) 81.\\n17. Laplace (1783/1786) OC (10) 295–338.\\n18. Hald (1998) 236 and, for a detailed discussion of Laplace’s birth\\nstudies, 230–45.\\n19. Laplace in Philosophical Essay on Probabilities, Dale’s translation\\n77.\\n20. Hahn (2004) 104.\\n21. Sir William Herschel wrote a firsthand account in his diary. See\\nDreyer vol. I, lxii, and Hahn in Woolf.\\n22. Laplace from Exposition du Système du Monde in Crosland 90.\\n23. Glenn Shafer interview.\\n24. Laplace, Essai Philosophique, translated in Hahn (2005) 189 and in\\nDale (1995) 124.\\n3. Many Doubts, Few Defenders\\n \\n1. Clerke 200–203.\\n2. Bell ix and 172–82.\\n3. David 30.\\n4. Gillispie (1997) 67, 276–77.\\n5. Pearson (1929) 208.\\n6. Porter (1986) 36.\\n7. Mill in Gigerenzer et al. (1989) 33.\\n8. Quoted by Dale (1998) 261.\\n9. G. Chrystal in Hald (1998) 275.\\n10. Le procès Dreyfus vol. 3, 237–31.\\n11. Molina in Bailey (1950) 95–96.\\n12. Rubinow (1914) 13.\\n13. Rubinow (1917) 35.\\n14. Rubinow (1914–15) 14.\\n15. Rubinow (1917) 42.\\n16. Rubinow (1914–15) 14.\\n17. Anonymous in Pruitt (1964) 151.\\n18. Whitney (1918) 287.\\n19. Pruitt 169.\\n20. Ibid., 170.\\n21. Ibid.\\n22. Pearson in MacKenzie (1981) 204.\\n23. J. L. Coolidge in Hald (1998) 163.\\n24. Kruskal 1026.\\n25. Savage (1976) 445–46.\\n26. Leonard Darwin in MacKenzie (1981) 19.\\n27. Fisher in Box (2006) 127.\\n28. Fisher (1925) 1.\\n29. Kruskal 1026.\\n30. Ibid., 1029.\\n31. Fisher in Kotz and Johnson I 13.\\n32. Fisher in Gill 122.\\n33. Fisher (1925) 9–11.\\n34. Hald (1998) 733.\\n35. Savage (1976) 446.\\n36. E. Pearson in Reid 55–56.\\n37. Perks 286.\\n38. Fisher in Neyman Supplement 154–57.\\n39. Tukey, according to Brillinger e-mail.\\n40. aip.org/history/curie/scandal. Accessed April 18, 2006.\\n41. De Finetti (1972).\\n42. Lindley letter to author.\\n43. Essen-Möller in Kaye (2004).\\n44. Huzurbazar 19.\\n45. Lindley (1983) 14.\\n46. Howie 126.\\n47. Ibid., 210.\\n48. Jeffreys (1939) 99.\\n49. Lindley (1991) 11.\\n50. Ibid., 391.\\n51. Jeffreys (1938) 718.\\n52. Jeffreys (1939) v.\\n53. Goodman (2005) 284.\\n54. Howie 165.\\n55. Box (1978) 441.\\n56. Lindley (1986a) 43.\\n57. Jeffreys (1961) 432.\\n58. Lindley (1983) 8.\\n59. Lindley (1991) 10.\\n4. Bayes Goes to War\\n \\n1. Churchill 598.\\n2. Peter Twinn in Copeland (2006) 567.\\n3. Atkinson and Feinberg 36.\\n4. D. G. Kendall in ibid., 48.\\n5. Alastair Denniston in Copeland (2006) 57 and (2004) 219.\\n6. Patrick Mahon in Copeland (2004) 271.\\n7. Ibid., 279.\\n8. Max Newman in Gandy and Yates 7.\\n9. Copeland (2006) 379.\\n10. Copeland (2004) 258.\\n11. Copeland (2006) 379.\\n12. Copeland (2004) 281.\\n13. Good (1979) 394.\\n14. Anonymous to author.\\n15. Britton 214.\\n16. Hinsley and Stripp 155.\\n17. Good interview.\\n18. Michie’s draft chapter and Good interview.\\n19. Copeland (2004) 279.\\n20. Ibid., 287–88.\\n21. Ibid., 292.\\n22. Ibid., 289.\\n23. Ibid., 260.\\n24. For the entire letter episode, ibid., 336–37.\\n25. Shiryaev (1991) 313.\\n26. Ibid.\\n27. Kolmogorov (1942).\\n28. Arnold.\\n29. Copeland (2006) 383.\\n30. Copeland (2006) 380–82.\\n31. Turing (1942).\\n32. Shannon in Kahn (1967) 744.\\n33. Waddington 27.\\n34. Koopman (1946) 771.\\n35. Koopman (1980) 17.\\n36. Ibid., 18.\\n37. Ibid., 60–61.\\n38. Andresen 82–83.\\n39. Copeland (2006) 80–81.\\n40. Michie in Copeland (2006) 380.\\n41. Ibid., 244.\\n42. Edward H. Simpson letter to author.\\n43. Ibid.\\n44. Good in Britton 221.\\n45. Hodges (2000) 290.\\n46. Dennis Lindley letter to author.\\n47. Hilton 7.\\n5. Dead and Buried Again\\n \\n1. Good interview.\\n2. Sampson et al. 135.\\n3. John W. Pratt interview.\\n4. Perks 286.\\n5. DeGroot (1986a) 40–53.\\n6. Kotz and Johnson I xxxviii.\\n7. Anonymous in Reid 273.\\n6. Arthur Bailey\\n \\n1. Biographical details are from interviews and correspondence with\\nhis son and daughter-in-law, Robert A. and Shirley Bailey.\\n2. Bailey (1942, 1943) 31–32.\\n3. Hewitt (1969) 80.\\n4. Bailey (1950) 7.\\n5. Ibid., 31–32.\\n6. Ibid., 7–9.\\n7. Pruitt 165.\\n8. Bailey (1950) 8.\\n9. PCAS 37 94–115.\\n10. The Longley-Cook episode is in Carr 241–43.\\n11. Charles C. Hewitt Jr. interview.\\n12. Hans Bühlmann letter to author.\\n7. From Tool to Theology\\n \\n1. Stephan et al., 953.\\n2. Good interview.\\n3. Reid 216.\\n4. Fisher (1958) 274.\\n5. Reid 256.\\n6. Ibid., 226.\\n7. Ibid., 274.\\n8. Good in Kotz and Johnson I 380.\\n9. Fienberg (2006) 19.\\n10. Lindley in Smith (1995) 312.\\n11. Donald Michie in Copeland (2006) 240.\\n12. Stephen Fienberg interview.\\n13. George E. P. Box interview.\\n14. Smith (1995) 308.\\n15. Sampson (1999) 126–27.\\n16. Ibid., 128.\\n17. Kotz and Johnson I 520.\\n18. Lindley (1989) 14.\\n19. Savage (1956).\\n20. Lindley in Erickson 49.\\n21. Savage in Fienberg (2006) 16–19.\\n22. Schrödinger 704.\\n23. Savage in Erickson 297.\\n24. David Spiegelhalter interview.\\n25. Robert E. Kass interview.\\n26. Anonymous.\\n27. Maurice G. Kendall 185.\\n28. Kruskal in Brooks, online.\\n29. Savage in Lindley letter to author.\\n30. Rivett.\\n31. Lindley letter to author.\\n32. Smith (1995) 312.\\n33. Lindley letter to author.\\n8. Jerome Cornfield, Lung Cancer, and Heart\\nAttacks\\n \\n1. Marvin Hoffenberg interview.\\n2. Ibid.\\n3. Cornfield (1975) 14.\\n4. Memorial Symposium 55.\\n5. Gail 9.\\n6. Ibid.\\n7. Gail 10.\\n8. Stories from Memorial Symposium 52 and 56.\\n9. Cornfield (1962) 58.\\n10. Gail 5.\\n11. Cornfield (1967) 41.\\n12. Cornfield (1975) 9–11.\\n13. Memorial Symposium 52.\\n14. Ellen Cornfield interview.\\n9. There’s Always a First Time\\n \\n1. Jardini 119.\\n2. Harken.\\n3. Albert Madansky interview.\\n4. Iklé (1958) 3.\\n5. Ibid., 73.\\n6. Ibid., 8, 114.\\n7. Iklé (1958) 74.\\n8. Madansky interview.\\n9. Lindley (1985) 104.\\n10. Madansky interview.\\n11. Ibid.\\n12. Ibid.\\n13. Iklé (1958) 54.\\n14. Ibid., 53–54.\\n15. Madansky interview.\\n16. Iklé (1958) 153.\\n17. Iklé (2006) 46–47.\\n18. Ibid.\\n19. Ibid.\\n10. 46,656 Varieties\\n \\n1. Good (1971) 62–63.\\n2. Glenn Shafer interview.\\n3. Lindley letter to author.\\n4. Box interview.\\n5. Ibid.\\n6. Efron (1977) and interview.\\n7. Box interview.\\n8. Box (2006) 555–56.\\n9. Bross (1962) 309–10.\\n10. Savage (1962) 307.\\n11. Ericson (1981) 299.\\n12. Box interview.\\n13. “What I . . . me . . . it was . . . angry . . . heads.” Lindley to Smith\\n(1995) 310–11.\\n14. Bennett 36.\\n15. Smith (1995) 311.\\n16. Box interview.\\n17. Ibid.\\n18. Homer Warner interview.\\n19. Leahy (1960) 50.\\n20. Tribe (1971a) 1376.\\n11. Business Decisions\\n \\n1. Fienberg (1990) 206.\\n2. Schleifer interview.\\n3. Pratt interview.\\n4. Pratt, Raiffa, Schlaifer (1965) 1.1.\\n5. Savage (1956) letter.\\n6. Schlaifer letter of August 22, 1956.\\n7. Memorial Service (1994).\\n8. Arthur Schleifer interview.\\n9. Raiffa in Fienberg (2008) 137.\\n10. Ibid., 138.\\n11. Ibid., 139.\\n12. Ibid., 141.\\n13. Fienberg (2006) 10.\\n14. Raiffa (1968) 283.\\n15. Raiffa interview.\\n16. Raiffa (2006) 32.\\n17. Fienberg (2008) 10.\\n18. Raiffa interview.\\n19. Memorial Service.\\n20. Fienberg (2008) 142.\\n21. Pratt, Memorial Service.\\n22. Memorial Service.\\n23. Arthur Schleifer interview.\\n24. Ibid.\\n25. Ibid.\\n26. Fienberg (2006) 18.\\n27. Raiffa (2006) 48, 51.\\n28. Raiffa interview.\\n29. Schleifer interview.\\n30. Raiffa, Memorial Service.\\n31. Raiffa (1968).\\n32. Lindley in Smith (1995) 312.\\n33. McGinnis.\\n34. Raiffa and Pratt (1995).\\n12. Who Wrote The Federalist?\\n \\n1. Most of the quotations from Mosteller and Wallace in this chapter\\ncome from their book, published in 1964 and 1984 under different\\ntitles. Exceptions will be noted.\\n2. David L. Wallace interview.\\n3. Fienberg et al. 147.\\n4. Ibid., 192.\\n5. Petrosino.\\n6. Kolata 397.\\n7. DeGroot (1986c) 322.\\n8. Albers et al. (1990) 256–57.\\n9. Kolata 398.\\n10. Robert E. Kass interview.\\n13. The Cold Warrior\\n \\n1. Bamford 430–31. The author covered this controversy for the Trenton\\nN.J. Times.\\n2. Stephen Fienberg interview and e-mail.\\n3. Brillinger in Brillinger (2002a) 1549.\\n4. Anscombe 296.\\n5. Wheeler in Brillinger (2002b) 193.\\n6. Descriptions of Tukey come from Anscombe 289, Bradford Murphy\\ninterview, and McCullagh 541.\\n7. Elizabeth Tukey and Tukey in Brillinger (2002a) 1561–2.\\n8. John Chambers, Bell Labs.\\n9. Ibid.\\n10. Tukey (1962) 5, 7.\\n11. Kotz and Johnson II 449.\\n12. Anscombe 294.\\n13. Bell Labs News (1985) (25) 18 and Brillinger (2002a) 1556.\\n14. Tukey in Brillinger (2002a) 1561.\\n15. Wallace interview.\\n16. Fienberg (2006) 24.\\n17. Wainer 285, Anscombe 290, and Wallace interview.\\n18. Box and Edgar Gilbert interviews, McCullagh 544 and 554, and\\nPratt interview, respectively.\\n19. Tukey (1967) in Jones (4) 589.\\n20. Tukey in Lyle V. Jones, (III) 108; (IV) xiv; (III) 188; and (III) 394,\\nrespectively.\\n21. Brillinger (2002a) 1561; L. Jones (1986) (IV) 771–2; Casella 312,\\nrespectively.\\n22. Casella 332 and McCullagh 547, respectively.\\n23. L. Jones (III) 277. “A natural . . . framework”: Casella 312.\\n24. Wallace, in interviews with the author.\\n25. Gnanadesikan.\\n26. L. Jones (IV) 589.\\n27. Brillinger interview.\\n28. Anscombe 300.\\n29. Wallace interview.\\n30. Brillinger e-mail.\\n31. Wallace interview.\\n14. Three Mile Island\\n \\n1. In Lyle Jones (IV) 686 and Box and Tiao (1973) 1.\\n2. Bather 346–47 and Holmes interview, respectively.\\n3. Both Diaconis and Lindley recalled this incident in interviews.\\n4. Efron (1978) 232.\\n5. Lindley to Smith (1995) 313.\\n6. Apostalakis interview.\\n15. The Navy Searches\\n \\n1. Quotations from John Craven are—unless noted otherwise—from\\ninterviews with the author.\\n2. Craven wrote The Silent War: The Cold War Battle Beneath the Sea\\nat the navy’s behest in two weeks without notes in order to rebut the\\npopular book Blind Man’s Bluff: The Untold Story of American\\nSubmarine Espionage (1998) by Sontag and Drew. In his own book,\\nCraven said he attended Raiffa’s lectures; later he told me that he\\nprobably heard about Raiffa’s work from others at MIT.\\n3. Wagner (1988).\\n4. Ibid., 9.\\n5. Quotations from Henry R. (“Tony”) Richardson are from interviews\\nwith the author.\\n6. Capt. Frank A. Andrews e-mail.\\n7. Richardson interview.\\n8. Lewis 99–100, 133, 165, 168. Her Pulitzer Prize–winning book is\\ngenerally regarded as the best on-site source.\\n9. Craven 173.\\n10. Lewis 206 and 208.\\n11. Wagner 10.\\n12. Craven 205–7.\\n13. Stone (1975) 54.\\n14. Craven 202–3.\\n15. Stone et al. (1999) ix.\\n16. Joseph H. Discenza interview.\\n17. Stone (1999) ix and (1983) 209.\\n18. Ibid., (1999) ix.\\n19. VAdm. John “Nick” Nicholson interview.\\n20. Ray Hilborn interview.\\n16. Eureka!\\n \\n1. A. Philip Dawid interview.\\n2. In Donald Owen (1976) 421.\\n3. Cooke 20.\\n4. Jeffrey E. Harris interview.\\n5. Adrian Raftery interview.\\n6. Raftery (1986) 145–46.\\n7. Stuart Geman interview.\\n8. Shafer (1990) 440; and Diaconis in DeGroot (1986c) 334,\\nrespectively.\\n9. Lindley in Diaconis and Holmes (1996) 5 and in letter to the author.\\n10. AFM Smith (1984) 245, 255.\\n11. Alan Gelfand interview.\\n12. Christian Robert and George Casella.\\n13. Mayer in Householder 19.\\n14. W. Keith Hastings interview.\\n15. S. Gelfand interview.\\n16. Robert and Casella (2008).\\n17. Gelfand et al. (1990).\\n18. Gill 332.\\n19. Kuhn.\\n20. David Spiegelhalter interview.\\n21. Spiegelhalter, Abrams, and Myles.\\n22. Taylor and Gerrodette (1993).\\n23. Raftery interview.\\n24. Paul R. Wade interview.\\n25. Blackwell in DeGroot (1986a).\\n26. Diaconis and Holmes (1996) 5.\\n27. Sir John Russell and William Gladstone in the nineteenth century\\nand Harold Wilson in the twentieth.\\n17. Rosetta Stones\\n \\nAlmost all the quotations in this chapter come from interviews with the\\nauthor. Exceptions are noted here.\\n1. Unwin 190; Schneider; Ludlum 394. The phrase “We’re all Bayesians\\nnow” is sometimes attributed to John Maynard Keynes, but it may\\nhave first appeared in 1976 in John C. Henretta and Richard T.\\nCampbell’s article, Status Attainment and Status Maintenance: A\\nStudy of Stratification in Old Age in American Sociological Review\\n(41) 981–92. To complicate matters, Campbell was paraphrasing an\\nearlier popular expression, “We’re all Keynesians now,” which has\\nbeen attributed to Milton Friedman in 1966 and which was\\n“popularized” by President Richard Nixon in 1971.\\nI am indebted to Stephen Senn, Michael Campbell, and Wikipedia for\\nhelping sort out the origins of the “Keynesians” quotation.\\n2. Dawid in Swinburne (2002) 84\\n3. Greenspan.\\n4. Ibid.\\n5. New York Times January 4, 2009.\\n6. Weaver 15.\\nglossary\\n \\nalgorithm a formula defining a sequence of steps in order to solve a\\nproblem\\nanalysis a higher branch of mathematics\\na priori see prior\\naxiom an assumption upon which a mathematical theory is based\\nban a measure of probability expressed in logarithms to the base 10 so\\nthat multiplication can be replaced by addition\\nBayes’ rule a mathematical device combining prior information with\\nevidence from data (its formula appears on p. 31 with a simplified\\nversion on p. 257.)\\nBayesian network a graphical model that compactly represents\\nprobabilities and their relationships. Each random variable is\\ndenoted by a node, and a line between two nodes indicates their\\ninterdependency.\\ncentering points types of averages, e.g., the mean, median, and mode\\nchange point the point when change occurs in time-ordered data\\ncredibility a measure of the credence that actuaries place in a particular\\nbody of claims experience as they set insurance policy rates\\ncryptography writing and breaking ciphers, communications that third\\nparties cannot understand\\ncurse of high dimensionality the explosive growth of data sets as more\\nvariables are added\\ndata bits of information that can be represented numerically\\nfiducial probability R. A. Fisher’s controversial attempt to apply\\nprobability to unknown parameters without using Bayes’ rule or\\npriors\\nfilter a process that makes data immune to the noise in a system and that\\nextracts information from the data\\nfrequency a branch of probability theory that measures the relative\\nfrequency of an event that can be repeated over and over again under\\nmuch the same conditions\\ngenerating function a mathematical shortcut for making approximations\\nhierarchical Bayes a method that develops mathematical models by\\nbreaking complex processes into stages called hierarchies\\nhypothesis a proposition that is to be tested or modified with new\\nevidence\\ninduction drawing conclusions about natural laws or regularities from\\nan observation or experiment; the opposite of deduction\\ninfer deriving natural laws and regularities from a well-defined\\nstatement or observation\\ninverse probability the branch of probability theory that draws\\nconclusions about antecedents or causes of observed events, e.g.,\\nBayes’ rule\\nlikelihood principle an approach to using Bayes’ theorem without\\nassuming any prior probabilities\\nlikelihood ratio the comparison between the probabilities of an\\nobservation when a hypothesis is true and when it is untrue\\nMarkov chain a process that assumes the probability of an event\\ndepends only on the immediately preceding events\\nMCMC a process that combines Markov chains and the Monte Carlo\\nprocedure\\nmodel a mathematical system used to understand another mathematical,\\nphysical, biological, or social system\\nMonte Carlo method a computer method to simulate probability\\ndistributions by taking random samples\\nmultivariate containing many unknowns and variables\\nnaïve Bayes a special, fast kind of Bayesian network\\nnull hypothesis a plausible hypothesis that might explain a particular set\\nof data; a null hypothesis can be compared with other alternatives\\nodds the ratio of the probabilities that an event will either occur or not\\noccur\\noperations research or operational research a scientific approach to\\ndecision making\\nparameter in a mathematical expression, a quantity that is normally\\nassumed to be constant; the value of the constant, however, can be\\nchanged as conditions are changed\\nposterior in Bayes’ theorem, the probability of a conclusion after\\nevidence has been considered\\nprior the probability of a hypothesis before new data is observed\\nprobability the mathematics of uncertainty; the numerical measure of\\nuncertainty\\nrotors the geared wheels on Enigma machines\\nsampling the selection of a finite number of observations in order to\\nlearn about a much larger statistical population\\nsequential analysis the continuous analysis of data as they arrive while\\ntaking into account the effect of previous data\\nstatistics a branch of applied mathematics that measures uncertainty and\\nexamines its consequences\\nstopping rule a sampling method in which data are evaluated as they\\nare collected; the sampling stops when significant results are\\nobtained\\nsubjective probability Bayesian probability, a measure of personal\\nbelief in a particular hypothesis\\ntransforms mathematical tools that change one kind of function into\\nanother that is easier to use\\nbibliography\\n \\nAbbreviations\\n \\nJASA Journal of the American Statistical Association\\nJRSS Journal of the Royal Statistical Society\\nOC\\nOeuvres Complètes de Laplace\\nPCAS Proceedings of the Casualty Actuarial Society\\nPart I. Enlightenment and the Anti-Bayesian\\nReaction\\n \\nChapter 1. Causes in the Air\\nBayes, Joshua. Sermons and Funeral Orations. English Short Title\\ndatabase of 18th-century microfilms. Reels 7358 no. 08; 7324 no. 06;\\n7426 no. 03; and 7355 no. 08.\\nBayes, Thomas. (1731) “Divine benevolence: Or, an attempt to prove\\nthat the principal end of the divine providence and government is the\\nhappiness of his creatures.” London.\\n———. (1763) An Introduction to the Doctrine of Fluxions, and\\nDefence of the Mathematicians against the Objections of the\\nAuthor of the Analyst. Printed for J. Noon, London. The Eighteenth\\nCentury Research Publications Microfilm A 7173 reel 3774 no. 06.\\nBayes, Thomas, and Richard Price. (1763) An essay towards solving a\\nproblem in the doctrine of chances. By the late Rev. Mr. Bayes,\\nF.R.S. Communicated by Mr. Price, in a letter to John Canton,\\nA.M.F.R.S. A letter from the late Reverend Mr. Thomas Bayes,\\nF.R.S., to John Canton, M.A. and F.R.S. Author(s): Mr. Bayes and Mr.\\nPrice. Philosophical Transactions (1683–1775) (53) 370–418.\\nRoyal Society. The original Bayes–Price article.\\nBebb, ED. (1935) Nonconformity and Social and Economic Life\\n1660–1800. London: Epworth Press.\\nBellhouse, David R. (2002) On some recently discovered manuscripts\\nof Thomas Bayes. Historia Mathematica (29) 383–94.\\n———. (2007a) The Reverend Thomas Bayes, FRS: A biography to\\ncelebrate the tercentenary of his birth. Statistical Science (19:1) 3–\\n43. With Dale (2003) the main source for Bayes’ life.\\n———. (2007b) Lord Stanhope’s papers on the Doctrine of Chances.\\nHistoria Mathematica (34) 173–86.\\nBru, Bernard. (1987) Preface in Thomas Bayes. Essai en vue de\\nrésoudre un problème de la doctrine des chances, trans. and ed., J-P\\nCléro. Paris.\\n———. (1988) Estimations laplaciennes. Un exemple: La recherche de\\nla population d’un grand empire, 1785–1812. J. Soc. Stat. Paris\\n(129) 6–45.\\nCantor, Geoffrey. (1984) Berkeley’s The Analyst revisited. Isis (75)\\nDec. 668–83.\\nChesterfield PDS. (1901) Letters to His Son: On the Fine Art of\\nBecoming a Man of the World and a Gentleman. M. Walter Dunne.\\nCone, Carl B. (1952) Torchbearer of Freedom: The Influence of\\nRichard Price on Eighteenth-Century Thought. University of\\nKentucky Press.\\nDale, Andrew I. (1988) On Bayes’ theorem and the inverse Bernoulli\\ntheorem. Historia Mathematica (15) 348–60.\\n———. (1991) Thomas Bayes’s work on infinite series. Historia\\nMathematica (18) 312–27.\\n———. (1999) A History of Inverse Probability from Thomas Bayes\\nto Karl Pearson. 2d ed. Springer. One of the foundational works in\\nthe history of probability.\\n———. (2003) Most Honourable Remembrance: The Life and Work\\nof Thomas Bayes. Springer. With Bellhouse, the main source for\\nBayes’ life.\\nDaston, Lorraine. (1988) Classical Probability in the Enlightenment.\\nPrinceton University Press.\\nDeming WE, ed. (1940) Facsimiles of Two Papers by Bayes, With\\nCommentaries by W. E. Deming and E. C. Molina. Graduate School.\\nDepartment of Agriculture. Washington, D.C.\\nEarman, John. (1990) Bayes’ Bayesianism. Studies in History and\\nPhilosophy of Science (21) 351–70.\\n———. (2002) Bayes, Hume, Price, and miracles. In Bayes’s Theorem,\\ned., Richard Swinburne. 91–109.\\nGillies, Donald A. (1987) Was Bayes a Bayesian? Historia\\nMathematica (14) 325–46.\\nHaakonssen, Knud. (1996) Enlightenment and Religion: Rational\\nDissent in Eighteenth-Century Britain. Cambridge University Press.\\nHacking, Ian. (1990) The Taming of Chance. Cambridge University\\nPress.\\n———. (1991) Bayes, Thomas. Biographical \\nDictionary \\nof\\nMathematicians vol. 1, Charles Scribner’s Sons.\\nHald, Anders. (1990) A History of Probability and Statistics and Their\\nApplications before 1750. John Wiley and Sons.\\n———. (1998) A History of Mathematical Statistics from 1750 to\\n1930. John Wiley and Sons. A classic.\\nHembry, Phyllis M. (1990) The English Spa 1560–1815: A Short\\nHistory. Athlone Press, Fairleigh Dickinson University Press.\\nHolder, Rodney D. (1998) Hume on miracles: Bayesian interpretation,\\nmultiple testimony, and the existence of God. British Journal for the\\nPhilosophy of Science (49) 49–65.\\nHolland JD. (1968) An eighteenth-century pioneer Richard Price, D.D.,\\nF.R.S. (1723–1791). Notes and Records of the Royal Society of\\nLondon (23) 43–64.\\nHume, David. (1748) An Enquiry Concerning Human Understanding.\\nWidely available. Online see Project Gutenberg.\\nJacob, Margaret C. (1976) The Newtonians and the English Revolution\\n1689–1720. Cornell University Press.\\nJesseph DM. (1993) Berkeley’s Philosophy of Mathematics. University\\nof Chicago Press.\\nKlein, Lawrence E. (1994) Shaftesbury and the Culture of Politeness:\\nMoral Discourse and Cultural Politics in Early Eighteenth-\\nCentury England. Cambridge University Press.\\nMiller, Peter N. (1994) Defining the Common Good: Empire, Religion\\nand \\nPhilosophy \\nin \\nEighteenth \\nCentury \\nEngland. Cambridge\\nUniversity Press.\\nOwen, David. (1987) Hume versus Price on miracles and prior\\nprobabilities: Testimony and the Bayesian calculation. Philosophical\\nQuarterly (37) 187–202.\\nPrice, Richard. Four Dissertations. 3d ed. (1772). Dissertation IV: On\\nthe nature of historical evidence and miracles. Google online.\\nSobel, Jordan Howard. (1987) On the evidence of testimony for\\nmiracles: A Bayesian interpretation of David Hume’s analysis.\\nPhilosophical Quarterly (37:147) 166–86.\\nStanhope G, Gooch GP. (1914) The Life of Charles Third Earl\\nStanhope. Longmans, Green.\\nStatistical Science (2004) Issue devoted to Thomas Bayes. (19:1)\\nMany useful articles.\\nStigler, Stephen M. (1983). Who discovered Bayes’s Theorem?\\nAmerican Statistician 37 290–96.\\n———. (1986). The History of Statistics: The Measurement of\\nUncertainty before 1900. Belknap Press of Harvard University Press.\\nA classic and the place to start for Thomas Bayes.\\n———. (1999). Statistics on the Table: The History of Statistical\\nConcepts and Methods. Harvard University Press.\\nThomas, DO. (1977) The Honest Mind: The Thought and Work of\\nRichard Price. Clarendon Press. Thomas is the authority on Price and\\nedited his correspondence. Thomas, DO, and Peach, WB. (–1994)\\nEds. The Correspondence of Richard Price, vols 1-3. Duke\\nUniversity Press.\\nWatts, Michael R. (1978) The Dissenters vols. 1 and 2. Clarendon\\nPress.\\nChapter 2. The Man Who Did Everything\\nAlbrecht, Peter. (1998) What do you think of smallpox inoculations? A\\ncrucial question in the eighteenth century, not only for physicians. In\\nThe Skeptical Tradition around 1800, eds., J. van der Zande, RH\\nPopkin. Dordrecht, Kluwer Academic Publishers. 283–96.\\nArago, F. (1875) Laplace: Eulogy before the French Academy. Trans.\\nBaden Powell. Smithsonian Institution. Annual report 1874 in\\nCongressional Papers for 43rd Congress. Washington, D.C., 129–68.\\nArbuthnot J. (1711) An argument for Divine Providence, taken from the\\nconstant regularity observed in the births of both sexes. Philos.\\nTrans. Roy. Soc., Lond. (27) 186–90.\\nBaker, Keith Michael. (1975) Condorcet: From Natural Philosophy to\\nSocial Mathematics. University of Chicago Press.\\nBiot, JB. (1850) Une anecdote relative à M. Laplace. Journal Des\\nSavants 65–71.\\nBuffon. (1774) A Monsieur de la Place. Journal Officiel May 24, 1879,\\np. 4262; and Comptes Rendus Hebdomadaires des Séances de\\nl’Académie des Sciences (88) 1879, 1019. I am indebted to Roger\\nHahn for this letter.\\nBugge T, Crosland M. (1969) Science in France in the Revolutionary\\nEra. Society for the History of Technology and MIT Press.\\nClark W, Golinski J, Schaffer S. (1999) The Sciences in Enlightened\\nEurope. University of Chicago Press.\\nCondorcet, Jean-Antoine-Nicolas de Caritat, B. Bru, P. Crépel (1994)\\nCondorcet, Arithmétique politique Textes rares ou inédits (1767–\\n1789). Presses Universitaires de France.\\nCrosland, Maurice P. (1967) The Society of Arcueil; A View of French\\nScience at the Time of Napoleon I. Harvard University Press.\\nDale, Andrew I. (1995) Pierre-Simon Laplace: Philosophical Essay\\non Probabilities. Trans. and notes by Dale. Springer-Verlag.\\n———. (1999) A History of Inverse Probability from Thomas Bayes\\nto Karl Pearson. 2d ed. Springer. One of the foundational works in\\nthe history of probability.\\nDaston, Lorraine. (1979) D’Alembert’s critique of probability theory.\\nHistoria Mathematica (6) 259–79.\\nDhombres, Jean. (1989) Books: reshaping science. In Revolution in\\nPrint: The Press in France 1775–1800, eds., R Darnton, D Roche.\\nUniversity of California Press. 177–202.\\nDoel, Ronald E. (1990) Theories and origins in planetary physics. Isis\\n(90) 563–68.\\nDreyer JLF, ed. (1912) The Scientific Papers of Sir William Herschel,\\nvol. I. London: Royal Society and Royal Astronomical Society.\\nDunnington, G. Waldo. Carl Friedrich Gauss: Titan of Science.\\nExposition Press, 1955.\\nDuveen DI, Hahn R. (1957) Laplace’s succession to Bézout’s post of\\nexaminateur des élèves de l’artillerie. Isis (48) 416–27.\\nDuveen DI, Hahn R (1958) Deux Lettres de Laplace à Lavoisier. Revue\\nd’histoire des Sciences et de leurs Applications (11:4) 337–42.\\nFourier, Joseph. (1830) Historical Eulogy of the M. le Marquis de\\nLaplace. Trans. RW Haskins. Buffalo; and (1831) Eloge historique\\nde M. le marquis de Laplace, prononcé . . . le 15 juin 1829, MASIF\\n(10) lxxxi-cii.\\nFox, Robert. (1974) The rise and fall of Laplacian Physics. Historical\\nStudies in the Physical Sciences (4) 89–136.\\n———. (1987) La professionalisation: un concept pour l’historien de\\nla science française au XIXe siècle. History and Technology (4)\\n413–22.\\nGillispie, Charles C. (1972) Probability and politics: Laplace,\\nCondorcet, and Turgot. Proceedings of the American Philosphical\\nSociety (116) 1–20.\\n———. (1978) Laplace, Pierre-Simon, Marquis De. Dictionary of\\nScientific Biography, Supplement I, Vol. XV. Charles Scribner’s\\nSons.\\n———. (1979) Mémoires inedits ou anonymes de Laplace. Revue\\nd’Histoire des Sciences et de Leurs Applications (32) 223–80.\\n———. (2004) Science and Polity in France: The End of the Old\\nRegime. And Science and Polity in France: The Revolutionary and\\nNapoleonic Years. Princeton University Press.\\nGillispie, CC, with Robert Fox and Ivor Grattan-Guinness. (1997)\\nPierre-Simon Laplace 1749–1827: A Life in Exact Science.\\nPrinceton University Press.\\nGreenberg, John. (1986) Mathematical physics in eighteenth-century\\nFrance. Isis (77) 59–78.\\nGrimaux, Édouard. (1888) Lavoisier 1743–1794. Alcan, Paris.\\nGrimsley, Ronald. (1963) Jean d’Alembert 1717–83. Clarendon Press.\\nGuerlac, Henry. (1976) Chemistry as a branch of physics: Laplace’s\\ncollaboration with Lavoisier. Historical Studies in the Physical\\nSciences (7) 193–276.\\nHahn, \\nRoger. \\n(1955) \\nLaplace’s \\nreligious \\nviews. \\nArchives\\nInternationals d’Histoire des Sciences (8) 38–40.\\n———. (1967a) Laplace as a Newtonian Scientist. William A. Clark\\nMemorial Library 1967.\\n———. (1967b) Laplace’s first formulation of scientific determinism in\\n1773. Nadbitka. Actes du XIe Congrès International d’Histoire des\\nSciences. (2) 167–171.\\n———. (1969) Élite scientifique et democratie politique dans la\\nFrance révolutionnaire. Dix-Huitième Siècle (1) 252–73.\\n———. (1976) Scientific careers in eighteenth-century France. In The\\nEmergence of Science in Western Europe, ed., Maurice Crossland.\\nNew York: Science History Publications.\\n———. (1981) Laplace and the vanishing role of God in the physical\\nuniverse. In The Analytic Spirit, ed., Harry Woolf. Cornell University\\nPress. 85–95.\\n———. (1987a) Changing patterns for the support of scientists from\\nLouis XIV to Napoleon. History and Technology (4) 401–11.\\n———. (1987b) Laplace and Boscovich. Proceedings \\nof \\nthe\\nBicentennial Commemoration of R. G. Boscovich, eds., M. Bossi, P.\\nTucci. Milan.\\n———. (1989) The triumph of scientific activity: From Louis XVI to\\nNapoleon. Proceedings of the Annual Meeting of the Western\\nSociety for French History (16) 204–11.\\n———. (1990) The Laplacean view of calculation. In The Quantifying\\nSpirit in the 18th Century, eds., T Frängsmyr, HL Heilbron, RE\\nRider. University of California Press. 363–80.\\n———. (1994) Le role de Laplace à l’École Polytechnique. In La\\nFormation polytechnicienne, 1794–1994, eds., B. Belhoste, A.\\nDahan and A. Picon. Seyssel.\\n———. (1995) Lavoisier et ses collaborateurs: Une Équipe au Travail.\\nIn Il y a 200 Ans Lavoisier, ed., C. Demeulenaere-Douyère, Paris:\\nTechnique et Documentation Lavoisier. 55–63.\\n———. (2005) Pierre Simon Laplace, 1749–1827: A Determined\\nScientist. Harvard University Press; (2004) Le Système du Monde:\\nPierre Simon Laplace, Un Itinéraire dans la Science. Trans. Patrick\\nHersant. Éditions Gallimard. These are the same book, the original in\\nEnglish, the translation in French. These books are my primary\\nsources for Laplace’s life.\\nHald, Anders. (1998) A History of Mathematical Statistics from 1750\\nto 1930. John Wiley and Sons. A classic.\\nHankins, Thomas L. (1970) Jean d’Alembert: Science and the\\nEnlightenment. Oxford University Press.\\n———. (1985) Science and the Enlightenment. Cambridge University\\nPress.\\nHarte, Henry H. (1830) On the System of the World. English translation\\nof Laplace’s Exposition du système du monde. Dublin University\\nPress.\\nHeilbron HL. (1990) Introductory essay and The measure of\\nenlightenment. In The Quantifying Spirit in the 18th Century, eds., T\\nFrängsmyr, HL Heilbron, RE Rider. University of California Press.\\n1–24, 207–41.\\nHerivel, John. (1975) Joseph Fourier: The Man and the Physicist.\\nClarendon Press.\\nHolmes, Frederick Lawrence. (1961) Antoine Lavoisier—The Next\\nCrucial Year; or, the Sources of His Quantitative Method in\\nChemistry. Cornell University Press.\\nKoda H, Bolton A. (2006) Dangerous Liaisons: Fashion and\\nFurniture in the Eighteenth Century. Metropolitan Museum of Art\\nand Yale University Press.\\nLaplace, Pierre Simon. (1878–1912) Oeuvres \\nComplètes \\nde\\nLaplace.14 vols. National Bibliothèque de la France. Available\\nonline. In some cases, two dates are given; the first is the year when\\nLaplace read his paper to the academy, the second when it was\\npublished. We are indebted to Charles C. Gillispie for rationalizing\\nLaplace’s publication dates.\\n———. (1773) Recherches: 1° sur l’intégration des equations\\ndifférentielles aux différences finies, and sur leur usage dans la\\nthéorie des hazards; 2° Sur le principe de la gravitation universelle,\\nand sur les inégalités séculaires des planètes qui en dependent.\\n(February 10, 1773) OC (8) 69–197, 198–275.\\n———. (1774a) Mémoire sur la probabilité des causes par les\\névénements. OC (8) 27–69. This is Laplace’s discovery of inverse\\nprobability, his first version of what is now known as Bayes’ rule.\\nFor the English translation with modern mathematical notation, see\\nStigler (1986).\\n———. (1774b) Mémoire sur les suites récurro-récurrentes et sur leurs\\nusages dans la théorie des hazards. OC (8) 5–24.\\n———. (1776) Sur le principe de la gravitation universelle et sur les\\ninégalités séculaires des planets qui en dependent. OC (8) 201–78.\\n———. (1778/81) Mémoire sur les Probabilités. OC (9) 383–485.\\n———. (1782/1785) Mémoire sur les approximations des formules qui\\nsont functions de très grands nombres. OC (10) 209–294.\\n———. (1783/1786) Mémoire sur les approximations des formulas qui\\nsont functions de très grands nombre (suite). OC (10) 295–338.\\n———. (1783/1786) Sur les naissances, les mariages, et les morts à\\nParis, depuis 1771 jusqu’en 1784, et dans toute l’étendue de la\\nFrance, pendant les années 1781 et 1782. OC (11) 35–49.\\n———. (1787/1788) Sur l’équation séculaire de la lune.” OC (11)\\n243–71.\\n———. (1788) Théorie de Jupiter et de Saturne. OC (11) 95–207 and\\n(Suite) 211–39.\\n———. (1800) Séances des Écoles Normales, receuillies par des\\nSténographes, et revues par les Professeurs, nouvelle édition, tome\\nsixième, Paris: l’Primerie du Cercle-Social.\\n———. (1815/1818) Sur l’Application du calcul des probabilities à\\nla philosophie naturelle. OC (13) 98–116.\\n———. (1818) Troisième Supplément, Application de calcul des\\nprobabilités aux opérations géodésiques. OC (7) 531–80.\\n———. (1826/1829) Mémoire sur les deux grandes inégalités de\\nJupiter et de Saturne. OC (13) 313–33.\\nLind, Vera. (1998) Skepticism and the discourse about suicide in the\\neighteenth century. In The Skeptical Tradition around 1700, eds., J\\nvan der Zande, RH Popkin. Kluwer Academic Publishers. 296–313.\\nLindberg DC, Numbers RL, eds. (1986) God and Nature: Historical\\nEssays on the Encounter between Christianity and Science.\\nUniversity of California Press.\\n———. (2003) When Science and Christianity Meet. University of\\nChicago Press.\\nLuna, Frederick A. de. (1991) The Dean Street style of revolution: J.-P.\\nBrissot, jeune philosophe. French Historical Studies (17:1) 159–90.\\nMaréchal, Pierre Sylvain. (VIII) Dictionnaire des athées anciens et\\nmodernes. Paris. 231–32.\\nMarmottan, Paul. (1897). Lettres de Madame de Laplace à Élisa\\nNapoléon, princesse de Lucques et de Piombino. Paris.\\nMazzotti, Massimo. (1998) The geometers of God: Mathematics and\\nreaction in the Kingdom of Naples. Isis (89) 674–701.\\nNumbers, Ronald L. (1977) Creation by Natural Law: Laplace’s\\nNebular Hypothesis in American Thought. University of Washington\\nPress.\\nOrieux, Jean. (1974) Talleyrand: The Art of Survival. Alfred A. Knopf.\\nA classic about Laplace’s era.\\nOutram, Dorinda. (1983) The ordeal of vocation: The Paris Academy of\\nSciences and the Terror, 1793–95. History of Science (21) 251–73.\\nParcaut M et al. (1979) History of France. Encyclopaedia Britannica\\n(7) 611–81.\\nPelseneer, Jean. (1946) La religion de Laplace. Isis (36) 158–60.\\nPoirier, Jean-Pierre. (1998) Lavoisier: Chemist, Biologist, Economist.\\nTrans. Rebecca Balinski. University of Pennsylvania Press.\\nPorter, Roy. (2003) Introduction. In The Cambridge History of Science\\n(4) Eighteenth-Century Science, ed., R Porter. Cambridge University\\nPress.\\nRappaport, Rhoda. (1981) The liberties of the Paris Academy of\\nSciences 1716–1785. In The Analytic Spirit, ed., Harry Woolf.\\nCornell University Press. 225–53. Richards, Joan L. (2006)\\nHistorical mathematics in the French eighteenth century. Isis (97)\\n700–713.\\nRoche, Daniel. (1998) France in the Enlightenment. Trans. Arthur\\nGoldhammer. Harvard University Press. A classic.\\nSarton, George. (1941) Laplace’s religion. Isis (33) 309–12.\\nShafer, Glenn. (1990) The unity and diversity of probability. Statistical\\nScience (5:4) 435–62.\\nShepherd W. (1814) Paris in Eighteen Hundred and Two and Eighteen\\nHundred and Fifteen. 2d ed. M. Carey.\\nSimon, Lao G. (1931) The influence of French mathematicians at the\\nend of the eighteenth century upon the teaching of mathematics in\\nAmerican colleges. Isis (15) 104–23.\\nStigler SM. (1975) Napoleonic statistics: The work of Laplace.\\nBiometrika (62:2) 503–17.\\n———. (1978). Laplace’s early work: Chronology and citations. Isis\\n(69) 234–54.\\n———. (1982) Thomas Bayes’s Bayesian Inference. JRSS, A. (145)\\nPart 2, 250–58. Bayes’ article with modern mathematical notation\\nand Stigler’s commentary. The starting place for anyone interested in\\nBayes.\\n———. (1983) Who discovered Bayes’s Theorem? American\\nStatistician (37) 290–96.\\n———. (1986a) Laplace’s 1774 memoir on inverse probability.\\nStatistical Science (1) 359–63. Stigler’s English translation with\\nmodern mathematical notation. The best place to read this famous\\npaper.\\n———. (1986b). The History of Statistics: The Measurement of\\nUncertainty before 1900. Belknap Press of Harvard University\\nPress. A classic.\\n———. (2003) Casanova’s lottery. University of Chicago Record\\n(37:4) 2–5.\\nTodhunter I. (1865) A History of the Mathematical Theory of\\nProbability: From the Time of Pascal to that of Laplace. Cambridge\\nUniversity Press.\\nUlbricht, Otto. (1998) The debate about capital punishment and\\nskepticism in late enlightenment Germany. In The Skeptical Tradition\\naround 1800, eds., J Van der Zande, RH Popkin. Kluwer Academic\\nPublishers. 315–28.\\nUnion des Physiciens de Caen. (1999) L’Année Laplace. Section\\nAcadémique \\nde \\nCaen,\\nhttp://www.udppc.asso.fr/section/caen/caen.htm\\nVoltaire. (1961) On the Church of England, on the Presbyterians, on\\nAcademies. In Philosophical Letters. Bobbs-Merrill.\\nWilliams, L. Pearce. (1956) Science, education and Napoleon I. Isis\\n(47) 369–82.\\nZabell SL. (1988) Buffon, Price, and Laplace: Scientific attribution in\\nthe 18th century. Archive for the History of Exact Sciences (39) 173–\\n82.\\nChapter 3. Many Doubts, Few Defenders\\nAlexander, R. Amir. (2006) Tragic mathematics: Romantic narratives\\nand the refounding of mathematics in the early nineteenth century. Isis\\n(97) 714–26.\\nAnonymous. (August 27, 1899) Traps Mercier and Maurel: Capt.\\nFreystaetter convicts both of giving false evidence—Bertillon affords\\nmore amusement. New York Times 1,2. By a courtroom reporter at\\nDreyfus’s trial.\\nAnonymous. (1964) Edward C. Molina. American Statistician (18:3)\\n36.\\nBarnard, George A. (1947) Review: [untitled]. JASA (42:240) 658–65.\\nBell ET. (1937) Men of Mathematics. Touchstone 1986 edition.\\nBellamy, Paul B. (1997) A History of Workmen’s Compensation 1898–\\n1915: From Courtroom to Board-room. Garland Publishing.\\nBennett JH, ed. (1990) Statistical Inference and Analysis: Selected\\nCorrespondence of R. A. Fisher. Clarendon Press.\\nBolt, Bruce A. (1991) Sir Harold Jeffreys and geophysical inverse\\nproblems. Chance (4:2) 15–17.\\nBox, Joan Fisher. (1978) R. A. Fisher: The Life of a Scientist. John\\nWiley.\\nBroemling, Lyle D. (2002) The Bayesian contributions of Edmond\\nLhoste. ISBA Bulletin 3–4.\\nBru, Bernard. (1993) Doeblin’s life and work from his correspondence.\\nContemporary Mathematics (149) 1–64.\\n———. (1996) Problème de l’efficacité du tir à l’école d’artillerie de\\nMetz. Aspects théoriques et expérimentaus. Mathématiques et\\nsciences humaines (136) 29–42.\\n———. (1999) Borel, Lévy, Neyman, Pearson et les autres. MATAPLI\\n(60) 51–60.\\n———. (2006) Les leçons de calcul des probabilities de Joseph\\nBertrand: Les Lois du hazard. Journ@l électronique d’Histoire des\\nProbabilités et de la Statistique/Electronic Journal of History of\\nProbability and Statistics. (2:2) www.jehps.net.\\nClerke, Agnes Mary. (1911) Laplace. Encyclopaedia Britannica (16)\\n200–203.\\nCochran WM. (1976) Early development of techniques in comparative\\nexperimentation. In On the History of Statistics and Probability, ed.,\\nDB Owen. Marcel Dekker. 1–26.\\nCook, Alan. (1990) Sir Harold Jeffreys, 2 April 1891–18 March 1989.\\nBiographical Memoirs of Fellows of the Royal Society (36) 302–33.\\nCrépel, Pierre. (1993) Henri et la droite de Henry. MATAPLI (36) 19–\\n22.\\nDale, Andrew I. (1999) A History of Inverse Probability from Thomas\\nBayes to Karl Pearson. 2d ed. Springer. One of the foundational\\nworks in the history of probability.\\nDaston, Lorraine J. (1987) The domestication of risk: mathematical\\nprobability and insurance 1650–1830. In The \\nProbabilistic\\nRevolution I, eds., L Krüger, L Daston, M Heidel-berger. MIT Press.\\n237–60.\\n———. (1994) How probabilities came to be objective and subjective.\\nHistoria Mathematica (21) 330–44.\\nDaston L, Galison P. (2007) Objectivity. Zone Books.\\nDavid, Florence Nightingale. (1962) Games, Gods and Gambling.\\nCharles Griffin. 1998 Dover Edition.\\nDawson, Cree S., et al. (2000) Operations research at Bell Laboratories\\nthrough the 1970s: Part 1. Operations Research (48) 205–15.\\nDe Finetti, Bruno. (1972) Probability, Induction and Statistics: The\\nArt of Guessing. John Wiley and Sons.\\nEdwards AWF. (1994) R. A. Fisher on Karl Pearson. Notes and\\nRecords of the Royal Society of London (48) 97–106.\\n———. (1997) What did Fisher mean by “Inverse Probability” in\\n1912–1922? Statistical Science (12) 177–84.\\nEfron, Bradley. (1998) R. A. Fisher in the 21st century. Statistical\\nScience (13) 95–122.\\nEstienne JE. (March 10, 1890) “Étude sur les erreurs d’observation.” In\\nArchives de L’Institut de France. Académie des Sciences.\\n———. (1892) “La probabilité de plusieurs causes étant connue, à\\nquelle cause est-il plausible d’attribuer l’arrivé de l’évènement?”\\nComptes \\nRendus \\ndes \\nSéances \\nde \\nL’Académie \\ndes \\nSciences\\n(114:semester 1892) 1223.\\n———. (1905/6) Loisirs d’Artilleurs. Berger-Levrault.\\nFagen MD, ed. (1975) The History of Engineering and Science in the\\nBell System: The History of the Early Years 1875–1925. Vol. 1. Bell\\nTelephone Laboratories Inc.\\nFienberg, Stephen E. (1992) Brief history of statistics in three and one-\\nhalf chapters: A review essay. Statistical Science (7) 208–25.\\nFilon LNG. (1936) Karl Pearson 1857–1936. Obituary Notices of the\\nRoyal Society (2) 73–110.\\nFisher, Arne. (1916) Note on an application of Bayes’ rule in the\\nclassification of hazards in experience rating. PCAS (3) 43–48.\\nFisher, Ronald Aylmer. (1925) Statistical Methods for Research\\nWorkers. Oliver and Boyd.\\nGigerenzer G, Swijtink Z, Porter T, Daston L, Beatty J, Krüger L.\\n(1989) The Empire of Chance: How Probability Changed Science\\nAnd Everyday Life. Cambridge University Press. Many useful\\narticles.\\nHacking, Ian. [1989] Was there a probabilistic revolution 1800–1930?\\nIn The Probabilistic Revolution, eds., L Krüger, LJ Daston, and M\\nHeidelberger. Vol. 1. MIT Press.\\nHald, Anders. (1998) A History of Mathematical Statistics from 1750\\nto 1930. John Wiley and Sons. A classic.\\nHowie, David. (2002) Interpreting Probability: Controversies and\\nDevelopments \\nin \\nthe \\nEarly \\nTwentieth \\nCentury. Cambridge\\nUniversity Press. The Fisher-Jeffreys debate.\\nHuzurbazar, Vassant S. (1991) Sir Harold Jeffreys: Recollections of a\\nstudent. Chance (4:2) 18–21.\\nJeffreys, Bertha Swirles. (1991) Harold Jeffreys: Some reminiscences.\\nChance (4:2) 22–26.\\nJeffreys, Harold. (1939, 1948, 1961). Theory of Probability. Clarendon\\nPress.\\nKass RE, Raftery AE. (1995) Bayes factors. JASA (90:430) 773–95.\\nKaye, David H. (2007) Revisiting Dreyfus: A more complete account of\\na trial by mathematics. Minnesota Law Review (91:3) 825–35.\\nKnopoff, Leon. (1991) Sir Harold Jeffreys: The Earth: Its origin,\\nhistory, and physical constitution. Chance (4:2) 24–26.\\nKolmogorov AN, Yushkevich AP. (1992) Mathematics of the 19th\\nCentury, vol. 1. Birkäuser Verlag.\\nKrüger L, Daston L, Heidelberger M, eds. (1987) The Probabilistic\\nRevolution, vol. 1: Ideas in History. MIT Press.\\nKrüger L, Gigerenzer G, Morgan M, eds. (1987) The Probabilistic\\nRevolution, vol. 2: Ideas in History. MIT Press.\\nKruskal, William. (1980) The Significance of Fisher: A review of R. A.\\nFisher: The Life of a Scientist. Journal of the American Statistical\\nAssociation (75) 1019–30.\\nLe process Dreyfus devant le conseil de guerre de Rennes (7 aout-9\\nseptembre 1899): compte-rendu sténographique in extenso. (1899)\\nhttp://gallica2.bnf.fr/ark:/12148/bpt6k242524.zoom.r=procès.f335.la\\nngEN.tableDesMatieres.\\nLightman, Bernard. (2007) Victorian \\nPopularizers \\nof \\nScience.\\nUniversity of Chicago Press.\\nLindley DV. (1983) Transcription of a conversation between Sir Harold\\nJeffreys and Professor D. V. Lindley from a videotape made on behalf\\nof the Royal Statistical Society. In St. John’s College, Cambridge,\\nUK, Papers of Sir Harold Jeffreys A25.\\n———. (1986a) On re-reading Jeffreys. In Pacific Statistical\\nCongress, eds., IS Francis, BFJ Manly, FC Lam. Elsevier.\\n———. (1986b) Bruno de Finetti, 1906–1985. JRSS Series A\\n(General) (149) 252.\\n———. (1989) Obituary: Harold Jeffreys, 1891–1989. JRSS Series A\\n(Statistics in Society) (152:3) 417–18.\\n———. (1991) Sir Harold Jeffreys. Chance (4:2) 10–14, 21.\\nLoveland, Jeff. (2001) Buffon, the certainty of sunrise, and the\\nprobabilistic reductio ad absurdum. Archives of the History of\\nExact Sciences (55) 465–77.\\nMacKenzie, Donald A. (1981) Statistics in Britain 1865–1930: The\\nSocial Construction of Scientific Knowledge. Edinburgh University\\nPress.\\n———. (1989) Probability and statistics in historical perspective. Isis\\n(80) 116–24.\\nMagnello, M. Eileen. (1996) Karl Pearson’s Gresham Lectures: W. F.\\nR. Weldon, speciation and the origins of Pearsonian statistics. British\\nJournal for the History of Science (29:1) 43–63.\\nMarie, Maximilien. (1883–88) Histoire des sciences mathématiques et\\nphysiques. Vol. 10. Paris: Gauthier-Villars. 69–98.\\nMellor DH. (1995) Better than the stars: A radio portrait of Frank\\nRamsey. Philosophy (70) 243–62. The original version was\\nbroadcast \\nby \\nBBC \\nRadio \\n3 \\nFebruary \\n27, \\n1978.\\nhttp://www.Dar.cam.ac.uk/~dhm11/RanseyLect.html. Acc. May 21,\\n2004.\\nMillman S. (1984) The History of Communications and Sciences\\n(1925–1980). Vol. 5. AT&T Bell Labs.\\nMiranti, Paul J. Jr. (2002) Corporate learning and traffic management at\\nthe Bell System, 1900–1929: Probability theory and the evolution of\\norganizational capabilities. Business History Review (76:4) 733–65.\\nMolina, Edward C. (1913) Computation formula for the probability of\\nan event happening at least C times in N trials. American\\nMathematical Monthly (20) 190–93.\\n———. (1922) The theory of probabilities applied to telephone\\ntrunking problems. Bell System Technical Journal (1) 69–81.\\n———. (1931) Bayes’ theorem. Annals of Mathematical Statistics (2)\\n23–27.\\n———. (1941) Commentary in Facsimiles of Two Papers by Bayes,\\ned. W. Edwards Deming. Graduate School, Department of\\nAgriculture.\\n———. (1946) Some fundamental curves for the solution of sampling\\nproblems. Annals of Mathematical Statistics (17) 325–35.\\nMoore, Calvin C. (2007) Mathematics at Berkeley: A History. AK\\nPeters.\\nMorehead EJ. (1989) Our Yesterdays: The History of the Actuarial\\nProfession in North America 1809–1979. Society of Actuaries.\\nMorgan, Augustus de. (1839) Laplace. Penny Cylcopaedia of the\\nSociety for the Diffusion of Useful Knowledge. London: 1833–46.\\n(13) 325–28.\\nMowbray AH. (1914–15) How extensive a payroll exposure is\\nnecessary to give a dependable pure premium? PCAS (1) 24–30.\\n———. (1915) The determination of pure premiums for minor\\nclassifications on which the experience data is insufficient for direct\\nestimate. PCAS (2) 124–33.\\nNeyman J. (1934) Statistical problems in agricultural experiment. With\\ndiscussion. Supplement to the JRSS. (2:2) 107–80. (Discussion pp.\\n154–80.)\\n———. (1976) The emergence of mathematical statistics: a historical\\nsketch with particular reference to the United States. In On the\\nHistory of Statistics and Probability, ed., DB Owen. Marcel Dekker.\\n147–94.\\nOlkin, Ingram. (1992) A conversation with Churchill Eisenhart.\\nStatistical Science (7) 512–30.\\nOtis, Stanley L. (1914–15) A Letter of Historical Interest. PCAS (1) 8–\\n9.\\nPearson, Egon S. (1925) Bayes’ theorem examined in the light of\\nexperimental sampling. Biometrika (17) 388–442.\\n———. (1936 and 1937) Karl Pearson: An appreciation of some\\naspects of his life and work. Biometrika (28) 193–257 and (29) 161–\\n248.\\n———. (1962) Some thoughts on statistical inference. Annals of\\nMathematical Statistics. (33:2) 394–403.\\n———. (1968) Studies in the history of probability and statistics. XX:\\nSome early correspondence between W. S. Gosset, R. A. Fisher, and\\nKarl Pearson, with notes and comments. Biometrika (55:3) 445–57.\\nPearson, Karl. (1892) The Grammar of Science. W. Scott.\\n———. (1901) The Ethic of Freethought and Other Addresses and\\nEssays. 2d ed. Charles Black.\\n———. (1912) Social Problems: Their Treatment, Past, Present, and\\nFuture. Dulau.\\n———. (1929) Laplace, being extracts from lectures delivered by Karl\\nPearson. Biometrika (21) 202–16.\\nPerryman, Francis S. (1937) Experience rating plan credibilities. PCAS\\n(24) 60–125.\\nPorter, Theodore M. (1986) The Rise of Statistical Thinking, 1820–\\n1900. Princeton University Press.\\n———. (1995) Trust in Numbers: The Pursuit of Objectivity in\\nScience and Public Life. Princeton University Press.\\n———. (2003) Statistics and physical theories. In The Cambridge\\nHistory of Science. Vol. 5: The Modern Physical and Mathematical\\nSciences, ed. Mary Jo Nye. Cambridge University Press.\\n———. (2004) Karl Pearson: The Scientific Life in a Statistical Age.\\nPrinceton University Press.\\nPruitt, Dudley M. (1964) The first fifty years. PCAS (51) 148–81.\\nReed, Lowell J. (1936) Statistical treatment of biological problems in\\nirradiation. In Biological Effects of Radiation, Vol. 1, ed. Benjamin\\nM. Duggar, 227–51. McGraw-Hill.\\nReid, Constance. (1982) Neyman—from Life. Springer-Verlag.\\nRubinow, Isaac M. (1913) Social Insurance. Henry Holt.\\n———. (1914–15) Scientific Methods of Computing Compensation\\nRates. PCAS (1) 10–23.\\n———. (1915) Liability loss reserves. PCAS (1:3) 279–95.\\n———. (1917) The theory and practice of law differentials. PCAS (4)\\n8–44.\\n———. (1934) A letter. PCAS (21).\\nSchindler GE Jr., ed. (1982) A History of Switching Technology (1925–\\n1975). Vol. 3. Bell Telephone Laboratories.\\nSearle GR, ed. (1976) Eugenics and Politics in Britain 1900–1914.\\nNoordhoff International Publishing.\\nSeddik-Ameur, Nacira. (2003) Les tests de normalité de Lhoste.\\nMathematics and Social Sciences/Mathématiques et Sciences\\nHumaines (162: summer) 19–43.\\nStigler, Stephen M. (1986). The \\nHistory \\nof \\nStatistics: \\nThe\\nMeasurement of Uncertainty before 1900. Belknap Press of Harvard\\nUniversity Press. A classic.\\n———. (1999). Statistics on the Table: The History of Statistical\\nConcepts and Methods. Harvard University Press.\\nTaqqu, Murad S. (2001) Bachelier and his times: A conversation with\\nBernard Bru. Finance and Stochastics (5) 3–32.\\nWhitney, Albert W. (1918) The theory of experience rating. PCAS (4)\\n274–92.\\nWilhelmsen L. (1958) Actuarial activity in general insurance in the\\nnorthern countries of Europe. ASTIN Bulletin (1) 22–27.\\nWilkinson RI. (1955) An appreciation of E. C. Molina. First\\nInternational Teletraffic Congress, Copenhagen, June 20th-June\\n23rd, 1955. International Teletraffic Congress 30–31.\\nWilloughby, William Franklin. (1898) Workingmen’s \\nInsurance.\\nThomas Y. Crowell.\\nZabell, Sandy L. (1989) R. A. Fisher on the history of inverse\\nprobability. Statistical Science (4) 247–56.\\n———. (1989) The Rule of Succession. Erkenntnis (31) 283–321.\\n———. (1992) R. A. Fisher and fiducial argument. Statistical Science\\n(7) 369–87.\\nPart II. Second World War Era\\n \\nChapter 4. Bayes Goes to War\\nAndresen, Scott L. (Nov.–Dec. 2001) Donald Michie: Secrets of\\nColossus revealed. IEEE Intelligent Systems 82–83.\\nArnold, VI. (2004) A.N. Kolmogorov and natural science. Russian\\nMath. Surveys (59:1) 27–46.\\nBarnard, GA & Plackett, RL. (1985) Statistics in the United Kingdom,\\n1939–45. In AC Atkinson, SE Fienberg, eds., A Celebration of\\nStatistics. Springer-Verlag. 31–55.\\nBarnard GA. (1986) Rescuing our manufacturing industry—some of the\\nstatistical problems. The Statistician (35) 3–16.\\nBauer FL. (2000) Decrypted Secrets. Springer.\\nBurroughs J, Lieberman D, Reeds J. (2009) The secret life of Andy\\nGleason. Notices of the American Mathematical Society (in draft).\\nBooss-Bavnbek B, Hoeyrup J. (2003) Mathematics \\nand \\nWar.\\nBirkhäuser Verlag.\\nBritton JL. (1992) Collected \\nWorks \\nof \\nA. \\nM. \\nTuring: \\nPure\\nMathematics. North-Holland.\\nBudiansky, Stephen. (2000) Battle of Wits: The Complete Story of\\nCodebreaking in World War II. Free Press.\\nCarter, Frank L. (1998) Codebreaking with the Colossus Computer.\\nBletchley Park Trust.\\n———. (2008) Breaking Naval Enigma. Bletchley Park Trust.\\nChampagne L, Carl RG, Hill R. (2003) Multi-agent techniques: Hunting\\nU-boats in the Bay of Biscay. Proceedings of SimTecT May 26–29,\\nAdelaide, Australia.\\nChentsov, Nikolai N. (1990) The unfathomable influence of\\nKolmogorov. Annals of Statistics (18:03) 987–98.\\nChurchill, Winston. (1949) Their Finest Hour. Houghton Mifflin.\\nCollins, Graham P. (October 14, 2002) Claude E. Shannon: Founder of\\nInformation Theory. Scientific American 14ff.\\nCopeland, B. Jack, ed. (2004) The Essential Turing. Clarendon Press.\\nEssential essays.\\nCopeland BJ et al. (2006) Colossus: The Secrets of Bletchley Park’s\\nCodebreaking Computers. Oxford University Press. Essential essays.\\nEisenhart, Churchill. (1977) The birth of sequential analysis (obituary\\nnote on retired RAdm. Garret Lansing Schuyler). Amstat News\\n(33:3).\\nEpstein R, Robert G, Beber G., eds. (2008) Parsing the Turing Test:\\nPhilosophical and Methodical Issues in the Quest for the Thinking\\nComputer. Springer.\\nErskine, Ralph. (October 2006) The Poles reveal their secrets: Alastair\\nDenniston’s account of the July 1939 meeting at Pyry. Cryptologia\\n(30) 204–305.\\nFagen MD. (1978) The History of Engineering and Science in the Bell\\nSystem: National Service in War and Peace (1925–1975). Vol. 2.\\nBell Telephone Labs.\\nFeferman AB, Feferman S. (2004) Alfred Tarski: Life and Logic.\\nCambridge University Press.\\nFienberg SE. (1985) Statistical developments in World War II: An\\ninternational perspective. In A Celebration of Statistics, eds., AC\\nAtkinson, SE Fienberg. Springer-Verlag. 25–30.\\nGandy R.O, Yates C.E.M., eds. (2001) Collected Works of A. M.\\nTuring: Mathematical Logic. North-Holland.\\nGood, Irving John. (1950) Probability and the Weighing of Evidence.\\nLondon: Charles Griffin.\\n———. (1958) The interaction algorithm and practical Fourier\\nanalysis. JRSS. Series B. (20) 361–72.\\n———. (1958) Significance tests in parallel and in series. JASA (53)\\n799–813.\\n———. (1965) The Estimation of Probabilities: An Essay on Modern\\nBayesian Methods. Research Monograph 30, MIT Press.\\n———. (1979) Studies in the history of probability and statistics.\\nXXXVII A. M. Turing’s statistical work in World War II. Biometrika\\n(66:2) 393–96. Reprinted with Introductory Remarks in Pure\\nMathematics, ed., JR Britton, vol. of Collected Works of A.M.\\nTuring. North-Holland, 1992.\\n———. (1983) Good Thinking: The Foundations of Probability and\\nIts Applications. University of Minnesota Press.\\n———. (1984) A Bayesian approach in the philosophy of inference.\\nBritish Journal for the Philosophy of Science (35) 161–66.\\n———. (2000) Turing’s anticipation of Empirical Bayes in connection\\nwith the cryptanalysis of the Naval Enigma. Journal of Statistical\\nComputation and Simulation (66) 101–11, and in Gandy and Yates.\\nHinsley FH, Stripp A, eds. (1993) Codebreakers: The Inside Story of\\nBletchley Park. Oxford University Press.\\nHilton, Peter. (2000) Reminiscences and reflections of a codebreaker.\\nIn Coding \\nTheory \\nand \\nCryptography: \\nFrom \\nEnigma \\nand\\nGeheimschreiber to Quantum Theory, ed., WD Joyner. Springer-\\nVerlag. 1–8.\\nHodges, Andrew. (1983, 2000) Alan Turing: The Enigma. Walker. A\\nclassic.\\n———. The Alan Turing Webpage. http://www.turing.org.uk/turing/.\\n———. (2000) Turing, a natural philosopher. Routledge. In The Great\\nPhilosophers, eds., R. Monk and F. Raphael. Weidenfeld and\\nNicolson.\\n———. (2002) Alan Turing—a Cambridge Scientific Mind. In\\nCambridge Scientific Minds, eds., Peter Harmon, Simon Mitton.\\nCambridge University Press.\\nHosgood, Steven. http://tallyho.bc.nu/~steve/banburismus.html.\\nKahn, David. (1967) The Codebreakers: The Story of Secret Writing.\\nMacmillan. A classic.\\nKendall, David G. (1991a) Kolmogorov as I remember him. Statistical\\nScience (6:3) 303–12.\\n———. (1991b) Andrei Nikolaevich Kolmogorov. 25 April 1903–20\\nOctober 1987. Biographical Memoirs of Fellows of the Royal\\nSociety. (37) 300–319.\\nKolmogorov, Andrei N. (1942) Determination of the center of scattering\\nand the measure of accuracy by a limited number of observations.\\nIzvestiia Akademii nauk SSSR. Series Mathematics (6) 3–32. In\\nRussian.\\nKolmogorov AN, Hewitt E. (1948) Collection of Articles on the\\nTheory of Firing. Rand Publications. Edited by Kolmogorov and\\ntranslated by Hewitt.\\nKoopman, Bernard Osgood. (1946) OEG Report No. 56, Search and\\nScreening. Operations Evaluation Group, Office of the Chief of\\nNaval Operations, Navy Department, Washington, D.C.\\n———. (1980) Searching and Screening: General Principles with\\nHistorical Applications. Pergamon Press.\\nKozaczuk, Wladyslaw. (1984) Enigma. Trans. Christopher Kasparek.\\nUniversity Publications of America.\\nKuratowski, Kazimierz. (1980) A Half Century of Polish Mathematics,\\nRemembrances and Reflections. Pergamon Press.\\nLee, JAN (1994) Interviews with I. Jack Good and Donald Michie,\\n1992. http://ei.cs.vt.edu/~history/Good.html. Downloaded February\\n14, 2006.\\nMichie, Donald. (unpublished) Turingery and Turing’s sequential Bayes\\nRule. I am indebted to Jack Copeland and the Michie family for\\nletting me read this draft chapter.\\nMilllman S, ed. (1984) The History of Communications Sciences\\n(1925–1980). Vol. 5. AT&T Bell Labs.\\nMorison, Samuel Eliot. (2001) The Battle of the Atlantic: September\\n1939–May 1943. University of Illinois Press (1947 edition by Little,\\nBrown).\\nMorse PM, Kimball GE. (1951) Methods of Operations Research.\\nTechnology Press of MIT and John Wiley and Sons.\\nMorse PM. (1982) In Memoriam: Bernard Osgood Koopman, 1900–\\n1981. Operations Research (30) viii, 417–27.\\nNewman \\nMHA. \\n(1953) \\nAlan \\nMathison \\nTuring, \\n1912–1954.\\nBiographical Memoirs of Fellows of the Royal Society (1) 253–63.\\nRandell B. (1980) The Colossus. In A History of Computing in the\\nTwentieth Century: A Collection of Essays, eds., Metropolis N,\\nHowlett J, Rota G-C. Academic Press.\\nRejewski M. (1981) How Polish mathematicians deciphered the\\nEnigma. Annals of the History of Computing (3) 223.\\nRukhin, Andrew L. (1990) Kolmogorov’s contributions to mathematical\\nstatistics. Annals of Statistics (18:3) 1011–16.\\nSales, Tony. www.codesandciphers.org.uk/aescv.htm.\\nShannon, Claude E. (July, October 1948) A mathematical theory of\\ncommunication. Bell System Technical Journal (27) 379–423, 623–\\n56.\\n———. \\n(1949) \\nCommunication \\ntheory \\nof \\nsecrecy \\nsystems.\\nnetlab.cs.ucla.edu/wiki/files/Shannon1949.pdf. Acc. March 31, 2007.\\nShiryaev, Albert N. (1989) Kolmogorov: Life and Creative Activities.\\nAnnals of Probability (17:3) 866–944.\\n———. (1991) Everything about Kolmogorov was unusual. Statistical\\nScience (6:3) 313–18.\\n———. (2003) On the defense work of A. N. Kolmogorov during\\nWorld War II. In Mathematics and War, eds., B. Booss-Bavnbek & J.\\nHoeyrup. Birkhaeuser.\\nSloane NJA, Wyner AD., eds. (1993) Claude Elwood Shannon:\\nCollected Papers. IEEE Press.\\nSyrett, David. (2002) The Battle of the Atlantic and Signals\\nIntelligence: U-Boat Tracking Papers, 1941–1947. Navy Records\\nSociety.\\nTuring, Alan M. (1942) Report by Dr. A. M. Turing, Ph.D. and Report\\non Cryptographic Machinery Available at Navy Department,\\nWashington. \\nhttp://www.turing.org.uk/sources/washington.html.\\nAccessed June 2, 2009.\\n———. (1986) A. M. Turing’s Ace Report of 1946 and Other Papers,\\neds., BE Carpenter, RW Doran. MIT Press.\\nWaddington CH. (1973) O.R. in World War 2: Operations Research\\nagainst the U-Boat. Scientific Books.\\nWeierud, \\nFrode.\\nhttp://cryptocellar.web.cern.ch/cryptocellar/Enigma/index.html. \\nA\\ncentral archives for the history of cryptanalysis during the Second\\nWorld War.\\nWelchman, Gordon. (1983) The Hut Six Story: Breaking the Enigma\\nCodes. McGraw-Hill.\\nWiener, Norbert. (1956) I Am a Mathematician. MIT Press.\\nZabell SL. (1995) Alan Turing and the Central Limit Theorem.\\nAmerican Mathematical Monthly (102:6) 483–94.\\nChapter 5. Dead and Buried Again\\nBox GEP, Tiao GC. (1973) Bayesian Inference in Statistical Analysis.\\nAddison-Wesley.\\nCox, Gertrude. (1957) “Statistical frontiers.” JASA (52) 1–12.\\nDeGroot, Morris H. (1986a) A conversation with David Blackwell.\\nStatistical Science (1:1) 40–53.\\nErickson WA, ed. (1981) The Writings of Leonard Jimmie Savage: A\\nMemorial Selection. American Statistical Association and Institute\\nof Mathematical Statistics.\\nFienberg, Stephen E. (2006) When did Bayesian inference become\\nBayesian? Bayesian Analysis (1) 1–40.\\nLindley, Dennis V. (1957) Comments on Cox. In Breakthroughs in\\nStatistics I, eds., NL Johnson and S Kotz. xxxviii.\\nPerks, Wilfred. (1947) Some observations on inverse probability\\nincluding a new indifference rule. Journal of the Institute of\\nActuaries (73) 285–334.\\nReid, Constance. (1982) Neyman—from Life. Springer-Verlag.\\nSampson AR, Spencer B, Savage IR. (1999) A conversation with I.\\nRichard Savage. Statistical Science (14) 126–48.\\nPart III. The Glorious Revival\\n \\nChapter 6. Arthur Bailey\\nAlbers, Donald J. (1983) Mathematical People. Birkhäuser.\\nBailey, Arthur L. (1929) A Summary of Advanced Statistical Methods.\\nUnited Fruit Co. Research Department. Reprinted 1931 as Circular\\nno. 7.\\n———. (1942, 1943) Sampling Theory in Casualty Insurance, Parts I\\nthrough VII. PCAS (29) 50–93 and (30) 31–65.\\n———. (1945) A generalized theory of credibility. PCAS (32) 13–20.\\n———. (1948) Workmen’s compensation D-ratio revisions. PCAS (35)\\n26–39.\\n———. (1950) Credibility procedures: Laplace’s generalization of\\nBayes’ rule and the combination of collateral knowledge with\\nobserved data. PCAS (37) 7–23. Six discussions of this paper and the\\nauthor’s reply are in the same volume at 94–115.\\n———. (1950) Discussion of Introduction to Credibility Theory by L.\\nH. Longley-Cook. Reprint of 1950 discussion in PCAS (1963) (50)\\n59–61.\\nBailey, Robert A, Simon LJ. (1959) An actuarial note on the credibility\\nof experience of a single private passenger car. PCAS (46) 159–64.\\nBailey RA, Simon LJ. (1960) Two studies in automobile insurance\\nratemaking. PCAS (47) 1–19. This was later reprinted in ASTIN\\nBulletin (1) 192–217.\\nBailey RA. (1961) Experience rating reassessed. PCAS (48) 60–82.\\nBorch, Karl. (1963) Recent developments in economic theory and their\\napplication to insurance. ASTIN Bulletin (2) 322–41.\\nBühlmann, Hans. (1967) Experience rating and credibility. ASTIN\\nBulletin (4) 199–207.\\nBühlmann H, Straub E. (1970) Credibility for loss ratios. Bulletin of\\nthe Swiss Association of Actuaries: (70) 111–33. English trans. by\\nC.E. Brooks.\\nCarr, William HA. (1967) Perils: Named and Unnamed. The Story of\\nthe Insurance Company of North America. McGraw-Hill.\\nCox, Gertrude. (1957) “Statistical frontiers.” JASA (52) 1–12.\\nDeGroot, Morris H. (1986a) A conversation with David Blackwell.\\nStatistical Science (1:1) 40–53.\\nHachemeister, Charles A. (1974) Credibility for regression models with\\napplication to trend. In Credibility: Theory and Applications, ed., P.\\nM. Kahn, 129–64.\\nHewitt, Charles C., Jr. (1964, 1965, 1969). Discussion. PCAS (51) 44–\\n45; (52) 121–27; (56) 78–82.\\nHewitt CC Jr. (1970) Credibility for severity. PCAS (57) 148–71.\\n———. (1975) Credibility for the layman. In Credibility (Theory and\\nApplications), Academic Press and in Proceedings of the Berkeley\\nActuarial Research Conference on Credibility, September 19–21.\\nHickman, James C., and Heacox, Linda. (1999) Credibility theory: The\\ncornerstone of actuarial science. North American Actuarial Journal\\n(3:2) 1–8.\\nJewell, William S. (2004) Bayesian statistics. Encyclopedia of\\nActuarial Science. Wiley. 153–66.\\nKahn, PM. (1975) Credibility: Theory and Applications. Academic\\nPress.\\nKlugman SA, Panjer HH, Willmot GE. (1998) Loss Models: From Data\\nto Decisions. John Wiley and Sons.\\nLongley-Cook, Laurence H. (1958) The casualty actuarial society and\\nactuarial studies in development of non-life insurance in North\\nAmerica. ASTIN Bulletin (1) 28–31.\\n———. (1962) An introduction to credibility theory. PCAS (49) 184–\\n221.\\n———. (1964) Early actuarial studies in the field of property and\\nliability insurance. PCAS (51) 140–47.\\n———. (1972) Actuarial aspects of industry problems. PCAS (49) Part\\nII 104–8.\\nLundberg, Ove. (1966) Une note sur des systèmes de tarification basées\\nsur des modèles du type Poisson composé. ASTIN Bulletin (4) 49–\\n58.\\nMayerson, Allen L. (1964) A Bayesian view of credibility. PCAS (51)\\n85–104.\\nMiller RB, Hickman JC. (1974) Insurance credibility theory and\\nBayesian estimation. In Credibility: Theory and Applications, ed.\\nPM Kahn, 249–70.\\nMiller Robert B. (1989) Actuarial applications of Bayesian statistics. In\\nBayesian Analysis in Econometrics and Statistics: Essays in Honor\\nof Harold Jeffreys, ed. Arnold Zellner. Robert E. Krieger.\\nMorris C, Van Slyke L. (1978) Empirical Bayes methods for pricing\\ninsurance classes. Proceedings of the Business and Economics\\nStatistics Section. Statweb.byu.edu/faculty/gwf/revnaaj.pdf.\\nPerks, Wilfred. (1947) Some observations on inverse probability\\nincluding a new indifference rule. Journal of the Institute of\\nActuaries (73) 285–334.\\nTaylor GC. (1977) Abstract credibility. Scandinavian Actuarial\\nJournal 149–68.\\n———. (1979) Credibility analysis of a general hierarchical model.\\nScandinavian Actuarial Journal 1–12.\\nVenter, Gary G. (fall 1987) Credibility. CAS Forum 81–147.\\nChapter 7. From Tool to Theology\\nArmitage P. (1994) Dennis Lindley: The first 70 years. In Aspects of\\nUncertainty: A Tribute to D. V. Lindley, eds., PR Freeman and AFM\\nSmith. John Wiley and Sons.\\nBanks, David L. (1996) A Conversation with I. J. Good. Statistical\\nScience (11) 1–19.\\nDubins LE, Savage LJ. (1976) Inequalities for Stochastic Processes\\n(How to Gamble If You Must). Dover.\\nBox, George EP, et al. (2006) Improving Almost Anything. Wiley.\\nBox GEP, Tiao GC. (1973) Bayesian Inference in Statistical Analysis.\\nAddison-Wesley.\\nCramér, H. (1976). Half of a century of probability theory: Some\\npersonal recollections. Annals of Probability (4) 509–46.\\nD’Agostini, Giulio. (2005) The Fermi’s Bayes theorem. Bulletin of the\\nInternational Society of Bayesian Analysis (1) 1–4.\\nEdwards W, Lindman R, Savage LJ. (1963) Bayesian statistical\\ninference for psychological research. Psychological Review (70)\\n193–242.\\nErickson WA, ed. (1981) The Writings of Leonard Jimmie Savage: A\\nMemorial Selection. American Statistical Association and Institute\\nof Mathematical Statistics.\\nFerguson, Thomas S. (1976) Development of the decision model. In DB\\nOwen, ed., On the History of Statistics and Probability. Marcel\\nDekker. 333–46.\\nFienberg, Stephen E. (2006) When did Bayesian inference become\\nBayesian? Bayesian Analysis (1) 1–40.\\nJohnson NL, Kotz S, eds. (1997) Breakthroughs in Statistics. Vols. 1–3.\\nSpringer. Important reprints of twentieth century articles, primarily\\npost-1940s.\\nKendall, Maurice G. (1968) On the future of statistics – a second look.\\nJournal of the Royal Statistical Society Series A (131) 182–204.\\nLindley, Dennis V. (1953) Statistical inference (with discussion). JRSS,\\nSeries B (15) 30–76.\\n———. (1957) A statistical paradox. Biometrika (44: 1/2) 187–92.\\n———. (1968) Decision making. The Statistician (18) 313–26.\\n———. (1980) L. J. Savage—his work in probability and statistics.\\nAnnals of Statistics (8) 1–24.\\n———. (1983) Theory and practice of Bayesian statistics. The\\nStatistician (32) 1–11.\\n———. (1986) Savage revisited: Comment. Statistical Science (1)\\n486–88.\\n———. (1990) Good’s work in probability, statistics and the\\nphilosophy of science. J. Statistical Planning and Inference (25)\\n211–23.\\n———. (2000) The philosophy of statistics. The Statistician (49) 293–\\n337.\\n———. (2004) Bayesian thoughts. Significance (1) 73–75.\\nMathews J, Walker RL. (1965) Mathematical Methods of Physics. W.\\nA. Benjamin.\\nOld, Bruce S. (1961) The evolution of the Office of Naval Research.\\nPhysics Today (14) 30–35.\\nRigby, Fred D. (1976) Pioneering in federal support of statistics\\nresearch. In DB Owen, ed., On the History of Statistics and\\nProbability. Marcel Dekker. 401-18.\\nRivett, Patrick. (1995) Aspects of Uncertainty. [Review] Journal of the\\nOperational Research Society (46) 663–70.\\nSampson AR, Spencer B, Savage IR. (1999) A conversation with I.\\nRichard Savage. Statistical Science (14) 126–48.\\nSavage LJ. (1954) The Foundations of Statistics. Wiley.\\n———. (1962) The \\nFoundations \\nof \\nStatistical \\nInference: \\nA\\nDiscussion. London: Methuen.\\n———. (1976) On rereading R. A. Fisher. Annals of Statistics (4)\\n441–500.\\nSchrödinger, Erwin. (1944) The statistical law of nature. Nature (153)\\n704-5.\\nShafer, Glenn. (1986) Savage revisited. Statistical Science (1) 463–85.\\nSmith, Adrian. (1995) A conversation with Dennis Lindley. Statistical\\nScience (10) 305–19.\\nStephan FF. et al. (1965) Stanley S. Willks. JASA (60:312) 953.\\nChapter 8. Jerome Cornfield, Lung Cancer, and\\nHeart Attacks\\nAnonymous. \\n(1980) \\nObituary: \\nJerome \\nCornfield \\n1912–1979.\\nBiometrics (36) 357–58.\\nArmitage, Peter. (1995) Before and after Bradford Hill: Some trends in\\nmedical statistics. JRSS, Series A (158) 143–53.\\nCenters for Disease Control. (1999) Achievements in public health,\\n1900–1999: Decline in deaths from heart disease and stroke, United\\nStates, 1900–1999. MMWR Weekly (48:30) 649–56.\\nCornfield, Jerome. (1951) A method of estimating comparative rates\\nfrom clinical data: Applications to cancer of the lung, breast, and\\ncervix. in Breakthroughs in Statistics 3 (1993), eds., S. Kotz and NL\\nJohnson. Springer. Introduction by Mitchell H. Gail.\\n———. (1962) Joint dependence of risk of coronary heart disease on\\nserum cholesterol and systolic blood pressure: A discriminant\\nfunction analysis. Federation Proceedings (21:4) Part II. July–\\nAugust. Supplement no. 11.\\n———. (1967) Bayes Theorem. Review \\nof \\nthe \\nInternational\\nStatistical Institute (35) 34–49.\\n———. (1969) The Bayesian outlook and its application. Biometrics\\n(25:4) 617–57.\\n———. (1975) A statistician’s apology. JASA (70) 7–14.\\nDoll, Richard. (1994) Austin Bradford Hill. Biographical Memoirs of\\nFellows of the Royal Society. (40) 129–40.\\n———. (2000) Smoking and lung cancer. American Journal of\\nRespiratory and Critical Care Medicine (162:1) 4–6.\\n———. (1995) Sir Austin Bradford Hill: A personal view of his\\ncontribution to epidemiology. JRSS: Series A (Statistics in Society)\\n(158) 155–63.\\nDuncan JW, Shelton WC. (1978) Revolution in United States\\nGovernment Statistics 1926–1976. U.S. Department of Commerce.\\nJerome Cornfield Memorial Issue. (March 1982) Biometrics\\nSupplement, Current Topics in Biostatistics and Epidemiology (38).\\nDuncan JW, Shelton WC. (1978) Revolution in United States\\nGovernment Statistics 1926–1976. U.S. Department of Commerce.\\nGail, Mitchell H. (1996) Statistics in Action. JASA (91:322) 1–13.\\nGreen, Sylvan B. (1997) A conversation with Fred Ederer. Statistical\\nScience (12:2) 125–31.\\nGreenhouse SW, Halperin M. (1980) Jerome Cornfield, 1912–1979.\\nAmerican Statistician (34) 106–7.\\nGreenhouse, Samuel W. (1982) Jerome Cornfield’s contributions to\\nepidemiology. Biometrics Supplement. 33–45.\\nGreenhouse \\nSW, \\nGreenhouse \\nJB. \\n(1998) \\nCornfield, \\nJerome.\\nEncyclopedia of Biostatistics, vol. 1, ed., P. Armitage, T. Colton.\\n955–59.\\nKass RE, Greenhouse JB. Comment: A Bayesian perspective.\\nStatistical Science (4:4) 310–17.\\nMemorial Symposium in honor of Jerome Cornfield. (1981) Jerome\\nCornfield: \\nCurriculum, \\nvitae, \\npublications \\nand \\npersonal\\nreminiscences. From Fred Ederer–Jerome Cornfield Collection, Acc\\n1999–022, in the History of Medicine Division, National Library of\\nMedicine.\\nNational Cancer Institute. (1994) Tobacco and the Clinician (5) 1–22.\\nSadowsky DA, Gilliam AG, Cornfield J. (1953) The statistical\\nassociation between smoking and carcinoma of the lung. Journal of\\nthe National Cancer Institute (13:5) 1237–58.\\nSalsburg, David. (2001) The Lady Tasting Tea: How Statistics\\nRevolutionized Science in the Twentieth Century. W. H. Freeman.\\nTruett J, Cornfield J, Kannel W. (1967) A multivariate analysis of the\\nrisk of coronary heart disease in Framingham. Journal of Chronic\\nDiseases (20:7) 511–24.\\nZelen, Marvin. (1982) The contributions of Jerome Cornfield to the\\ntheory of statistics in A Memorial symposium in honor of Jerome\\nCornfield, March 1982. Biometrics (38) 11–15.\\nChapter 9. There’s Always a First Time\\nAnonymous. (1991) U.S. nuclear weapons accidents; danger in our\\nmidst. Defense Monitor. Center for Defense Information, World\\nSecurity Institute. http://www/Milnet.com. Acc. Jan. 25, 2007.\\nCaldwell, Dan. (1987) Permissive action links. Survival (29) 224–38.\\nGott, Richard. (1963) The evolution of the independent British\\ndeterrent. International Affairs (Royal Institute of International\\nAffairs 1944-) (39) 238–52.\\nHerken, Gregg. (1985) Counsels of War. Knopf.\\nHounshell, David. (1997) The Cold War, RAND, and the generation of\\nknowledge, 1946–1962. Historical Studies in the Physical and\\nBiological Sciences (27) 237–67.\\nIklé, Fred Charles. (1958) The Social Impact of Bomb Destruction.\\nUniversity of Oklahoma Press.\\n———. (2006) Annihilation from Within: The Ultimate Threat to\\nNations. Columbia University Press.\\nIklé, Fred Charles, with Aronson GJ, Madansky A. (1958) On the risk\\nof an accidental or unauthorized nuclear detonation. RM-2251 U.S.\\nAir Force Project Rand. RAND Corp.\\nJardini, David R. (1996) Out of the Blue Yonder: The RAND\\nCorporation’s Diversification into Social Welfare Research, 1946–\\n1968. Dissertation, Carnegie Mellon University.\\nKaplan, Fred. (1983) The Wizards of Armageddon. Simon and Schuster.\\nMadansky, Albert. (1964) Externally Bayesian Groups. RAND Corp.\\n———. (1990) Bayesian analysis with incompletely specified prior\\ndistributions.\\nIn Bayesian and Likelihood Methods in Statistics and Econometrics:\\nEssays in Honor of George A. Barnard, ed. S. Geisser. North\\nHolland. 423–36.\\nMangravite, Andrew. (spring 2006) Cracking Bert’s shell and loving the\\nbomb. Chemical Heritage (24:1) 22.\\nSmith, Bruce LR. (1966) The RAND Corporation: Case Study of a\\nNonprofit Advisory Corporation. Harvard University Press.\\nU.S. Department of Defense. (April 1981) Narrative Summaries of\\nAccidents \\nInvolving \\nU.S. \\nNuclear \\nWeapons \\n1950–1980.\\nhttp://www.dod.mil/pubs/foi/reading_room/635.pdf.Acc.Jan.29,\\n2007. I am indebted to the Center for Defense Information for this\\nreference.\\nWohlstetter SJ et al. (April 1954) Selection and Use of Strategic Air\\nBases. RAND Corporation Publication R266.\\nWohlstetter, Albert. (1958) The delicate balance of terror. RAND Corp.\\nPublication 1472. Wyden, Peter. (June 3, 1961) The chances of\\naccidental war. Saturday Evening Post.\\nChapter 10. 46,656 Varieties\\nAnonymous. (1965) Bayes-Turing. NSA Technical Journal. I think IJ\\nGood is the author.\\n———. (1971) Multiple hypothesis testing. NSA Technical Journal.\\n63–72.\\n———. (1972) The strength of the Bayes score. NSA Technical\\nJournal. 87–111.\\nBather, John. (1996) A conversation with Herman Chernoff. Statistical\\nScience (11) 335–50.\\nBennett, JH, ed. (1990) Statistical Inference and Analysis: Selected\\nCorrespondence of R. A. Fisher. Clarendon Press.\\nDeGroot, MH. (1986c) A conversation with Charles Stein. Statistical\\nScience (1) 454–62.\\nEdwards W, Lindman H, Savage LJ. (1963) Bayesian statistical\\ninference for psychological research. Psychological Research (70:3)\\n193–242.\\nEfron, Bradley. (1977) Stein’s paradox in statistics. Scientific\\nAmerican (236) 119–27.\\n———. (1978) Controversies in the foundations of statistics. American\\nMathematical Monthly (85) 231–46.\\nGood IJ. (1971) 46656 Varieties of Bayesians. Letter to the Editor.\\nAmerican Statistician (25) 62–63.\\nJahn, RG, Dunne BJ, Nelson RD. (1987) Engineering anomalies\\nresearch. Journal of Scientific Exploration (1:1) 21–50.\\nJames W, Stein CM. (1961) Estimation with quadratic loss function.\\nProc. of the 4th Berkeley Symp. Math. Statist. and Prob. (1) 361.\\nJefferys, William H. (1990) Bayesian analysis of random event\\ngenerator data. Journal of Scientific Exploration (4:2) 153–69.\\nLeahy FT. (1960) Bayes marches on. NSA Technical Journal. (U) 49–\\n61.\\n———. (1964) Bayes factors. NSA Technical Journal. 1–5.\\n———. (1965) Bayes factors. NSA Technical Journal. 7–10.\\nRobbins, Herbert. (1956) An empirical Bayes approach to statistics. In\\nProc. of the 3rd Berkeley Symp. Math. Statist. and Prob. 1954–\\n1955. (1) University of California Press. 157–63.\\nSmith, Adrian. (1995) A conversation with Dennis Lindley. Statistical\\nScience 10 305–319.\\nStein, Charles. (1956) Inadmissibility of the usual estimator for the\\nmean of a multivariate normal distribution. In Proc. of the 3rd\\nBerkeley Symp. Math. Statist. and Prob., 1954–1955, vol. I, ed., J.\\nNeyman. University of California Press. 197–206.\\nTribe, Laurence H. (1971a) Trial by mathematics: Precision and ritual\\nin the legal process. Harvard Law Review (84:6) 1329–93.\\n———. (1971b) A further critique of mathematical proof. Harvard\\nLaw Review (84:8) 1810–20.\\nZellner, Arnold. (2006) S. James Press and Bayesian analysis.\\nMacroeconomic Dynamics. (10) 667–84.\\nPart IV. To Prove Its Worth\\n \\nChapter 11. Business Decisions\\nNote: HBSA GC File is in the Faculty Biography Collection, Harvard\\nBusiness School Archives, Baker Library, Harvard Business School.\\nAisner, Jim. (1994) Renowned Harvard Business School Professor\\nRobert O. Schlaifer Dead at 79. Harvard University.\\nAnonymous. (1959) Interpretation and reinterpretation: The Chicago\\nMeeting, 1959.\\nAmerican Historical Review (65) 733–86.\\nAnonymous (March 24, 1962) Math + Intuition = Decision. Business\\nWeek 54, 56, 60. HBSA Fac. Biography series GC 772.20, Harvard\\nBusiness School Archives, Baker Library, Harvard Business School.\\nAnonymous. (November 22, 1963) Harbus News.\\nAnonymous. (November 3, 1971) Yale statistician Leonard Savage\\nDies; Authored book on gambling. New Haven Register, 23.\\nAnonymous. (October 1985) Schlaifer and Fuller retire. HBS Bulletin.\\n18–19. HBSA GC File, R.O. Schlaifer.\\nAnonymous. (1992) Schlaifer awarded Ramsey Medal. Decision\\nAnalysis Society Newsletter (11:2).\\nBilstein, Roger E. (1977) Development of aircraft engines and fuels.\\nTechnology and Culture 18) 117–18.\\nBirnberg JG. (1964) Bayesian statistics: A review. Journal of\\nAccounting Research (2) 108–16.\\nFienberg, Stephen E. (2008) The early statistical years: 1947–1967.\\nA conversation with Howard Raiffa. Statistical Science (23:1) 136–49.\\nFienberg SE, Zellner A. (1975) Studies in Bayesian Econometrics and\\nStatistics: In Honor of Leonard J. Savage. North-Holland.\\nGottlieb, Morris J. (1960) Probability and statistics for business\\ndecisions. Journal of Marketing (25) 116–17.\\nHarvard \\nUniversity \\nStatistics \\nDepartment.\\nhttp//www.stat.Harvard.edu/People/Department_History.html. Kemp,\\nFreda. (2001) Applied statistical decision theory: Understanding\\nrobust and exploratory data analysis. The Statistician (50) 352–53.\\nMassie, Joseph L. (1951) Development of aircraft engines; development\\nof aviation fuels. Journal of Business of the University of Chicago\\n(24) 141–42.\\nMcGinnis, John A. (November 22, 1963) “Only God can make a tree.”\\nHarbus News.\\nHBSA Faculty Biography Series GC 772.20, Robert O. Schlaifer.\\nMemorial Service, Robert O. Schlaifer, Friday, December 2, 1994.\\nHBSA GC 772.20 Faculty Biography.\\nNocera, John. (1994) A Piece of the Action: How the Middle Class\\nJoined the Money Class. Simon and Schuster.\\nPratt JW, Raiffa H, Schlaifer R. (1964) The foundations of decision\\nunder uncertainty: An elementary exposition. JASA (59) 353–75.\\n———. (1965) Introduction to Statistical Decision Theory. McGraw-\\nHill.\\nPratt, John W. (1985) [Savage Revisited]: Comment. Statistical Science\\n(1) 498–99.\\nRaiffa, Howard. (1968) Decision Analysis: Introductory Lectures on\\nChoices under Uncertainty. Addison-Wesley.\\n———. (2002) Tribute to Robert Wilson on his 65th Birthday. Berkeley\\nElectronic Press. http://www.bepress.com/wilson/art2.\\n———. (2006) A Memoir: Analytical Roots of a Decision Scientist.\\nUnpublished. I am indebted to Dr. Raiffa for letting me read and\\nquote from his manuscript.\\nRaiffa H, Schlaifer R. (1961) Applied Statistical Decision Theory.\\nMIT Press.\\nRamsey Award Winners. (1988) Videotaped talk by Howard Raiffa,\\nRonald Howard, Peter C. Fishburn, and Ward Edwards at the Joint\\nNational Meeting of the Operations Research Society of America.\\nSan Diego. I am indebted to INFORMS for letting me watch the\\nvideo.\\nSavage, Jimmie. (October 1, 1956) Letter to Committee on Statistics\\nFaculty, Chicago. In Manuscripts and Archives, Yale University\\nLibrary.\\nSaxon, Wolfgang. (July 28, 1994) Robert O. Schlaifer, 79, managerial\\neconomist. New York Times.\\nSchlaifer, Robert. (1936) Greek theories of slavery from Homer to\\nAristotle. Harvard Studies in Classical Philology (47) 165–204.\\nSchlaifer R, Heron SD. (1950) Development of Aircraft Engines.\\nDevelopment of Aviation Fuels. Graduate School of Business\\nAdministration, Harvard University.\\nSchlaifer, Robert O. (1959) Probability and Statistics for Business\\nDecisions: An Introduction to Managerial Economics under\\nUncertainty. McGraw-Hill.\\nChapter 12. Who Wrote The Federalist?\\nAlbers DJ, Alexanderson GL, Reid C., eds. (1990) More Mathematical\\nPeople. Harcourt Brace Jovanovich.\\nBrooks, E. Bruce. (2001) Tales of Statisticians: Frederick Mosteller.\\nwww.UMass.edu/wsp/statistics/tales/mosteller.html. Acc. December\\n21, 2004.\\nChang, Kenneth. (July 27, 2006) C. Frederick Mosteller, a pioneer in\\nstatistics, dies at 89. New York Times.\\nCochran WG, Mosteller F, Tukey JW. (1954) Statistical Problems of\\nthe Kinsey Report on Sexual Behavior in the Human Male.\\nAmerican Statistical Association.\\nConverse, Jean M. (1987) Survey Research in the United States: Roots\\nand Emergence 1890–1960. University of California Press.\\nFienberg SE, Hoaglin DC, eds. (2006) Selected Papers of Frederick\\nMosteller. Springer.\\nFienberg SE et al., eds. (1990) A Statistical Model: Frederick\\nMosteller’s Contributions to Statistics, Science and Public Policy.\\nSpringer-Verlag.\\nHedley-Whyte J. (2007) Frederick Mosteller (1916–2006): Mentoring,\\nA Memoir. International Journal of Technology Assessment in\\nHealth Care (23) 152–54.\\nIngelfinger, Joseph, et al. (1987) Biostatistics in Clinical Medicine.\\nMacmillan.\\nJones, James H. (1997) Alfred C. Kinsey: A Public/Private Life. W. W.\\nNorton.\\nKinsey AC, Pomeroy WB, Martin CE. (1948) Sexual Behavior in the\\nHuman Male. WB Saunders.\\nKolata, Gina Bari. (1979) Frederick Mosteller and applied statistics.\\nScience (204) 397–98.\\nKruskal W, Mosteller F. (1980) Representative sampling, IV: The\\nhistory of the concept in statistics, 1895–1939. International\\nStatistical Review (48) 169–95.\\nMosteller, Frederick, et al. (1949) The Pre-Election Polls of 1948.\\nSocial Science Research Council.\\nMosteller F, Tukey J. (1954) Data analysis, including statistics. In The\\nCollected Works of John W. Tukey, vol. 4, ed. Lyle V. Jones.\\nWadsworth and Brooks.\\nMosteller F, Rourke REK, Thomas GB Jr. (1961, 1970) Probability\\nwith Statistical Applications. Addison-Wesley.\\nMosteller F, Wallace DL. (1964) Inference and Disputed Authorship,\\nThe Federalist. Addison-Wesley; and (1984) Applied Bayesian and\\nClassical Inference: The Case of the Federalist Papers. Springer-\\nVerlag. These two books are identical but meant for different\\naudiences.\\nMosteller F, Wallace DL. (1989) Deciding authorship. In Statistics: A\\nGuide to the Unknown, eds., Judith M. Tanur et al. Wadsworth and\\nBrooks/Cole. 115–25.\\nPetrosino, Anthony. (2004) Charles Frederick [Fred] Mosteller.\\nJamesLindLibrary.org.\\nSquire, Peverill. (1988) Why the 1936 Literary Digest poll failed.\\nPublic Opinion Quarterly (52) 125–33.\\nZeckhauser RJ, Keeney RL, Sebenius JK. (1996) Wise Choices:\\nDecisions, Games, and Negotiations. Harvard Business School\\nPress.\\nChapter 13. The Cold Warrior\\nAnscombe, FR. (2003) Quiet contributor: the civic career and times of\\nJohn W. Tukey. Statistical Science (18:3) 287–310.\\nBamford, James. (1983) The Puzzle Palace: A Report on America’s\\nMost Secret Agency. Penguin. Bean, Louis H. (1950) The pre-\\nelection polls of 1948 (review). JASA (45) 461–64.\\nBell \\nLabs. \\nMemories \\nof \\nJohn \\nW. \\nTukey.\\nhttp://cm.belllabs.com/cm/ms/departments/sia/tukey/Acc. Feb. 27,\\n2007\\nBell Telephone Labs. (1975–85) The History of Engineering and\\nScience in the Bell System. Vols. 1–7.\\nBrillinger, David R. (2002a) John W. Tukey: His life and professional\\ncontributions. Annals of Statistics (30) 1535–75.\\n———. (2002b) John Wilder Tukey (1915–2000). Notices of the\\nAmerican Mathematical Society (49:2) 193–201.\\n———. (2002c) John W. Tukey’s work on time series and spectrum\\nanalysis. Annals of Statistics (30) 1595–1618.\\nCasella G et al. (2003) Tribute to John W. Tukey. Statistical Science\\n(18) 283–84.\\nComputer History Museum. “Selling the Computer Revolution.”\\nwww.computerhistory.org/brochures/companies. Acc. March 7,\\n2007.\\nDempster, Arthur P. (2002) John W. Tukey as “philosopher.” Annals of\\nStatistics (30) 1619–28.\\nGnanadesikan R, Hoaglin DC. (1993) A Discussion with Elizabeth and\\nJohn Tukey, Parts I and II. DVD. American Statistical Association.\\nJones, Lyle V., ed. (1986) The Collected Works of John W. Tukey. Vol.\\nIII: Philosophy and Principles of Data Analysis: 1949–1964.\\nWadsworth and Brooks/Cole.\\nLeonhardt, David. (2000) John Tukey: Statistician who coined 2 crucial\\nwords. www.imstat.org/Bulletin/Sept2000/node18.html. Acc. April\\n7, 2007.\\nLink, Richard F. (1989) Election night on television. In Statistics: A\\nGuide to the Unknown, eds., Judith M. Tanur et al. Wadsworth and\\nBrooks/Cole. 104–12.\\nMcCullagh, Peter. (2003) John Wilder Tukey. Biographical Memoirs of\\nthe Fellows of the Royal Society London (49) 537–55.\\nMosteller F, Tukey JW. (1954) Data analysis, including statistics. In The\\nCollected Works of John W. Tukey, vol. IV, ed. Lyle V. Jones.\\nRobinson, Daniel J. (1999) The Measure of Democracy: Polling,\\nMarket Research, and Public Life, 1930–1945. University of\\nToronto Press.\\nTedesco, John. Huntley, Chet. Museum of Broadcast Communications.\\nwww.museum.tv/archives/etv/H/htmlH/huntleychet/huntleychet.htm.\\nAcc. July 17, 2007.\\nTukey, John W. (1962) The future of data analysis. Annals of\\nMathematical Statistics (33) 1–67.\\n———. (1984) The Collected Works of John W. Tukey: Time Series:\\n1949–1964, 1965–1984. Vols. 1, 2. Ed. David R. Brillinger.\\nWadsworth Advanced Books and Software.\\n———. (1984) The Collected Works of John W. Tukey: Philosophy\\nand Principles of Data Analysis, 1949–1953; 1965–1986. Vols. 3, 4.\\nEd. Lyle V. Jones.Wadsworth Advanced Books and Software.\\nWaite CH, Brinkley, David. Museum of Broadcast Communications.\\nwww.museum.tv/archives/etv/B/htmlB/brinkleydav/brinkleydav.html.\\nAcc. July 16, 2007.\\nChapter 14. Three Mile Island\\nAnonymous. (1982) Using experience to calculate nuclear risks.\\nScience (217) 338.\\nApostolakis, George E. (1988) Editorial: The interpretation of\\nprobability \\nin \\nprobabilistic \\nsafety \\nassessments. \\nReliability\\nEngineering and System Safety (23) 247–52.\\n———. (1990) The concept of probability in safety assessments of\\ntechnological systems. Science (250) 1359(6).\\n———. (2004) How useful is quantitative risk assessment? Risk\\nAnalysis (24) 515–20.\\nBarnett, Vic. (1973, 1982, 1999) Comparative Statistical Inference.\\nJohn Wiley and Sons.\\nBather, John. (1996) A conversation with Herman Chernoff. Statistical\\nScience (11) 335–50.\\nBier, Vicki M. (1999) Challenges to the acceptance of probabilistic risk\\nanalysis. Society for Risk Analysis (19) 703–10.\\nCooke, Roger M. (1991) Experts in Uncertainty: Opinion and\\nSubjective Probability in Science. Oxford University Press.\\nFeynman, Richard P. (1986) Appendix F: Personal observations on the\\nreliability \\nof \\nthe \\nShuttle.\\nhttp://www.Science.ksc.nasa.gov/shuttle/missions/51-l/docs/rogers-\\ncommission/Appendix-F.txt.\\n———. (1987) Mr. Feynman Goes to Washington. Engineering and\\nScience. California Institute of Technology. (vol. 50) 6–22.\\nHarris, Bernard. (2004) Mathematical methods in combating terrorism.\\nRisk Analysis (24:4) 985–88.\\nMartz HF, Zimmer WJ. (1992) The risk of catastrophic failure of the\\nsolid rocket boosters on the space shuttle. American Statistician (46)\\n42–47.\\nRussell, Cristine. (1974) Study gives good odds on nuclear reactor\\nsafety. BioScience (24) 605–06.\\nSelvidge, Judith. (1973) A three-step procedure for assigning\\nprobabilities to rare events. In Utility, Probability, and Human\\nDecision Making, ed. Dirk Wendt and Charles Vlek. D. Reidel\\nPublishing.\\nU.S. Atomic Energy Commission. (1974) Reactor Safety Study: An\\nAssessment of Accident Risks in U.S. Commercial Nuclear Power\\nPlants. \\nWASH-1400. \\nNUREG-75/014. \\nNational \\nTechnical\\nInformation Service.\\nWebb, Richard E. (1976) The Accident Hazards of Nuclear Power\\nPlants. University of Massachusetts Press.\\nWilson, Richard. (2002) Resource letter: RA-1: Risk analysis.\\nAmerican Journal of Physics (70) 475–81.\\nChapter 15. The Navy Searches\\nAndrews, Capt. Frank A., ed. (1966) Aircraft Salvops Med: Sea Search\\nand Recovery of an Unarmed Nuclear Weapon by Task Force 65,\\nInterim Report. (1966) Chief of Naval Operations, U.S. Navy.\\nArkin, William, and Handler, Joshua. (1989) Naval Accidents 1945–\\n1988, Neptune Paper No. 3. Greenpeace.\\nAssociated Press (August 31, 1976) Soviet sub and U.S. frigate\\ndamaged in crash. New York Times 5; U.S. frigate and Soviet\\nsubmarine collide. The Times of London 5.\\nBelkin, Barry. (1974) Appendix A: An alternative measure of search\\neffectiveness for a clearance operation. Wagner, Associates.\\nUnpublished.\\nCenters for Disease Control and Prevention (CDC). (April 20, 2005)\\nPlutonium. Department of Health and Human Services Agency, CDC\\nRadiation \\nEmergencies \\nRadioisotope \\nBrief.\\nwww.bt.cdc.gov/radiation Accessed July 29, 2006.\\nChurch BW et al. (2000) Comparative \\nPlutonium-239 \\nDose\\nAssessment \\nfor \\nThree \\nDesert \\nSites: \\nMaralinga, \\nAustralia;\\nPalomares, Spain; and the Nevada Test Site, USA Before and After\\nRemedial Action. Lawrence Livermore National Laboratory.\\nCraven, John Piña. (2002) The Silent War: The Cold War Battle\\nBeneath the Sea. Simon and Schuster.\\nFeynman, Richard P. (1985) Surely You’re Joking, Mr. Feynman! W. W.\\nNorton.\\nGonzalez II, Ruiz SS. (1983) Doses from Potential Inhalation by\\nPeople Living Near Plutonium Contaminated Areas. Oak Ridge\\nNational Laboratory.\\nHandler J, Wickenheiser A, Arkin WM. Naval Safety 1989: The Year of\\nthe \\nAccident, \\nNeptune \\nPaper \\nNo. \\n4. \\nGreenpeace.\\nhttp//www.destroyersonline.com/usndd/ff1047/f1047pho.htm.\\nDestroyersOnLine web page. Voge collision picture.\\nLewis, Flora. (1967) One of Our H-Bombs is Missing. McGraw-Hill.\\nA Pulitzer Prize winner.\\nMoody, Dewitt H. (2006) 40th anniversary of Palomares. Faceplate\\n(10:2) 15–19.\\nNicholson, John H. (1999) Foreword in Under Ice: Waldo Lyon and\\nthe Development of the Arctic Submarine by William Leary. Texas\\nA&M University Press.\\nOtto, M. (1998) Course ‘Filling Station.’ Foreign Technology Division,\\nWright-Patterson AFB.\\nPlace WM, Cobb FC, Defferding CG. (1975) Palomares Summary\\nReport. Defense Nuclear Agency, Kirtland Air Force Base.\\nReuters (October 11, 2006) Radioactive snails lead to Spain–U.S.\\natomic probe.\\nRichardson HR, Stone LD. (1971) Operations analysis during the\\nunderwater search for Scorpion. \\nNaval \\nResearch \\nLogistics\\nQuarterly (18) 141–57.\\n———. (1984) Advances in search theory with application to\\npetroleum exploration, Report to National Science Foundation.\\nDaniel H. Wagner, Associates.\\nRichardson HR, Discenza JH. (1980) The United States Coast Guard\\nComputer-Assisted Search Planning System (CASP). Naval Research\\nLogistics Quarterly (27:4) 659–80.\\nRichardson HR, Weisinger JR. (1984) The search for lost satellites.\\nProceedings of the 7th MIT-ONR Workshop on C3 Systems, eds., M.\\nAthans, A. Levis.\\nRichardson, Henry R. (1986) Search theory. Center for Naval Analyses,\\nAlexandria, Va.\\nRichardson HR, Stone LD, Monarch WR, Discenza JH. (2003)\\nProceedings of the SPIE Conference on Optics and Photonics, San\\nDiego. SPIE.\\nSontag S, Drew C, with Drew AL. (1998) Blind Man’s Bluff: The\\nUntold Story of American Sub marine Espionage. Public Affairs.\\nStone, Lawrence D. (1975) Theory of Optimal Search. Academic\\nPress.\\n———. (1983) The process of search planning: Current approaches\\nand continuing problems. Operations Research (31) 207–33.\\n———. (1989) What’s happened in search theory since the 1975\\nLanchester Prize? Operations Research (37) 501–06.\\n———. (1990) Bayesian estimation of undiscovered pool sizes using\\nthe discovery record. Mathematical Geology (22) 309–32.\\nStone LD, Barlow CA, Corwin TL. (1999) Bayesian Multiple Target\\nTracking. Artech House.\\nTaff LG. (1984) Optimal searches for asteroids. Icarus (57) 259–66.\\nU.S. Air Force Medical Service. (July 29, 2006) Air Force Releases\\nReports on Palomares, Spain and Thule Airbase, Greenland Nuclear\\nWeapons Accidents. AFMS.mil/latestnews/palomares.htm. Acc. July\\n29, 2006.\\nU.S. Department of Energy. (Palomares, Spain medical surveillance and\\nenvironmental \\nmonitoring.\\nwww.eh.doe.gov/health/ihp/indalo/spain/html. Acc. July 29, 2006.\\nWagner, Daniel H. (1988) History of Daniel H. Wagner, Associates\\n1963–1986. Daniel H. Wagner, Associates.\\nPart V. Victory\\n \\nChapter 16. Eureka!\\nAlder, Berni J. (1990) Transcript of interview with Berni J. Alder\\nconducted June 18, 1990. American Institute of Physics, Center for\\nthe History of Physics.\\nBayarri MJ, Berger JO. (2004) The interplay of Bayesian and\\nfrequentist analysis. Statistical Science (19) 58–80.\\nBerger, James O. (2000) Bayesian analysis: A look at today and\\nthoughts of tomorrow. JASA (95) 1269.\\n———. (2006) The case for objective Bayesian analysis. Bayesian\\nAnalysis (1:3) 385–402.\\nBesag, Julian. (1974) Spatial interaction in the statistical analysis of\\nlattice systems. JRSS B (36) 192–236.\\nBritton JL, ed. (1992) Collected Works of A. M. Turing: Pure\\nMathematics. North-Holland.\\nCappé O, Robert CP. (2000) Markov chain Monte Carlo: 10 years and\\nstill running! JASA (95) 1282–86\\nCouzin, Jennifer. (2004) The new math of clinical trials. Science (303)\\n784–86.\\nDeGroot, Morris H. (1986b) A conversation with Persi Diaconis.\\nStatistical Science (1:3) 319–34.\\nDiaconis P, Efron B. (1983) Computer-intensive methods in statistics.\\nScientific American (248) 116–30.\\nDiaconis, Persi. (1985) Bayesian statistics as honest work. Proceedings\\nof the Berkeley Conference in Honor of Jerzy Neyman and Jack\\nKiefer (1), eds., Lucien M. Le Cam and Richard A. Olshen.\\nWadsworth.\\nDiaconis P, Holmes S. (1996) Are there still things to do in Bayesian\\nstatistics? Erkenntnis (45) 145–58.\\nDiaconis P. (1998) A place for philosophy? The rise of modeling in\\nstatistical science. Quarterly of Applied Mathematics (56:4) 797–\\n805.\\nDuMouchel WH, Harris JE. (1983) Bayes methods for combining the\\nresults of cancer studies in humans and other species. JASA (78) 293–\\n308.\\nEfron, Bradley. (1986) “Why isn’t everyone a Bayesian?” American\\nStatistician (40) 1.\\nGelfand, Alan E. (2006) Looking back on 15 years of MCMC: Its\\nimpact on the statistical (and broader) research community.\\nTranscript of Gelfand’s speech when awarded Parzen Prize for\\nStatistical Innovation.\\nGelfand AE, Smith AFM. (June 1990) Sampling-based approaches to\\ncalculating marginal densities. JASA (85:410) 398–409.\\nGelfand AE et al. (December 1990) Illustration of Bayesian inference in\\nnormal data models using Gibbs Sampling. JASA (85:412) 972–85.\\nGeman S, Geman D. (1984) Stochastic relaxation, Gibbs distributions\\nand the Bayesian restoration of images. IEEE Trans. Pattern Anal.\\nMach. Intell. (6) 721–40.\\nGill, Jeff. (2002) Bayesian Methods: A Social and Behavioral\\nSciences Approach. Chapman and Hall.\\nHanson KM. (1993) Introduction to Bayesian image analysis. In\\nMedical Imaging: Image Processing, ed. MH Loew. Proc. SPIE\\n(1898) 716–31.\\nHastings WK. (1970) Monte Carlo sampling methods using Markov\\nchains and their applications. Biometrika (57:1) 97–109.\\nHively, Will. (1996) The mathematics of making up your mind.\\nDiscover (17:5) 90(8). Early popular-level description of Bayes.\\nHouseholder, Alston S. (1951) Monte Carlo Method: Proceedings of a\\nSymposium Held June 29, 30, and July 1, 1949. National Bureau of\\nStandards Applied Mathematics Series 12. v.\\nHubert, Peter J. (1985) Data analysis: In search of an identity. In\\nProceedings of the Berkeley Conference in Honor of Jerzy Neyman\\nand Jack Kiefer, eds., Lucien M. Le Cam and Richard A. Olshen.\\nWadsworth.\\nHunt BR. (1977) Bayesian methods in nonlinear digital image\\nrestoration. IEEE Transactions on Computers (C-26:3) 219–29.\\nKay, John. (2003) What is the chance of your being guilty? Financial\\nTimes (London). June 29, 21.\\nKuhn, Thomas S. (1962). The Structure of Scientific Revolutions.\\nUniversity of Chicago Press.\\nLeonhardt, David. (2001) Adding art to the rigor of statistical science.\\nNew York Times, April 28. B 9.\\nLindley, DV. (1965) Introduction to Probability and Statistics from a\\nBayesian Viewpoint. Cambridge University Press.\\nLuce, R. Duncan. (2003) Whatever happened to information theory in\\npsychology? Review of General Psychology (7:2) 183–88.\\nMalakoff, David. (1999) “Bayes offers a ‘new’ way to make sense of\\nnumbers,” “A brief guide to Bayes theorem,” “The Reverend Bayes\\ngoes to court,” and “An improbable statistician.” Science (286:5444)\\n1460ff.\\nMarkoff, John. (2000) Microsoft sees software ‘agent’ as way to avoid\\ndistractions. New York Times, July 17 C1.\\nMetropolis N, Ulam S. (1949) The Monte Carlo method. JASA (44:247)\\n335–41.\\nMetropolis, Nicholas. (1987) The beginning of the Monte Carlo method.\\nLos Alamos Science (15) 125–30.\\nNeiman, Fraser D. (2000) Coincidence or causal connection? The\\nrelationship between Thomas Jefferson’s visits to Monticello and\\nSally Heming’s conceptions. William and Mary Quarterly, 3d ser.\\n(57:1) 198–210.\\nPress, S. James (1986) [Why isn’t everyone a Bayesian?]: Comment.\\nAmerican Statistician (40) 9–10.\\nRaftery, Adrian E. (1986) Choosing models for cross-classifications.\\nAmerican Sociological Review (51:1) 145–46.\\nRaftery AE, Zeh JE. (1998) Estimating bowhead whale population size\\nand rate of increase from the 1993 census. JASA (93:442) 451–63.\\nRobert C, Casella G. (2008) A history of Markov chain Monte Carlo—\\nsubjective recollections from incomplete data. Unpublished draft\\nkindly provided by C. Robert.\\nRoyal Statistical Society. “News Release: Royal Statistical Society\\nconcerned by issues raised in Sally Clark case.” October 23, 2001.\\nhttp://www.rss.org.uk/archive/reports/sclark.html Acc. February 13,\\n2004.\\nSalsburg, David. (2001) The Lady Tasting Tea: How Statistics\\nRevolutionized Science in the Twentieth Century. W. H. Freeman.\\nSivia DS. (1996) Data Analysis: A Bayesian Tutorial. Clarendon\\nPress.\\nSmith, Adrian F.M. (1983) Comment. JASA (78) 310–11.\\nSpiegelhalter DJ et al. (1999) An Introduction to Bayesian methods in\\nhealth technology assessment. British Medical Journal (319) 508–\\n12.\\nSpiegelhalter DJ, Abrams KR, Myles JP. (2004) Bayesian Approaches\\nto Clinical Trials and HealthCare Evaluation. John Wiley.\\nSpiegelhalter, David J. (2004) Incorporating Bayesian ideas into\\nhealthcare evaluation. Statistical Science (19) 156–74.\\nTaylor BL, Gerrodette T. (1993) The uses of statistical power in\\nconservation biology: the vaquita and Northern Spotted Owl.\\nConservation Biology (7) 489–787.\\nWeinberger, Steven E. (2008) Diagnostic evaluation and initial\\nmanagement of the solitary pulmonary nodule. Online in UpToDate,\\ned. Basow, DS. Waltham, Mass.\\nChapter 17. Rosetta Stones\\nAbazov VM et al. (2007) Search for production of single top quarks via\\nt c g and tug flavor-changing-neutral-current couplings. Physical\\nReview Letters (99) 191802.\\nAnderson, Philip W. (1992) The Reverend Thomas Bayes, needles in\\nhaystacks, and the fifth force. Physics Today (45:1) 9, 11.\\nAoki, Masanao. (1967) The Optimization of Stochastic Systems.\\nAcademic Press.\\nBerger JO. (2003) Could Fisher, Jeffreys and Neyman have agreed on\\ntesting? Statistical Science (18:1) 1–12.\\nBrockwell AE, Rojas AL, Kass RE. (2004) Recursive Bayesian\\ndecoding of motor cortical signals by particle filtering. Journal of\\nNeurophysiology (91) 1899–1907.\\nBroemeling, Lyle D. (2007) Bayesian Biostatistics and Diagnostic\\nMedicine. Chapman and Hall.\\nBrown, Emery N, et al. (1998) A statistical paradigm for neural spike\\ntrain decoding applied to position prediction from ensemble firing\\npatterns of rat hippocampal place cells. Journal of Neuroscience\\n(18) 7411–25.\\nCampbell, Gregory. (2009) Bayesian statistics at the FDA: The\\ntrailblazing experience with medical devices. Emerging Issues in\\nClinical Trials, Rutgers Biostatistics Day, April 3, 2009.\\nhttp://www.stat.rutgers.edu?iob/bioconf09/slides/campbell.pdf. Acc.\\nOctober 8, 2009.\\nCommittee on Fish Stock Assessment Methods, National Research\\nCouncil. (1998) Improving Fish Stock Assessments. National\\nAcademy of Sciences.\\nDawid, AP. (2002) Bayes’s theorem and weighing evidence by juries.\\nIn Bayes’s Theorem, ed. Richard Swinburne. 71–90.\\nDoya, Kenji, et al, eds. (2007) Bayesian Brain: Probabilistic\\nApproaches to Neural Coding. MIT Press.\\nEfron, Bradley. (2005). Bayesians, frequentists, and scientists. JASA\\n(469) 1–11.\\n———. (2005) Modern science and the Bayesian-frequentist\\ncontroversy. \\nwww-stat.Stanford.edu/~brad/papers/NEW-Mod-\\nSci_2005. Acc. June 13, 2007.\\n———. (2006) Microarrays, Empirical Bayes, and the two-groups\\nmodel. www-stat.Stanford.edu/brad/papers/twogroups.pdf Acc. June\\n13, 2007.\\nFrith, Chris. (2007) Making Up the Mind: How the Brain Creates Our\\nMental World. Blackwell.\\nGastwirth JL, Johnson WO, Reneau DM. (1993) Bayesian analysis of\\nscreening data: Application to AIDS in blood donors. Canadian\\nJournal of Statistics (19) 135–50.\\nGeisler WS, Kersten D. (2002) Illusions, perception and Bayes. Nature\\nNeuroscience (5:6) 508–10.\\nGoodman J, Heckerman D. (2004) Fighting spam with statistics.\\nSignificance (1) 69–72.\\nGoodman, Steven N. (1999) Toward evidence-based medical statistics,\\nParts 1 and 2. Annals of Internal Medicine (130:12) 995–1013.\\n———. (2005) Introduction to Bayesian methods I: measuring the\\nstrength of evidence. Clinical Trials (2:4) 282–90.\\nGreenspan, Alan. (2004) Risk and uncertainty in monetary policy. With\\npanel discussion by Martin Feldstein, Mervyn King, Janet L. Yellen.\\nAmerican Economic Review (94:2) 33–48.\\nHelm, Leslie. (Oct. 28, 1996) Improbable Inspiration. Los Angeles\\nTimes B1. www-stat.Stanford.edu/brad/papers/twogroups.pdf.\\nHeuer, Richards J. Jr., ed. (1978) Quantitative Approaches to Political\\nIntelligence: The CIA Experience. Westview.\\nHillborn R, Mangel M. (1997) The Ecological Detective: Confronting\\nModels with Data. Princeton University Press.\\nHively, Will. (1996) The mathematics of making up your mind.\\nDiscovery (17) 98(8).\\nKass, Robert E. (2006) Kinds of Bayesians (Comment on articles by\\nBerger and by Goldstein). Bayesian Analysis (1) 437–40.\\nKaye, David H. (in press) The Double Helix and the Law of Evidence.\\nHarvard University Press.\\nKaye DH, Bernstein D, Mnookin J. (2004) The New Wigmore, A\\nTreatise on Evidence: Expert Evidence. Aspen Publishers.\\nKersten D, Mamassian P, Yuille A. (2004) Object perception as\\nBayesian inference. Annual Review of Psychology (55) 271–305.\\nKiani R, Shadlen MN. (2009) Representation of confidence associated\\nwith a decision by neurons in the parietal cortex. Science (324) 759–\\n64.\\nKnill DC, Pouget A. (2004) The Bayesian brain: The role of uncertainty\\nin neural coding and computation. Trends in Neurosciences (27)\\n712–19.\\nKörding KP, Wolpert DM. (2004) Bayesian integration in sensorimotor\\nlearning. Nature (427) 244–47.\\nLeamer, Edward E. (1983) Let’s take the con out of econometrics.\\nAmerican Economic Review (73) 31–43.\\nLebiere, Christian. (1999) The dynamics of cognition: An ACT-%\\nmodel of cognitive arithmetic. Kognitionswissenschaft (8) 5–19.\\nLinden G, Smith B, York J. (2003) Amazon.com recommendations.\\nIEEE Internet Computing (7:1) 76–80.\\nLudlum, Robert. (2005) The Ambler Warning. St. Martin’s.\\nO’Hagan A, Luce BR. (2003) A Primer on Bayesian Statistics in\\nHealth Economics and Outcomes Research. MEDTAP International.\\nPearl, Judea. (1988) Probabilistic Reasoning in Intelligence Systems:\\nNetworks of Plausible Inference. Morgan Kaufman Publishers.\\nPouget A et al. (2009) Neural Computations as Laplacian (or is it\\nBayesian?) probabilistic inference. In draft.\\nQuatse JT, Najmi A. (2007) Empirical Bayesian targeting. Proceedings,\\n2007 World Congress in Computer Science, Computer Engineering,\\nand Applied Computing, June 25–28, 2007.\\nSchafer JB, Konstan J, Riedl J. (1999) Recommender systems in E-\\ncommerce. In ACM Conference on Electronic Commerce (EC-99)\\n158–66.\\nSchafer JB, Konstan J, Riedl J. (2001) Recommender systems in E-\\ncommerce. Data Mining and Knowledge Discovery (5) 115–53.\\nSchneider, Stephen H. (2005) The Patient from Hell. Perseus Books.\\nSpolsky, \\nJoel. \\n(2005)\\n(http://www.joelonsoftware.com/items/2005/10/17.html).\\nSwinburne, Richard, ed. (2002) Bayes’s Theorem. Oxford University\\nPress.\\nTaylor BL et al. (2000) Incorporating uncertainty into management\\nmodels for marine mammals. Conservation Biology (14) 1243–52.\\nUnwin, Stephen D. (2003) The Probability of God: A Simple\\nCalculation that Proves the Ultimate Proof. Random House.\\nWade, Paul R. (1999) A comparison of statistical methods for fitting\\npopulation models to data. In Marine Mammal Survey and\\nAssessment Methods, eds., Garner et al. Rotterdam: AA Balkema.\\n———. \\n(2000) \\nBayesian \\nmethods \\nin \\nconservation \\nbiology.\\nConservation Biology (14) 1308–16.\\n———. (2001) Conservation of exploited species in an uncertain\\nworld: Novel methods and the failure of traditional techniques. In\\nConservation of Exploited Species, eds., JD Reynolds et al.\\nCambridge University Press. 110–44.\\nWeaver, Warren. (1955) Translation. In Machine Translation of\\nLanguages: Fourteen Essays, eds., WN Locke, AD Booth. MIT\\nTechnology Press and John Wiley.\\n———. (1963) Lady Luck: The Theory of Probability. Dover\\nPublications.\\nWesterfield, H. Bradford, ed. (1995) Inside CIA’s Private World:\\nDeclassified Articles from the Agency’s Internal Journal, 1955–\\n1992. Yale University Press.\\nWolpert DM, Ghahramani Z. (2005) Bayes’ rule in perception, action,\\nand cognition. In The Oxford Companion to the Mind, ed., Gregory\\nRL. Oxford Reference OnLine.\\nWolpert DM. (December 8, 2005) The puppet master: How the brain\\ncontrols the body. Francis Crick Lecture, Royal Society. Online.\\nZellner, Arnold. (2006) Bayesian econometrics: Past, present and\\nfuture. HGB Alexander Research Foundation, University of Chicago.\\nPaper 0607.\\nAppendixes\\nCampbell, Michael J. (2008) The doctor sees the light. Significance\\n(5:4) 172.\\nFrith, Chris. (2007) Making Up The Mind: How the Brain Creates our\\nMental World. Blackwell.\\nElmore Joann G et al. (April 16, 1998) Ten-year risk of false positive\\nscreening mammograms and clinical breast examinations. New\\nEngland Journal of Medicine (338:16) 1089–96.\\nKerlikowske Karla et al. (November 24, 1993) Positive predictive\\nvalue of screening mammography by age and family history of breast\\ncancer. JAMA (270: 20) 2444–50.\\nKolata, Gina (November 23, 2009) Behind cancer guidelines, quest for\\ndata. New York Times.\\nNational Cancer Institute (2009) Breast cancer screening: harms of\\nscreening. Accessed October 16 2009. pp. 1–4.\\nWeaver DL et al. (2006) Pathologic findings from the Breast Cancer\\nSurveillance Consortium: population-based outcomes in women\\nundergoing biopsy after screening mammography. Cancer (106) 732.\\nCited in Fletcher, Suzanne W. (2010) Screening for breast cancer.\\nwww.uptodate.com\\nindex\\n \\nAbelson, Robert, 168\\naccidents.\\nSee safety\\nacquired immune deficiency syndrome, 216, 227\\nAdair, Douglass, 159\\nair quality, 215–16\\nAlexander, Hugh, 71, 82, 83\\nAmerican Statistical Association, 117, 135\\nAmerican Telephone and Telegraph Company, x, 40–42, 243–44\\nAnderson, John R., 247–48\\nAndrews, Frank A., 187–190, 193, 197–200, 202\\nAndrews, Harry C., 218\\nAnscombe, Frank R., 166, 169, 173\\nanti-Semitism, 143–44\\nAoki, Masanao, 205,\\nAronson, Gerald J., 126–27\\narifical intelligence, 81, 250–51\\nartillary 28, 29, 38, 63, 72–73, 80, 116\\nasteroids 209,\\nastronomy 14, 16–18, 19, 21, 28, 32–33, 36–37,\\nAT&T Labs, 243–44\\nAutomatic Target Recognition (ATM),241\\nautomobile insurance, 95\\naverages, 130–32\\nBailey Arthur L., 91–96, 120, 125,131\\nBailey, Helen, 91\\nBailey, Robert A., 95\\nBailey, William O., 174\\nBanburismus 66–72, 75, 80\\nBarnard George A., 69, 132\\nBarnett, Otto, 135\\nBayes, Thomas: Bayes’ rule discovered by, ix, 3, 6–10, 22, 130\\nin dictionary, 215, 225\\nlife and death of, 3–5\\nportrait of, 259\\nlife and death date of, 259\\nBayes’ Factor,116\\nBayesian inference, 129–30.\\nSee also inverse probability\\nBayes’ rule: abandonment of, 9–10, 11, 12, 37–38, 40, 61, 86–88, 176,\\n213\\nacceptance of, ix, xi, 3, 45–46, 107, 134–36, 161–62, 175, 181, 203, 216–\\n17, 221–22, 224–25, 232, 233–35, 250–51\\nBayes’ Factor, 116\\nBayesian inference, 129–30\\nbelief in, ix, xi, 8, 11, 233–34\\ncause-and-effect and, 5–6, 11\\ncomputation and, 134, 139–40, 159–61, 177–78, 195\\ndisagreement about, ix, x–xi, 3, 8–9, 35–38, 57, 105–6, 129–36, 176–78\\ndiscovery of, ix–x, 3, 6–10, 20–22, 23, 31–32, 129–30, 142, 143, 176\\nempirical Bayes, 129, 134\\nequal probabilities in, 8–9, 21, 22, 23, 36–37, 87\\nexperience in, ix, xi, 6–9, 11\\nfrequentism compared empirically, 157–58, 159–61\\ndata in, ix, xi, 6–9, 11, 23, 53–54, 156, 234\\ninstitutional support for, 134–35, 177, 178, 213–14, 220, 221–22, 224–25\\nintegration of functions in, 134\\ninverse probability in, 6–10, 11\\nlikelihood in, 8\\nname of, ix–x, 11, 12, 32, 36\\nobjectivity and, ix, x, 8, 11\\nas philosophy, 3, 97, 105–6, 116–17, 123, 147–48, 253–54\\nposteriors in, 8\\npractical applications for, generally, 139–40, 209\\npriors in, 8, 31–32, 87, 139\\nprobability in, 6–9, 11, 233–34\\npublications of, 9–11, 12, 20, 22, 93, 110\\nsecrecy about, 3, 42, 83–86, 168–69, 170–71, 173, 213, 224\\nstatements of, ix, 8, 11–12, 20, 23, 31–32, 41\\nsubjectivity and, ix, x, 8\\nterminology of, 8\\nuncertainty and, xi, 8\\nunified approach and, 170\\nvarieties of, 129:\\nbelief: in Bayes’rule, generally, ix, xi, 8,11, 233–34\\ninsurance and, 93\\nprobability and, 36, 51–52, 156, 233–34.\\nSee also intuition\\nsubjectivity\\nBell, E. T., 34\\nBell, Robert M., 243–44\\nBell, Laboratories, 40, 67, 76–77\\nBell, telephone systems, x, 40–42\\nBerger, James O., 56, 177, 178, 236\\nBarkely, George, 4\\nBerkson, Joseph, 112\\nBernardo, José M., 220\\nBernoulli, Jakob, 121\\nBerthollet, Claude, 30\\nBertillon, Alphonse, 38–39\\nBertrand, Joseph Louis François, 38, 73\\nBesag, Julian, 218 biology.\\nSee genetic science\\nmedicine\\nBirch, Frank, 66, 70\\nBirnbaum, Allan, 132\\nBlackwell, David, 88, 232\\nBletchley Park, 65–66, 71–72, 73–74, 82, 83–84.\\nSee also Enigma code\\nBlinder, Alan S., 237\\nblood pressure, 115–16\\nBlunt, Anthony, 85, 86\\nbombes, 65–67, 70–72, 74, 75–76, 80\\nBorel, Émile, 51–52, 67, 103\\nBouvard, Alexis, 32\\nBox, George E. P., 51, 130–34, 169, 176, 177\\nbrain, xi, 248–51\\nBretthorst, Larry, 227\\nBrezhnev, Leonid, 196–97\\nBrillinger, David R., 168, 170, 172, 173, 174\\nBrinkley, David, 163\\nBrown, Emery N., 248–49\\nBrown, Gordon, 86\\nBrown, Peter F., 237, 245–47\\nBrown, Tommy, 75\\nBuchanan, Chester L., 198, 201, 202\\nBucy, Richard, 205\\nBUGS, 226, 228, 229\\nBühlmann, Hans, 96\\nBurgess, Guy, 85, 86\\nbusiness, 140, 141–43, 145–53, 168, 176–77, 243–44.\\nSee also economics\\ninsurance\\nCampbell, George Ashley, 40\\ncancer, x, 108–9, 110–16, 227–28, 235, 255–57\\nCanton, John, 5\\ncapital punishment, 28\\nCasella, George, 224\\nCassels, Ian, 82\\ncasualty insurance, 3, 91–96\\ncause-and-effect, 5–6, 9, 10–11, 19–21, 35\\ncensus, 27, 173\\nCentral Intelligence Agency, 127, 135, 136\\ncentral limit theorem, 21, 30–31\\nChallenger, x, 103, 215\\nchange points, 216–17\\nChernoff, Herman, 177–78\\ncholesterol, x, 115–16\\nChomsky, Noam, 245\\nChrystal, George, 37–38\\nChurchill, Winston, 61, 71–72, 76, 83–84\\nClairaut, Alexis Claude, 14\\nClancy, Tom, 196\\nclassification problems, 155, 242–43\\nClayton, David, 221, 226\\nClippy, 243\\ncoal mines, 216–17\\nCochran, William, 146\\nCognitive Tutors, 247–48\\nCold War: cryptography and, 83–84\\nmilitary in, 215\\nnuclear weapons and, x, 3, 119–20, 124\\nTukey in, 164–66, 173–75\\nColeman, James, 146\\nColossi, 74, 80–82, 83–84\\ncommunications, x, 40–42, 76–77\\ncomputation: Bayes’ rule and, generally, 139–40, 177–78\\nbusiness and, 148–49\\ncomputers and, 177–78, 195, 199–200, 213–15, 219–26, 233, 234, 250–\\n51\\ndimensionality and, 213–15\\nfrequentism and, 214, 225\\nhierarchies and, 214–15\\nintegration of functions and, 134\\ncomputer languages, xi, 160\\ncomputers: as brains, 250–51\\nColossi, 74, 80–82, 83–84\\ncomputation and, 140, 177–78, 195, 199–200, 213–15, 219–26, 233, 234,\\n250–51\\ndevelopment of, 84–85, 99\\nThe Federalist papers and, 157, 159–60\\ndata and, 234, 242, 250–51\\nlanguages for, xi, 160\\nMarkov chains and, 221–26\\nin medicine, 135\\npriors and, 242, 243–44\\nby Radio Corporation of America, 163, 167, 172, 173\\nat RAND Corporation, 125\\nsearch and, 197, 199–200\\nsoftware for, 226, 228, 229, 242–45, 247–48\\nstatistics and, 167, 225\\nuncertainty and, 234\\ncomputer software, 226, 228, 229, 242–45, 247–48\\nCondorcet, Marquis de, 18, 23, 27, 29, 37\\nconjugate priors, 125, 148, 149\\nCook, James, 18\\nCoolidge, Julian L., 46\\nCopernicus, Nicolaus, 16\\nCornfield, Jerome: 108–118, 154, 166, 168, 174\\nCournot, Antoine-Augustin, 121\\nCox, Gertrude, 88\\nCraven, John Piña: 183–88, 191–203\\nCredibility, 44–45, 94–96\\nCromwell’s Rule, 123\\ncryptography, 73–74, 99–100, 135–36, 164–65, 173–75, 245.\\nSee also Enigma code\\nCurie, Marie, 51\\ncurse of high dimensionality, 214\\nDale, Andrew I., 8\\nd’Alembert, Jean Le Rond, 15–19\\nDarwin, Charles Galton, 85\\nDarwin, Leonard, 47\\ndata: in astronomy, 17–18, 19, 21\\nin Bayes’ rule, generally, ix, xi, 6–9, 11, 23, 53–54, 156, 234\\nbrains and, 248–50\\nbusiness and, 142, 147–48\\nin communications, 76–77\\ncomputers and, 234, 242, 250–51\\nelection results and, 171, 172, 173\\nfinance and, 237–38\\ngender and, 26\\ninsurance and, 93\\ninverse probability and, 36, 53–54\\nLaplace and, 17–18, 24\\nlikelihood principle and, 104, 132\\nin mathematics, 19\\nobjectivity and, 103\\nprobability and, 36, 50, 55–56\\nquantities of, 67, 77\\nsearch for, 246, 247\\nspeech recognition and, 246\\nin statistics, 49–50, 103, 167\\nsubjectivity and, 103\\ntelephone systems and, 39\\nDavid, Florence Nightingale, 34–35\\nDawid, A. Philip, 214, 239\\nde Buffon, Comte, 25\\ndecision theory, 57–58, 236–37\\ndecision trees, 148–49, 180\\nde Finetti, Bruno: influence of, 103, 148\\ninsurance and, 95–96\\nLindley on, 57\\nNobel Prize and, 236\\nprediction by, 178\\nprobability and, 233–34\\npublication by, 87, 220\\nsubjectivity and, 52, 58, 67–68\\nDeGroot, Morris H., 134, 220\\nDelambre, Jean-Baptiste, 29\\nDeming, W. Edwards, 110, 130, 176\\nde Moivre, Abraham, 6, 19\\nde Morgan, Augustus, 34\\nDempster, Arthur P., 221\\nDenniston, Alastair G., 70\\nDewey, Thomas, 154\\nDiaconis, Persi, 159, 161, 178, 219, 232, 240, 251\\ndictionary, 215, 225\\ndiesel engines, 215–16\\nDigital Sandbox, 241\\ndimensionality, 213–15\\nDiscenza, Joseph H., 204\\ndisease. See medicine\\nDNA. See genetic science\\nDodds, Harry W., 154\\nDoeblin, Wolfgang, 64\\nDoenitz, Karl, 69\\nDoll, Richard, 109, 111, 112\\nDreyfus, Alfred, x, 3, 38–39\\nDriscoll, Agnes Meyer, 75\\nDulles, John Foster, 154\\nDuMouchel, William H., 215–16\\nEarth, x, 54\\nearthquakes, x, 54–58, 164\\ne-commerce, xi, 243–44\\neconomics, 135, 236–38.\\nSee also business education, 4, 13–14, 158–59, 165–66, 247–48\\nEdwards, Ward, 133\\nEfron, Bradley, 178, 234\\nEisenhower, Dwight, 81, 119, 179\\nelections, x, 154, 163–64, 166–73, 174–75\\ne-mail, xi, 242–43, 244–45\\nempirical Bayes, 129, 134\\nEncyclopaedia Britannica, 34, 40\\nEncyclopédie, 15\\nEnigma code: Banburismus and, 66–72, 75, 80\\nBayes’ rule applied to, x, 3, 66–69, 73–74, 75–76\\nbombes and, 65–67, 70–72, 74, 75–76, 80\\nbreaking of, x, 3, 75, 80\\ncodebooks for, 70–71, 75\\ndevelopment of, 62–63\\nhypotheses and, 66–68, 75–76\\ninverse probability and, 68–69\\nmathematics and, 62, 63\\noperation of, 62, 70\\nprobability and, 66–67\\nafter Second World War, 83–84, 100–101\\nsubjectivity and, 67–68\\nTukey works on, 174\\nTuring works on, x, 3, 65–72, 74, 75–77\\nU-boats and, 61–62, 65–66, 69–70, 71, 74–75, 77, 80, 84.\\nSee also JN-25 code\\nTunny-Lorenz codes\\nepidemiology, 108–18, 215–16\\nequal probabilities: astronomy and, 36–37\\nin Bayes’ rule, generally, 8–9, 21, 22, 23, 36–37, 87\\ncryptography and, 99–100\\nThe Federalist papers and, 157, 161\\nFisher and, 48, 133–34\\ngender and, 25\\nmilitary and, 38, 73, 241\\nstatistics and, 50\\nEssen-Möller, Erik, 52–53\\nEstienne, Jean Baptiste Eugène, 39–40\\neugenics, 45–48\\nexperience, ix, xi, 5, 6–9, 11\\nexperimental design, 117\\nexpert opinion, 149–50, 179, 185–86\\nexploratory data analysis, 170\\nFasson, Anthony, 75\\nfederal government, 110–11.\\nSee also individual agencies\\nThe Federalist papers, 3, 155–58, 159–61, 243\\nFederal Reserve, 236–37\\nFeldstein, Martin, 236–37\\nFermi, Enrico, 102, 176, 222\\nFeynman, Richard, 102–3\\nfiducial probability, 132, 133, 170\\nFienberg, Stephen, 165, 168\\nfilters, xi, 205, 225, 240–41, 242–45, 248–49\\nfinance. See economics\\nFirst World War, 39–40, 62\\nFisher, Ronald Aylmer: cancer and, 112–13, 116\\nequal probabilities and, 133–34\\nfiducial probability and, 132, 133\\nfrequentism and, generally, 45, 46–48, 49–51, 53–54, 234\\nat Graduate School, 110\\non impossibility, 121\\ninfluence of, 87–88, 92, 94, 141, 147, 178\\nintuition and, 101\\nJeffreys and, 55–58\\nlikelihood principle of, 47, 53, 92, 233\\nLindley and, 133\\nNeyman and, 98–99\\nnuclear weapons and, 121\\npriors and, 129\\nSecond World War and, 64\\nTukey and, 169–70\\nfisheries, 209, 230–31\\nFleming, Ian, 70–71\\nFlowers, Thomas H., 81, 82\\nFood and Drug Administration, 228–29\\nforensic science, 235–36\\nFox, Robert, 35\\nFranco, Francisco, 190, 194\\nFrench Revolution, 29, 35–36\\nfrequentism: Bayes’ rule accepted in, 233–34\\nBayes’ rule compared empirically, 157–58, 159–61\\nbusiness and, 141, 142\\nchange points and, 216–17\\ncomputation and, 214, 225\\nCornfield and, 116–17\\ndecision theory and, 236\\ndimensionality and, 214\\nexpert opinion and, 179\\nThe Federalist papers and, 157–58, 159–61\\ngenetic science and, 47–48\\nhypotheses and, 116–17, 142, 217, 234\\nimage analysis and, 219\\ninsurance and, 92, 94\\nlikelihood principle and, 132, 233\\nLindley’s Paradox and, 132–33\\nmilitary and, 241\\nmovies and, 178\\nnuclear weapons and, 123\\nphilosophy and, 253–54\\npractical applications and, generally, 209\\npriors and, 104, 177\\nprobability and, 36, 50, 55–57, 99, 130, 142, 145–46, 156, 170\\nsocial science and, 217\\nstatistics and, 47–48, 87–88, 98–99, 104–5, 142, 214, 234, 253\\nStein’s Paradox and, 131–32\\nsubjectivity and, 104, 129\\nTukey and, 169–70\\nuncertainty and, 55–57, 142\\nunified approach and, 170\\nFriedman, Milton, 102, 159, 235\\nFuchs, Klaus, 85\\ngambling: astronomy and, 36\\nBayes’ rule and, 11\\nbeliefs and, 51–52\\ngame theory, 236\\nat Harvard Business School, 148\\nLaplace and, 19, 20, 21, 32\\nprobability and, 6, 9, 51–52\\nstatistics and, 106–7\\nsubjectivity and, 185\\ngame theory, 236.\\nSee also gambling\\nGastwirth, Joseph L., 227\\nGates, Bill, 242\\nGauss, C. F., 102\\nGelfand, Alan E., 220–22, 224–25\\nGeman, Donald, 218–19, 221\\nGeman, Stuart, 218–19, 221, 251\\ngender, x, 24–27\\ngenerating functions, 25\\ngenetic science, xi, 45–48, 225, 235–36, 238–40\\nGerrodette, Timothy, 230\\nGibbs, Josiah Willard, 219\\nGibbs sampling, 218–19, 221, 225–26\\nGilbert, Edgar N., 169\\nGillispie, Charles Coulston, 35\\nGini, Corrado, 52\\nGleason, Andrew, 83\\nGod: Bayes’ rule and, ix, 10, 11, 253–54\\ncause-and-effect and, 5–6\\nevil and, 4\\nexistence of, 177, 235\\nhappiness and, 4\\nnatural law and, 6, 30\\nprobability and, 19–20.\\nSee also religion\\nGoheen, Robert F., 165\\nGoldwater, Barry M., 172\\nGood, I. J. “Jack”: on Bayes’ rule’s varieties, 129\\nColossi computers and, 81\\ncryptography and, 68, 69, 74, 82, 83–84, 86, 99–100, 135, 173, 174\\ngenetic science and, 239\\non Markov chains, 222\\npriors and, 178\\npublication by, 99–101\\nat Royal Statistical Society, 87, 99\\nat Virginia Tech, 98, 176\\nGoodman, Joshua, 242\\nGoodman, Steven N., 56\\nGoogle, xi, 244–45, 247\\nGorry, Anthony, 135\\nGraham, Evarts A., 109\\nGrattan-Guinness, Ivor, 35\\nGraunt, John, 24\\ngravitation, 6, 14, 16–18, 21, 28, 56\\nGrazier, Colin, 75\\nGreen, Peter, 226–27\\nGreenspan, Alan, 236, 237\\nGregg, Walter, 122–23, 183\\nGrenander, Ulf, 218\\nGroves, Leslie R., 165\\nGuest, William S., 190–92, 193\\nHald, Anders, 48\\nHalley, Edmond, 14\\nHalley’s comet, 14\\nHamilton, Alexander, 155–58, 159–61\\nHammersley, John M., 223\\nHammond, E. Cuyler, 112\\nhappiness, 4\\nHarris, Jeffrey E., 215–16\\nHarris, Louis, 168\\nHarsanyi, John C., 236\\nHartley, David, 9\\nHarvard Business School, 140–43, 146–53, 156–57, 237\\nHarvard College, 158\\nHastings, W. Keith, 223\\nhealthcare. See medicine\\nheart attacks, x, 114–16\\nHeckerman, David E., 228, 242, 243\\nHemings, Sally, 235–36\\nhierarchies, 214–15\\nHilborn, Ray, 209\\nHill, Austin Bradford “Tony,” 109–10, 111, 112\\nHills, Susan E., 224\\nHiss, Alger, 85\\nHitler, Adolf, 61, 73, 81\\nHoff, Peter, 244\\nHoffenberg, Marvin, 110\\nHolmes, Susan, 178, 238–39\\nhomosexuality, 85–86\\nHorn, Daniel, 112\\nHorwitz, Eric, 242, 243\\nHoward, Ron, 228\\nHoward, W. M. “Jack,” 184\\nhuman immunodeficiency virus, 227\\nHume, David, 5–6, 10–11, 121\\nHung, Wing H., 220–21\\nHunt, Bobby R., 218\\nHunter, J. Stuart, 177\\nHunter, William G., 177\\nHuntley, Chet, 163, 172\\nHuntley-Brinkley Report, 163–64, 166–68, 171–73, 174–75\\nhydrogen bomb, 119–128, 182–95.\\nSee also nuclear weapons\\nhypotheses: astronomy and, 238\\nbusiness and, 145–46\\nCornfield and, 116–17\\ncryptography and, 66–68, 75–76, 83\\nearthquakes and, 55–57\\nfrequentism and, 116–17, 142, 217, 234\\nLindley’s Paradox and, 132–33\\nNeyman-Pearson theory for, 49\\nnuclear weapons and, 185–86, 195\\nsearch and, 185–86, 195, 197, 198–202, 204–5, 206–8\\nsocial science and, 217\\nsubmarines and, 197, 198–202, 206–8\\nU.S. Coast Guard and, 204–5\\nIBM, 245–7\\nIklé, Fred Charles, 120, 123, 126, 127\\nimage analysis, 217–19, 220–21, 227, 238, 240–41\\nimpossibility, 121\\ninsurance: casualty, 3, 91–96\\nprobability and, 8–9, 19\\nsubjectivity and, 44–45, 93\\nworkers’ compensation, x, 3, 42–45, 93, 131\\nintegration, 134\\nInternational Society for Bayesian Analysis, 135\\nInternet, 242–45\\nintuition, 33, 101, 150, 151, 241.\\nSee also belief\\nsubjectivity\\ninverse probability: astronomy and, 21, 32–33, 36–37\\nBayes’ rule and, generally, 6–10, 11\\nbeliefs and, 36\\ncancer and, 113–14\\ncause-and-effect and, 9\\ncentral limit theorem and, 30–31\\nearthquakes and, 54–58\\nEnigma code and, 68–69\\nFisher on, 48\\nimage analysis and, 218\\ndata and, 36, 53–54\\nLaplace and, 19–28, 30–33, 113–14\\nmilitary and, 38\\nobjectivity and, 36, 37\\noperations research and, 79\\nsubjectivity and, 36, 37\\nterminology of, 129–30\\nJahn, Robert G., 133\\nJames, Willard D., 131\\nJay, John, 155\\nJaynes, Edwin T., 176, 227\\nJefferson, Thomas, 235–36\\nJeffreys, Harold: computation and, 134\\nCornfield and, 116\\ndecision making and, 234\\nearthquakes and, 53–58\\ninfluence of, 103, 116, 147\\nLindley’s Paradox and, 132\\nobjectivity and, 178\\nphysical sciences and, 176\\npractical applications and, 145, 161\\npublication by, 87\\nSecond World War and, 64, 69, 79\\nJesus Christ, 177\\nJN-25 code, 82–83\\nJohnson, Lyndon B., 172, 188, 190, 193, 196\\nJohnson, Wesley O., 227\\nJordan, Michael I., 239\\njudicial systems, 27–28, 38–39, 52–53, 135, 136, 235–36\\nKahn, David, 99–100\\nKahneman, Daniel, 236\\nKalman, Rudolf E., 205\\nKalman filters, 205, 225, 240–41, 248–49.\\nAlso called Kalman-Bucy filters.\\nKass, Robert E., 105, 234\\nKeen, Harold “Doc,” 65\\nKemble, Edwin, 141\\nKempthorne, Oscar, 88\\nKennedy, John F., 127, 163, 168, 218\\nKepler, Johannes, 16\\nKeynes, John Maynard, 37, 46, 235\\nKimball, George E., 78\\nKing, Ernest, 78\\nKinsey, Alfred C., 154\\nKinsey Report, 117, 154–55, 166–67\\nKnox, Dillwyn, 65\\nKoller, Daphne, 239–40\\nKolmogorov, Andrei, x, 72–73, 76, 77, 80, 101, 121\\nKoopman, Bernard O., 78–80, 184, 187, 188, 204\\nKoren, Yehuda, 243–44\\nKruskal, William, 46, 106\\nKuhn, Thomas, 225\\nLaird, Nan, 221\\nLalande, Joseph, 14\\nlanguage, 245–47\\nLaplace, Marie Anne, 28–29, 30\\nLaplace, Pierre Simon: astronomy and, 14, 16–18, 19, 21, 28, 32–33,\\n36–37\\nBailey uses, 93\\nBayes’ rule discovered by, ix–x, 3, 20–22, 23, 31–32, 129–30, 176\\nbiographical details on, 13–14, 15–16, 22–23, 28–30, 33\\ncentral limit theorem and, 21, 30–31\\ncriticism of, 34–38\\nfrequency methods and, 31, 156\\ngambling and, 19, 20, 21\\ngender and, 24–27\\ndata and, 17–18, 24\\nintuition of, 33\\ninverse probability and, 19–28, 30–33, 113–14\\nmathe matics and, 14, 15, 16, 18–24, 33\\nreligion and, 13–14, 14–15, 19–20, 30, 36\\nRoyal Academy of Sciences and, 16, 18, 21, 22–23, 29\\nstatistics and, 35\\nLavoisier, Antoine, 29\\nlaw. See judicial systems\\nLawrence, Charles E., 225\\nLeahy, F. T., 135–36\\nlearning, 247–48, 249–50. See also education\\nLedley, Robert S., 135\\nLeibniz, Gottfried, 14\\nLeMay, Curtis E., 119, 127, 182\\nLepaute, Nicole-Reine, 14\\nlikelihood, xi, 8, 104, 132, 222, 233.\\nLindberg, Jon, 192\\nLindley, Dennis: administration by, 176\\non Bayes’ rule, generally, 88, 232\\ncomputation and, 134, 214–15, 219–20\\nCornfield and, 116\\nDiaconis and, 178\\nforensic science and, 235\\nhierarchies and, 214–15\\non information, 249–50\\nJeffreys and, 55, 57, 58\\non Laplace, 130\\nLindley’s Paradox, 132–33\\non Markov chains, 223\\nmathematics and, 148\\nMosteller and, 178\\npractical applications and, 139, 156, 178\\non priors, 123\\nprobability and, 55, 233–34\\npublication by, 99, 101, 103–4, 107\\nat Royal Statistical Society, 99, 107\\non Schlaifer, 152\\nLindley’s Paradox, 132–33\\nLindman, Harold, 133\\nLink, Richard F., 168, 172, 174\\nLiu, Jun S., 225\\nLoane, Ed P., 187–88\\nlocal effectiveness probability, 191–92, 195, 197, 203–4\\nLongley-Cook, L. H., 94–95\\nLoredo, Tom, 238\\nLorenz machines, 73–74, 75, 84\\nLos Alamos National Laboratory, 218\\nLouis XVIII, 33\\nLSD, 126–27\\nLudlum, Robert, 235\\nLusted, Lee B., 135\\nMaclean, Donald, 85, 86\\nMadansky, Albert, 120–28, 149, 176\\nMadison, James, 155–58, 159–61\\nMahon, Patrick, 68\\nmammograms, 255–57\\nMarie, Maximilien, 34\\nMarkov, Andrei Andreyevich, 222\\nMarkov chains, 149, 151, 221–26, 246\\nMarkowitz, Harry, 236\\nmathematics: astronomy and, 14, 16–18, 19\\nbusiness and, 142–43, 148–49, 151\\nEnigma code and, 62, 63\\nThe Federalist papers and, 157–58\\nLaplace, and, 14\\nLaplace and, 14, 15, 16, 18–24, 33\\nmilitary and, 97, 119\\nnuclear weapons and, 186–92, 193\\nprobability and, 23–24, 33, 72\\nreason and, 4\\nreligion and, 4, 5–6, 11\\nscience and, 167\\nsearch and, 186–92, 193, 201\\nSecond World War and, 63–64\\nstatistics and, 97–98, 101, 103–6, 130, 157–58, 167, 214\\nsubmarines and, 201\\nMauchly, John, 168\\nMaxwell, James Clerk, 37\\nMayer, Maria Goeppert, 222\\nMayerson, Allen L., 95\\nMcCarthy, Joseph, 85, 87\\nMcCullagh, Peter, 169\\nMCMC, 224–6, 232.\\nSee also Markov chains\\nMonte Carlo simulation\\nMcNamara, Robert, 194\\nmeans, 130–32\\nmedical devices, 228–29\\nmedicine: cancer, x, 108–9, 110–14, 215–16, 227–28, 235, 255–57\\ndiagnosis in, 135, 226–29, 255–57\\nheart attacks, x, 114–16\\nstrokes, 226–27, 244\\ntreatment in, 116, 235\\nX-rays, 53\\nMercer, Robert L., 237–38, 245–47\\nMeshenberg, M. P., 101\\nmeta-analysis, 215–16\\nmetric system, 29\\nMetropolis, Nicholas, 222–23, 224\\nMichie, Donald, 81, 82\\nMicrosoft, 242–43\\nmilitary: asteroids and, 209\\nin Cold War, generally, 164–65, 173–75, 215\\nequal probabilities and, 38, 73\\nof France, 29, 38–40\\nimage analysis and, 240, 241\\ninverse probability and, 38\\nmathematics and, 97\\nnuclear weapons and, 119–28, 182–95\\nrobotics and, 240\\nof Russia, 72–73\\nsatellites and, 209\\nstatistics and, 97\\nsubmarines and, 194–203, 206–8\\ntranslation and, 247\\nweapons systems and, 241.\\nSee also Second World War\\nMill, John Stuart, 36, 52\\nMilner-Barry, P. Stuart, 71–72\\nmines, coal, 216–17\\nminesweeping, 184\\nmodeling: averaging and, 244\\nBUGS and, 226\\nimaging and, 218, 221\\nNetflix and, 243–44\\ncomparing and, 226–27,\\nrevolution in, 233–34\\nafter 1998, 225\\nsociology and, 216–17\\nMolina, Edward C., 40–42, 76, 93, 110\\nMontagu, Elizabeth, 5\\nMonte Carlo simulation, 199–200, 202, 205, 218–19, 221–22, 225–26\\nMooney, J. Brad, 192–93\\nMorgenstern, Oskar, 144\\nMorse, Philip M., 78\\nMorton, Keith W., 223\\nMosteller, Frederick, 146, 154–62, 171, 176, 177, 178, 243\\nmovies, 149–50, 178, 243–44\\nMoynihan, Daniel Patrick, 159, 162\\nmultivariate revolution, 213–14\\nMurdoch, Patrick, 5\\nnaïve Bayes, 244\\nNapoleon Bonaparte, 27, 30\\nNash, John, 236\\nNational Aeronautics and Space Administration, 215\\nNational Broadcasting Corporation, 163–64, 166–68, 171–73, 174–75\\nNational Institutes of Health, 110–11, 117\\nNational Security Agency, 135–36, 164–65, 173–74\\nnatural law, x, 6, 30\\nNeiman, Fraser D., 236\\nNetflix, 243–44\\nnetworks, 228, 239, 242, 245, 248\\nneuroscience, 248–50\\nNewman, Max, 81, 84, 85\\nNewton, Isaac, 4, 6, 14, 16–18, 56\\nNeyman, Jerzy: cancer and, 112\\nempirical Bayes and, 134\\nFisher and, 98–99\\nfrequentism and, generally, 49–51, 234\\nat Graduate School, 110\\ninfluence of, generally, 83, 87, 92, 96, 141, 178\\nLindley and, 133\\npractical applications and, generally, 145\\npriors and, 129\\nSecond World War and, 64\\nTukey and, 170\\nat UC Berkeley, 98–99, 107, 177\\nNicholson, John, 206, 207–8\\nNightingale, Florence, 35\\nNixon, Richard M., 163, 168, 235\\nNobel Prize, 236\\nNollet, Jean Antoine, 15\\nNorvig, Peter, 244\\nNovak, Kim, 114\\nnuclear energy, x, 3, 117, 178–81\\nnuclear weapons: development of, 85\\nearthquakes and, 164\\nexpert opinion and, 185–86\\nhypotheses and, 185–86, 195\\nimage analysis and, 218\\nlocation of, x, 3, 182–95\\nMarkov chains and, 222\\nmathematics and, 186–92, 193\\noperations research and, 186–92\\nPalomares accident, 182–95\\npriors and, 186, 187–88, 195\\nprobability and, 121–22, 185–86, 187–88, 191–92, 193, 195\\nsafety of, 119–28, 182–83, 189–90, 194–95\\nsubjectivity and, 185–86, 195\\nThule accident, 194\\nobjectivity: Bayes’ rule and, generally, ix, x, 8, 11\\ninformation and, 103\\ninverse probability and, 36, 37\\npriors and, 103, 178\\nprobability and, 36, 37, 106\\nstatistics and, 103, 106.\\nSee also subjectivity\\noil drilling, 149, 209\\nOperation Chrome Dome, 182–83, 194–95\\noperations research, 77–80, 119–20, 141, 186–92\\nopinion polls, 154–55, 163–64, 166–67, 171\\nOrear, Jay, 102\\nOrts, Francisco Simo, 186, 192–93, 194\\nPalomares accident, 182–95\\npaternity law, 52–53\\nPearl, Judea, 228, 239\\nPearson, Egon: empirical Bayes and, 134\\nfrequentism and, generally, 48–49, 234\\ninfluence of, 130, 141, 147, 178\\npractical applications and, 139, 145\\nTukey and, 170\\nPearson, Karl, 35, 45–46, 48–49, 132\\nPeirce, Charles Sanders, 37\\npharmaceuticals, 229\\nphilosophy: Bayes’ rule as, 3, 97, 105–6, 116–17, 123, 147–48, 253–54\\nfrequentism and, 253–54\\nphysical sciences, 102–3, 176, 214, 222–23, 238.\\nSee also astronomy\\nearthquakes\\nPierce, John R., 174\\nPoincaré, Henri, 39, 40\\nPoisson distribution, 42\\npopulation, 27\\nposteriors: in Bayes’ rule, 8\\nin communications, 77\\nconjugate priors and, 149\\nfiducial probability and, 133\\nin heart disease study, 115\\nlocation and, 203–4\\nnuclear weapons and, 125\\npractical applications: for Bayes’ rule , generally, 139–40, 209, 232\\nin business, 91–96, 139–53, 176–77\\ncomputation and, 177–78\\nfrequentism and, 209\\nLindley and, 178\\nNeyman and, 145\\nSavage and, 150\\nsocial science and, 156–57, 161\\nTukey and, 167\\nPratt, John W., 139, 147, 149–50, 151, 153, 165, 168, 178\\nPratt, Joy, 149–50\\npredictions, x, 154, 163–64, 166–73, 174–75\\nPrice, Richard, ix, 9, 10–11, 23, 32, 94, 23, 121\\nPrinceton University, 164–65\\npriors: in Bayes’ rule , generally, 8, 31–32, 87, 139\\nbusiness and, 142, 149\\nin communications, 77\\ncomputers and, 242, 243–44\\nconjugate priors, 125, 148, 149\\nin credibility theory, 96\\ncryptography and, 74, 83, 99–100\\nearthquakes and, 55\\ne-commerce and, 243–44\\nelection results and, 168–69, 171\\nThe Federalist papers and, 160–61\\nfiducial probability and, 132\\nfinance and, 237–38\\nFisher on, 48\\nfrequentism and, 104, 177\\ngenetic science and, 239\\nin heart disease study, 115\\nimage analysis and, 240\\nin insurance, 92, 93, 94–95\\nmeans and, 131\\nnuclear weapons and, 121–26, 186, 187–88, 195\\nobjectivity and, 103, 178\\noperations research and, 79\\nPearson , Egon, uses, 49\\npharmaceuticals and, 229\\nprobability and, 132\\nsearch and, 186, 187–88, 195, 197, 198–202, 203–4, 204–5, 206–8\\nstatistics and, 50, 92, 103, 117, 131\\nsubjectivity and, 129, 178\\nsubmarines and, 197, 198–202, 206–8\\nTukey and, 168–69\\nU.S. Coast Guard and, 204–5.\\nprobability: astronomy and, 19\\nin Bayes’ rule , generally, 6–9, 11, 233–34\\nbeliefs and, 36, 51–52, 156, 233–34\\nbrains and, 249–50\\nbusiness and, 142, 145–46\\nof cancer, 255–57\\ncause-and-effect and, 6, 19–21\\ncryptography and, 66–67, 82–83\\nThe Federalist papers and, 157–58, 159–61\\nfiducial probability, 132, 133, 170\\nfrequentism and, 36, 50, 55–57, 99, 130, 142, 145–46, 156, 170\\ngambling and, 6, 9, 51–52\\nGod and, 19–20\\nin heart disease study, 115–16\\nimage analysis and, 240\\nimpossibility and, 121\\ninformation and, 36, 50, 55–56\\ninsurance and, 8–9, 19\\nKolmogorov and, 72, 101\\nlocation and, 185–86, 187–88, 191–92, 193, 195, 197, 198–202, 203–4,\\n204–5, 206–8\\nmathematics and, 23–24, 33, 72\\nnuclear energy and, 180\\nnuclear weapons and, 121–28, 185–86, 187–88, 191–92, 193, 195\\nobjectivity and, 36, 37, 106\\noperations research and, 79\\npriors and, 132\\nrobotics and, 240\\nsocial sciences and, 64\\nstatistics and, 35, 49–51, 64, 99, 104–5, 106\\nsubjectivity and, 36, 37, 50, 51–52, 103, 104–5, 106, 145\\nsubmarines and, 197, 198–202, 206–8\\ntelephone systems and, 41\\nterminology of, xi\\nuncertainty and, 19, 26, 52, 55–57, 242\\nU.S. Coast Guard and, 204–5\\nutility and, 103.\\nSee also equal probabilities\\ninverse probability\\nlikelihood\\nprobability of causes.\\nSee inverse probability\\nprostheses, 249\\npsychokinetic power, 133\\npsychologists/psychology, 57, 107, 126, 155, 168, 225, 236\\npublic health, 215–17\\np-values, 55–56, 133, 217\\nquantum mechanics, 57\\nQuetelet, Adolphe, 37\\nRacine-Poon, Amy, 224\\nRadio Corporation of America, 163, 167, 172, 173\\nRaftery, Adrian, 216–17, 231\\nRaiffa, Howard: biographical details on, 140, 143–44\\nbusiness and, 144–53, 168\\nconjugate priors and, 125, 148, 149\\nCraven and, 184–85\\ndecision trees of, 140, 148–49, 180\\npractical applications and, 156, 157, 161\\nin public policy, 176–77\\nRainich, G. Y., 102\\nRamsey, Frank P., 52, 58, 67, 87, 103, 147, 148, 233–34\\nRAND Corporation, 3, 88, 119–28, 194\\nrandomization, 109\\nRapp, Elizabeth R., 166, 169\\nRasmussen, Norman Carl, 179–80\\nreason, 4, 35–36\\nReber, Rufus K., 184, 191\\nReed, Lowell J., 53\\nRejewski, Marián, 62\\nreligion: Bayes and, 3–5\\nLaplace and, 13–14, 14–15, 19–20, 30, 36\\nmathematics and, 4, 5–6, 11\\nscience and, 30\\nstatistics and, 253–54.\\nSee also God\\nRenaissance Technologies, 237–38\\nRichardson, Henry R., 187–92, 194, 195, 197–209\\nRobbins, Herbert, 134\\nRobert, Christian P., 224\\nrobotics, 240–41, 249\\nRommel, Erwin, 81\\nRoosevelt, Franklin D., 76\\nRosenberg, Ethel and Julius, 85\\nRosenberg, James A., 201, 203\\nRosenbluth, Arianna and Marshall, 223\\nRounthwaite, Robert, 242\\nRoyal Academy of Sciences, 15, 16, 18, 21, 22–23, 29\\nRoyal Society, 4, 5, 9, 10–11, 50, 56–57\\nRoyal Statistical Society, 87, 99, 107, 232\\nRubinow, Isaac M., 43\\nsafety: of coal mines, 216–17\\nof nuclear energy, x, 3, 117, 178–81\\nof nuclear weapons, 119–28, 182–83, 189–90, 194–95\\nof space shuttles, x, 103, 215\\nsatellites, 209\\nSaunderson, Nicholas, 9\\nSavage, Leonard Jimmie: on Birnbaum, 132\\ndeath of, 176\\nde Finetti and, 95–96\\neconomics and, 135\\nepidemiology and, 116, 117\\non fiducial probability, 132\\non Fisher, 46\\ninfluence of, 147, 148\\nLindley’s Paradox and, 133\\nmathematics and, 148\\nMosteller and, 159\\nnuclear weapons and, 119–20\\npractical applications and, 139, 150, 156, 157, 161\\nprobability and, 233–34\\npublication by, 99, 101–7\\non Schlaifer, 142, 148\\nsubjectivity and, 169, 173, 178\\nTukey and, 169\\nat University of Chicago, 156\\nSavage, Richard, 102\\nSchlaifer, Robert: biographical details on, 140–41\\nbusiness and, 141–43, 144, 145, 146–53, 168, 171\\ncomputers and, 177\\nconjugate priors and, 125, 148\\npractical applications and, 156, 157, 161\\nSchleifer, Arthur, Jr., 140, 147\\nSchneider, Stephen H., 235\\nSchrödinger, Erwin, 105\\nSchwartz, Andrew B., 249\\nscience, 30, 167.\\nSee also individual fields of\\nScott, George C., 127\\nsearch: computers and, 195, 197, 199–200, 204\\nexpert opinion and, 185–86\\nhypotheses and, 185–86, 193, 195, 197, 198\\nmathematicians and, 186–9, 201\\nof minesweeping, 184\\nof Monte Carlo, 199–200, 205\\nof nuclear weapons, x, 3, 182–95\\nfor oil drilling, 149, 209\\noperations research and, 186–92\\npriors and, 186, 187–88, 195, 197, 198–202, 203–4, 204–5, 206–8\\nprobability and, 185–86, 187–88, 191–92, 193, 195, 197, 198–202, 203–\\n4, 204–5, 206–8\\nof satellites, 209\\nsubjectivity and, 185–86, 195, 204–5, 206–8\\nof submarines, x, 3, 182, 196–203, 206–8\\nsubmarines for, 193, 194\\nof Suez explosives, 203–4\\nof U-boats, 77–80\\nuncertainty and, 198, 201, 206–8\\nby U.S. Coast Guard, 182, 204–6\\nsearch effectiveness probability (SEP), 191–92, 195, 197, 203–4\\nSearle, William F., Jr., 184\\nSecond World War: battles of, 61, 69, 71, 72, 74–75, 77, 80, 81\\nBayes’ rule applied during, x, 3, 66–69, 73–74, 75–77, 77–80, 82–86, 215\\ncommunications during, 76–77\\ncomputers during, 74, 80–82, 83–84\\nmathematics and, 63–64\\noperations research during, 77–80\\nRaiffa during, 143\\nSchlaifer during, 141\\nstatistics and, 63–64\\nU-boats in, 61–62, 65–66, 69–70, 71, 74–75, 77–80, 84, 141.\\nSee also Enigma code\\nSeptember 11, 2001, terrorist attacks, 241\\nsequential analysis, 67, 69, 144\\nsexuality, 85–86, 117, 154–55, 166–67\\nShafer, Glenn, 32, 129, 219\\nShannon, Claude, x, 67, 76–77, 174, 235, 245\\nshipwrecks, xi\\nSigSaly voice scrambler, 76\\nSilver, Nate, 175\\nSimon, Leroy J., 95\\nSimpson, Edward H., 82\\nSimpson, Steven G., 201\\nSmith, Adrian F. M., 214, 219–22, 224–25, 232\\nsmoking, x, 108–9, 110–14, 115–16\\nSmyth, Henry, 165\\nSocial Science Research Council, 154\\nsocial sciences: frequentism and, 57, 217;\\nLaplace and, 32\\npractical applications for, 156–57, 161, 167\\nprobability and, 64\\nstatistics and, 154–55.\\nSee also economics\\njudicial systems, psychology\\nspace shuttles, x, 103, 215\\nspeech recognition, 245–47\\nSpiegelhalter, David J., 105, 226, 228, 229\\nspying, 84–6.\\nSee also cryptography\\nStanhope, Philip, second earl of, 5, 6, 9\\nstatistical sampling, 222\\nstatistics: American Statistical Association, 117, 135\\ncause-and-effect and, 35\\nclassification problems in, 155\\ncomputers and, 167, 225\\ndepartments of, 97–98, 103, 106, 107, 130, 146, 158, 176, 177, 214\\nearthquakes and, 54–58\\nequal probabilities and, 50\\nfederal government uses, 110–11\\nThe Federalist papers and, 155–58, 159–61\\nfrequentism and, 47–48, 87–88, 98–99, 104–5, 142, 214, 234, 253\\ngambling and, 106–7\\ngenetic science and, 45–48\\ninformation in, 49–50, 103, 167\\nLaplace and, 35\\nmathematics and, 97–99, 101, 103–6, 130, 157–58, 167, 214\\nmeans and, 130–32\\nmilitary and, 97, 119\\nnuclear weapons and, 123–24\\nobjectivity and, 103, 106\\nopinion polls and, 166–67\\npriors and, 50, 92, 103, 117, 131\\nprobability and, 35, 49–51, 64, 99, 104–5, 106\\nreligion and, 253–54\\nscience and, 130\\nSecond World War and, 63–64\\nsocial science and, 154–55\\nsubjectivity and, 50, 103, 104–5, 106, 220\\ntelephone systems and, 39\\nStein, Charles, 44, 130–31, 177\\nStein’s Paradox, 130–32\\nStigler, Stephen M., 9, 34\\nStone, Lawrence D., 198–99, 200, 201, 202, 203, 204–5, 207, 209\\nStrategic Air Command, 119–20, 123, 124–25, 125–26, 126–27, 182–\\n83, 194–95\\nstrokes, 226–27, 244\\nsubjectivity: Bayes’ rule and, generally, ix, x, 8\\nbelief and, 51–52\\nbusiness and, 142, 145–46, 150, 151\\nEnigma code and, 67–68\\nfrequentism and, 104, 129\\ngambling and, 185\\ninformation and, 103\\ninsurance and, 44–45, 93\\ninverse probability and, 36, 37\\nlocation and, 185–86, 195, 204–5, 206–8\\nnuclear energy and, 180\\nnuclear weapons and, 185–86, 195\\npriors and, 129, 178\\nprobability and, 36, 37, 50, 51–52, 103, 104–5, 106, 145\\nRaiffa and, 144–45\\nreason and, 35–36\\nstatistics and, 50, 103, 104–5, 106, 220\\nsubmarines and, 206–8\\nTukey and, 169, 173\\nU.S. Coast Guard and, 204–5\\nutility and, 103.\\nSee also belief\\nintuition\\nsubmarines: for location, 193, 194\\nlocation of, x, 3, 182, 196–203, 206–8\\nsilencing, 141.\\nSee also U-boats\\nSuez Canal, 203–4\\nSulzberger, Arthur, 154\\nsupernova 1987A, 238\\nSwinburne, Richard, 177\\nSwirles, Bertha, 54\\nTanner, Martin A., 220–21\\nTanur, Judith, 174\\nTaylor, Barbara L., 230\\nTeledyne Energy Systems, 215\\ntelephone systems, x, 40–42\\nTeller, Augusta, 223\\nTeller, Edward, 165, 223\\nterminology, xi, 8, 129–30\\nterrorism, 241–42, 247\\nthinking, 248–51.\\nSee also learning\\nThree Mile Island, 180–81\\nThrun, Sebastian, 240\\nThule accident, 194\\nTierney, Luke, 224\\ntranslation, 245–47\\nTravis, Robert F., 122\\ntree-flipping, 149\\nTribe, Laurence H., 136\\nTruman, Harry, 154\\nTukey, John W., 77, 159, 163–75, 176, 177, 233\\nTunny-Lorenz codes, 73–74, 75, 84\\nTurchin, Valentin Fedorovich, 219\\nTuring, Alan M.: biographical details on, 64–65\\ncomputers and, 80–82, 84–85, 99\\nempirical Bayes and, 134\\nEnigma code and, x, 3, 65–72, 74, 75–76\\nforensic science and, 235\\ngenetic science and, 239\\nJN-25 code and, 82\\nafter Second World War, 83–86, 99\\nTunny-Lorenz codes and, 74, 75\\nTutte, William T., 74\\nTversky, Amos, 236\\nTwinn, Peter, 66, 70, 71\\nU-boats: battles with, 61, 69, 74–75, 77, 80, 141\\nEnigma code and, 61–62, 65–66, 69–70, 71, 77, 80, 84\\nlocation of, 77–80\\nUlam, Stanislaw, 165\\nuncertainty: Bayes’ rule and, generally, xi, 8\\nbeliefs and, 52\\nbrains and, 248–50\\nbusiness and, 142, 145–46, 150\\ncomputers and, 234\\nepidemiology and, 116–17\\nfrequentism and, 55–57, 142\\ngender and, 26\\nlocation and, 201, 206–8\\nmilitary and, 119\\nnuclear energy and, 180\\noperations research and, 79\\nprobability and, 19, 26, 52, 55–57, 242\\nsubmarines and, 201, 206–8\\ntelephone systems and, 40–42\\nunified approach, 170\\nUnwin, Stephen D., 235\\nupdating: Bayes and, 8, 11\\nBayesian networks and, 228\\nCIA and, 136\\nDreyfus and, 39\\nelections and, 171\\ninsurance and, 92, 95\\nLaplace and, 33\\nnavy and, 80, 192, 195, 201–2\\nNetflix and, 244\\nRAND and 124\\nWall Street and, 237\\nU.S. Air Force, 215.\\nSee also Strategic Air Command\\nU.S. Census Bureau, 173\\nU.S. Coast Guard, 182, 204–6\\nU.S. Navy, 182–95, 196–203, 206–8\\nU.S.S. Scorpion, 197–203\\nutility, 103\\nVan Dusen, Henry P., 154\\nvision, 248, 250\\nVolinsky, Christopher T., 243–44\\nVoltaire, 15\\nvon Humboldt, Alexander, 26–27\\nvon Mises, Hilda, 144\\nvon Mises, Richard, 94\\nvon Neumann, John, 84, 125, 144, 167, 222\\nvoting, 27, 117, 175\\nWaddington, Conrad H., 78\\nWade, Paul R., 231\\nWagner, Daniel H., 186–88\\nWald, Abraham, 69, 144\\nWallace, David: computation and, 134\\non cryptography, 173\\nelection results and, 168–69\\ne-mail filters and, 243\\nThe Federalist papers and, 156–58, 159–61\\nTukey and, 170–72, 174–75\\nWallis, Allen, 103\\nWarner, Homer, 135\\nweapons systems, 240.\\nSee also nuclear weapons\\nWeaver, Warren, 245\\nWelchman, Gordon, 65, 70, 71, 74\\nwhales, 230–31\\nWheeler, John A., 165\\nWhitney, Albert Wurts, 43–45, 93, 131\\nWhitworth, Jimmy, 82\\nWilliams, Frederick, 155–56\\nWilson, Matthew A., 248\\nWohlstetter, Albert, 123\\nWolpert, Daniel, 250\\nwomen, 29, 41, 68, 71, 158–59\\nworkers’ compensation insurance, x, 3, 42–45, 93, 131\\nWorld Wars. See First World War\\nSecond World War\\nWynder, Ernst L., 109, 111\\nX-rays, 53\\nYoutz, Cleo, 159, 160\\nZeh, Judith, 230–31\\nZellner, Arnold, 134–35\\nZola, Émile, 39\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')]\n"
     ]
    }
   ],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced RAG (Routing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(docs)\n",
    "query_engine = index.as_query_engine(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "# Define the GetSources function\n",
    "def GetSources(response):\n",
    "    sources = []\n",
    "    for node in response.source_nodes:\n",
    "        # Access the TextNode object directly\n",
    "        text_node = node.node\n",
    "\n",
    "        # Assuming metadata is stored within the TextNode's metadata\n",
    "        source = text_node.metadata.get('file_name')  # Access metadata using .metadata.get()\n",
    "        page = text_node.metadata.get('page_label')   # Access metadata using .metadata.get()\n",
    "\n",
    "        sources.append(f\"Source: {source[:30]}..., Page: {page}\")\n",
    "    return \"\\n\".join(sources)\n",
    "\n",
    "# Create a custom query engine tool with citation inclusion\n",
    "class CitationQueryEngineTool(QueryEngineTool):\n",
    "    def query(self, query):\n",
    "        response = super().query(query)\n",
    "        sources = GetSources(response)\n",
    "        return f\"{response}\\n\\nCitations:\\n{sources}\"\n",
    "\n",
    "# Create tools with citation support\n",
    "vector_tool = CitationQueryEngineTool(\n",
    "    index.as_query_engine(),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"vector_search\",\n",
    "        description=\"Useful for searching for specific facts with citations.\",\n",
    "    ),\n",
    ")\n",
    "summary_tool = CitationQueryEngineTool(\n",
    "    index.as_query_engine(response_mode=\"tree_summarize\"),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"summary\",\n",
    "        description=\"Useful for summarizing an entire document with citations.\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "    \n",
    "# vector_tool = QueryEngineTool(\n",
    "#     index.as_query_engine(),\n",
    "#     metadata=ToolMetadata(\n",
    "#         name=\"vector_search\",\n",
    "#         description=\"Useful for searching for specific facts.\",\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# summary_tool = QueryEngineTool(\n",
    "#     index.as_query_engine(response_mode=\"tree_summarize\"),\n",
    "#     metadata=ToolMetadata(\n",
    "#         name=\"summary\",\n",
    "#         description=\"Useful for summarizing an entire document.\",\n",
    "#     ),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "\n",
    "query_engine = RouterQueryEngine.from_defaults(\n",
    "    [vector_tool, summary_tool], select_multi=False, verbose=True, llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: The question requests a comprehensive overview of the evolution and application of Bayesian probability. Choice (2) is most relevant as it pertains to summarizing an entire document which likely contains historical context, theoretical development, practical applications including wartime intelligence use..\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpx/_transports/default.py:72\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    125\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {socket\u001b[38;5;241m.\u001b[39mtimeout: ReadTimeout, \u001b[38;5;167;01mOSError\u001b[39;00m: ReadError}\n\u001b[0;32m--> 126\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettimeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mquery_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProvide a comprehensive overview of how Bayesian probability evolved from\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m a theoretical concept to a critical wartime intelligence tool\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/base/base_query_engine.py:52\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     51\u001b[0m         str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 52\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m     54\u001b[0m     QueryEndEvent(query\u001b[38;5;241m=\u001b[39mstr_or_query_bundle, response\u001b[38;5;241m=\u001b[39mquery_result)\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/query_engine/router_query_engine.py:194\u001b[0m, in \u001b[0;36mRouterQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to select query engine\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m     final_response \u001b[38;5;241m=\u001b[39m \u001b[43mselected_query_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# add selected result\u001b[39;00m\n\u001b[1;32m    197\u001b[0m final_response\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m final_response\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/base/base_query_engine.py:52\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     51\u001b[0m         str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 52\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m     54\u001b[0m     QueryEndEvent(query\u001b[38;5;241m=\u001b[39mstr_or_query_bundle, response\u001b[38;5;241m=\u001b[39mquery_result)\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/query_engine/retriever_query_engine.py:179\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    176\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mQUERY, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str}\n\u001b[1;32m    177\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[1;32m    178\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve(query_bundle)\n\u001b[0;32m--> 179\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_response_synthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_bundle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     query_event\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: response})\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/response_synthesizers/base.py:241\u001b[0m, in \u001b[0;36mBaseSynthesizer.synthesize\u001b[0;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m     query \u001b[38;5;241m=\u001b[39m QueryBundle(query_str\u001b[38;5;241m=\u001b[39mquery)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    238\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mSYNTHESIZE,\n\u001b[1;32m    239\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[1;32m    240\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[0;32m--> 241\u001b[0m     response_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMetadataMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     additional_source_nodes \u001b[38;5;241m=\u001b[39m additional_source_nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    250\u001b[0m     source_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(nodes) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(additional_source_nodes)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/response_synthesizers/tree_summarize.py:162\u001b[0m, in \u001b[0;36mTreeSummarize.get_response\u001b[0;34m(self, query_str, text_chunks, **response_kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[43msummary_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_chunks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mstructured_predict(\n\u001b[1;32m    169\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_cls,\n\u001b[1;32m    170\u001b[0m             summary_template,\n\u001b[1;32m    171\u001b[0m             context_str\u001b[38;5;241m=\u001b[39mtext_chunks[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    172\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs,\n\u001b[1;32m    173\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/llms/llm.py:596\u001b[0m, in \u001b[0;36mLLM.predict\u001b[0;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mis_chat_model:\n\u001b[1;32m    595\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_messages(prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args)\n\u001b[0;32m--> 596\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m     output \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/core/llms/callbacks.py:173\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m    165\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    166\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m     },\n\u001b[1;32m    171\u001b[0m )\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    175\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[1;32m    176\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    177\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[1;32m    178\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[1;32m    179\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/llama_index/llms/ollama/base.py:286\u001b[0m, in \u001b[0;36mOllama.chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m ollama_messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_ollama_messages(messages)\n\u001b[1;32m    284\u001b[0m tools \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 286\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mollama_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(response)\n\u001b[1;32m    298\u001b[0m tool_calls \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/ollama/_client.py:331\u001b[0m, in \u001b[0;36mClient.chat\u001b[0;34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat\u001b[39m(\n\u001b[1;32m    287\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    288\u001b[0m   model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    296\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[1;32m    297\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/ollama/_client.py:175\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[1;32m    173\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/ollama/_client.py:116\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 116\u001b[0m   r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     r\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpx/_client.py:837\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    822\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    824\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    825\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    826\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    835\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    836\u001b[0m )\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpx/_transports/default.py:235\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(request\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[0;32m--> 235\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    156\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/httpx/_transports/default.py:89\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     88\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: timed out"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Provide a comprehensive overview of how Bayesian probability evolved from\"\n",
    "    \" a theoretical concept to a critical wartime intelligence tool\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian probability began as an intellectual exploration within statistical theory before transitioning into practical applications across various fields, including warfare. Initially discussed in the contexts such as neuroscience and cognitive science (as shown by works from Sharon Bertsch McGrayne to Judea Pearl's \"Probabilistic Reasoning\"), Bayesian probability provided a framework for understanding how knowledge could be updated with new evidence, which is inherently useful in decision-making processes.\n",
      "\n",
      "The utilization of Bayes theorem and related methodologies saw an evolution from purely academic studies to being employed practically during significant historical events such as World War II (notably by John von Neumann) for code breaking efforts against the Enigma cipher, mentioned implicitly within documents referencing its impact on intelligence systems. This period marked a pivotal moment where Bayesian methods were recognized not just in theoretical discussions but also in their capacity to handle real-world problems involving uncertainty and incomplete information—key characteristics of wartime scenarios like cryptanalysis.\n",
      "\n",
      "Further advancements continued with the integration into cognitive science, as exemplified by Cognitive Tutors that employ Bayesian inference for evaluating student skill levels (as suggested in documents citing educational applications). This progression underscores how principles originally grounded in mathematics and philosophy were gradually adapted to address complex tasks such as interpreting data from sensory inputs or making decisions under uncertainty, which are vital components of intelligence work.\n",
      "\n",
      "Moreover, the development described by Emery N. Brown's research on utilizing Bayesian methods for brain signal interpretation further illustrates this trajectory wherein theoretical concepts were translated into real-time applications to decode and predict behaviors—critical in both medical prosthetics as well as intelligence gathering during wartime operations, enabling a more sophisticated response based on probabilistic reasoning.\n",
      "\n",
      "In summary, Bayesian probability transitioned from academic discussions about cognition (as per Cognitive Tutors and studies by McGrayne) to practical applications in fields such as cryptography and neuroscience before finding its niche within wartime intelligence operations during World War II—a testament of the theory's adaptability, impactful utility across various disciplines.\n",
      "\n",
      "This transition was not linear but rather a multidisciplinary journey that showcased Bayesian probability’s versatility in handling uncertainty and making informed decisions based on probabilistic reasoning – key traits for intelligence work during conflicts where information is often incomplete or deceptive, requiring robust methodologies to extract actionable insights.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian probability has seen an evolutionary journey that spans several centuries. Its story begins with Thomas Bayes, who discovered the foundational theorem in the mid-18th century amidst religious controversies over rational conclusions about God through empirical evidence from our world. Despite his groundbreaking work being initially recognized by a friend and editor named Richard Price posthumously due to its lack of immediate significance during Baye's time, this principle laid dormant for several decades following Laplace’s independent discovery in the 1770s.\n",
    "\n",
    "Laplace refined Bayes theorem into what is widely used today by applying it extensively across vast amounts of data to draw conclusions on natural laws and phenomena—such as understanding why more boys than girls are born, which he identified using this statistical methodology despite societal conventions suggesting otherwise at that time.\n",
    "\n",
    "However, the broader scientific community during Bayes' era considered his contributions subjective due largely to their lack of empirical application beyond religious debates and philosophies surrounding probability theory—an outlook not entirely changed even after Laplace’s death until practical applications came into focus elsewhere in history. \n",
    "\n",
    "The turnaround from being deemed a theoretical curiosity occurred during the Second World War, where Bayesian methods were employed by Alan Turing to crack Enigma's code for Allied forces—this effort dramatically altered wartime strategies and ultimately saved Britain while also propelling developments in computing technology.\n",
    "\n",
    "Post-war applications expanded further into various fields; Jerome Cornfield used it clinically, Arthur Bailey made contributions within the realm of statistics education, The Cold War era saw its use by figures like John von Neumann who applied Bayesian methods to nuclear strategy and decision making during an arms race fraught with uncertainty.\n",
    "\n",
    "In modern times, this probabilistic framework is integral not only in intelligence operations but also across business decisions (e.g., stock market predictions), medical diagnostics through the application of algorithms for interpreting mammograms or assessing heart attack risks using Bayesian statistics as described by researchers Goodman and Heckerman; it has even found its way into consumer experiences with search engines like Amazon optimizing recommendations based on user behavior.\n",
    "\n",
    "Bayesian probability's journey from a mathematical curiosity to an indispensable tool in decision-making processes underlines the transformative power of theoretical concepts when applied practically—a narrative that underscores both its historical significance and contemporary relevance across various realms, including science, business, technology, medicine, military intelligence operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: The request asks for specific details about Alan Turing's cryptographic methods at Bletchley Park. Choice (1) is most relevant as it pertains to searching for and finding precise facts with citations that would include such detailed information..\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Tell me about the specific details about Alan Turing's cryptographic methods at Bletchley Park\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Bletchley Park during World War II, Alan Turing developed a unique approach to tackle complex coding challenges. He was instrumental in designing an innovative machine known as the \"bombe,\" which significantly accelerated code-breaking efforts against German military communications encoded by Enigma machines. This high-speed electromechanical device tested various wheel arrangements for potential correct decryption, rapidly eliminating impossible combinations and focusing on likely ones to find matches with intercepted messages.\n",
      "\n",
      "Turing's work didn't stop there; he also improved the existing bombe design alongside colleagues Gordon Welchman and Harold \"Doc\" Keen. Their collective effort resulted in a more advanced prototype that enhanced Bletchley Park’s ability to decipher intricate naval codes, which were notoriously difficult due to their complex configurations involving multiple reflectors, rotors, plugboards, clip positions around the machine's wheels, and starting position possibilities.\n",
      "\n",
      "In parallel with mechanical advancements like bombe machines, Turing explored theoretical foundations that would later influence computational methods applied in code-breaking activities at Bletchley Park—including Bayesian probability scoring systems for pattern recognition within encrypted messages. This integration of probabilistic models into the cryptographic process marked an important intellectual contribution by enhancing machine efficiency and precision during critical wartime decryption tasks, eventually leading to groundbreaking achievements like shortening World War II in Europe significantly through timely intelligence gathered from intercepted communications.\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At Bletchley Park during World War II, Alan Turing developed a unique approach to tackle complex coding challenges. He was instrumental in designing an innovative machine known as the \"bombe,\" which significantly accelerated code-breaking efforts against German military communications encoded by Enigma machines. This high-speed electromechanical device tested various wheel arrangements for potential correct decryption, rapidly eliminating impossible combinations and focusing on likely ones to find matches with intercepted messages.\n",
    "\n",
    "Turing's work didn't stop there; he also improved the existing bombe design alongside colleagues Gordon Welchman and Harold \"Doc\" Keen. Their collective effort resulted in a more advanced prototype that enhanced Bletchley Park’s ability to decipher intricate naval codes, which were notoriously difficult due to their complex configurations involving multiple reflectors, rotors, plugboards, clip positions around the machine's wheels, and starting position possibilities.\n",
    "\n",
    "In parallel with mechanical advancements like bombe machines, Turing explored theoretical foundations that would later influence computational methods applied in code-breaking activities at Bletchley Park—including Bayesian probability scoring systems for pattern recognition within encrypted messages. This integration of probabilistic models into the cryptographic process marked an important intellectual contribution by enhancing machine efficiency and precision during critical wartime decryption tasks, eventually leading to groundbreaking achievements like shortening World War II in Europe significantly through timely intelligence gathered from intercepted communications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat History to RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "\n",
    "chat_engine = CondensePlusContextChatEngine.from_defaults(\n",
    "    index.as_retriever(),\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \"You are a chatbot, able to have normal interactions, as well as talk\"\n",
    "        \" about the Kendrick and Drake beef.\"\n",
    "        \"Here are the relevant documents for the context:\\n\"\n",
    "        \"{context_str}\"\n",
    "        \"\\nInstruction: Use the previous chat history, or the context above, to interact and help the user.\"\n",
    "    ),\n",
    "    verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COS243_Final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
