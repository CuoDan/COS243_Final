{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/COS243_Final/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_parse import LlamaParse\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup LLM with Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LLAMACLOUD_API_KEY = os.getenv(\"LLAMACLOUD_API_KEY\")\n",
    "\n",
    "llm = Ollama(model=\"phi3.5:3.8b-mini-instruct-q8_0\", api_key=\"OLLAMA_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Settings Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload and Import ebooks function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:55:11.403 python[3648:47500388] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ebook content imported successfully to data/The Theory That Would Not Die How Bayes Rule Cracked the Enigma Code, Hunted Down Russian Submarines, and Emerged Triumphant from Two Centuries of Controversy by Sharon Bertsch McGrayne.pdf.txt.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from ebooklib import epub\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def upload_and_import_ebook(file_path=None, save_directory=\"data\"):\n",
    "    # Create a Tkinter root window\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the root window\n",
    "\n",
    "    # Open a file dialog to select an ebook or PDF file if no file path is provided\n",
    "    if not file_path:\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Select an Ebook or PDF\",\n",
    "            filetypes=[(\"Ebook and PDF Files\", \"*.epub *.pdf\")]\n",
    "        )\n",
    "\n",
    "    if file_path:\n",
    "        content = \"\"\n",
    "        file_extension = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "        if file_extension == \".epub\":\n",
    "            # Load the ebook\n",
    "            book = epub.read_epub(file_path)\n",
    "            \n",
    "            # Extract the content\n",
    "            for item in book.get_items():\n",
    "                if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "                    content += item.get_body_content().decode('utf-8')\n",
    "        \n",
    "        elif file_extension == \".pdf\":\n",
    "            # Load the PDF\n",
    "            pdf_document = fitz.open(file_path)\n",
    "            \n",
    "            # Extract the content\n",
    "            for page_num in range(pdf_document.page_count):\n",
    "                page = pdf_document.load_page(page_num)\n",
    "                content += page.get_text()\n",
    "\n",
    "        # Ensure the save directory exists\n",
    "        os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "        # Save the content to a file in the save directory\n",
    "        save_path = os.path.join(save_directory, os.path.basename(file_path) + \".txt\")\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "        return save_path\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example usage with file dialog\n",
    "ebook_path = upload_and_import_ebook()\n",
    "if ebook_path:\n",
    "    print(f\"Ebook content imported successfully to {ebook_path}.\")\n",
    "else:\n",
    "    print(\"No ebook or PDF selected.\")\n",
    "\n",
    "# Example usage with file path\n",
    "# ebook_path = upload_and_import_ebook(\"path/to/your/ebook_or_pdf.epub\")\n",
    "# if ebook_path:\n",
    "#     print(f\"Ebook content imported successfully to {ebook_path}.\")\n",
    "# else:\n",
    "#     print(\"Invalid file path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ebook_path:\n",
    "    docs = SimpleDirectoryReader(input_files=[ebook_path]).load_data()\n",
    "else:\n",
    "    ebook_path = \"sample_books/The Theory That Would Not Die How Bayes Rule Cracked the Enigma Code, Hunted Down Russian Submarines, and Emerged Triumphant from Two Centuries of Controversy by Sharon Bertsch McGrayne.pdf.txt\"\n",
    "    docs = SimpleDirectoryReader(input_files=[ebook_path]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced RAG (Routing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(docs)\n",
    "query_engine = index.as_query_engine(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function to include citations in the response\n",
    "def include_citations(response, docs):\n",
    "    citations = []\n",
    "    for doc in docs:\n",
    "        if hasattr(doc, 'page_number'):\n",
    "            citations.append(f\"Page {doc.page_number}\")\n",
    "        elif hasattr(doc, 'section'):\n",
    "            citations.append(f\"Section {doc.section}\")\n",
    "    return f\"{response}\\n\\nCitations: {', '.join(citations)}\"\n",
    "\n",
    "# Custom query engine tool with citation inclusion\n",
    "class CitationQueryEngineTool(QueryEngineTool):\n",
    "    def query(self, query):\n",
    "        response = super().query(query)\n",
    "        return include_citations(response, self.index.documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "# vector_tool = QueryEngineTool(\n",
    "#     index.as_query_engine(),\n",
    "#     metadata=ToolMetadata(\n",
    "#         name=\"vector_search\",\n",
    "#         description=\"Useful for searching for specific facts.\",\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# Create tools with citation support\n",
    "vector_tool = CitationQueryEngineTool(\n",
    "    index.as_query_engine(),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"vector_search\",\n",
    "        description=\"Useful for searching for specific facts with citations.\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# summary_tool = QueryEngineTool(\n",
    "#     index.as_query_engine(response_mode=\"tree_summarize\"),\n",
    "#     metadata=ToolMetadata(\n",
    "#         name=\"summary\",\n",
    "#         description=\"Useful for summarizing an entire document.\",\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "summary_tool = CitationQueryEngineTool(\n",
    "    index.as_query_engine(response_mode=\"tree_summarize\"),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"summary\",\n",
    "        description=\"Useful for summarizing an entire document with citations.\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "\n",
    "query_engine = RouterQueryEngine.from_defaults(\n",
    "    [vector_tool, summary_tool], select_multi=False, verbose=True, llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: Summarizing the evolution of Bayesian probability requires an overview that encapsulates its theoretical origins and practical applications. Choice (2) is most relevant as it specifically mentions summarizing a document with citations, which implies covering historical contexts along with key developments in detail..\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Provide a comprehensive overview of how Bayesian probability evolved from\"\n",
    "    \" a theoretical concept to a critical wartime intelligence tool\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian probability began as an intellectual debate within academia during its inception by Reverend Thomas Bayes, who initially worked on the theorem independently. However, it was Pierre Simon Laplace who later discovered and further developed this rule to address vast amounts of data around him—a testament to his stature among mathematicians and scientists like himself.\n",
    "\n",
    "Despite its intellectual promise shown by both men's work in theory formulation during the 18th century, Bayesian probability was initially met with skepticism from academic circles who criticized it as subjective or impractical for precise scientific inquiry—a sentiment that persisted into subsequent centuries.\n",
    "\n",
    "Parallel to this theoretical development and controversy were practical applications of Bayes' rule in real-world emergencies, notably during the Second World War. Alan Turing utilized a formulation derived from Laplace’s work known as 'Bayesian inference', applying it successfully against Nazi Germany by breaking their Enigma code—a feat that significantly contributed to Britain winning the war and also marked an important milestone in computing history, leading towards modern electronic computers.\n",
    "\n",
    "Thus over time, Bayes' rule evolved from a theoretical concept mired in academic controversy into one of practical significance for decision-making amidst uncertainty during critical wartime intelligence tasks—a journey that underscores the dynamic interaction between theory and real-world application across different domains including computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: The request pertains to finding specific facts about Alan Turing's cryptographic methods with the possibility of needing citations. Choice (1) directly addresses this requirement as it is useful for searching and providing factual information along with references..\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Tell me about the specific details about Alan Turing's cryptographic methods at Bletchley Park\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alan Turing played a significant role in cracking various codes during his time at Bletchley Park. He was involved with studying probability theory and Enigma codes, which were initially managed by other analysts like Dillwyn Knox who had solved simpler Italian naval code systems. Upon joining the GC&CS research center upon declaring war on Germany in 1939, Turing quickly became a key player due to his unique set of interests that spanned from abstract mathematics and topology to applied probability and machine thinking concepts.\n",
    "\n",
    "One notable contribution by Turing was designing an advanced electromechanical device named the \"bombe.\" This innovative creation significantly improved upon previous models, drastically increasing Bletchley Park's ability to break German codes more efficiently than before through faster testing of possible wheel arrangements in Enigma machines.\n",
    "\n",
    "In addition to his work with bombes for deciphering messages encrypted by the Army and air force units during World War II, Turing also made significant strides towards tackling complex naval communications encoded using intricate German systems called Tunny-Lorenz codes—systems that were nearly impossible to crack manually due to their complexity.\n",
    "\n",
    "Turing's efforts did not stop at mechanical improvements; he applied his knowledge of Bayesian probability and introduced a scoring system based on bans, which became integral for the functioning of large digital computers called Colossi later developed by engineer Thomas H. Flowers. These machines were capable of breaking naval Enigma codes much faster than previous methods due to their programmable nature enhanced with Turing's Bayesian model and contributed significantly towards shortening war duration in Europe according to Gen. Dwight \"Ike\" Eisenhower, who made key decisions based on intel provided by the Colossi during critical moments like planning for Normandy invasion.\n",
    "\n",
    "Through his work at Bletchley Park alongside other intellectuals such as Donald Michie and mathematician Gordon Welchman—the latter also having been a student of Turing's earlier in Cambridge University, which had indirectly influenced their shared obsession with machine learning —he played an instrumental role not only during World War II but set the foundation for modern computing. His contributions to cryptography were groundbreaking and paved way towards advancements that would continue even after his time at Bletchley Park was over, including moving onto voice encryption duties later in 1945."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat History to RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "\n",
    "chat_engine = CondensePlusContextChatEngine.from_defaults(\n",
    "    index.as_retriever(),\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \"You are a chatbot, able to have normal interactions, as well as talk\"\n",
    "        \" about the Kendrick and Drake beef.\"\n",
    "        \"Here are the relevant documents for the context:\\n\"\n",
    "        \"{context_str}\"\n",
    "        \"\\nInstruction: Use the previous chat history, or the context above, to interact and help the user.\"\n",
    "    ),\n",
    "    verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COS243_Final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
